<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>深度学习的概念们</title>
    <url>/2025/06/05/000-deep-learning-concepts/</url>
    <content><![CDATA[<h2 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a>张量（Tensor）</h2><p>张量是深度学习中用于存储和计算数据的基本数据结构，可以把它理解为高维数组的泛化。</p>
<p>定义和结构</p>
<p>张量是一个带有形状（shape）和数值（data）的多维数组结构，0 维张量是标量，1 维张量是向量，2 维张量是矩阵，高阶张量就是三维及以上。</p>
<table>
<thead>
<tr>
<th><strong>名称</strong></th>
<th><strong>数学维度</strong></th>
<th><strong>举例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>标量</td>
<td>0D</td>
<td>5</td>
</tr>
<tr>
<td>向量</td>
<td>1D</td>
<td>[1, 2, 3]</td>
</tr>
<tr>
<td>矩阵</td>
<td>2D</td>
<td><code>[[1, 2], [3, 4]]</code></td>
</tr>
<tr>
<td>三维张量</td>
<td>3D</td>
<td><code>[[[...], [...]], [...]]</code></td>
</tr>
<tr>
<td>n 维张量</td>
<td>nD</td>
<td>形如 shape&#x3D;(2, 3, 28, 28)</td>
</tr>
</tbody></table>
<p>用法</p>
<table>
<thead>
<tr>
<th><strong>用法</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>表示数据</td>
<td>各种类型的输入数据（图像、文本、音频、视频等），支持多维结构</td>
</tr>
<tr>
<td>表示模型参数</td>
<td>网络中的权重、偏置、卷积核等参数</td>
</tr>
<tr>
<td>数值计算</td>
<td>所有计算（矩阵乘法、卷积、激活、归一化等）的基本单位</td>
</tr>
<tr>
<td>自动求导</td>
<td>追踪计算图，实现反向传播和梯度更新</td>
</tr>
<tr>
<td>GPU 加速</td>
<td>适配并行计算，可高效运行在 GPU 上</td>
</tr>
<tr>
<td>高维数据操作</td>
<td>提供强大的维度变换、索引、切片、广播等操作，方便处理复杂结构</td>
</tr>
</tbody></table>
<hr>
<h2 id="神经网络（Neural-Network）"><a href="#神经网络（Neural-Network）" class="headerlink" title="神经网络（Neural Network）"></a>神经网络（Neural Network）</h2><p>神经网络是一个由大量简单计算单元（称为“人工神经元“或“节点”）​​分层互联而成的计算模型。</p>
<p>基本组成单元（神经元&#x2F;节点）</p>
<ul>
<li><strong>输入：</strong> 接收来自前一层或其他源的数据（<strong>特征</strong>）和<strong>权重</strong></li>
<li><strong>计算：</strong> 对输入进行<strong>加权求和</strong>，并加上一个<strong>偏置（bias）</strong>，这个值代表该节点接收到的“总刺激”</li>
<li><strong>激活：</strong> 将加权求和的结果传入一个<strong>非线性激活函数</strong>（如 ReLU、Sigmoid、Tanh）。激活函数是神经网络具有强大表达能力、避免退化为线性模型的关键，它决定该节点是否“激活”以及激活的强度</li>
<li><strong>输出：</strong> 将激活函数处理后的值传递给下一层神经元</li>
</ul>
<p>层级结构</p>
<ul>
<li><strong>输入层：</strong> 接收原始数据（如图像像素值、文本编码、传感器数据等），每个节点对应一个输入特征</li>
<li><strong>隐藏层：</strong> 位于输入层和输出层之间，可以有一层或多层，用于对特征进行层层变换和抽象提取，隐藏层的节点数量及其连接方式决定模型的容量和复杂度，是信息处理的核心区域，特征在此逐步被抽象化</li>
<li><strong>输出层：</strong> 产生最终的预测结果（如分类类别、数值、概率分布等）。激活函数通常根据任务而定，例如：Sigmoid 用于二分类概率，Softmax 用于多分类概率，线性回归则可能不使用激活函数<br>层与层之间的节点连接可以是<strong>全连接</strong>（即每个节点与下一层所有节点相连），也可以采用其他连接方式（如卷积）。每条连接都对应一个<strong>权重（Weight）</strong>，它是神经网络的核心参数，表示某个输入特征对当前节点的重要性。每个节点还会有一个<strong>偏置（Bias）</strong>，这是一个独立的可学习参数，相当于一个“激活门槛”，即便输入总和为零也能激活节点。</li>
</ul>
<p>神经网络的运行原理<br>神经网络的运行机制围绕两个核心过程展开：<strong>前向传播（Forward Propagation）</strong> 和 <strong>反向传播（Back Propagation）</strong>。</p>
<ol>
<li><strong>前向传播：</strong> 原始输入数据从输入层开始，逐层传递。在每一层，每个节点对输入进行加权求和、加偏置并通过激活函数处理，最终到达输出层，得出模型的预测结果。其目的是计算给定输入下的输出，即预测值。</li>
<li><strong>学习（训练）机制：</strong><br> 首先定义一个<strong>损失函数</strong>（如均方误差 MSE、交叉熵 Cross-Entropy），用于衡量预测值与真实目标之间的差距（损失）。<br> 接着，通过<strong>反向传播</strong>算法计算损失函数对网络中每一个权重和偏置的<strong>梯度（Gradient）</strong>，这个梯度表示为了减小损失，该参数应如何调整。<br> 然后利用这些梯度，通过优化算法（如随机梯度下降 SGD、Adam、RMSprop 等）更新所有参数。简单地说，就是：<code>新权重 = 旧权重 - 学习率 × 损失对该权重的梯度。</code><br> 这个过程会在整个训练数据集上反复执行，通常以多个小批量进行，每次完整遍历一轮称为一个 Epoch。通过不断迭代，网络的预测将越来越接近目标。</li>
</ol>
<p>核心流程：​</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入数据 -&gt; 前向传播 -&gt; 计算损失 -&gt; 反向传播求梯度 -&gt; 优化算法更新参数 -&gt; （重复前向传播...）-&gt; 模型收敛（损失不再显著下降或达到预定条件）</span><br></pre></td></tr></table></figure>

<p>用法</p>
<table>
<thead>
<tr>
<th><strong>应用类型</strong></th>
<th><strong>说明</strong></th>
<th><strong>常用网络</strong></th>
</tr>
</thead>
<tbody><tr>
<td>图像分类</td>
<td>输入图片，输出类别</td>
<td>CNN（卷积神经网络）</td>
</tr>
<tr>
<td>语音识别</td>
<td>音频转文字</td>
<td>RNN、Transformer</td>
</tr>
<tr>
<td>文本情感分析</td>
<td>判断情感极性</td>
<td>RNN、BERT</td>
</tr>
<tr>
<td>机器翻译</td>
<td>英文转中文等</td>
<td>Transformer</td>
</tr>
<tr>
<td>图像生成</td>
<td>生成照片&#x2F;艺术图</td>
<td>GAN</td>
</tr>
<tr>
<td>时间序列预测</td>
<td>股票、气温预测</td>
<td>RNN、LSTM</td>
</tr>
<tr>
<td>特征提取</td>
<td>提取中间层特征</td>
<td>CNN、预训练模型</td>
</tr>
</tbody></table>
<hr>
<h2 id="权重（Weight）"><a href="#权重（Weight）" class="headerlink" title="权重（Weight）"></a>权重（Weight）</h2><p>权重是连接神经元之间的系数，表示一个输入对输出的重要程度。换句话说，<strong>权重是模型学习的参数</strong>，它决定了每个输入特征对预测结果的影响。</p>
<p>权重本质上是一个张量，存储在神经元之间（输入层→隐藏层、隐藏层→隐藏层、隐藏层→输出层）的连线上，量化上游神经元信号对下游神经元的<strong>影响程度</strong>。其初始值常随机设置（如正态分布），训练过程通过优化算法（如SGD&#x2F;Adam）基于损失函数反馈动态调整。</p>
<p>核心机制</p>
<ol>
<li>​<strong>线性变换</strong>​：在神经元激活前执行 加权求和 操作（即输入特征向量 $X$ 与权重向量 $W$ 的点积）：  输出 &#x3D; $w1x1 + w2x2 + … + wnxn$+ 偏置项</li>
<li>​<strong>特征重要性学习</strong>​：网络通过反向传播调整权重：<ul>
<li>正权重​ → 增强信号 → 正向关联特征</li>
<li>​负权重​ → 抑制信号 → 负向关联特征</li>
<li>​近似零权重​ → 屏蔽无效特征</li>
</ul>
</li>
<li>​<strong>知识载体</strong>​：训练后稳定的权重矩阵编码了模型从数据中学习到的核心内在逻辑（如边缘检测器、语义特征提取器）。</li>
</ol>
<p>用法场景</p>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>前向传播</td>
<td>决定输入特征对输出的贡献</td>
</tr>
<tr>
<td>模型训练</td>
<td>通过梯度下降不断更新</td>
</tr>
<tr>
<td>模型存储</td>
<td>训练完成后模型参数即为权重和偏置集合</td>
</tr>
<tr>
<td>迁移学习</td>
<td>已训练模型的权重可用于新任务，作为预训练参数</td>
</tr>
</tbody></table>
<hr>
<h2 id="偏置（Bias）"><a href="#偏置（Bias）" class="headerlink" title="偏置（Bias）"></a>偏置（Bias）</h2><p>偏置（Bias）​​ 是神经网络的另一类核心可学习参数，与权重协同工作，为模型提供<strong>灵活性</strong>和<strong>表达能力</strong>。<br>偏置本质是一个张量，​是独立于输入特征的存在，它对神经元的加权求和结果 （$z &#x3D; W·X$）进行<strong>平移操作</strong>​：  $输出 &#x3D; z + b &#x3D; W·X + b$，一般与权重同步优化，初始值常设为0或较小值（如0.01）。</p>
<p>核心机制</p>
<ol>
<li><strong>打破原点对称性</strong>​：若无偏置，所有神经元的计算起点强制为原点（$X&#x3D;0 → z&#x3D;0$），这就限制了模型的表达能力。偏置允许决策边界（或特征空间划分面）​<strong>自由平移</strong>，突破坐标原点的束缚，使得模型拟合能力提高。</li>
<li>​<strong>阈值调节器</strong>​：可以在激活函数前调整信号的基准位置（以Sigmoid为例）：<ul>
<li>$b &gt; 0$ ➔ 加权输出 $z$ 整体右移，这样更易激活神经元</li>
<li>$b &lt; 0$ ➔ $z$ 整体左移，这样使得神经元更难激活</li>
</ul>
</li>
<li><strong>补偿数据偏差</strong>​：学习数据中的系统偏移（如所有样本的标签存在固定偏移量）。比如预测房价时，即便所有输入特征为0（如零面积房屋），房价也不应为0，偏置可学习该基准值。</li>
</ol>
<p>用法场景</p>
<table>
<thead>
<tr>
<th><strong>应用场景</strong></th>
<th><strong>是否使用偏置</strong></th>
<th><strong>作用与说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>全连接层（Dense &#x2F; Linear）</strong></td>
<td>默认使用</td>
<td>提供输出的可调“起点”，允许模型学习数据的平移特性</td>
</tr>
<tr>
<td><strong>卷积层（Conv2d &#x2F; Conv1d &#x2F; Conv3d）</strong></td>
<td>默认使用</td>
<td>给每个卷积核增加偏置，有助于处理背景亮度或全局偏移等问题</td>
</tr>
<tr>
<td><strong>循环神经网络（RNN、LSTM、GRU）</strong></td>
<td>使用多个偏置项</td>
<td>控制不同门（输入门、遗忘门、输出门等）的激活偏移，提高时序建模能力</td>
</tr>
<tr>
<td><strong>Transformer 中的注意力机制（Attention）</strong></td>
<td>一般在线性变换时使用</td>
<td>在生成 Query、Key、Value 向量时常通过含偏置的线性层增强表达力</td>
</tr>
<tr>
<td><strong>批归一化（BatchNorm）之后</strong></td>
<td>常关闭偏置</td>
<td>因为 BatchNorm 自带偏移与缩放参数（γ 与 β），原始层的 bias 可省略</td>
</tr>
<tr>
<td><strong>激活函数之前（如 ReLU、Sigmoid）</strong></td>
<td>使用偏置</td>
<td>通过加偏置调整输入激活值范围，使得激活函数在有效区间工作</td>
</tr>
<tr>
<td><strong>AutoEncoder（自编码器）</strong></td>
<td>编码器与解码器中的线性层都使用</td>
<td>提高压缩与重构能力</td>
</tr>
<tr>
<td><strong>生成对抗网络（GAN）</strong></td>
<td>生成器和判别器都常含偏置</td>
<td>增强网络表达能力</td>
</tr>
<tr>
<td><strong>图神经网络（GNN）</strong></td>
<td>在图卷积层中常包含</td>
<td>保证节点在无邻居输入时仍有输出可能</td>
</tr>
<tr>
<td><strong>深度残差网络（ResNet）</strong></td>
<td>通常保留偏置</td>
<td>残差块内的卷积层默认使用偏置，提升表示能力</td>
</tr>
<tr>
<td><strong>迁移学习（Fine-tune）</strong></td>
<td>或冻结偏置</td>
<td>在微调阶段可能保留或冻结偏置，看任务需求而定</td>
</tr>
</tbody></table>
<hr>
<h2 id="前向传播（Forward-Pass）"><a href="#前向传播（Forward-Pass）" class="headerlink" title="前向传播（Forward Pass）"></a>前向传播（Forward Pass）</h2><p>前向传播是神经网络的<strong>数据加工流水线</strong>​，将原始输入数据从输入层逐层向前流动，通过加权计算与非线性变换，最终在输出层生成预测结果。这也是神经网络进行<strong>特征抽象</strong>的核心过程。</p>
<p>运行原理<br>神经元视角：<code>输出 = 激活函数(权重x输入 + 偏置)</code>，就像流水线上的加工站，接收原料（输入），用特定工具（权重）加工，质检员（激活函数）决定是否放行。<br>网络层视角：<code>输入层 → 隐藏层₁ → ... → 隐藏层ₙ → 输出层</code>  ，类似工厂装配线：</p>
<ol>
<li>初级车间：提取边缘&#x2F;颜色特征（浅层网络）</li>
<li>中级车间：组装成纹理&#x2F;部件（中层网络）</li>
<li>高级车间：合成完整物体（深层网络）<br>在代码中的典型用法（PyTorch为例）</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">128</span>)   <span class="comment"># 第一层：全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">10</span>)    <span class="comment"># 第二层：输出层（10类）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)         <span class="comment"># 线性变换</span></span><br><span class="line">        x = F.relu(x)           <span class="comment"># 非线性激活</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)         <span class="comment"># 输出层线性变换</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>作用</p>
<ol>
<li><strong>预测输出</strong>：输入样本经过网络计算预测结果</li>
<li><strong>计算损失</strong>：前向传播的结果与真实标签比较，得到损失值</li>
<li><strong>反向传播的基础</strong>：只有先完成前向传播，才能基于损失计算梯度，执行反向传播和参数更新</li>
</ol>
<hr>
<h2 id="反向传播（Backward-Pass）"><a href="#反向传播（Backward-Pass）" class="headerlink" title="反向传播（Backward Pass）"></a>反向传播（Backward Pass）</h2><p>反向传播（Back Propagation）是训练神经网络的核心算法，它通过<strong>从输出层向输入层反向传递误差信号</strong>来计算网络中每个参数的梯度，从而用梯度下降法优化参数。</p>
<p>工作流程：</p>
<ol>
<li><strong>前向传播（Forward Pass）</strong>：输入数据经过网络一层层传播，得到预测结果。</li>
<li><strong>计算损失</strong>：使用损失函数评估预测值与真实值之间的误差。</li>
<li><strong>反向传播（Backward Pass）</strong>：<ul>
<li>从输出层开始，计算损失函数对输出的梯度</li>
<li>利用链式法则，逐层向前计算每个参数的梯度（即损失函数对各层参数的导数）</li>
</ul>
</li>
<li><strong>参数更新</strong>：使用梯度下降等优化算法，根据计算出的梯度对每个参数进行更新。</li>
</ol>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>模型训练过程中的参数更新</strong></td>
<td>与优化器配合，自动计算并更新网络中每一层的权重和偏置</td>
</tr>
<tr>
<td><strong>计算梯度信息</strong></td>
<td>使模型能够感知“如何调整”才能减小误差</td>
</tr>
<tr>
<td><strong>实现自动微分（autograd）机制</strong></td>
<td>如 PyTorch &#x2F; TensorFlow 内部都基于反向传播自动求导</td>
</tr>
<tr>
<td><strong>调试模型收敛问题</strong></td>
<td>通过监控梯度是否为0、是否爆炸&#x2F;消失，判断训练是否正常</td>
</tr>
</tbody></table>
<hr>
<h2 id="损失函数（Loss-Function）"><a href="#损失函数（Loss-Function）" class="headerlink" title="损失函数（Loss Function）"></a>损失函数（Loss Function）</h2><p>损失函数是训练过程中的“评价器”，它衡量模型预测结果与真实值之间的差距，核心组成如下：</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>预测值（Output &#x2F; Logits）</strong></td>
<td>模型输出的结果（可能是分数、概率或回归值）</td>
</tr>
<tr>
<td><strong>真实标签（Ground Truth）</strong></td>
<td>数据集中真实的目标值，用于监督学习</td>
</tr>
<tr>
<td><strong>误差度量方式（Metric）</strong></td>
<td>衡量“预测值”和“真实值”之间距离的方法，如L1、L2、交叉熵等</td>
</tr>
<tr>
<td><strong>可微性设计</strong></td>
<td>损失函数需具备可导性，以便参与反向传播计算梯度</td>
</tr>
</tbody></table>
<p>工作原理<br>损失函数的核心机制是<strong>将模型的“预测结果”转化为“可以优化的标量反馈”</strong>，从而驱动神经网络更新参数。</p>
<ol>
<li><strong>前向传播阶段</strong>：<ul>
<li>模型对输入数据做出预测，输出结果如 $\hat{y}$</li>
<li>损失函数将 $\hat{y}$ 与真实值 $y$ 比较，计算出一个损失值 $L(\hat{y}, y)$</li>
</ul>
</li>
<li><strong>反向传播阶段</strong>：<ul>
<li>利用损失值对网络参数反向求导，生成梯度</li>
<li>梯度引导优化器调整模型参数以最小化损失</li>
</ul>
</li>
</ol>
<blockquote>
<p>损失值越大 → 模型越差，损失值越小 → 模型越接近理想预测</p>
</blockquote>
<p>用法：</p>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>指导模型学习方向</strong></td>
<td>通过损失函数提供反馈，让模型知道哪些预测是错误的、需要纠正的</td>
</tr>
<tr>
<td><strong>计算梯度的起点</strong></td>
<td>所有参数的梯度都基于损失函数的导数进行计算</td>
</tr>
<tr>
<td><strong>衡量模型性能变化趋势</strong></td>
<td>训练过程中，监控 loss 能帮助判断是否收敛、是否过拟合等</td>
</tr>
<tr>
<td><strong>任务定制</strong></td>
<td>分类、回归、分割等任务使用不同类型的损失函数（如交叉熵、MSE、Dice Loss）</td>
</tr>
<tr>
<td><strong>多目标训练</strong></td>
<td>可组合多个损失函数进行加权，用于多任务学习或辅助任务引导训练</td>
</tr>
</tbody></table>
<p>常见的损失函数：</p>
<table>
<thead>
<tr>
<th><strong>任务类型</strong></th>
<th><strong>常见损失函数</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>分类</strong></td>
<td>交叉熵损失（Cross Entropy）</td>
</tr>
<tr>
<td><strong>回归</strong></td>
<td>均方误差（MSE）、平均绝对误差（MAE）</td>
</tr>
<tr>
<td><strong>分割 &#x2F; 检测</strong></td>
<td>Dice Loss、IoU Loss、Focal Loss</td>
</tr>
<tr>
<td><strong>对比学习</strong></td>
<td>Triplet Loss、Contrastive Loss</td>
</tr>
</tbody></table>
<hr>
<h2 id="梯度（Gradient）"><a href="#梯度（Gradient）" class="headerlink" title="梯度（Gradient）"></a>梯度（Gradient）</h2><p>梯度是模型学习方向的“指南针”，是告诉每个参数“往哪走才能更好”的关键信息。梯度的本质是一个向量，它反映了<strong>损失函数对模型参数的偏导数</strong>，从组成上看，梯度涉及以下要素：</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>损失函数（Loss）</strong></td>
<td>衡量预测值与真实值之间的误差，是梯度的“源头”</td>
</tr>
<tr>
<td><strong>模型参数（权重、偏置）</strong></td>
<td>需要被优化的目标，是梯度的“作用对象”</td>
</tr>
<tr>
<td><strong>偏导数（Partial Derivative）</strong></td>
<td>描述损失在每个参数维度上的变化率</td>
</tr>
<tr>
<td><strong>梯度向量</strong></td>
<td>多维参数对应多个偏导，整体形成一个方向性的向量</td>
</tr>
</tbody></table>
<p>工作原理<br>梯度是<strong>指明函数在当前点上最陡峭上升（或下降）的方向和速率</strong>。<br>在深度学习中，我们关心的是如何<strong>减小损失函数的值</strong>，因此会反向使用梯度信息：</p>
<ol>
<li><strong>梯度的方向</strong>：告诉我们如果参数朝哪个方向微调，损失会变大。</li>
<li><strong>负梯度方向</strong>：我们采用负梯度方向作为更新方向，以减少损失。</li>
<li><strong>梯度大小</strong>：决定了更新步长的大小（配合学习率使用）。</li>
</ol>
<blockquote>
<p>举个例子：若某个参数的梯度是 0.5，就表示该参数若增加一点，损失会相应增加（损失函数对该参数是“上升”趋势），所以我们要朝“反方向”调整它。</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>参数更新</strong></td>
<td>梯度用于指导优化器（如 SGD、Adam）更新每一层的参数</td>
</tr>
<tr>
<td><strong>误差传播（反向传播）</strong></td>
<td>反向传播过程的核心计算就是梯度链式相乘</td>
</tr>
<tr>
<td><strong>调试训练过程</strong></td>
<td>梯度消失&#x2F;爆炸等问题是训练失败的重要信号</td>
</tr>
<tr>
<td><strong>自动求导</strong></td>
<td>框架（如 PyTorch）通过自动微分机制计算每个参数的梯度</td>
</tr>
<tr>
<td><strong>神经网络学习机制的本质体现</strong></td>
<td>训练的全部过程，其实就是围绕着“计算并利用梯度”展开的</td>
</tr>
</tbody></table>
<hr>
<h2 id="梯度下降（Gradient-Descent）"><a href="#梯度下降（Gradient-Descent）" class="headerlink" title="梯度下降（Gradient Descent）"></a>梯度下降（Gradient Descent）</h2><p>梯度下降是一种“聪明的试错”方法，通过沿着误差减少的方向不断微调参数，使模型逐步逼近最优性能。它由以下几个核心要素构成：</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>模型参数</strong>（如权重 W、偏置 b）</td>
<td>需要被优化的变量</td>
</tr>
<tr>
<td><strong>损失函数</strong> $\mathcal{L}$</td>
<td>衡量预测结果与真实值之间的误差</td>
</tr>
<tr>
<td><strong>梯度</strong> $\nabla \mathcal{L}$</td>
<td>损失函数对每个参数的导数，表示误差随参数变化的趋势</td>
</tr>
<tr>
<td><strong>学习率</strong> $\eta$</td>
<td>控制每次参数更新的步长，决定收敛速度和稳定性</td>
</tr>
</tbody></table>
<p>工作原理<br>在当前点上，计算损失函数对参数的梯度，朝梯度反方向移动参数，减小损失。<br>具体步骤如下：</p>
<ol>
<li><strong>前向传播</strong>：模型对输入数据生成预测结果；</li>
<li><strong>计算损失</strong>：通过损失函数得到预测误差；</li>
<li><strong>反向传播</strong>：计算损失函数对每个参数的梯度；</li>
<li><strong>参数更新</strong>：按以下公式更新每个参数：<br> $\theta \leftarrow \theta - \eta \cdot \nabla_\theta \mathcal{L}$    $\theta$：待更新的参数  $\eta$：学习率  $\nabla_\theta \mathcal{L}$：该参数的梯度<br>这个过程持续进行，直到损失函数收敛或达到设定轮数。</li>
</ol>
<p>梯度下降广泛应用于深度学习模型训练，是模型“学习”的基础：</p>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>神经网络训练的核心优化方法</strong></td>
<td>所有模型参数的更新都依赖梯度下降</td>
</tr>
<tr>
<td><strong>与反向传播结合</strong></td>
<td>梯度由反向传播计算，梯度下降据此更新参数</td>
</tr>
<tr>
<td><strong>支持多种变体</strong></td>
<td>包括批量（Batch）、小批量（Mini-batch）、随机（SGD）三种方式</td>
</tr>
<tr>
<td><strong>可与高级优化器结合</strong></td>
<td>如 Adam、RMSProp、Momentum 等都基于梯度下降改进</td>
</tr>
<tr>
<td><strong>调节学习率以控制训练过程</strong></td>
<td>过小 → 学得慢；过大 → 震荡或发散；可配合调度策略如余弦退火、Warmup等</td>
</tr>
</tbody></table>
<p>梯度下降三种常见形式</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>特点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>批量梯度下降</strong></td>
<td>每轮使用全部数据，计算精确，但慢</td>
<td>小数据集</td>
</tr>
<tr>
<td><strong>随机梯度下降（SGD）</strong></td>
<td>每个样本单独更新，波动大但快</td>
<td>大数据训练、在线学习</td>
</tr>
<tr>
<td><strong>小批量梯度下降</strong></td>
<td>每次使用部分样本，速度与稳定性兼顾</td>
<td>实际最常用</td>
</tr>
</tbody></table>
<hr>
<h2 id="学习率（Learning-Rate）"><a href="#学习率（Learning-Rate）" class="headerlink" title="学习率（Learning Rate）"></a>学习率（Learning Rate）</h2><p>学习率（Learning Rate）是梯度下降等优化算法中的一个关键超参数，控制着每次模型参数更新的“步长”</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>学习率值（η 或 lr）</strong></td>
<td>一个标量，表示每一步更新沿梯度方向移动的幅度</td>
</tr>
<tr>
<td><strong>优化器</strong></td>
<td>学习率是优化器（如SGD、Adam等）的输入</td>
</tr>
<tr>
<td><strong>梯度信息</strong></td>
<td>与学习率配合决定参数的实际更新量</td>
</tr>
<tr>
<td><strong>动态调整策略（可选）</strong></td>
<td>可以采用学习率调度器根据训练进度动态变化</td>
</tr>
</tbody></table>
<p>工作原理：</p>
<blockquote>
<p><strong>决定梯度更新的“步长”大小，直接影响模型收敛速度和稳定性。</strong></p>
</blockquote>
<p>在参数更新中，学习率控制了“走多远”：<br>$\theta \leftarrow \theta - \eta \cdot \nabla_\theta \mathcal{L}$</p>
<table>
<thead>
<tr>
<th><strong>情况</strong></th>
<th><strong>影响</strong></th>
</tr>
</thead>
<tbody><tr>
<td>学习率太大</td>
<td>更新过猛，可能震荡或发散，无法收敛</td>
</tr>
<tr>
<td>学习率太小</td>
<td>收敛速度慢，训练效率低，容易陷入局部最优或提前停止</td>
</tr>
</tbody></table>
<p>用法<br>学习率是训练过程中必须设置的重要超参数，使用方式包括：</p>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>固定学习率训练</strong></td>
<td>设置一个固定值，适用于简单问题或短时间训练</td>
</tr>
<tr>
<td><strong>逐步衰减（Step Decay）</strong></td>
<td>每隔一定epoch将学习率缩小，比如除以10</td>
</tr>
<tr>
<td><strong>余弦退火（Cosine Annealing）</strong></td>
<td>学习率按余弦函数周期变化，有利于跳出局部最优</td>
</tr>
<tr>
<td><strong>Warm-up</strong></td>
<td>在训练开始阶段先用较小学习率“热身”，避免初始梯度爆炸</td>
</tr>
<tr>
<td><strong>自适应学习率（如Adam）</strong></td>
<td>优化器内部根据梯度历史动态调整每个参数的学习率</td>
</tr>
<tr>
<td><strong>手动调参</strong></td>
<td>可视化 loss 曲线和验证指标，手动调整学习率以优化训练表现</td>
</tr>
</tbody></table>
<p>学习率常见设置技巧</p>
<table>
<thead>
<tr>
<th><strong>训练目标</strong></th>
<th><strong>建议策略</strong></th>
</tr>
</thead>
<tbody><tr>
<td>模型初期不稳定</td>
<td>使用 warm-up 或较小初始学习率</td>
</tr>
<tr>
<td>模型收敛缓慢</td>
<td>适当调大学习率或改用带动量的优化器</td>
</tr>
<tr>
<td>模型震荡或 loss 上下跳动</td>
<td>适当降低学习率</td>
</tr>
<tr>
<td>训练中后期精调</td>
<td>使用调度器降低学习率以精细收敛</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>学习率就像“油门”，踩得太猛容易翻车，踩得太轻走不动，只有控制得当，模型训练才能又快又稳。</strong></p>
</blockquote>
<hr>
<h2 id="优化器（Optimizer）"><a href="#优化器（Optimizer）" class="headerlink" title="优化器（Optimizer）"></a>优化器（Optimizer）</h2><p>优化器是神经网络训练中用于<strong>更新模型参数</strong>的模块，它基于<strong>梯度信息</strong>，决定每次如何调整参数以减小损失函数。</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>模型参数</strong>（weights &#x2F; biases）</td>
<td>需要被优化的变量</td>
</tr>
<tr>
<td><strong>损失函数的梯度</strong> $\nabla \mathcal{L}$</td>
<td>通过反向传播计算得到</td>
</tr>
<tr>
<td><strong>学习率（Learning Rate）</strong></td>
<td>决定每次更新的步长</td>
</tr>
<tr>
<td><strong>动量 &#x2F; 累积项</strong>（某些优化器有）</td>
<td>如 SGD with Momentum、Adam 等，引入历史信息增强稳定性</td>
</tr>
<tr>
<td><strong>优化规则</strong></td>
<td>每种优化器都有自己独特的参数更新公式和机制</td>
</tr>
</tbody></table>
<p>工作原理</p>
<blockquote>
<p><strong>利用损失函数的梯度信息，按一定规则更新参数，以使损失函数逐步下降，模型性能不断提升。</strong></p>
</blockquote>
<p>以最基础的梯度下降法为例：<br>$\theta \leftarrow \theta - \eta \cdot \nabla_\theta \mathcal{L}$</p>
<p>不同的优化器在此基础上会加入各种机制来提高训练效率与稳定性：</p>
<table>
<thead>
<tr>
<th><strong>优化器</strong></th>
<th><strong>关键机制</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>SGD（随机梯度下降）</strong></td>
<td>使用当前样本或小批量样本的梯度</td>
</tr>
<tr>
<td><strong>SGD + Momentum</strong></td>
<td>引入“惯性”，缓解震荡，增强方向感</td>
</tr>
<tr>
<td><strong>RMSProp</strong></td>
<td>自动调整每个参数的学习率，抑制震荡</td>
</tr>
<tr>
<td><strong>Adam</strong></td>
<td>综合 Momentum 和 RMSProp，自适应调整每个参数的更新步长</td>
</tr>
</tbody></table>
<p>用法：</p>
<table>
<thead>
<tr>
<th><strong>用法场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>训练神经网络</strong></td>
<td>反向传播后由优化器根据梯度更新模型参数</td>
</tr>
<tr>
<td><strong>选择合适优化器</strong></td>
<td>小模型可用 SGD，大模型推荐 Adam；分类任务多用 Adam 或 AdamW</td>
</tr>
<tr>
<td><strong>调整学习率</strong></td>
<td>大多数优化器需手动设置初始学习率，必要时配合调度器</td>
</tr>
<tr>
<td><strong>支持参数分组</strong></td>
<td>可为不同层设置不同学习率、权重衰减等超参数（如 param_groups）</td>
</tr>
<tr>
<td><strong>结合正则化</strong></td>
<td>优化器常配合 L2 正则（weight decay）防止过拟合</td>
</tr>
</tbody></table>
<p>常用优化器对比表</p>
<table>
<thead>
<tr>
<th><strong>优化器</strong></th>
<th><strong>是否使用动量</strong></th>
<th><strong>是否自适应学习率</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody><tr>
<td>SGD</td>
<td>否</td>
<td>否</td>
<td>简单、高效，适合小规模数据</td>
</tr>
<tr>
<td>SGD + Momentum</td>
<td>是</td>
<td>否</td>
<td>更平稳、更快收敛</td>
</tr>
<tr>
<td>RMSProp</td>
<td>否</td>
<td>是</td>
<td>更适合非平稳目标或循环网络</td>
</tr>
<tr>
<td>Adam</td>
<td>是</td>
<td>是</td>
<td>默认首选，适用于大多数任务</td>
</tr>
<tr>
<td>AdamW</td>
<td>是</td>
<td>是</td>
<td>Adam 的改进版，更适合 Transformer 类模型（如 BERT、ViT）</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>优化器是训练的“驾驶员”，它读取梯度信息，控制模型参数沿着“更优方向”前进，让模型不断逼近理想状态。</strong></p>
</blockquote>
<hr>
<h2 id="激活函数（Activation-Function）"><a href="#激活函数（Activation-Function）" class="headerlink" title="激活函数（Activation Function）"></a>激活函数（Activation Function）</h2><p>激活函数是<strong>神经网络中每个神经元内部的非线性变换函数</strong>，它决定了每一层输出的形式，控制信息的传播和模型的表达能力。</p>
<table>
<thead>
<tr>
<th><strong>组成部分</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>输入信号</strong>（一般为线性加权和）</td>
<td>来自前一层的输出，即 $z &#x3D; w^\top x + b$</td>
</tr>
<tr>
<td><strong>激活函数本体</strong></td>
<td>将输入信号变换为非线性输出，如 ReLU、Sigmoid、Tanh 等</td>
</tr>
<tr>
<td><strong>输出结果</strong></td>
<td>作为当前神经元的输出传递给下一层</td>
</tr>
</tbody></table>
<p>工作原理</p>
<blockquote>
<p><strong>对神经元的线性输出进行非线性映射，从而打破神经网络的线性性，使模型能学习复杂、高阶的表示。</strong></p>
</blockquote>
<p>没有激活函数的神经网络，哪怕有多层，整体仍是线性函数，无法解决实际问题中的非线性关系。</p>
<p>常见激活函数及机制特点：</p>
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>表达式</strong></th>
<th><strong>机制说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>ReLU</strong></td>
<td>$f(x) &#x3D; \max(0, x)$</td>
<td>保留正值，抑制负值，收敛快，简洁高效</td>
</tr>
<tr>
<td><strong>Sigmoid</strong></td>
<td>$f(x) &#x3D; \frac{1}{1 + e^{-x}}$</td>
<td>输出范围(0, 1)，适用于概率建模，但梯度容易消失</td>
</tr>
<tr>
<td><strong>Tanh</strong></td>
<td>$f(x) &#x3D; \tanh(x)$</td>
<td>输出范围(-1, 1)，比Sigmoid居中，但仍可能梯度消失</td>
</tr>
<tr>
<td><strong>Leaky ReLU</strong></td>
<td>$f(x) &#x3D; \max(0.01x, x)$</td>
<td>改进ReLU，允许负值通过，避免神经元“死亡”</td>
</tr>
<tr>
<td><strong>GELU &#x2F; Swish</strong></td>
<td>更复杂</td>
<td>新型激活函数，用于BERT、Vision Transformer等</td>
</tr>
</tbody></table>
<p>用法<br>激活函数广泛用于神经网络的各层中，具体用法包括：</p>
<table>
<thead>
<tr>
<th><strong>应用场景</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>隐藏层激活函数</strong></td>
<td>通常使用 ReLU 或其变体，提升训练效率和非线性表达能力</td>
</tr>
<tr>
<td><strong>输出层激活函数</strong></td>
<td>根据任务类型选择：回归 → 无激活 &#x2F; ReLU，二分类 → Sigmoid，多分类 → Softmax</td>
</tr>
<tr>
<td><strong>防止梯度问题</strong></td>
<td>Tanh&#x2F;Sigmoid 早期常用，但容易梯度消失；ReLU 更常用于深层网络</td>
</tr>
<tr>
<td><strong>搭配正则化使用</strong></td>
<td>常与 BatchNorm、Dropout 一起增强训练稳定性和泛化能力</td>
</tr>
<tr>
<td><strong>注意选择位置</strong></td>
<td>激活函数通常在每层线性操作（Linear &#x2F; Conv）之后使用：</td>
</tr>
</tbody></table>
<p>激活函数的对比简表：</p>
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>非线性</strong></th>
<th><strong>导数计算</strong></th>
<th><strong>是否零均值</strong></th>
<th><strong>是否抗梯度消失</strong></th>
<th><strong>常用位置</strong></th>
</tr>
</thead>
<tbody><tr>
<td>ReLU</td>
<td>✅</td>
<td>简单</td>
<td>否</td>
<td>✅</td>
<td>隐藏层</td>
</tr>
<tr>
<td>Tanh</td>
<td>✅</td>
<td>复杂</td>
<td>✅</td>
<td>一定程度✅</td>
<td>RNN 中常用</td>
</tr>
<tr>
<td>Sigmoid</td>
<td>✅</td>
<td>复杂</td>
<td>否</td>
<td>❌</td>
<td>输出层（二分类）</td>
</tr>
<tr>
<td>Softmax</td>
<td>✅</td>
<td>稍复杂</td>
<td>-</td>
<td>-</td>
<td>输出层（多分类）</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>激活函数是神经网络的“灵魂”，它赋予网络理解非线性世界的能力，使模型不仅能加减乘除，更能思考弯弯绕绕。</strong></p>
</blockquote>
<hr>
<h2 id="归一化（Normalization）"><a href="#归一化（Normalization）" class="headerlink" title="归一化（Normalization）"></a>归一化（Normalization）</h2><p>用于<strong>标准化神经网络层输入</strong>，它通过<strong>调整数据的均值和方差</strong>，来解决深度学习模型训练中常见的问题，比如内部协变量偏移、梯度消失&#x2F;爆炸，从而<strong>加速模型收敛、提高训练稳定性、改善模型泛化能力</strong>。</p>
<p>主要归一化方法</p>
<ol>
<li>​<strong>批归一化</strong>：​在一个训练批次内，对同一个神经元​（特征通道）在所有样本上的激活值进行归一化。</li>
<li>​<strong>层归一化</strong>： 对单个样本，在一个层（所有神经元）的激活值上进行归一化（计算均值和方差）。</li>
<li>​<strong>实例归一化</strong>：对单个样本，在其空间维度上（对卷积层而言，是高度H和宽度W），对每个特征通道单独进行归一化。</li>
<li>​<strong>组归一化</strong>​：主要是对<strong>单个样本</strong>，将其特征通道划分为 ​<strong>G 个组</strong>，然后对<strong>每个组内的所有通道上的激活值</strong>​（跨越通道维度）进行归一化。</li>
</ol>
<p>原理</p>
<ol>
<li><strong>缓解内部协变量偏移（Internal Covariate Shift）：</strong> 在训练时，每层输入的分布不断变化，会导致训练不稳定，而归一化强制每层输入保持稳定分布（均值为 0，方差为 1），从而提升模型收敛效率。</li>
<li><strong>改善梯度传播：</strong> 归一化使激活值落入激活函数的线性敏感区间（如 Sigmoid&#x2F;Tanh 的中段），从而避免梯度消失或爆炸。</li>
<li><strong>轻度正则化作用（主要对 BN 而言）：</strong> Batch 内统计带来的噪声有助于防止过拟合，提升泛化能力。</li>
<li><strong>允许更大学习率：</strong> 训练过程更稳定，能使用更大的学习率，进一步提升训练效率。</li>
</ol>
<p>用法</p>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>推荐归一化方法</strong></th>
<th><strong>原因说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>卷积网络 + 大Batch（≥32）</strong></td>
<td>BatchNorm（BN）</td>
<td>训练快、性能好，是标准选择</td>
</tr>
<tr>
<td><strong>卷积网络 + 小Batch</strong></td>
<td>GroupNorm（GN）</td>
<td>不依赖 batch，适合目标检测、分割等任务</td>
</tr>
<tr>
<td><strong>RNN &#x2F; Transformer</strong></td>
<td>LayerNorm（LN）</td>
<td>不受序列长度与 batch 大小影响，是 NLP&#x2F;时序模型标准配置</td>
</tr>
<tr>
<td><strong>图像生成 &#x2F; 风格迁移任务</strong></td>
<td>InstanceNorm（IN）</td>
<td>去除图像对比度等风格信息，更关注结构与纹理生成</td>
</tr>
</tbody></table>
<hr>
<h2 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h2><p>是通过在训练过程中<strong>引入额外的约束或惩罚</strong>，限制模型的复杂性，使其更倾向于学习数据中<strong>泛化的模式（General Pattern）​</strong>，而不是对训练数据中的<strong>噪声或特定细节（Specific Detail&#x2F;Noise）​</strong>进行精确记忆。</p>
<p>核心目标：解决过拟合</p>
<ul>
<li>​<strong>过拟合：​</strong>​ 模型在训练集上表现极好，但在未见过的测试集或真实数据上表现很差。这表明模型记住了训练数据的“个性”，而非掌握了数据的“共性”。</li>
<li>​<strong>欠拟合：​</strong>​ 模型在训练集上都表现不佳，说明模型能力不够或训练不足。正则化主要解决的是过拟合问题。</li>
</ul>
<p>常见正则化技术及其机制</p>
<ol>
<li>​<strong>L1 正则化（Lasso Regression）​</strong>： 鼓励模型学习<strong>稀疏（Sparse）权重</strong>。它倾向于将不重要的特征权重<strong>精确地压缩到0</strong>，实现<strong>特征选择（Feature Selection）​</strong>​ 。被压缩到零的特征对预测基本没有贡献。​</li>
<li>​<strong>L2 正则化（Ridge Regression &#x2F; Weight Decay - 权重衰减）​</strong>：鼓励模型学习<strong>较小、分布分散（Diffuse）的权重</strong>。它惩罚过大的权重值，防止模型过度依赖少数几个特征。使权重趋向于零但不精确为零（除非λ极大）。能有效<strong>缓解多重共线性问题</strong>，提高模型的<strong>稳定性和泛化能力</strong>。是深度学习中<strong>最常用</strong>的正则化方式之一（常直接称为 Weight Decay）。​</li>
<li>​<strong>Dropout</strong>：​在<strong>训练阶段</strong>的<strong>每次前向传播（Forward Pass）​</strong>​ 过程中，以预先设定的概率 <code>p</code>（Dropout Rate）​<strong>随机暂时丢弃（置零）​</strong>​ 网络中的神经元（通常是隐藏层节点）。一方面<strong>打破协同适应性（Co-adaptation）​</strong>，​ 迫使网络不能过度依赖少数几个特定神经元或特征。每个神经元都必须学会在随机的、缺失部分信息的子集（“残破的网络”）中有效工作。另一方面<strong>隐式的模型集成（Ensembling）​</strong>，​不同的 Dropout 模式相当于在训练多个“瘦身”后的子网络。在测试（推理）阶段，所有神经元被保留，但它们的输出值要乘以 <code>(1 - p)</code>（近似平均集成效果）。这大大增强了泛化能力。</li>
<li>​<strong>数据增强（Data Augmentation）​</strong>：在<strong>不改变数据标签（Label）​</strong>​ 的前提下，对原始训练数据进行<strong>合理、多样化的变换或生成新的合成数据</strong>。通过生成大量不同的训练样本变体，​<strong>模拟数据的自然变异</strong>，让模型学习到<strong>更鲁棒、更具不变性的特征</strong>，减少对特定数据点和噪声的敏感性。本质上是在<strong>增加训练集的有效大小和多样性</strong>。</li>
<li>​<strong>早停法（Early Stopping）​</strong>：<strong>监测模型在验证集（Validation Set）上的性能</strong>​（如loss或accuracy）。当验证集性能在一定迭代次数（epoch）或迭代步数（steps）后不再提升，甚至开始下降时，​<strong>停止训练</strong>。</li>
<li>​<strong>模型复杂度约束</strong>： 直接限制了模型拟合复杂函数（包括噪声）的能力，使其更倾向于学习更简单、更泛化的模式。这样直观有效，但在设计时需要根据数据复杂度进行经验性选择（容量太小会导致欠拟合）。通常结合其他正则化技术（如 L2 正则化&#x2F;Dropout）以在保持一定容量的同时控制过拟合。</li>
</ol>
<p>用法<br><strong>深度学习：​</strong>​</p>
<ul>
<li>​<strong>L2 正则化 (Weight Decay)​</strong>​ 一般常用方式</li>
<li>​<strong>Dropout</strong>​ 在 FC 层、CNN 中被广泛应用（常放在 FC 层之后）</li>
<li>​<strong>数据增强</strong>​ 是图像任务的必备项，文本、语音任务应用也越来越多</li>
<li>​<strong>Batch Normalization</strong>​ 被广泛用于稳定训练和加速收敛，还可以顺带正则化。 </li>
<li>​<strong>早停法</strong>​ 使用方便有效</li>
<li>结合起来使用，如 <code>Dropout + L2 + Data Augmentation</code><br><strong>选择依据：​</strong>​</li>
<li>​<strong>数据量：​</strong>​ 小数据时更依赖正则化（数据增强、Dropout、L1&#x2F;L2、强约束）</li>
<li>​<strong>数据噪声：​</strong>​ 噪声大时更需要正则化（Dropout、数据清洗）</li>
<li>​<strong>任务&#x2F;模型：​</strong>​ 不同模型有其偏好（CNN常用Dropout+BN+数据增强；RNN常用L2&#x2F;梯度裁剪）</li>
<li>​<strong>计算资源：​</strong>​ 数据增强、早停法等需额外计算&#x2F;验证</li>
<li>​<strong>问题目标：​</strong>​ 是否需要特征选择（L1）或可解释性（模型约束）</li>
<li>​<strong>超参数调节：​</strong>​ 正则化强度（如 λ, Dropout Rate, 数据增强强度）需要通过验证集仔细调整</li>
</ul>
<hr>
<h2 id="动量（Momentum）"><a href="#动量（Momentum）" class="headerlink" title="动量（Momentum）"></a>动量（Momentum）</h2><p><strong>动量（Momentum）​</strong>​ 是一种优化算法，用于加速梯度下降过程并减少振荡。其核心思想是引入历史梯度信息的加权平均，模拟物理中的“动量”概念，帮助参数更新在正确方向上积累速度，从而更快收敛并逃离局部极小值或鞍点。</p>
<p>核心机制​</p>
<ol>
<li>​<strong>历史梯度的累积</strong>​<br> 每次更新时，不仅考虑当前梯度，还加入之前更新方向的加权值，形成“惯性”：<br> $$v_t &#x3D; \beta v_{t-1} + (1 - \beta) \nabla_\theta J(\theta_t)$$<ul>
<li>$v_t$：当前动量（更新方向）</li>
<li>$\beta$：动量系数（通常取0.9），控制历史信息的权重</li>
<li>$\nabla_\theta J(\theta_t)$：当前梯度</li>
</ul>
</li>
<li>​<strong>参数更新</strong>​<br> 使用动量项替代原始梯度更新参数：<br> $$ \theta_{t+1} &#x3D; \theta_t - \alpha v_t $$<ul>
<li>$\alpha$：学习率</li>
</ul>
</li>
</ol>
<p>解决的问题</p>
<ol>
<li>​<strong>梯度振荡</strong>​<br> 在损失函数的狭窄山谷中，传统SGD会因梯度方向反复变化而振荡。动量通过累积同方向梯度，平滑更新路径，加速穿过平坦区域。<blockquote>
<p>​<strong>示例</strong>​：山谷中，梯度在两侧来回震荡，动量使其沿谷底方向加速。</p>
</blockquote>
</li>
<li>​<strong>局部极小值与鞍点</strong>​<br> 动量提供的“惯性”帮助跳出局部极小值或缓慢穿越鞍点（梯度接近零的区域）。</li>
<li>​<strong>噪声鲁棒性</strong>​<br> 对小批量（mini-batch）的梯度噪声具有平滑作用，提升稳定性。</li>
</ol>
<p>物理类比​<br>想象一个球从山坡滚下：</p>
<ul>
<li>​<strong>传统SGD</strong>​：球每一步只根据当前坡度调整方向，容易卡在局部凹坑</li>
<li>​<strong>动量法</strong>​：球拥有“速度”，下坡时加速，遇到反向坡度时速度逐渐衰减而非立刻转向，更易越过小障碍</li>
</ul>
<p>超参数选择​</p>
<ul>
<li>​<strong>动量系数</strong> $\beta$：<ul>
<li>常用值：​<strong>0.9</strong>​（保留90%历史梯度方向）</li>
<li>$\beta \uparrow$：对历史依赖更强，更新更平滑，但可能过度惯性</li>
<li>$\beta \downarrow$：更依赖当前梯度，振荡可能增加</li>
</ul>
</li>
<li>​<strong>学习率</strong> $\alpha$​​：<br>  通常需略高于标准SGD（因动量加速收敛），但需调优避免发散</li>
</ul>
<p>使用场景</p>
<ul>
<li>​<strong>训练加速</strong>​：在卷积网络（CNN）、循环网络（RNN）中常见，收敛速度显著提升</li>
<li>​<strong>振荡抑制</strong>​：在病态条件（如不同特征尺度差异大）的问题中表现更稳定</li>
<li>​<strong>与自适应方法结合</strong>​：如Adam（融合动量与RMSProp），成为主流优化器之一</li>
</ul>
<hr>
<h2 id="独热编码（One-Hot-Encoding）"><a href="#独热编码（One-Hot-Encoding）" class="headerlink" title="独热编码（One-Hot Encoding）"></a>独热编码（One-Hot Encoding）</h2><p><strong>独热编码（One-Hot Encoding）​</strong>​ 是将分类变量转换为数值形式的标准化技术，使算法能够正确处理非数值特征（如颜色、国家、类别）。其核心思想是为每个类别生成一个<strong>二元向量</strong>​（仅包含0和1），长度等于类别总数，且仅在对应类别位置为1。</p>
<p>核心机制<br><strong>编码过程</strong>​ ：假设一个特征有 <code>k</code> 个类别，创建一个全零向量 <code>[0, 0, ..., 0]</code>，长度为 <code>k</code>。将该特征对应的类别位置设为 <code>1</code>。<br>​<strong>示例</strong>​：颜色特征包含 <code>[红, 绿, 蓝]</code> 三个类别：    </p>
<ul>
<li>红 → <code>[1, 0, 0]</code></li>
<li>绿 → <code>[0, 1, 0]</code></li>
<li>蓝 → <code>[0, 0, 1]</code></li>
</ul>
<p>解决的问题</p>
<ol>
<li>​<strong>分类特征的数值化</strong>​：机器学习模型（如神经网络、SVM）只能处理数值输入，无法直接处理“颜色&#x3D;红”等文本信息。</li>
<li>​<strong>避免数值陷阱</strong>​：若直接赋值（如红&#x3D;1、绿&#x3D;2、蓝&#x3D;3），模型可能错误认为：数值大小反映重要性（如蓝&gt;红），类别间存在线性关系（如（红+蓝）&#x2F;2&#x3D;绿）。独热编码通过<strong>等距表示</strong>消除此类偏差。</li>
</ol>
<p>应用场景​</p>
<ul>
<li>​<strong>结构化数据</strong>​：处理表格中的分类列（如性别、产品类型）</li>
<li>​<strong>自然语言处理（NLP）​</strong>​：将词转换为向量（词袋模型的基础）</li>
<li>​<strong>推荐系统</strong>​：用户或物品的类别特征编码</li>
</ul>
<p>局限性​</p>
<table>
<thead>
<tr>
<th>​<strong>问题</strong>​</th>
<th>​<strong>原因</strong>​</th>
<th>​<strong>解决方案</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>维度爆炸</strong>​</td>
<td>类别数 <code>k</code> 过大时，编码后特征维度急剧增加（如国家有200类 → 200列）</td>
<td>嵌入层（Embedding）、特征哈希（Hashing）</td>
</tr>
<tr>
<td>​<strong>数据稀疏性</strong>​</td>
<td>矩阵中大量0值，存储计算效率低</td>
<td>使用稀疏矩阵格式存储（如<code>scipy.sparse</code>）</td>
</tr>
<tr>
<td>​<strong>类别信息丢失</strong>​</td>
<td>忽略类别间潜在关系（如“动物”与“植物”的距离）</td>
<td>嵌入表示（如Word2Vec）、目标编码</td>
</tr>
<tr>
<td>​<strong>新类别处理</strong>​</td>
<td>测试集出现训练时未见的类别（如训练集无“紫”，测试出现“紫”）</td>
<td>统一预留“未知”类别位或舍弃该特征</td>
</tr>
</tbody></table>
<p>替代方案​</p>
<ol>
<li>​<strong>标签编码（Label Encoding）​</strong>：​直接分配数值标签（如红→0, 绿→1, 蓝→2），​<strong>仅适用于有序类别</strong>​（如学历：小学&lt;中学&lt;大学）。  <strong>风险</strong>​：无序类别引入虚假顺序关系（如“红&lt;绿”无意义）。  </li>
<li>​<strong>嵌入（Embedding）​</strong>​  ：用低维稠密向量表示类别（如将1000个国家映射为16维向量），可学习类别间语义关系。</li>
<li>​<strong>特征哈希（Hashing Trick）​</strong>​：用哈希函数压缩维度（固定输出维度），牺牲少量精度以换取效率。</li>
</ol>
<hr>
<h2 id="池化（Pooling）"><a href="#池化（Pooling）" class="headerlink" title="池化（Pooling）"></a>池化（Pooling）</h2><p><strong>池化（Pooling）​</strong>​ 是卷积神经网络（CNN）中的核心操作，通过对局部区域进行<strong>降采样</strong>​（downsampling），逐步减少特征图的空间尺寸，从而压缩信息并增强特征的鲁棒性。其本质是<strong>保留显著特征，抑制冗余细节</strong>，类似于人眼忽略细节、关注整体轮廓的认知机制。</p>
<p>核心目的​</p>
<ol>
<li>​<strong>降低维度</strong>​：减少特征图尺寸（如将224×224变为112×112），​<strong>显著降低计算量和参数量</strong>。</li>
<li>​<strong>平移不变性（Invariance）​</strong>：​使模型对微小位置变化不敏感（如猫的耳朵在图像中移动几个像素仍能被识别）。</li>
<li>​<strong>特征层次化</strong>​：逐层抽象，浅层保留边缘等细节，深层提取语义特征（如“猫脸”）。</li>
<li>​<strong>防止过拟合</strong>：​压缩信息减少模型容量，抑制噪声干扰。</li>
</ol>
<p>主要类型与操作方式​</p>
<ol>
<li><strong>最大池化（Max Pooling）​</strong> ：保留最显著特征（如纹理、边缘），适用于特征识别任务（如图像分类）<br> ​<strong>操作</strong>​：取局部窗口内的最大值  $\text{Output} &#x3D; \max(\text{Region})$</li>
<li><strong>平均池化（Average Pooling）</strong>  ：平滑区域特征，抑制极端值，适用于需要保留整体信息的任务（如生成模型）<br> <strong>操作</strong>​：取局部窗口内的平均值  $\text{Output} &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^{N} x_i$</li>
<li><strong>全局池化（Global Pooling）</strong>：​​代替全连接层，直接输出分类概率，减少参数量（如ResNet、Inception中使用）。<br> <strong>操作</strong>​：对整个特征图进行池化（取全局最大值或平均值）</li>
</ol>
<p>关键参数与计算</p>
<ul>
<li>​<strong>池化窗口（Kernel Size）​</strong>​：一般为2×2或3×3</li>
<li>​<strong>步长（Stride）​</strong>​：通常等于窗口大小（如2×2窗口步长为2）</li>
<li>​<strong>填充（Padding）​</strong>​：通常设为0（<code>valid</code>模式）</li>
</ul>
<p>​输出尺寸公式​：<br>$$<br>\text{Output Size} &#x3D; \left\lfloor \frac{\text{Input Size} - \text{Kernel Size}}{\text{Stride}} + 1 \right\rfloor<br>$$</p>
<p>与卷积层的区别​</p>
<table>
<thead>
<tr>
<th>​<strong>特性</strong>​</th>
<th>​<strong>卷积层</strong>​</th>
<th>​<strong>池化层</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>参数</strong>​</td>
<td>有权重（可学习）</td>
<td>无权重（固定操作）</td>
</tr>
<tr>
<td>​<strong>作用</strong>​</td>
<td>特征提取（主动学习）</td>
<td>特征压缩（被动降维）</td>
</tr>
<tr>
<td>​<strong>通道处理</strong>​</td>
<td>跨通道融合</td>
<td>各通道独立操作</td>
</tr>
<tr>
<td>​<strong>信息保留</strong>​</td>
<td>保留细节</td>
<td>保留最显著特征</td>
</tr>
</tbody></table>
<p>局限性与现代替代方案​</p>
<ol>
<li>​<strong>信息丢失问题</strong>​：池化会丢弃非最大值信息，可能导致细节损失（如小物体检测）。<br> ​<strong>解决方案</strong>​：<ul>
<li>​<strong>步长卷积（Strided Convolution）​</strong>​：用步长&gt;1的卷积代替池化（如VGG16）</li>
<li>​<strong>空洞卷积（Dilated Convolution）​</strong>​：扩大感受野且不降采样</li>
</ul>
</li>
<li>​<strong>位置信息破坏</strong>：​平移不变性可能损害需要位置的任务（如目标检测）。<br> ​<strong>解决方案</strong>​：<ul>
<li>减少池化层数量（如YOLO仅用1次最大池化）</li>
<li>使用可学习池化（如<strong>LPPool</strong>、<strong>SoftPool</strong>）</li>
</ul>
</li>
<li>​<strong>全局信息缺失</strong>​：浅层池化丢失长距离依赖。<br> ​<strong>解决方案</strong>​：​<strong>自注意力机制</strong>​（如Transformer）</li>
</ol>
<p>用法​</p>
<ol>
<li>​<strong>基础架构</strong>​：CNN浅层优先使用<strong>最大池化</strong>​（保留强特征），深层可尝试<strong>全局池化</strong>替代全连接层。</li>
<li>​<strong>尺寸控制</strong>​：避免频繁池化导致特征图过小（如小于4×4时停止池化）。</li>
<li>​<strong>任务适配</strong>​：<ul>
<li>​<strong>分类任务</strong>​：池化提升平移不变性</li>
<li>​<strong>检测&#x2F;分割任务</strong>​：减少池化层或使用步长卷积保留位置信息</li>
</ul>
</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title>基于回归任务的气温预测</title>
    <url>/2025/02/28/002-nn-weather-forecast/</url>
    <content><![CDATA[<p>回归任务：通过输入一些样本数据或者特征，经过多层神经网络，最后能得到一个预测值。</p>
<h2 id="1-气温数据处理"><a href="#1-气温数据处理" class="headerlink" title="1.气温数据处理"></a>1.气温数据处理</h2><h3 id="1-数据加载"><a href="#1-数据加载" class="headerlink" title="1.数据加载"></a>1.数据加载</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_csv</span>():  </span><br><span class="line">    path = Path(<span class="string">&quot;data&quot;</span>)  </span><br><span class="line">    filename = <span class="string">&quot;temps.csv&quot;</span>  </span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(path / filename)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;shape:<span class="subst">&#123;features.shape&#125;</span>\n columns:<span class="subst">&#123;features.columns&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(features[:<span class="number">5</span>]) <span class="comment"># 打印前5条数据</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shape:(348, 9)</span><br><span class="line"></span><br><span class="line">columns:Index([&#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;week&#x27;, &#x27;temp_2&#x27;, &#x27;temp_1&#x27;, &#x27;average&#x27;, &#x27;actual&#x27;, &#x27;friend&#x27;], dtype=&#x27;object&#x27;)</span><br><span class="line"></span><br><span class="line">   year  month  day  week  temp_2  temp_1  average  actual  friend</span><br><span class="line">0  2016      1    1   Fri      45      45     45.6      45      29</span><br><span class="line">1  2016      1    2   Sat      44      45     45.7      44      61</span><br><span class="line">2  2016      1    3   Sun      45      44     45.8      41      56</span><br><span class="line">3  2016      1    4   Mon      44      41     45.9      40      53</span><br><span class="line">4  2016      1    5  Tues      41      40     46.0      44      41</span><br></pre></td></tr></table></figure>
<p><code>temps.csv</code>是个348 * 9的数据，<code>temp_2</code>是那一天对应的前天的最高温度，<code>temp_1</code>是那一天对应的昨天的最高温度，<code>average</code>历史上相同<code>month</code>和<code>day</code>的平均最高温度，<code>actual</code>当天实际问题，也是真实标签值，<code>friend</code>朋友预测的最高温度。</p>
<p>简而言之，用<code>year  month  day  week  temp_2  temp_1  average friend</code>对应的数据预测<code>actual</code>对应的。</p>
<h3 id="2-独热编码"><a href="#2-独热编码" class="headerlink" title="2.独热编码"></a>2.独热编码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = load_csv()</span><br><span class="line">features = pd.get_dummies(features)</span><br><span class="line"><span class="built_in">print</span>(features[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p>独热编码（One-Hot Encoding）将每个类别转换为一个独立的二进制向量，有以下几个特点：</p>
<ul>
<li>无序特征表示：用于无顺序关系的类别特征。例如，颜色，形状</li>
<li>维度增加：每个类别会增加一列，维度的增加，可能会增加计算的复杂性</li>
<li>稀疏矩阵：生成的矩阵通常是稀疏的，即大多数值都是 0。因此，在某些情况下，可以使用稀疏矩阵来节省内存。</li>
<li>没有信息损失：每个类别都被完整地表示为一个向量，没有丢失任何关于类别的信息</li>
<li>不引入大小关系：不会误导模型认为类别之间存在某种顺序或大小关系。例如，Red、Green 和 Blue 都被等价地表示为三个不同的向量，而不是 Red &gt; Green &gt; Blue 之类的关系</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">编码前</span><br><span class="line">   week</span><br><span class="line">0   Fri</span><br><span class="line">1   Sat</span><br><span class="line">2   Sun</span><br><span class="line">3   Mon</span><br><span class="line">4  Tues</span><br><span class="line">编码后</span><br><span class="line">   week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed</span><br><span class="line">0      True     False     False     False       False      False     False</span><br><span class="line">1     False     False      True     False       False      False     False</span><br><span class="line">2     False     False     False      True       False      False     False</span><br><span class="line">3     False      True     False     False       False      False     False</span><br><span class="line">4     False     False     False     False       False       True     False</span><br></pre></td></tr></table></figure>

<h3 id="3-日期转化与数据绘制"><a href="#3-日期转化与数据绘制" class="headerlink" title="3.日期转化与数据绘制"></a>3.日期转化与数据绘制</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 转换日期  -&gt; datetime对象</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_datetime</span>(<span class="params">features</span>):  </span><br><span class="line">    years = features[<span class="string">&#x27;year&#x27;</span>]  </span><br><span class="line">    months = features[<span class="string">&#x27;month&#x27;</span>]  </span><br><span class="line">    days = features[<span class="string">&#x27;day&#x27;</span>]  </span><br><span class="line">    <span class="keyword">return</span> [datetime.datetime(year, month, day) <span class="keyword">for</span> year, month, day <span class="keyword">in</span> <span class="built_in">zip</span>(years, months, days)]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">draw_csv</span>(<span class="params">dates, features</span>):  </span><br><span class="line">    <span class="comment"># 指定默认风格  </span></span><br><span class="line">    plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 设置布局  </span></span><br><span class="line">    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">10</span>))  </span><br><span class="line">    fig.autofmt_xdate(rotation=<span class="number">45</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 当天最高温度（标签值）  </span></span><br><span class="line">    ax1.plot(dates, features[<span class="string">&#x27;actual&#x27;</span>])  </span><br><span class="line">    ax1.set_xlabel(<span class="string">&#x27;&#x27;</span>)  </span><br><span class="line">    ax1.set_ylabel(<span class="string">&#x27;Temperature&#x27;</span>)  </span><br><span class="line">    ax1.set_title(<span class="string">&#x27;Max Temp&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 昨天最高温度  </span></span><br><span class="line">    ax2.plot(dates, features[<span class="string">&#x27;temp_1&#x27;</span>])  </span><br><span class="line">    ax2.set_xlabel(<span class="string">&#x27;&#x27;</span>)  </span><br><span class="line">    ax2.set_ylabel(<span class="string">&#x27;Temperature&#x27;</span>)  </span><br><span class="line">    ax2.set_title(<span class="string">&#x27;Previous Max Temp&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前天最高温度  </span></span><br><span class="line">    ax3.plot(dates, features[<span class="string">&#x27;temp_2&#x27;</span>])  </span><br><span class="line">    ax3.set_xlabel(<span class="string">&#x27;Date&#x27;</span>)  </span><br><span class="line">    ax3.set_ylabel(<span class="string">&#x27;Temperature&#x27;</span>)  </span><br><span class="line">    ax3.set_title(<span class="string">&#x27;Two Days Prior Max Temp&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 朋友预测最高温度  </span></span><br><span class="line">    ax4.plot(dates, features[<span class="string">&#x27;friend&#x27;</span>])  </span><br><span class="line">    ax4.set_xlabel(<span class="string">&#x27;Date&#x27;</span>)  </span><br><span class="line">    ax4.set_ylabel(<span class="string">&#x27;Temperature&#x27;</span>)  </span><br><span class="line">    ax4.set_title(<span class="string">&#x27;Friend Estimate&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    plt.tight_layout(pad=<span class="number">2</span>)  </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250224175521.png"></p>
<h3 id="4-数据处理"><a href="#4-数据处理" class="headerlink" title="4.数据处理"></a>4.数据处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_train_data</span>(<span class="params">features</span>):  </span><br><span class="line">	data = features.drop(<span class="string">&#x27;actual&#x27;</span>, axis=<span class="number">1</span>)  <span class="comment"># 移除真实标签值，留下特征值  </span></span><br><span class="line">	data = np.array(data)  <span class="comment"># 转换成用于数值计算的高效数据结构的NumPy数组</span></span><br><span class="line">	<span class="keyword">return</span> preprocessing.StandardScaler().fit_transform(data)  <span class="comment"># 数据变化，适应训练</span></span><br></pre></td></tr></table></figure>

<p><code>preprocessing.StandardScaler()</code>: 对特征数据进行标准化，将数据的均值调整为 0，标准差调整为 1。对于特征的取值范围差异较大时，模型可能会对大范围的特征更敏感，标准化可以使得每个特征具有相似的尺度，从而提高模型训练的效果。另外在数据标准化后一些优化算法（如梯度下降法）的收敛速度会加快。</p>
<h2 id="2-模型定义"><a href="#2-模型定义" class="headerlink" title="2.模型定义"></a>2.模型定义</h2><h3 id="1-构造参数"><a href="#1-构造参数" class="headerlink" title="1.构造参数"></a>1.构造参数</h3><p><code>input_size</code>: 输入特征数量<br><code>hidden_size</code>: 隐藏层的神经元数量<br><code>output_size</code>：输出的大小（在回归任务中通常是 1，表示预测值）</p>
<h3 id="2-全连接层"><a href="#2-全连接层" class="headerlink" title="2.全连接层"></a>2.全连接层</h3><p><code>nn.Linear(input_size, hidden_size)</code> 创建了一个 全连接层，将输入数据从 <code>input_size</code> 维度映射到 <code>hidden_size</code> 维度。即：<br>• 输入层的特征数为 <code>input_size</code>，每个样本有 <code>input_size</code>个特征<br>• 隐藏层有<code>hidden_size</code>个神经元<br>	<br><code>nn.Linear(hidden_size, output_size)</code> 另一个全连接层，它将隐藏层的输出从 hidden_size 维度映射到 output_size 维度。对于回归任务，output_size 通常是 1，表示预测一个连续值。</p>
<h3 id="3-激活函数"><a href="#3-激活函数" class="headerlink" title="3.激活函数"></a>3.激活函数</h3><p><code>nn.Sigmoid()</code> ：<strong>Sigmoid</strong>激活函数，对隐藏层的输出进行非线性变换。Sigmoid 函数的输出范围是 (0, 1)，它通常用于二分类任务中的输出层，或者用作隐藏层的激活函数来引入非线性。</p>
<h3 id="4-前向传播"><a href="#4-前向传播" class="headerlink" title="4.前向传播"></a>4.前向传播</h3><p><code>forward()</code> 定义了数据在网络中的流动方式。每当数据通过模型时，都会调用这个方法。</p>
<ul>
<li>输入数据 x 通过第一层 fc1（即全连接层）进行计算。输出是大小为 hidden_size 的向量</li>
<li>经过全连接层计算后，输出将通过 <strong>Sigmoid 激活函数</strong>，引入非线性变换</li>
<li>隐藏层的输出 x 再通过第二层 fc2（即另一个全连接层）进行计算，得到最终的输出。此时，输出是大小为 output_size 的向量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Weather_forecast_NN</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Weather_forecast_NN, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(input_size, hidden_size)    <span class="comment"># 第一层：输入层 -&gt; 隐藏层 </span></span><br><span class="line">        <span class="variable language_">self</span>.sigmoid = nn.Sigmoid()                      <span class="comment"># Sigmoid 激活函数  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(hidden_size, output_size)   <span class="comment"># 第二层：隐藏层 -&gt; 输出层  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)       <span class="comment"># 第一层  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.sigmoid(x)   <span class="comment"># 激活函数  </span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)       <span class="comment"># 第二层  </span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="3-模型训练、验证"><a href="#3-模型训练、验证" class="headerlink" title="3.模型训练、验证"></a>3.模型训练、验证</h2><h3 id="1-损失函数"><a href="#1-损失函数" class="headerlink" title="1.损失函数"></a>1.损失函数</h3><p><code>torch.nn.MSELoss(reduction=&#39;mean&#39;)</code> 均方误差（MSE）损失函数，表示计算损失时将所有样本的损失求平均值，常用于回归任务，衡量预测值与真实值之间的差距。</p>
<h3 id="2-优化器"><a href="#2-优化器" class="headerlink" title="2.优化器"></a>2.优化器</h3><p> Adam 优化器用于一种自适应优化算法，能够在训练过程中调整学习率，用于优化模型参数，学习率设置为0.001，为何设置0.001？因为0.001是一个比较保守的学习率值，它既不会太大导致不稳定，也不会太小导致收敛过慢，因此通常能够平衡训练速度与稳定性。 </p>
<h3 id="3-Mini-batch"><a href="#3-Mini-batch" class="headerlink" title="3.Mini-batch"></a>3.Mini-batch</h3><p> 将训练数据分成多个小批次（mini-batches），并在每个小批次上执行一次梯度更新。这样做的好处是避免了批量梯度下降的高计算开销，同时还能减少随机梯度下降的噪声，具有较好的稳定性和计算效率。<br>优点：</p>
<ol>
<li><strong>内存高效</strong>：每次仅使用小批次的数据进行计算，适合大规模数据集</li>
<li><strong>更稳定的训练过程</strong>：相比随机梯度下降，mini-batch 提供了更平滑的更新，使得训练过程更为稳定</li>
<li><strong>利用并行计算</strong>：小批量训练可以很好地与 GPU 等硬件加速工具配合，提高训练效率</li>
<li><strong>较快的收敛速度</strong>：由于每次更新的样本数较多，相比单样本更新（SGD），mini-batch 方法通常能更快收敛</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>收敛不如批量梯度下降精确</strong>：每次更新基于一个小批量数据，梯度计算不如批量梯度下降精确</li>
<li><strong>选择批次大小难度</strong>：需要根据任务、数据量和硬件等因素选择合适的 mini-batch 大小。如果选择不当，可能会导致训练不稳定或收敛过慢</li>
</ol>
<h3 id="4-tensor转换"><a href="#4-tensor转换" class="headerlink" title="4.tensor转换"></a>4.tensor转换</h3><p>提取当前批次的输入数据，转换为 <strong>PyTorch 张量</strong>。<code>requires_grad=True</code> 表示我们需要计算该数据的梯度。不需要为目标 yy 设置 <code>requires_grad</code>，因为它不是模型的参数，yy中使用 .view(-1, 1) 将其形状调整为 (batch_size, 1)，确保目标数据与模型输出的形状一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">train_data, valid_data</span>):  </span><br><span class="line">    input_size = train_data.shape[<span class="number">1</span>]  <span class="comment"># 每个样本特征数</span></span><br><span class="line">    hidden_size = <span class="number">128</span>                 <span class="comment"># 隐藏层的神经元数量</span></span><br><span class="line">    output_size = <span class="number">1</span>                   <span class="comment"># 输出层的神经元数量</span></span><br><span class="line">    batch_size = <span class="number">16</span>                   <span class="comment"># 每次更新模型时使用 16 个样本的数据</span></span><br><span class="line">    model = Weather_forecast_NN(input_size, hidden_size, output_size)  </span><br><span class="line">    mse_loss = torch.nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)  </span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)  </span><br><span class="line">  </span><br><span class="line">    losses = []  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):  </span><br><span class="line">        batch_loss = []  </span><br><span class="line">        <span class="comment"># MINI-Batch方法来进行训练</span></span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(train_data), batch_size):  </span><br><span class="line">            end = start + batch_size <span class="keyword">if</span> start + batch_size &lt; <span class="built_in">len</span>(train_data) <span class="keyword">else</span> <span class="built_in">len</span>(train_data)  </span><br><span class="line">            xx = torch.tensor(train_data[start:end], dtype=torch.float32, requires_grad=<span class="literal">True</span>)  </span><br><span class="line">            yy = torch.tensor(valid_data[start:end], dtype=torch.float32).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            prediction = model(xx)  <span class="comment"># 获取模型预测值</span></span><br><span class="line">            loss = mse_loss(prediction, yy) <span class="comment"># 计算模型预测值和真实标签之间的均方误差损失</span></span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 清空之前计算的梯度</span></span><br><span class="line">            loss.backward()   <span class="comment"># 反向传播：自动计算每个参数的梯度</span></span><br><span class="line">            optimizer.step()  <span class="comment"># 使用优化器更新模型的参数（权重和偏置）</span></span><br><span class="line">            batch_loss.append(loss.data.numpy())  <span class="comment"># 保存损失值并转化为NumPy数组</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 打印损失  </span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:  <span class="comment"># 每 100 次迭代打印一次损失</span></span><br><span class="line">            losses.append(np.mean(batch_loss))  </span><br><span class="line">            <span class="built_in">print</span>(i, np.mean(batch_loss))  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h2 id="4-模型测试"><a href="#4-模型测试" class="headerlink" title="4.模型测试"></a>4.模型测试</h2><p>使用<code>matplotlib</code>绘制出真实天气与预测天气的对比图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测值和实际值对比图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_valid_and_predictions_data</span>(<span class="params">dates, model, train_data, valid_data</span>):  </span><br><span class="line">  </span><br><span class="line">    x = torch.tensor(train_data, dtype=torch.<span class="built_in">float</span>)  </span><br><span class="line">    predict = model(x).data.numpy()  </span><br><span class="line">    <span class="comment"># 实际值  </span></span><br><span class="line">    plt.plot(dates, valid_data, <span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;actual&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 预测值  </span></span><br><span class="line">    plt.plot(dates, predict, <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>)  </span><br><span class="line">    plt.xticks(rotation=<span class="number">60</span>)  </span><br><span class="line">    plt.legend()  </span><br><span class="line">    <span class="comment"># 绘图配置  </span></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Date&#x27;</span>)  </span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Maximum Temperature (F)&#x27;</span>)  </span><br><span class="line">    plt.title(<span class="string">&#x27;Actual and Predicted Values&#x27;</span>)  </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250224230546.png"></p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>本文主要讲的是一个基于神经网络的天气预测模型，通过读取天气数据、预处理、模型训练展示了如何使用神经网络来解决一个回归问题，涉及知识点：</p>
<ol>
<li>数据标准化处理，对训练数据的特征进行归一化处理，使得每个特征具有均值为 0，标准差为 1，减少特征尺度差异对训练过程的影响</li>
<li>数据可视化，matplotlib绘制气温变化图和对比图</li>
<li>神经网络模型，一个简单的前馈神经网络（1 个隐藏层包含128个神经元）</li>
<li>损失函数与优化器<ul>
<li>损失函数：使用 均方误差（MSE）来衡量模型的预测结果与真实结果之间的差距</li>
<li>优化器：使用 Adam 优化器，这是一种自适应优化算法，能够动态调整学习率，通常能带来更好的训练效果</li>
</ul>
</li>
</ol>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>matplotlib: 3.8.4</li>
<li>numpy: 1.26.4</li>
<li>panda: 2.2.2</li>
</ul>
<p>数据集：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/002_nn_weather_forecast/data">https://github.com/keychankc/dl_code_for_blog/tree/main/002_nn_weather_forecast/data</a></p>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/002_nn_weather_forecast">https://github.com/keychankc/dl_code_for_blog/tree/main/002_nn_weather_forecast</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>全连接层</tag>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>模型训练</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>利用神经网络实现手写字体识别</title>
    <url>/2025/02/26/001-nn-digital-recognition/</url>
    <content><![CDATA[<p>本文主要是讲如何使用 PyTorch 实现手写数字识别，包括MNIST数据集加载处理、神经网络模型定义、训练并评估模型。</p>
<h2 id="1-Mnist数据集"><a href="#1-Mnist数据集" class="headerlink" title="1.Mnist数据集"></a>1.Mnist数据集</h2><p>Mnist数据集是美国国家标准与技术研究院收集的关于手写数字扫描图像及其对应识别数字的数据集。该数据集分为两部分：<br>第一部分包含60000幅28x28大小的灰度图及对应识别数字，用作训练数据，这些图像扫描自250个人的手写样本。<br>第二部分包含10000幅28x28大小的灰度图及对应识别数字，用作测试数据，为了保证测试结果，这些图像来自另外一批人。</p>
<span id="more"></span>

<p>部分训练数据：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250219151617.png"><br>部分训练数据对应识别数字：<br>[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1]</p>
<p>部分测试数据：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250219152042.png">部分测试数据对应识别数字：<br>[3 8 6 9 6 4 5 3 8 4 5 2 3 8 4 8 1 5 0 5 9 7 4 1]</p>
<h2 id="2-Mnist数据集数据处理"><a href="#2-Mnist数据集数据处理" class="headerlink" title="2.Mnist数据集数据处理"></a>2.Mnist数据集数据处理</h2><h3 id="1-数据加载"><a href="#1-数据加载" class="headerlink" title="1.数据加载"></a>1.数据加载</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_mnist</span>():  </span><br><span class="line">    path = Path(<span class="string">&quot;data/mnist&quot;</span>)  </span><br><span class="line">    filename = <span class="string">&quot;mnist.pkl.gz&quot;</span>  </span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>((path / filename).as_posix(), <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=<span class="string">&quot;latin-1&quot;</span>)  </span><br><span class="line">    <span class="keyword">return</span> x_train, y_train, x_valid, y_valid</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练数据集 训练结果集 测试数据集 验证结果集</span></span><br><span class="line">train_data, train_result, valid_data, valid_result = load_mnist()</span><br></pre></td></tr></table></figure>
<h3 id="2-数据打印"><a href="#2-数据打印" class="headerlink" title="2.数据打印"></a>2.数据打印</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练样本50000 每个样本784个像素点数据</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape) <span class="comment"># (50000, 784) </span></span><br><span class="line"><span class="comment"># 测试样本10000 每个样本784个像素点数据</span></span><br><span class="line"><span class="built_in">print</span>(valid_data.shape) <span class="comment"># (10000, 784)</span></span><br><span class="line"><span class="comment"># 打印第一个训练样本对应数字识别</span></span><br><span class="line"><span class="built_in">print</span>(train_result[<span class="number">0</span>]) <span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 打印第一个训练样本</span></span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="number">0</span>]) </span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/2025-02-20_13-30-34.jpg"></p>
<h3 id="3-数据转换"><a href="#3-数据转换" class="headerlink" title="3.数据转换"></a>3.数据转换</h3><p>张量（Tensor)：PyTorch 中的基础数据结构，类似于矩阵或多维数组，用于表示和存储数据。张量不仅支持数学运算，还能够支持深度学习模型中所需的自动求导功能（通过反向传播计算梯度），还能支持 GPU 加速。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将Mnist数据集的数据转化为可供PyTorch使用的张量</span></span><br><span class="line">train_data, train_result, valid_data, valid_result = <span class="built_in">map</span>(torch.tensor, (train_data, train_result, valid_data, valid_result))</span><br></pre></td></tr></table></figure>
<h3 id="4-数据打包和批量加载"><a href="#4-数据打包和批量加载" class="headerlink" title="4.数据打包和批量加载"></a>4.数据打包和批量加载</h3><p>创建训练和验证数据的 DataLoader 对象</p>
<ul>
<li>TensorDataset：将输入数据和标签组合成一个数据集，可以方便地用来处理训练集和验证集  </li>
<li>DataLoader：用来批量加载数据，支持多种功能，比如按批次加载数据、随机打乱数据、并行加载等</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_tensor_dataset</span>(<span class="params">batch</span>):  </span><br><span class="line">    train_ds = TensorDataset(train_data, train_result)  </span><br><span class="line">    valid_ds = TensorDataset(valid_data, valid_result)  </span><br><span class="line">    <span class="comment"># batch_size批次数据大小 </span></span><br><span class="line">    <span class="comment"># shuffle=True 每个 epoch 开始时随机打乱数据提高泛化能力</span></span><br><span class="line">    <span class="keyword">return</span> DataLoader(train_ds, batch_size=batch, shuffle=<span class="literal">True</span>), DataLoader(valid_ds, batch_size=bs * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-模型定义"><a href="#3-模型定义" class="headerlink" title="3.模型定义"></a>3.模型定义</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn  </span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mnist_NN</span>(nn.Module):  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># 定义属性  </span></span><br><span class="line">        <span class="comment"># 第一层全连接层 输入784个特征 -&gt; 输出128个神经元</span></span><br><span class="line">        <span class="variable language_">self</span>.hidden1 = nn.Linear(<span class="number">784</span>, <span class="number">128</span>) </span><br><span class="line">        <span class="comment"># 第二层全连接层 128 -&gt; 256     </span></span><br><span class="line">        <span class="variable language_">self</span>.hidden2 = nn.Linear(<span class="number">128</span>, <span class="number">256</span>)    </span><br><span class="line">        <span class="comment"># 输出层 256 -&gt; 10分类   </span></span><br><span class="line">        <span class="variable language_">self</span>.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>) </span><br><span class="line">        <span class="comment"># Dropout层，用于防止过拟合，在每次前向传播中，随机丢弃 50% 的神经元          </span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 前向传播  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="comment"># 第一层全连接层的输出经过 ReLU 激活函数。ReLU 将所有负值转换为 0，正值保持不变，引入非线性</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.hidden1(x))         </span><br><span class="line">        <span class="comment"># 将中间层的输出送入 Dropout 层，随机丢弃一部分神经元，以减小过拟合的风险          </span></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)     </span><br><span class="line">        <span class="comment"># 第二层全连接层的输出经过 ReLU 激活函数                                     </span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.hidden2(x))      </span><br><span class="line">        <span class="comment"># 再次进行 Dropout 操作，丢弃一些神经元                          </span></span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)        </span><br><span class="line">        <span class="comment"># 输出层给出10个类别的预测值（数字0到9），每个值代表该数字的得分或概率              </span></span><br><span class="line">        x = <span class="variable language_">self</span>.out(x)                                            </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>模型的输入的是图像数据，输出是个10分类。模型使用比较经典的基于全连接层的网络结构。</p>
<h3 id="1-全连接层（Fully-Connected-Layer）"><a href="#1-全连接层（Fully-Connected-Layer）" class="headerlink" title="1.全连接层（Fully Connected Layer）"></a>1.全连接层（Fully Connected Layer）</h3><p>公式:<br>$$<br>f_c &#x3D; w x + b<br>$$</p>
<ul>
<li>$w$：权重矩阵（weights），每个输入特征对应一个输出特征的权重</li>
<li>$x$：输入向量（input），通常是当前层的输入数据</li>
<li>$b$：偏置项（bias），是一个额外的参数，添加到线性变换中，以帮助模型更好地拟合数据</li>
<li>$f_c$：输出向量（output），表示该层经过线性变换后的结果，是通过加权和加上偏置计算出来的。</li>
</ul>
<p>在PyTorch中全连接层是通过 <code>nn.Linear(in_features, out_features)</code> 这个方法来实现的</p>
<ul>
<li><strong>in_features</strong>：输入特征的数量，即输入数据的维度</li>
<li><strong>out_features</strong>：输出特征的数量，即该层的神经元个数</li>
</ul>
<p> nn.Linear会自动处理权重矩阵和偏置项的初始化、更新和应用</p>
<h3 id="2-Dropout层"><a href="#2-Dropout层" class="headerlink" title="2.Dropout层"></a>2.Dropout层</h3><p>用于防止过拟合，在每次前向传播中，随机丢弃 50% 的神经元。</p>
<h3 id="3-前向传播（Forward-Propagation）"><a href="#3-前向传播（Forward-Propagation）" class="headerlink" title="3.前向传播（Forward Propagation）"></a>3.前向传播（Forward Propagation）</h3><p>输入数据（如图像、文本等）通过网络中各层的传递和计算，得到最终模型的输出的过程。<br>前向传播作用：</p>
<ul>
<li>根据输入数据生成模型的预测结果</li>
<li>对比预测结果和真实结果，计算出损失，用于反向传播更新权重</li>
</ul>
<h3 id="4-反向传播（Back-Propagation）"><a href="#4-反向传播（Back-Propagation）" class="headerlink" title="4.反向传播（Back Propagation）"></a>4.反向传播（Back Propagation）</h3><p>通过计算损失函数的梯度来调整神经网络的参数（即权重和偏置），从而最小化模型的损失，下次迭代更准确。<br>反向传播的主要作用：计算每层参数（权重、偏置）的梯度以及更新模型参数，优化模型性能<br>在pytorch中反向传播有现成的API，实现起来比较方便。</p>
<h3 id="5-激活函数（Activation-Function）"><a href="#5-激活函数（Activation-Function）" class="headerlink" title="5.激活函数（Activation Function）"></a>5.激活函数（Activation Function）</h3><p>决定了每个神经元的输出，使得神经网络能够学习到输入和输出之间复杂的非线性关系。如果没有激活函数，神经网络无论有多少层，它仍然只是一个线性变换，无法解决复杂的问题，比如图像分类、自然语言处理问题等。<br>常见的激活函数有：<strong>Sigmoid</strong>、<strong>Tanh</strong>、<strong>ReLU</strong>、<strong>Softmax</strong> 等</p>
<h4 id="1-ReLU激活函数"><a href="#1-ReLU激活函数" class="headerlink" title="1.ReLU激活函数"></a>1.ReLU激活函数</h4><p>$$<br>ReLU(x) &#x3D; max(0, x)<br>$$<br>特点：</p>
<ul>
<li><strong>计算简单</strong>​：仅需比较和取最大值操作，计算效率高</li>
<li>​<strong>非线性</strong>​：虽然形式简单，但能够引入非线性，使神经网络可以学习复杂模式</li>
<li>​<strong>稀疏激活</strong>​：负值输出为0，可让网络中的部分神经元保持“沉默”，提升模型的稀疏表示能力</li>
</ul>
<p>优点​：</p>
<ul>
<li>​<strong>缓解梯度消失问题</strong>​：在正区间梯度恒为1，避免了深层网络因梯度连乘导致的梯度消失，优于Sigmoid&#x2F;Tanh</li>
<li>​<strong>加速收敛</strong>​：相比Sigmoid&#x2F;Tanh，ReLU的梯度更稳定，训练速度通常更快</li>
<li>​<strong>生物学合理性</strong>​：类似神经元的“全有或全无”激活机制</li>
</ul>
<p>缺点​：</p>
<ul>
<li>​<strong>Dead ReLU问题</strong>​：如果神经元输出恒为0（如初始化不良或学习率过高），梯度无法更新，导致永久性“死亡”</li>
<li>​<strong>非零中心化</strong>​：输出均值非零，可能影响梯度下降的效率（但影响通常较小）</li>
</ul>
<h4 id="2-Sigmoid激活函数"><a href="#2-Sigmoid激活函数" class="headerlink" title="2.Sigmoid激活函数"></a>2.Sigmoid激活函数</h4><p>一般用在二分类问题中，通常用于模型的输出层，Sigmoid 函数将输入值（通常是一个实数）映射到一个范围为 <strong>(0, 1)</strong> 的值，输出类似于概率，可以解释为某个类别的概率。</p>
<p>特点：</p>
<ul>
<li>输出范围（0,1），适合于将输出解释为概率，特别是用于二分类任务</li>
<li>平滑且连续，适合用于模型的激活函数，因为它能提供稳定的梯度，帮助优化过程</li>
<li>单调递增，随着输入值的增大，输出值也不断增大</li>
<li>非线性，使得神经网络能够学习输入和输出之间的复杂关系</li>
<li>中心对称性，可以处理二分类问题中的“平衡”预测</li>
<li>梯度计算，可以通过函数值本身计算出来，计算上较为简单</li>
</ul>
<p>优点​：</p>
<ul>
<li>​<strong>概率输出</strong>​：天然适合二分类问题（如逻辑回归）</li>
<li><strong>可微性</strong>​：梯度计算简单，适用于反向传播</li>
</ul>
<p>缺点​：</p>
<ul>
<li><strong>梯度消失</strong>​：当输入 ∣x∣ 较大时，梯度接近0，导致深层网络难以训练。 例如：σ(5)≈1，此时梯度 σ′(5)≈0</li>
<li>​<strong>非零中心化</strong>​：输出均值&gt;0，可能使梯度更新呈“锯齿状”，影响收敛速度</li>
<li>​<strong>计算成本</strong>​：涉及指数运算，比ReLU慢</li>
</ul>
<h2 id="4-模型训练、验证"><a href="#4-模型训练、验证" class="headerlink" title="4.模型训练、验证"></a>4.模型训练、验证</h2><h3 id="1-损失函数（Loss-Function）"><a href="#1-损失函数（Loss-Function）" class="headerlink" title="1.损失函数（Loss Function）"></a>1.损失函数（Loss Function）</h3><p>模型训练中用于衡量模型预测与真实值之间差距的重要工具，选择什么损失函数取决于具体的任务类型。<br>回归任务常用的损失函数：</p>
<ul>
<li><strong>均方误差损失（MSE Loss）</strong>：用于预测房价、温度等连续值，对大的预测误差更为敏感，适合于要求精确度较高的回归问题</li>
<li><strong>平均绝对误差损失（MAE Loss）</strong>：适用于异常值（outliers）不太敏感时</li>
</ul>
<p>分类任务常用的损失函数：</p>
<ul>
<li><strong>交叉熵损失（Cross-Entropy Loss）</strong>：模型输出通常经过 <strong>Softmax</strong> 激活，表示每个类别的概率</li>
<li><strong>二分类交叉熵损失（Binary Cross-Entropy Loss）</strong>：适用于二分类任务（如垃圾邮件分类、图像中的物体检测等），模型输出通常经过 <strong>Sigmoid</strong> 激活，表示某一类的概率</li>
<li><strong>多标签二分类交叉熵损失（Multi-label Binary Cross-Entropy Loss）</strong>：适用于每个样本有多个标签的情况，例如图像可以同时包含多个物体</li>
</ul>
<p>生成模型损失函数：</p>
<ul>
<li><strong>对抗性损失（Adversarial Loss）</strong>：在生成对抗网络（GAN）中，生成器和判别器通过相互对抗来训练</li>
</ul>
<p>为了衡量模型预测的概率分布与实际标签的概率分布之间的差异，手写字体识别用的损失函数是交叉熵损失。</p>
<h3 id="2-优化器（Optimizer）"><a href="#2-优化器（Optimizer）" class="headerlink" title="2.优化器（Optimizer）"></a>2.优化器（Optimizer）</h3><p>在训练时，更新网络中参数（如权重和偏置）的算法。它的作用是通过计算损失函数的梯度，并根据梯度来调整模型的参数，使得模型的预测越来越接近真实值，从而最小化损失函数。</p>
<p>特点：</p>
<ul>
<li><strong>学习率（Learning Rate）</strong>：决定了每次更新时参数的调整幅度。学习率过大会导致训练不稳定，学习率过小则可能导致收敛速度过慢</li>
<li><strong>动量（Momentum）</strong>：在更新时引入历史梯度的影响，可以帮助优化器跳出局部最小值，快速收敛</li>
<li><strong>自适应学习率</strong>：根据参数的更新历史调整每个参数的学习率。这可以帮助优化器在不同的训练阶段更好地调整步长</li>
<li><strong>梯度裁剪（Gradient Clipping）</strong>：当梯度过大时，优化器会裁剪梯度值，防止梯度爆炸，保持训练稳定性</li>
<li><strong>加速收敛</strong>：通过使用动量、Adagrad、Adam 等优化技术，优化器可以更快地收敛，提高训练效率</li>
</ul>
<p>常用的优化器包括 <strong>SGD、Adam、RMSprop、Adagrad</strong> 等，它们各有优缺点，可以根据任务的需要选择合适的优化器。其中<strong>Adam</strong> 是最常用的优化器之一，它结合了动量和自适应学习率，能够加速收敛并减少调整学习率的工作。</p>
<p>手写字体识别用到的两种优化器：</p>
<ul>
<li><strong>随机梯度下降（Stochastic Gradient Descent, SGD）</strong>：每次更新只使用一个训练样本（或小批量数据），使得参数更新更加频繁，可以更快地收敛<ul>
<li>相比于传统的梯度下降，计算效率更高</li>
<li>可能会导致参数更新方向的噪声，收敛速度较慢，但有时能跳出局部最小值</li>
<li>需要设定批量大小（batch size）</li>
</ul>
</li>
<li><strong>Adam（Adaptive Moment Estimation）</strong>：结合了动量（Momentum）和自适应学习率（Adagrad），它能够有效地调整学习率，适应不同的梯度方向<ul>
<li>可以自动调整不同参数的学习率</li>
<li>非常适合处理大规模数据和非平稳目标</li>
</ul>
</li>
</ul>
<p>下面是在两种优化器<strong>SGD</strong>和<strong>Adam</strong>下的训练过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># optim.SGD(model.parameters(), lr=0.001)</span></span><br><span class="line">当前step:<span class="number">0</span> 验证集损失：<span class="number">2.2825574489593508</span></span><br><span class="line">当前step:<span class="number">1</span> 验证集损失：<span class="number">2.2580022922515868</span></span><br><span class="line">当前step:<span class="number">2</span> 验证集损失：<span class="number">2.2230858280181884</span></span><br><span class="line">当前step:<span class="number">3</span> 验证集损失：<span class="number">2.1703024547576906</span></span><br><span class="line">当前step:<span class="number">4</span> 验证集损失：<span class="number">2.090115145111084</span></span><br><span class="line">当前step:<span class="number">5</span> 验证集损失：<span class="number">1.972484421157837</span></span><br><span class="line">当前step:<span class="number">6</span> 验证集损失：<span class="number">1.81169817943573</span></span><br><span class="line">当前step:<span class="number">7</span> 验证集损失：<span class="number">1.619726370239258</span></span><br><span class="line">当前step:<span class="number">8</span> 验证集损失：<span class="number">1.4188599571228027</span></span><br><span class="line">当前step:<span class="number">9</span> 验证集损失：<span class="number">1.2381446369171143</span></span><br><span class="line">当前step:<span class="number">10</span> 验证集损失：<span class="number">1.090174704360962</span></span><br><span class="line">当前step:<span class="number">11</span> 验证集损失：<span class="number">0.9715679389953613</span></span><br><span class="line">当前step:<span class="number">12</span> 验证集损失：<span class="number">0.8798320659637451</span></span><br><span class="line">当前step:<span class="number">13</span> 验证集损失：<span class="number">0.8053891849517822</span></span><br><span class="line">当前step:<span class="number">14</span> 验证集损失：<span class="number">0.7459170845985412</span></span><br><span class="line">当前step:<span class="number">15</span> 验证集损失：<span class="number">0.6976882362365723</span></span><br><span class="line">当前step:<span class="number">16</span> 验证集损失：<span class="number">0.6561079911231995</span></span><br><span class="line">当前step:<span class="number">17</span> 验证集损失：<span class="number">0.6218576231002808</span></span><br><span class="line">当前step:<span class="number">18</span> 验证集损失：<span class="number">0.5916362497329712</span></span><br><span class="line">当前step:<span class="number">19</span> 验证集损失：<span class="number">0.5658870533943177</span></span><br><span class="line">当前step:<span class="number">20</span> 验证集损失：<span class="number">0.5439170695781708</span></span><br><span class="line">当前step:<span class="number">21</span> 验证集损失：<span class="number">0.523462038564682</span></span><br><span class="line">当前step:<span class="number">22</span> 验证集损失：<span class="number">0.5060828925609588</span></span><br><span class="line">当前step:<span class="number">23</span> 验证集损失：<span class="number">0.49091667313575743</span></span><br><span class="line">当前step:<span class="number">24</span> 验证集损失：<span class="number">0.4764920748233795</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># optim.Adam(model.parameters(), lr=0.001)</span></span><br><span class="line">当前step:<span class="number">0</span> 验证集损失：<span class="number">0.17698360292464493</span></span><br><span class="line">当前step:<span class="number">1</span> 验证集损失：<span class="number">0.14216668649837375</span></span><br><span class="line">当前step:<span class="number">2</span> 验证集损失：<span class="number">0.126948723224923</span></span><br><span class="line">当前step:<span class="number">3</span> 验证集损失：<span class="number">0.10562696368470788</span></span><br><span class="line">当前step:<span class="number">4</span> 验证集损失：<span class="number">0.10259809614447876</span></span><br><span class="line">当前step:<span class="number">5</span> 验证集损失：<span class="number">0.09621413100771606</span></span><br><span class="line">当前step:<span class="number">6</span> 验证集损失：<span class="number">0.09606640956951305</span></span><br><span class="line">当前step:<span class="number">7</span> 验证集损失：<span class="number">0.0986269654519856</span></span><br><span class="line">当前step:<span class="number">8</span> 验证集损失：<span class="number">0.09152188654057682</span></span><br><span class="line">当前step:<span class="number">9</span> 验证集损失：<span class="number">0.0928957357056439</span></span><br><span class="line">当前step:<span class="number">10</span> 验证集损失：<span class="number">0.08738993679527193</span></span><br><span class="line">当前step:<span class="number">11</span> 验证集损失：<span class="number">0.09072061020550318</span></span><br><span class="line">当前step:<span class="number">12</span> 验证集损失：<span class="number">0.08229427027562633</span></span><br><span class="line">当前step:<span class="number">13</span> 验证集损失：<span class="number">0.07957016561152414</span></span><br><span class="line">当前step:<span class="number">14</span> 验证集损失：<span class="number">0.08250478478346486</span></span><br><span class="line">当前step:<span class="number">15</span> 验证集损失：<span class="number">0.08225050425492227</span></span><br><span class="line">当前step:<span class="number">16</span> 验证集损失：<span class="number">0.08098026988087222</span></span><br><span class="line">当前step:<span class="number">17</span> 验证集损失：<span class="number">0.07714118722344865</span></span><br><span class="line">当前step:<span class="number">18</span> 验证集损失：<span class="number">0.0819709857826354</span></span><br><span class="line">当前step:<span class="number">19</span> 验证集损失：<span class="number">0.07824937357302988</span></span><br><span class="line">当前step:<span class="number">20</span> 验证集损失：<span class="number">0.08052018974055536</span></span><br><span class="line">当前step:<span class="number">21</span> 验证集损失：<span class="number">0.07852755540162325</span></span><br><span class="line">当前step:<span class="number">22</span> 验证集损失：<span class="number">0.07764818926507142</span></span><br><span class="line">当前step:<span class="number">23</span> 验证集损失：<span class="number">0.07755581210317905</span></span><br><span class="line">当前step:<span class="number">24</span> 验证集损失：<span class="number">0.07430763039904996</span></span><br></pre></td></tr></table></figure>
<p>很明显在手写字体识别模型训练中，使用<strong>Adam</strong>产生的损失要小于<strong>SGD</strong>优化器，损失越小代表模型识别的准确率越高。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算损失</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_batch</span>(<span class="params">m, loss_func, xb, yb, opt=<span class="literal">None</span></span>):  </span><br><span class="line">    loss = loss_func(m(xb), yb)  <span class="comment"># 预测结果和真实结果的差异，得到损失</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">        loss.backward()     <span class="comment"># 反向传播  </span></span><br><span class="line">        opt.step()          <span class="comment"># 更新模型参数（权重和偏置）  </span></span><br><span class="line">        opt.zero_grad()     <span class="comment"># 梯度清空，梯度默认会累加从而导致参数不准确</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> loss.item(), <span class="built_in">len</span>(xb)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练主方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">steps, m, loss_func, opt, train_dl, valid_dl</span>):  </span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps):  </span><br><span class="line">        m.train()  <span class="comment"># 设置为训练模式  </span></span><br><span class="line">        <span class="keyword">for</span> xb, yb <span class="keyword">in</span> train_dl:  </span><br><span class="line">            loss_batch(m, loss_func, xb, yb, opt)   <span class="comment"># 计算损失</span></span><br><span class="line">  </span><br><span class="line">        m.<span class="built_in">eval</span>()  <span class="comment"># 设置为验证模式  </span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁用梯度计算  </span></span><br><span class="line">            losses, nums = <span class="built_in">zip</span>(*[loss_batch(m, loss_func, xb, yb) <span class="keyword">for</span> xb, yb <span class="keyword">in</span> valid_dl])  </span><br><span class="line">        val_loss = np.<span class="built_in">sum</span>(np.multiply(losses, nums)) / np.<span class="built_in">sum</span>(nums)  <span class="comment"># 计算损失</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;当前step:&#x27;</span> + <span class="built_in">str</span>(step), <span class="string">&#x27;验证集损失：&#x27;</span> + <span class="built_in">str</span>(val_loss))</span><br></pre></td></tr></table></figure>
<p>模型定义以及主方法调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Mnist_NN()  <span class="comment"># 定义训练模型</span></span><br><span class="line">loss_func = F.cross_entropy  <span class="comment"># 定义损失函数为交叉熵损失</span></span><br><span class="line">opt1 = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># SGD优化器  </span></span><br><span class="line">opt2 = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># Adam优化器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">fit(<span class="number">25</span>, model, loss_func, opt2, train_dataloader, valid_dataloader)</span><br></pre></td></tr></table></figure>
<h2 id="5-模型测试"><a href="#5-模型测试" class="headerlink" title="5.模型测试"></a>5.模型测试</h2><p>用测试集的数据对训练完的模型去做验证，验证模型的准确率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">correct = <span class="number">0</span>  </span><br><span class="line">total = <span class="number">0</span>  </span><br><span class="line"><span class="keyword">for</span> xb, yb <span class="keyword">in</span> valid_dataloader:  </span><br><span class="line">    outputs = model(xb)  </span><br><span class="line">    _, pred = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)  </span><br><span class="line">    total += yb.size(<span class="number">0</span>)  </span><br><span class="line">    correct += (pred == yb).<span class="built_in">sum</span>().item()  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试集10000张图片正确率：%d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>
<p>SGD优化器输出：<br>测试集10000张图片正确率：87 %<br>Adam优化器输出：<br>测试集10000张图片正确率：97 %</p>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><p>Mnist数据集手写字体识别案例作为PyTorch库的HelloWorld，讲了在训练神经网络过程中的一些基本概念和PyTorch库的基础使用，包括</p>
<ol>
<li>数据预处理，图像像素值转化为[0, 1]（Mnist数据集已经做了）；</li>
<li>数据转化为PyTorch方便使用的Tensor数据格式；</li>
<li>使用DataLoader进行数据加载，方便高效训练；</li>
<li>有多个线性层组成并且后面跟随一个激活函数的全连接网络，最后输出0~9十分类；</li>
<li>使用交叉熵损失函数计算损失；</li>
<li>使用SGD和Adam优化器调整模型参数</li>
</ol>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>matplotlib: 3.8.4</li>
<li>numpy: 1.26.4</li>
</ul>
<p>数据集：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/001_nn_digital_recognition/data/mnist">https://github.com/keychankc/dl_code_for_blog/tree/main/001_nn_digital_recognition/data/mnist</a></p>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/001_nn_digital_recognition">https://github.com/keychankc/dl_code_for_blog/tree/main/001_nn_digital_recognition</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>全连接层</tag>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>模型训练</tag>
      </tags>
  </entry>
  <entry>
    <title>利用卷积神经网络实现手写字体识别</title>
    <url>/2025/03/02/003-cnn-digital-recognition/</url>
    <content><![CDATA[<p>前文 <a href="https://keychankc.github.io/2025/02/26/nn-digital-recognition/"><strong>利用神经网络实现手写字体识别</strong></a> 中构建的模型只单单使用了全连接层， 其中每一层的神经元都会与前一层的所有神经元相连接，这种结构其实更适合于结构化数据或一维数据。而像手写字体识别之类的图像结构数据，使用卷积神经网络其实会更合适一点，一方面通过卷积层可以提取局部特征，另一方面经过池化层还能减少参数量，提高处理效率。</p>
<h2 id="1-卷积神经网络"><a href="#1-卷积神经网络" class="headerlink" title="1.卷积神经网络"></a>1.卷积神经网络</h2><p>卷积神经网络（Convolutional Neural Network，简称CNN）是一种特别适合处理图像、视频、语音、文本等数据的神经网络结构，它通过模仿生物视觉系统的工作原理，利用 <strong>卷积层</strong>、<strong>池化层</strong> 和 <strong>全连接层</strong> 来提取数据中的空间特征，并通过训练来优化参数，这在计算机视觉任务中有着广泛应用。</p>
<h3 id="1-基本原理"><a href="#1-基本原理" class="headerlink" title="1.基本原理"></a>1.基本原理</h3><p>CNN的核心思想是“卷积”操作。简单来说，卷积是用一个小的矩阵（称为<strong>卷积核</strong>）在输入图像上滑动，通过和图像的局部区域进行逐点相乘并求和，提取出图像的局部特征。卷积操作通常会在多个卷积层次上进行，从而能够识别图像中的简单特征（如边缘、纹理）和复杂特征（如物体、面部等）。</p>
<span id="more"></span>
<h3 id="2-基本结构"><a href="#2-基本结构" class="headerlink" title="2.基本结构"></a>2.基本结构</h3><ol>
<li><strong>卷积层（Convolutional Layer）</strong>：也是CNN核心部分，通过卷积核在输入数据（如图像）上滑动，逐步提取边缘、纹理、角点等局部特征。卷积层会将输入数据映射到多个特征图（Feature Maps），每个卷积核生成一个特征图，即输出的通道数等于卷积核的数量。</li>
<li><strong>池化层（Pooling Layer）</strong>：用于 <strong>下采样</strong>，减少特征图的尺寸，从而减少计算量、提高模型的计算效率，并防止过拟合。常用的池化方法包括 <strong>最大池化</strong>（Max Pooling）和 <strong>平均池化</strong>（Average Pooling）。</li>
<li><strong>激活函数</strong>：卷积层和全连接层的输出通常会通过 <strong>激活函数</strong>（如 ReLU、Sigmoid 或 Tanh）进行非线性变换，以帮助模型学习复杂的特征。</li>
<li><strong>全连接层（Fully Connected Layer）</strong>：一般放在CNN的最后，通常会通过一个或多个全连接层将提取到的特征转换为最终输出。比如，图像分类的类别概率。</li>
</ol>
<h3 id="3-特点"><a href="#3-特点" class="headerlink" title="3.特点"></a>3.特点</h3><ol>
<li><strong>局部连接</strong>：每个卷积核只与输入数据的一个小区域进行连接（局部感受野），这样可以有效地捕捉数据的局部特征（如图像中的边缘、角点、纹理等）</li>
<li><strong>共享权重</strong>：同一个卷积核在所有输入区域使用相同的权重参数，这大大减少了参数的数量，提高了计算效率</li>
<li><strong>层次化特征提取</strong>：CNN 可以通过多层卷积操作逐层提取数据的特征，从低级特征（如边缘）到高级特征（如物体的形状），这种层次化的特征提取方式能够捕捉复杂的模式</li>
<li><strong>平移不变性</strong>：CNN 通过卷积操作具备一定的 <strong>平移不变性</strong>，即如果图像中的物体发生平移，卷积层仍能有效地识别物体。这是因为卷积核在图像中滑动，每个区域的特征都有相同的权重</li>
<li><strong>高效的参数共享</strong>：由于卷积核共享权重，CNN 的参数数量远低于传统的全连接神经网络，这样使得 CNN 更适合处理大型图像数据集，且训练时所需的计算和内存资源较少</li>
</ol>
<h2 id="2-数据集处理"><a href="#2-数据集处理" class="headerlink" title="2.数据集处理"></a>2.数据集处理</h2><p>加载 <strong>MNIST 数据集</strong>，并对数据进行预处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>():  </span><br><span class="line">    train_ds = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>,  </span><br><span class="line">                              train=<span class="literal">True</span>,  </span><br><span class="line">                              transform=transforms.ToTensor(),  </span><br><span class="line">                              download=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    test_ds = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>,  </span><br><span class="line">                             train=<span class="literal">False</span>,  </span><br><span class="line">                             transform=transforms.ToTensor())  </span><br><span class="line">    <span class="keyword">return</span> train_ds, test_ds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_loader</span>(<span class="params">train_ds, test_ds</span>):  </span><br><span class="line">    train_dl = torch.utils.data.DataLoader(dataset=train_ds,  </span><br><span class="line">                                           batch_size=batch_size,  </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)  </span><br><span class="line">    test_dl = torch.utils.data.DataLoader(dataset=test_ds,  </span><br><span class="line">                                          batch_size=batch_size,  </span><br><span class="line">                                          shuffle=<span class="literal">True</span>)  </span><br><span class="line">    <span class="keyword">return</span> train_dl, test_dl</span><br></pre></td></tr></table></figure>

<h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1.加载数据"></a>1.加载数据</h3><p>从 <code>torchvision</code>的datasets中导入自带的MNIST数据集并保存在<code>root</code>路径下，<code>train=True</code>，表示加载的是训练集（train&#x3D;False 则表示加载测试集）。</p>
<p>常用的数据集：<br>• <strong>图像分类</strong>：CIFAR-10、ImageNet等<br>• <strong>目标检测与分割</strong>：COCO、PASCAL VOC、Cityscapes等<br>• <strong>人脸识别</strong>：LFW（Labeled Faces in the Wild）<br>• <strong>支持学习与小样本学习</strong>：Omniglot</p>
<p>这些数据集大大方便了研究人员、开发者进行计算机视觉任务的训练和测试。随着计算机视觉的发展，datasets模块也在不断更新扩展中。</p>
<p>数据加载器（DataLoader）为了高效批量加载数据，batch_size为每个批次的数据量，shuffle表示是否打乱数据</p>
<h3 id="2-预处理"><a href="#2-预处理" class="headerlink" title="2.预处理"></a>2.预处理</h3><p><code>transforms.ToTensor()</code> 会将加载的图像数据转换为 <strong>张量（Tensor）</strong>，并将像素值从 [0, 255] 范围缩放到 [0, 1] 范围。此转换是为了方便后续神经网络训练。</p>
<h2 id="3-模型定义"><a href="#3-模型定义" class="headerlink" title="3.模型定义"></a>3.模型定义</h2><p><code>Mnist_CNN</code>模型中，包括两部分构造函数和前向传播，前向传播函数会在模型训练的时候自动调用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mnist_CNN</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Mnist_CNN, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Sequential(         <span class="comment"># 输入大小 (1, 28, 28)        </span></span><br><span class="line">	        nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),  </span><br><span class="line">            nn.ReLU(),                      <span class="comment"># relu层  </span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),    <span class="comment"># 进行池化操作</span></span><br><span class="line">        )                                   <span class="comment"># 输出(16, 14, 14)</span></span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),     <span class="comment"># 输出 (32, 14, 14)     </span></span><br><span class="line">            nn.ReLU(),                      <span class="comment"># relu层  </span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),                <span class="comment"># 进行池化操作</span></span><br><span class="line">		)                                   <span class="comment"># 输出 (32, 7, 7)    </span></span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.ReLU(),                         </span><br><span class="line">	    )                                   <span class="comment"># 输出 (64, 7, 7)</span></span><br><span class="line">	      </span><br><span class="line">        <span class="variable language_">self</span>.out = nn.Linear(<span class="number">64</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>)<span class="comment"># 全连接层得到的结果  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)  </span><br><span class="line">        x = <span class="variable language_">self</span>.conv3(x)  </span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)           <span class="comment"># flatten操作 (batch_size, 32 * 7 * 7)  </span></span><br><span class="line">        output = <span class="variable language_">self</span>.out(x)  </span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="1-构造函数"><a href="#1-构造函数" class="headerlink" title="1.构造函数"></a>1.构造函数</h3><p>构造函数会初始化神经网络的各个层，模型中定义了三个卷积层和一个全连接层：</p>
<h4 id="1-卷积层conv1"><a href="#1-卷积层conv1" class="headerlink" title="1.卷积层conv1"></a>1.卷积层conv1</h4><p><strong>nn.Conv2d</strong>：这是一个二维卷积层，用来提取输入图像的局部特征</p>
<ul>
<li><code>in_channels=1</code>：输入图像的通道数，MNIST 图像是单通道（灰度图），所以是 1</li>
<li><code>out_channels=16</code>：卷积层输出的特征图的通道数，设置为16，意味着该层将学习16个不同的特征</li>
<li><code>kernel_size=5</code>：卷积核的大小为5x5</li>
<li><code>padding=2</code>：在图像边缘添加2个像素的零填充，目的是让输出图像的大小与输入相对称</li>
</ul>
<p><strong>nn.ReLU()</strong>：这是一个激活函数层，使用 ReLU（Rectified Linear Unit）激活函数来对卷积结果进行非线性映射，ReLU 的作用是将所有负值置为零。</p>
<p><strong>nn.MaxPool2d</strong>：池化层，进行下采样（降维）操作。kernel_size&#x3D;2：池化窗口大小是2x2，表示每个2x2的区域都会被池化成一个最大值（最大池化），池化操作可以降低计算量并提取最重要的特征。</p>
<p>输出尺寸：原始输入图像的尺寸是 (28, 28)，经过卷积后，尺寸为 (28, 28)，再加上池化操作，最终输出为 (16, 14, 14)，也就是16个14x14的特征图。</p>
<h4 id="2-卷积层conv2"><a href="#2-卷积层conv2" class="headerlink" title="2.卷积层conv2"></a>2.卷积层conv2</h4><p>作用类似conv1，只是输入和输出的通道数发生了变化：</p>
<ul>
<li>输入通道是16（来自上一层 conv1 的输出），输出通道是32</li>
<li>卷积核大小、步长和填充方式保持不变</li>
</ul>
<p>输出尺寸：经过卷积和池化后，输出特征图的尺寸是 (32, 7, 7)，即32个7x7的特征图。</p>
<h4 id="3-卷积层conv3"><a href="#3-卷积层conv3" class="headerlink" title="3.卷积层conv3"></a>3.卷积层conv3</h4><p>作用同conv1和conv1，输入通道是32，输出通道是64，卷积核大小、步长和填充方式保持不变。<br>输出尺寸：经过这一层后，输出的特征图尺寸是 (64, 7, 7)，即64个7x7的特征图。</p>
<h4 id="4-全连接层out"><a href="#4-全连接层out" class="headerlink" title="4.全连接层out"></a>4.全连接层out</h4><p>做一个10分类的操作，将卷积层提取的特征映射到最终的分类结果</p>
<ul>
<li>因为conv3输出的特征图的尺寸是 (64, 7, 7)，输入特征的数量是 64 x 7 x 7 &#x3D; 3136</li>
<li>因为MNIST数据集有10个数字类别（0-9），输出特征的数量是 10</li>
</ul>
<h3 id="2-前向传播"><a href="#2-前向传播" class="headerlink" title="2.前向传播"></a>2.前向传播</h3><p>数据从输入到输出的流动过程，依次通过三个卷积层和一个全连接层</p>
<ul>
<li><code>x = self.conv1(x)</code>：输入数据首先通过 conv1 层，输出经过 ReLU 激活和池化后的特征</li>
<li><code>x = self.conv2(x)</code>：接着通过 conv2 层，继续提取特征</li>
<li><code>x = self.conv3(x)</code>：然后经过 conv3 层，进一步提取深层特征</li>
<li><code>x = x.view(x.size(0), -1)</code>：这里将卷积层输出的特征图展平（flatten）为一维向量，将(64, 7, 7)特征图转化为64 * 7 * 7 &#x3D; 3136个特征。x.size(0) 是批次大小（batch_size），-1 代表根据批次大小自动计算展平后的大小</li>
<li><code>output = self.out(x)</code>：将展平后的向量通过全连接层，输出 10 个分类结果</li>
</ul>
<h2 id="4-模型训练和验证"><a href="#4-模型训练和验证" class="headerlink" title="4.模型训练和验证"></a>4.模型训练和验证</h2><h3 id="1-计算准确率"><a href="#1-计算准确率" class="headerlink" title="1.计算准确率"></a>1.计算准确率</h3><p>返回预测正确的样本数和总样本数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">predictions, labels</span>):  </span><br><span class="line">    pred = torch.<span class="built_in">max</span>(predictions.data, <span class="number">1</span>)[<span class="number">1</span>]  </span><br><span class="line">    rights = pred.eq(labels.data.view_as(pred)).<span class="built_in">sum</span>()  </span><br><span class="line">    <span class="keyword">return</span> rights, <span class="built_in">len</span>(labels)</span><br></pre></td></tr></table></figure>
<p>实现：</p>
<ul>
<li><code>torch.max(predictions.data, 1)[1]</code>：返回每个样本在所有类别中最大概率的类别（即预测的类别）。torch.max 返回两个值，第一个是最大值，第二个是最大值对应的索引（即预测类别）</li>
<li><code>pred.eq(labels.data.view_as(pred))</code>：eq 函数用于判断预测值和真实标签是否相等。如果相等返回 True，否则返回 False</li>
<li><code>sum()</code>：统计预测正确的样本数</li>
</ul>
<h3 id="2-训练验证模型"><a href="#2-训练验证模型" class="headerlink" title="2.训练验证模型"></a>2.训练验证模型</h3><p>训练模型的主函数，进行<strong>模型训练</strong>和<strong>评估</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_loader, test_loader, num_epochs</span>):  </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):  </span><br><span class="line">        <span class="comment"># 当前epoch的训练结果</span></span><br><span class="line">        train_rights = []  </span><br><span class="line">        <span class="comment"># 针对容器中的每一批进行循环  </span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">            model.train()  </span><br><span class="line">            output = model(data)  </span><br><span class="line">            loss = criterion(output, target)  </span><br><span class="line">            optimizer.zero_grad()  </span><br><span class="line">            loss.backward()  </span><br><span class="line">            optimizer.step()  </span><br><span class="line">            right = accuracy(output, target)  </span><br><span class="line">            train_rights.append(right)  </span><br><span class="line">		</span><br><span class="line">            <span class="comment"># 每100个批次输出一次训练进度和损失</span></span><br><span class="line">            <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:  </span><br><span class="line">  </span><br><span class="line">                model.<span class="built_in">eval</span>()  </span><br><span class="line">                val_rights = []  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 迭代测试集中的每个批次</span></span><br><span class="line">                <span class="keyword">for</span> (data, target) <span class="keyword">in</span> test_loader:  </span><br><span class="line">                    output = model(data)  </span><br><span class="line">                    right = accuracy(output, target)  </span><br><span class="line">                    val_rights.append(right)  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 准确率计算  </span></span><br><span class="line">                train_r = (<span class="built_in">sum</span>([tup[<span class="number">0</span>] <span class="keyword">for</span> tup <span class="keyword">in</span> train_rights]), <span class="built_in">sum</span>([tup[<span class="number">1</span>] <span class="keyword">for</span> tup <span class="keyword">in</span> train_rights]))  </span><br><span class="line">                val_r = (<span class="built_in">sum</span>([tup[<span class="number">0</span>] <span class="keyword">for</span> tup <span class="keyword">in</span> val_rights]), <span class="built_in">sum</span>([tup[<span class="number">1</span>] <span class="keyword">for</span> tup <span class="keyword">in</span> val_rights]))  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 训练进度  </span></span><br><span class="line">                train_percent = <span class="number">100</span> * batch_idx / <span class="built_in">len</span>(train_loader)  </span><br><span class="line">                <span class="comment"># 训练集准确率  </span></span><br><span class="line">                train_set_accurate = <span class="number">100</span> * train_r[<span class="number">0</span>].numpy() / train_r[<span class="number">1</span>]  </span><br><span class="line">                <span class="comment"># 测试集正确率  </span></span><br><span class="line">                test_set_accurate = <span class="number">100</span> * val_r[<span class="number">0</span>].numpy() / val_r[<span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;&quot;&quot;当前epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> 训练进度:<span class="subst">&#123;train_percent:<span class="number">.0</span>f&#125;</span>% 损失:<span class="subst">&#123;loss.data:<span class="number">.6</span>f&#125;</span> 训练集准确率: <span class="subst">&#123;train_set_accurate:<span class="number">.2</span>f&#125;</span>% 测试集正确率: <span class="subst">&#123;test_set_accurate:<span class="number">.2</span>f&#125;</span>% &quot;&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>每个 epoch 中会执行以下步骤，每次迭代叫做一个epoch：</p>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul>
<li><code>for batch_idx, (data, target) in enumerate(train_loader):</code>：对于训练数据集（通过 train_loader 加载），每次获取一个批次的输入数据 data 和目标标签 target</li>
<li><code>model.train()</code>：将模型设置为训练模式（启用 dropout 和 batch normalization 等层）</li>
<li><code>output = model(data)</code>：通过模型对输入 data 进行前向传播，得到输出 output</li>
<li><code>loss = criterion(output, target)</code>：计算预测值 output 与真实标签 target 之间的损失（如交叉熵损失）</li>
<li><code>optimizer.zero_grad()</code>：在每个步骤之前清空梯度，以避免梯度累积</li>
<li><code>loss.backward()</code>：做反向传播，计算损失的梯度</li>
<li><code>optimizer.step()</code>：更新模型的参数（使用梯度下降或其他优化算法）</li>
</ul>
<h4 id="准确率计算"><a href="#准确率计算" class="headerlink" title="准确率计算"></a>准确率计算</h4><ul>
<li><code>right = accuracy(output, target)</code>：通过 accuracy 函数计算当前批次的正确预测数量</li>
<li><code>train_rights.append(right)</code>：将当前批次的正确预测数目添加到 train_rights 列表中</li>
</ul>
<h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><ul>
<li><code>model.eval()</code>：将模型设置为评估模式（禁用 dropout 和 batch normalization）</li>
<li><code>val_rights = []</code>：初始化 val_rights 列表来存储验证集的准确率</li>
<li><code>output = model(data)</code>：计算模型对测试集的预测</li>
<li><code>right = accuracy(output, target)</code>：计算当前批次的正确预测数</li>
<li><code>val_rights.append(right)</code>：将当前批次的预测结果添加到 val_rights</li>
</ul>
<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p>三次epoch输出，测试集正确率相比单纯利用神经网络构建的97%要高一点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前epoch:1 训练进度:0% 损失:2.298599 训练集准确率: 14.06% 测试集正确率: 10.32% </span><br><span class="line">当前epoch:1 训练进度:11% 损失:0.243815 训练集准确率: 78.31% 测试集正确率: 93.28% </span><br><span class="line">当前epoch:1 训练进度:21% 损失:0.137110 训练集准确率: 86.57% 测试集正确率: 96.24% </span><br><span class="line">当前epoch:1 训练进度:32% 损失:0.146362 训练集准确率: 89.68% 测试集正确率: 96.94% </span><br><span class="line">当前epoch:1 训练进度:43% 损失:0.161816 训练集准确率: 91.50% 测试集正确率: 97.73% </span><br><span class="line">当前epoch:1 训练进度:53% 损失:0.059365 训练集准确率: 92.69% 测试集正确率: 97.47% </span><br><span class="line">当前epoch:1 训练进度:64% 损失:0.114041 训练集准确率: 93.52% 测试集正确率: 98.34% </span><br><span class="line">当前epoch:1 训练进度:75% 损失:0.100607 训练集准确率: 94.16% 测试集正确率: 98.22% </span><br><span class="line">当前epoch:1 训练进度:85% 损失:0.006606 训练集准确率: 94.65% 测试集正确率: 98.47% </span><br><span class="line">当前epoch:1 训练进度:96% 损失:0.043186 训练集准确率: 95.04% 测试集正确率: 98.83% </span><br><span class="line">当前epoch:2 训练进度:0% 损失:0.003247 训练集准确率: 100.00% 测试集正确率: 98.75% </span><br><span class="line">当前epoch:2 训练进度:11% 损失:0.077238 训练集准确率: 98.47% 测试集正确率: 98.81% </span><br><span class="line">当前epoch:2 训练进度:21% 损失:0.032691 训练集准确率: 98.39% 测试集正确率: 98.75% </span><br><span class="line">当前epoch:2 训练进度:32% 损失:0.019059 训练集准确率: 98.47% 测试集正确率: 98.61% </span><br><span class="line">当前epoch:2 训练进度:43% 损失:0.172091 训练集准确率: 98.46% 测试集正确率: 98.73% </span><br><span class="line">当前epoch:2 训练进度:53% 损失:0.023476 训练集准确率: 98.50% 测试集正确率: 98.76% </span><br><span class="line">当前epoch:2 训练进度:64% 损失:0.013946 训练集准确率: 98.53% 测试集正确率: 98.97% </span><br><span class="line">当前epoch:2 训练进度:75% 损失:0.011354 训练集准确率: 98.57% 测试集正确率: 98.91% </span><br><span class="line">当前epoch:2 训练进度:85% 损失:0.024460 训练集准确率: 98.60% 测试集正确率: 98.98% </span><br><span class="line">当前epoch:2 训练进度:96% 损失:0.021631 训练集准确率: 98.63% 测试集正确率: 98.97% </span><br><span class="line">当前epoch:3 训练进度:0% 损失:0.055015 训练集准确率: 96.88% 测试集正确率: 98.94% </span><br><span class="line">当前epoch:3 训练进度:11% 损失:0.060590 训练集准确率: 99.12% 测试集正确率: 99.07% </span><br><span class="line">当前epoch:3 训练进度:21% 损失:0.066504 训练集准确率: 99.04% 测试集正确率: 98.85% </span><br><span class="line">当前epoch:3 训练进度:32% 损失:0.004511 训练集准确率: 99.03% 测试集正确率: 98.95% </span><br><span class="line">当前epoch:3 训练进度:43% 损失:0.019243 训练集准确率: 99.00% 测试集正确率: 99.17% </span><br><span class="line">当前epoch:3 训练进度:53% 损失:0.037509 训练集准确率: 99.01% 测试集正确率: 99.08% </span><br><span class="line">当前epoch:3 训练进度:64% 损失:0.004599 训练集准确率: 99.03% 测试集正确率: 98.95% </span><br><span class="line">当前epoch:3 训练进度:75% 损失:0.089442 训练集准确率: 99.01% 测试集正确率: 99.12% </span><br><span class="line">当前epoch:3 训练进度:85% 损失:0.018963 训练集准确率: 99.04% 测试集正确率: 98.58% </span><br><span class="line">当前epoch:3 训练进度:96% 损失:0.000661 训练集准确率: 99.04% 测试集正确率: 99.12% </span><br></pre></td></tr></table></figure>
<h3 id="3-调用"><a href="#3-调用" class="headerlink" title="3.调用"></a>3.调用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_size = <span class="number">28</span>  <span class="comment"># 图像的总尺寸28*28  </span></span><br><span class="line">num_epochs = <span class="number">3</span>   <span class="comment"># 训练的总循环周期  </span></span><br><span class="line">batch_size = <span class="number">64</span>  <span class="comment"># 一个批次的大小，64张图片  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 训练集 测试机  </span></span><br><span class="line">train_dataset, test_dataset = load_dataset()  </span><br><span class="line">train_loader, test_loader = load_loader(train_dataset, test_dataset)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 模型  </span></span><br><span class="line">model = Mnist_CNN()  </span><br><span class="line"><span class="comment"># 损失函数  </span></span><br><span class="line">criterion = nn.CrossEntropyLoss()  </span><br><span class="line"><span class="comment"># 优化器  </span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>) </span><br><span class="line"><span class="comment"># 训练  </span></span><br><span class="line">train(model, train_loader, test_loader, num_epochs)</span><br></pre></td></tr></table></figure>

<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>CrossEntropyLoss是PyTorch 中一个常用的损失函数，专门用于 <strong>分类任务</strong>，尤其是多类别分类。它结合了 <strong>Softmax</strong> 函数和 <strong>负对数似然损失</strong>（Negative Log-Likelihood Loss），用于处理分类任务中 <strong>概率输出</strong> 的问题。<br>适用范围：真实标签应该是一个 <strong>整数</strong>，表示每个样本的真实类别索引（而不是 one-hot 编码）</p>
<h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p><strong>Adam</strong> 是一种常用的优化算法，全名为 <strong>Adaptive Moment Estimation</strong>，它结合了 <strong>Momentum</strong> 和 <strong>RMSprop</strong> 的优点，能够自动调整学习率来提高训练效果，Adam 优化器会通过计算一阶矩（梯度的均值）和二阶矩（梯度的平方均值）来动态调整每个参数的学习率，从而提高训练的效率和稳定性。<br>适用范围：一种自适应优化算法，非常适用于大多数任务，尤其是当模型参数多，训练过程复杂的时候。</p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>本文主要讲通过使用卷积神经网络来实现手写数字识别，相较于神经网络使用卷积神经网络更适合处理图像、视频、语音、文本等的数据，正确率也相对高一点。</p>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
</ul>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/003_cnn_digital_recognition">https://github.com/keychankc/dl_code_for_blog/tree/main/003_cnn_digital_recognition</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>模型训练</tag>
        <tag>卷积神经网络</tag>
        <tag>卷积层</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV之信用卡卡号识别</title>
    <url>/2025/03/18/006-opencv-credit-card-ocr/</url>
    <content><![CDATA[<h2 id="1-OpenCV概述"><a href="#1-OpenCV概述" class="headerlink" title="1.OpenCV概述"></a>1.OpenCV概述</h2><p>OpenCV（Open Source Computer Vision Library）是一个开源的计算机视觉和图像处理库，主要用于 <strong>图像处理、视频分析、机器视觉、深度学习</strong> 等领域。它最初由 Intel 研发，现在由 <strong>OpenCV 组织</strong> 维护，目前支持 C++、Python、Java 等多种语言。擅长领域有：</p>
<ol>
<li>图像处理<ul>
<li>去噪：去掉照片上的噪点，让图像更清晰</li>
<li>平滑 &amp; 锐化：模糊处理（比如美颜相机的磨皮）、增强边缘（让模糊的字变得更清楚）</li>
<li>颜色调整：可以把彩色图转换成黑白图（灰度化），或者增强对比度</li>
<li>图像分割：把图片中的不同区域分开，比如把人的头像从背景中抠出来（绿幕抠像）</li>
</ul>
</li>
<li>物体检测与识别<ul>
<li>人脸检测：找到照片或视频里的人脸，并画出边框（Haar 级联分类器、DNN）</li>
<li>车牌识别：用于交通监控，自动读取车牌号码</li>
<li>目标检测：找出图片中的特定物体，比如识别商店里的商品、扫描条形码等</li>
</ul>
</li>
</ol>
<span id="more"></span>
<ol start="3">
<li> 运动跟踪<ul>
<li>光流法（Optical Flow）：计算物体在连续帧中的运动轨迹</li>
<li>目标跟踪算法（KCF, CSRT, Meanshift 等）：给定一个目标，让电脑自动跟踪它</li>
<li>背景建模（Background Subtraction）：检测哪些像素在变动，适用于监控场景</li>
</ul>
</li>
<li>视频处理<ul>
<li>视频稳定：去除视频抖动，让画面更流畅</li>
<li>背景去除：提取前景人物，换掉背景，比如绿幕抠像</li>
<li>帧间差分：检测视频中的移动物体，比如监控摄像头检测入侵者</li>
</ul>
</li>
<li>深度学习<ul>
<li>人脸识别（Face Recognition）: 结合 DNN 深度神经网络，实现人脸对比、身份认证</li>
<li>目标检测（Object Detection）:结合YOLO、SSD、Faster R-CNN 等深度学习模型</li>
<li>图像分割（Image Segmentation）:分割出物体的精确轮廓，而不仅仅是简单画个边框</li>
</ul>
</li>
</ol>
<h2 id="2-概述"><a href="#2-概述" class="headerlink" title="2.概述"></a>2.概述</h2><h3 id="1-目标"><a href="#1-目标" class="headerlink" title="1.目标"></a>1.目标</h3><p>识别信用卡数字，在控制台输出，同时在信用卡上标注出来。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250318132220.png"></p>
<h3 id="2-流程"><a href="#2-流程" class="headerlink" title="2.流程"></a>2.流程</h3><p>先解析模板数字，获取数字以及对应的数字轮廓特征，再解析信用卡指定位置数字轮廓特征，与模板数字做匹配，获取对应识别结果并标注出来。</p>
<h3 id="3-参数设置"><a href="#3-参数设置" class="headerlink" title="3.参数设置"></a>3.参数设置</h3><p>对应信用卡图片路径和模板图片路径配置参数<br><code>--image imgs/credit_card_02.png --template ocr_a_reference.png</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置参数  </span></span><br><span class="line">ap = argparse.ArgumentParser()  </span><br><span class="line">ap.add_argument(<span class="string">&quot;-i&quot;</span>, <span class="string">&quot;--image&quot;</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&quot;path to input image&quot;</span>)  </span><br><span class="line">ap.add_argument(<span class="string">&quot;-t&quot;</span>, <span class="string">&quot;--template&quot;</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&quot;path to template OCR-A image&quot;</span>)  </span><br><span class="line">args = <span class="built_in">vars</span>(ap.parse_args())</span><br></pre></td></tr></table></figure>
<h2 id="2-数字模板处理"><a href="#2-数字模板处理" class="headerlink" title="2.数字模板处理"></a>2.数字模板处理</h2><p>解析图像模板，提取 数字字符的轮廓，并将其存储为模板数据，方便后续匹配识别</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘图展示(任意按键消失)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cv_show</span>(<span class="params">name, _img</span>):  </span><br><span class="line">    cv2.imshow(name, _img)  </span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)  </span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sort_contours</span>(<span class="params">contours, method=<span class="string">&quot;left-to-right&quot;</span></span>):  </span><br><span class="line">    <span class="comment"># 1️⃣ 确定排序方式，默认升序，从左到右从上到下</span></span><br><span class="line">    reverse = <span class="literal">False</span>  </span><br><span class="line">    i = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&quot;right-to-left&quot;</span> <span class="keyword">or</span> method == <span class="string">&quot;bottom-to-top&quot;</span>:  </span><br><span class="line">        reverse = <span class="literal">True</span>  </span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&quot;top-to-bottom&quot;</span> <span class="keyword">or</span> method == <span class="string">&quot;bottom-to-top&quot;</span>:  </span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2️⃣ 计算轮廓的外接矩形，bounding_boxes轮廓位置大小</span></span><br><span class="line">    bounding_boxes = [cv2.boundingRect(c) <span class="keyword">for</span> c <span class="keyword">in</span> contours]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3️⃣ 按指定方向排序，将轮廓和对应的边界框绑定在一起</span></span><br><span class="line">    (_contours, bounding_boxes) = <span class="built_in">zip</span>(*<span class="built_in">sorted</span>(<span class="built_in">zip</span>(contours, bounding_boxes), key=<span class="keyword">lambda</span> b: b[<span class="number">1</span>][i], reverse=reverse))  </span><br><span class="line">    <span class="keyword">return</span> _contours, bounding_boxes</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resize</span>(<span class="params">image, width=<span class="literal">None</span>, height=<span class="literal">None</span>, inter=cv2.INTER_AREA</span>): </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    按比例缩放图片，支持指定宽度或高度 进行等比例缩放，避免图片失真  </span></span><br><span class="line"><span class="string">    :param image: 输入图像（numpy 数组）  </span></span><br><span class="line"><span class="string">    :param width: 目标 宽度，如果设为 None，则按 高度等比例缩放  </span></span><br><span class="line"><span class="string">    :param height: 目标 高度，如果设为 None，则按 宽度等比例缩放  </span></span><br><span class="line"><span class="string">    :param inter: 插值方法，默认使用 cv2.INTER_AREA（适用于缩小图片）  </span></span><br><span class="line"><span class="string">    :return: 图像（numpy 数组）  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1️⃣ 获取图像的原始宽高</span></span><br><span class="line">    dim = <span class="literal">None</span>  </span><br><span class="line">    (h, w) = image.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 2️⃣ 如果width和height 都为空，返回原图</span></span><br><span class="line">    <span class="keyword">if</span> width <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> height <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line">    <span class="comment"># 3️⃣ 计算新的尺寸</span></span><br><span class="line">    <span class="keyword">if</span> width <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">        r = height / <span class="built_in">float</span>(h)  </span><br><span class="line">        dim = (<span class="built_in">int</span>(w * r), height)  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">        dim = (width, <span class="built_in">int</span>(h * r))</span><br><span class="line">    <span class="comment"># 4️⃣ 执行缩放</span></span><br><span class="line">    resized = cv2.resize(image, dim, interpolation=inter)  </span><br><span class="line">    <span class="keyword">return</span> resized</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">template_parsing</span>(<span class="params">_template_img</span>):  </span><br><span class="line">    <span class="comment"># 1️⃣ 颜色转换：灰度化，将原始图片转换为灰度图像（去掉颜色信息）</span></span><br><span class="line">    <span class="comment"># 作用：减少计算量，提高后续处理速度</span></span><br><span class="line">    ref = cv2.cvtColor(_template_img, cv2.COLOR_BGR2GRAY)  </span><br><span class="line">    cv_show(<span class="string">&#x27;COLOR_BGR2GRAY&#x27;</span>, ref)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2️⃣ 二值化处理，像素值≤10变为白色（255），像素值&gt;10变为黑色（0）</span></span><br><span class="line">    <span class="comment"># 作用：突出白色数字/字符，便于后续轮廓检测</span></span><br><span class="line">    ref = cv2.threshold(ref, <span class="number">10</span>, <span class="number">255</span>, cv2.THRESH_BINARY_INV)[<span class="number">1</span>]  </span><br><span class="line">    cv_show(<span class="string">&#x27;THRESH_BINARY_INV&#x27;</span>, ref)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3️⃣ 轮廓检测，提取二值图中的轮廓</span></span><br><span class="line">    <span class="comment"># RETR_EXTERNAL 只提取外部轮廓，避免嵌套干扰</span></span><br><span class="line">    <span class="comment"># CHAIN_APPROX_SIMPLE 只存储必要的边界点，提高计算效率</span></span><br><span class="line">    ref_contours, _ = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  </span><br><span class="line">    <span class="comment"># 在原图上绘制轮廓红色，线宽1px</span></span><br><span class="line">    <span class="comment"># ref_contours:轮廓列表  -1:绘制所有轮廓  (0, 0, 255):红色   1:轮廓的线宽  </span></span><br><span class="line">    cv2.drawContours(_template_img, ref_contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)  </span><br><span class="line">    cv_show(<span class="string">&#x27;drawContours&#x27;</span>, _template_img)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4️⃣ 轮廓排序</span></span><br><span class="line">    <span class="comment"># 作用：按从左到右的顺序排列轮廓，确保数字顺序正确</span></span><br><span class="line">    ref_contours = utils.sort_contours(ref_contours, method=<span class="string">&quot;left-to-right&quot;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5️⃣ 提取单个数字区域</span></span><br><span class="line">    _digits_dict = &#123;&#125;  </span><br><span class="line">    <span class="keyword">for</span> (i, c) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ref_contours):  </span><br><span class="line">        (x, y, w, h) = cv2.boundingRect(c)  <span class="comment"># 获取最小外接矩形 </span></span><br><span class="line">        roi = ref[y:y + h, x:x + w]  <span class="comment"># 截取对应区域，提取数字</span></span><br><span class="line">        roi = cv2.resize(roi, (<span class="number">57</span>, <span class="number">88</span>))  <span class="comment"># 归一化尺寸，保证所有数字大小一致</span></span><br><span class="line">        _digits_dict[i] = roi  <span class="comment"># 以索引i作为key，以数字模板roi作为value </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6️⃣ 显示提取出的数字</span></span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> _digits_dict.items():  </span><br><span class="line">        cv_show(<span class="string">f&quot;Digit <span class="subst">&#123;key&#125;</span>&quot;</span>, value)  <span class="comment"># value是0~255的二维像素矩阵</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> _digits_dict  <span class="comment"># 用于后续模板匹配</span></span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250318141853.png"></p>
<h2 id="3-信用卡解析"><a href="#3-信用卡解析" class="headerlink" title="3.信用卡解析"></a>3.信用卡解析</h2><p>解析信用卡图像，提取卡号区域，并返回卡号的位置信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">credit_card_parsing</span>(<span class="params">_card_img</span>):  </span><br><span class="line">    <span class="comment"># 1️⃣ 将图像转换为灰度图,减少计算复杂度</span></span><br><span class="line">    gray = cv2.cvtColor(_card_img, cv2.COLOR_BGR2GRAY)  </span><br><span class="line">    cv_show(<span class="string">&#x27;gray&#x27;</span>, gray)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建了一个宽度为9，高度为3的矩形结构元素，适用于细长的信用卡号</span></span><br><span class="line">    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">9</span>, <span class="number">3</span>))  </span><br><span class="line">    <span class="comment"># 2️⃣ 进行顶帽变换（Top-Hat）（先腐蚀再膨胀），增强比背景亮的细小区域</span></span><br><span class="line">    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rect_kernel)  </span><br><span class="line">    cv_show(<span class="string">&#x27;tophat&#x27;</span>, tophat)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3️⃣ 计算水平梯度（Sobel 算子），检测水平方向的变化，适用于信用卡号的横向排列</span></span><br><span class="line">    grad_x = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=<span class="number">1</span>, dy=<span class="number">0</span>, ksize=-<span class="number">1</span>)  </span><br><span class="line">    grad_x = np.absolute(grad_x)  <span class="comment"># 取绝对值  </span></span><br><span class="line">    (minVal, maxVal) = (np.<span class="built_in">min</span>(grad_x), np.<span class="built_in">max</span>(grad_x))  <span class="comment"># gradX的最大和最小值  </span></span><br><span class="line">    grad_x = (<span class="number">255</span> * ((grad_x - minVal) / (maxVal - minVal)))  <span class="comment"># 将梯度值转换为图像像素值（0 表示黑色，255 表示白色）  </span></span><br><span class="line">    grad_x = grad_x.astype(<span class="string">&quot;uint8&quot;</span>)  <span class="comment"># 类型转8位无符号整型，[0, 255]  </span></span><br><span class="line">    cv_show(<span class="string">&#x27;gradX1&#x27;</span>, grad_x)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4️⃣ 通过闭操作（先膨胀，再腐蚀）将数字连在一起，减少破碎字符</span></span><br><span class="line">    grad_x = cv2.morphologyEx(grad_x, cv2.MORPH_CLOSE, rect_kernel)  </span><br><span class="line">    cv_show(<span class="string">&#x27;gradX2&#x27;</span>, grad_x)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 5️⃣ 将图像转换为二值图像（即只有黑白两种像素值），大于阈值的像素设置为 255（白色），小于或等于阈值的像素设置为 0（黑色）  </span></span><br><span class="line">    thresh = cv2.threshold(grad_x, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[<span class="number">1</span>]  </span><br><span class="line">    cv_show(<span class="string">&#x27;thresh1&#x27;</span>, thresh)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 6️⃣ 再次闭操作 使用更大的核（5x5）进行闭操作，填补字符内部的小孔洞，确保字符区域完整  </span></span><br><span class="line">    sq_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">5</span>, <span class="number">5</span>))  </span><br><span class="line">    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sq_kernel)  </span><br><span class="line">    cv_show(<span class="string">&#x27;thresh2&#x27;</span>, thresh)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 7️⃣ 计算轮廓：找到所有白色区域的轮廓  </span></span><br><span class="line">    thresh_contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  </span><br><span class="line">    cur_img = _card_img.copy()  </span><br><span class="line">    cv2.drawContours(cur_img, thresh_contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)  </span><br><span class="line">    cv_show(<span class="string">&#x27;img&#x27;</span>, cur_img)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 8️⃣ 过滤&amp;选择可能的卡号区域</span></span><br><span class="line">    _locations = []  </span><br><span class="line">    <span class="keyword">for</span> (i, c) <span class="keyword">in</span> <span class="built_in">enumerate</span>(thresh_contours):  </span><br><span class="line">        (x, y, w, h) = cv2.boundingRect(c)  </span><br><span class="line">        ar = w / <span class="built_in">float</span>(h)  <span class="comment"># 宽高比</span></span><br><span class="line">        <span class="comment"># 选择合适的区域，根据实际任务来，这里的基本都是四个数字一组  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">2.5</span> &lt; ar &lt; <span class="number">4.0</span>:  </span><br><span class="line">            <span class="keyword">if</span> (<span class="number">40</span> &lt; w &lt; <span class="number">55</span>) <span class="keyword">and</span> (<span class="number">10</span> &lt; h &lt; <span class="number">20</span>):  <span class="comment"># 宽 高</span></span><br><span class="line">                _locations.append((x, y, w, h))  </span><br><span class="line">    <span class="comment"># 将符合的轮廓从左到右排序  </span></span><br><span class="line">    <span class="keyword">return</span> gray, <span class="built_in">sorted</span>(_locations, key=<span class="keyword">lambda</span> x1: x1[<span class="number">0</span>])  </span><br><span class="line">    <span class="comment"># [(34, 111, 47, 14), (95, 111, 48, 14), (157, 111, 47, 14), (219, 111, 48, 14)]</span></span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250318150422.png"></p>
<h2 id="4-卡号分割与识别"><a href="#4-卡号分割与识别" class="headerlink" title="4.卡号分割与识别"></a>4.卡号分割与识别</h2><p>流程：</p>
<ol>
<li>遍历卡号区域，对每个区域进行预处理</li>
<li>提取数字轮廓，逐个数字进行匹配</li>
<li>使用模板匹配识别每个数字，并标注到原图上</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detect_parsing_digits</span>(<span class="params">_locations, _gray_img, _card_img, _digits_dict</span>):  </span><br><span class="line">    _output = []  <span class="comment"># 存储完整卡号的识别结果</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    :param _locations: 信用卡号的坐标列表，格式为[(x, y, w, h), ...]  </span></span><br><span class="line"><span class="string">    :param _gray_img: 处理后的灰度图  </span></span><br><span class="line"><span class="string">    :param _card_img: 原始信用卡彩色图，用于绘制识别结果  </span></span><br><span class="line"><span class="string">    :param _digits_dict: 数字模板字典 &#123;0:模板0,1:模板1, ...,9:模板9&#125;，用于模板匹配 </span></span><br><span class="line"><span class="string">    :return: 识别到的数字  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1️⃣ 遍历每个卡号区域</span></span><br><span class="line">    <span class="keyword">for</span> (i, (gX, gY, gW, gH)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(_locations):  </span><br><span class="line">        group_out_put = []  <span class="comment"># 存储当前4位数字的识别结果</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2️⃣ 提取卡号区域</span></span><br><span class="line">        group = _gray_img[gY - <span class="number">5</span>:gY + gH + <span class="number">5</span>, gX - <span class="number">5</span>:gX + gW + <span class="number">5</span>]  </span><br><span class="line">        cv_show(<span class="string">&#x27;group1&#x27;</span>, group)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3️⃣ 二值化处理，将卡号部分变白，背景变黑，提高对比度</span></span><br><span class="line">        group = cv2.threshold(group, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[<span class="number">1</span>] </span><br><span class="line">        cv_show(<span class="string">&#x27;group2&#x27;</span>, group)</span><br><span class="line">         </span><br><span class="line">        <span class="comment"># 4️⃣ 提取每个数字轮廓，确保从左到右排序</span></span><br><span class="line">        digit_contours, _ = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  </span><br><span class="line">        digit_contours = utils.sort_contours(digit_contours, method=<span class="string">&quot;left-to-right&quot;</span>)[<span class="number">0</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 5️⃣ 遍历每个数字轮廓  </span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> digit_contours:  </span><br><span class="line">            <span class="comment"># 裁剪出当前数字roi</span></span><br><span class="line">            (x, y, w, h) = cv2.boundingRect(c)  </span><br><span class="line">            roi = group[y:y + h, x:x + w] </span><br><span class="line">            <span class="comment"># 调整大小 (57, 88)，以匹配模板字典中的尺寸</span></span><br><span class="line">            roi = cv2.resize(roi, (<span class="number">57</span>, <span class="number">88</span>))  </span><br><span class="line">            cv_show(<span class="string">&#x27;roi&#x27;</span>, roi)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 6️⃣ 计算每个数字的匹配得分</span></span><br><span class="line">            scores = []  </span><br><span class="line">            <span class="comment"># 在模板中计算每一个得分  </span></span><br><span class="line">            <span class="keyword">for</span> (digit, digitROI) <span class="keyword">in</span> _digits_dict.items():  </span><br><span class="line">                <span class="comment"># 计算ROI与每个模板的匹配程度</span></span><br><span class="line">                result = cv2.matchTemplate(roi, digitROI, cv2.TM_CCOEFF)</span><br><span class="line">                <span class="comment"># 提取最佳匹配分数</span></span><br><span class="line">                (_, score, _, _) = cv2.minMaxLoc(result)  </span><br><span class="line">                scores.append(score)  </span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 7️⃣ 选择最佳匹配的数字  </span></span><br><span class="line">            group_out_put.append(<span class="built_in">str</span>(np.argmax(scores)))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 8️⃣ 在原图上绘制识别结果 </span></span><br><span class="line">        cv2.rectangle(_card_img, (gX - <span class="number">5</span>, gY - <span class="number">5</span>), (gX + gW + <span class="number">5</span>, gY + gH + <span class="number">5</span>), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)  </span><br><span class="line">        cv2.putText(_card_img, <span class="string">&quot;&quot;</span>.join(group_out_put), (gX, gY - <span class="number">15</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.65</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 9️⃣ 组合最终的信用卡号码</span></span><br><span class="line">        _output.extend(group_out_put)  </span><br><span class="line">    <span class="keyword">return</span> _output</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250318154002.png"></p>
<h2 id="5-整合调用"><a href="#5-整合调用" class="headerlink" title="5.整合调用"></a>5.整合调用</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    image_path = args[<span class="string">&quot;image&quot;</span>]  </span><br><span class="line">    template_path = args[<span class="string">&quot;template&quot;</span>]  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;image:<span class="subst">&#123;image_path&#125;</span>,template:<span class="subst">&#123;template_path&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 模板图片  </span></span><br><span class="line">    template_img = cv2.imread(template_path)  </span><br><span class="line">    cv_show(<span class="string">&#x27;template_img&#x27;</span>, template_img)  </span><br><span class="line">    digits_dict = template_parsing(template_img)  <span class="comment"># 每一个数字对应每一个模板  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 信用卡图片  </span></span><br><span class="line">    card_img = cv2.imread(image_path)  </span><br><span class="line">    card_img = utils.resize(card_img, width=<span class="number">300</span>)  </span><br><span class="line">    cv_show(<span class="string">&#x27;card_img&#x27;</span>, card_img)  </span><br><span class="line">    gray_img, locations = credit_card_parsing(card_img)  <span class="comment"># 灰度图 轮廓 从左到右排序 </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 检测解析 数字  </span></span><br><span class="line">    output = detect_parsing_digits(locations, gray_img, card_img, digits_dict)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 打印结果  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Credit Card #: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;&quot;</span>.join(output)))  </span><br><span class="line">    <span class="comment"># Credit Card #: 4020340002345678</span></span><br><span class="line">    cv2.imshow(<span class="string">&quot;Image&quot;</span>, card_img)  </span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><ol>
<li>模板处理要点<ul>
<li>转换为灰度图 ➝ cv2.cvtColor</li>
<li>二值化 ➝ cv2.threshold</li>
<li>轮廓检测 ➝ cv2.findContours</li>
<li>提取单个数字并归一化 ➝ cv2.boundingRect + cv2.resize</li>
</ul>
</li>
<li>信用卡号区域检测要点<ul>
<li>转换为灰度图 ➝ cv2.cvtColor</li>
<li>顶帽变换（增强数字区域）➝ cv2.morphologyEx</li>
<li>Sobel 梯度计算（检测横向边缘）➝ cv2.Sobel</li>
<li>闭操作（膨胀+腐蚀）（让数字连接在一起）➝ cv2.morphologyEx</li>
<li>二值化 ➝ cv2.threshold</li>
<li>轮廓检测（定位可能的卡号区域）➝ cv2.findContours</li>
<li>过滤候选区域（宽高比筛选）➝ sorted</li>
</ul>
</li>
<li>数字识别要点<ul>
<li>遍历卡号区域，提取感兴趣区域</li>
<li>二值化（提高对比度）</li>
<li>轮廓检测（提取单个数字）</li>
<li>逐个数字与模板匹配 ➝ cv2.matchTemplate</li>
<li>输出最佳匹配的数字</li>
</ul>
</li>
</ol>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
</ul>
<p>资源和代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/006_opencv_credit_card_ocr">https://github.com/keychankc/dl_code_for_blog/tree/main/006_opencv_credit_card_ocr</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>计算机视觉</tag>
        <tag>图像识别</tag>
        <tag>目标检测</tag>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title>基于迁移学习(ResNet-18)的花卉识别</title>
    <url>/2025/03/07/004-cnn-identify-flowers/</url>
    <content><![CDATA[<h2 id="1-迁移学习"><a href="#1-迁移学习" class="headerlink" title="1.迁移学习"></a>1.迁移学习</h2><p>做图像识别是不是每次都意味着要自定义模型，确定好 <strong>卷积层</strong>、<strong>池化层</strong> 和 <strong>全连接层</strong>，然后从0开始训练？不同类型的图像数据集会不会有通用的特征？如果训练样本比较少怎么办？是不是可以把已经训练好的模型，拿过来稍微改改就可以使用的？</p>
<p><strong>迁移学习（Transfer Learning）</strong> 就是这种可以将已有模型的知识迁移到新任务的学习方法，具有以下特点：</p>
<ul>
<li>适合数据量比较少的任务，但是有预训练知识，无需从头训练深度神经网络</li>
<li>更快的训练速度和更少的资源消耗</li>
<li>避免过拟合，训练效果更好，预训练的模型已经在大数据集上学到了<strong>通用特征</strong>（如边缘、形状、颜色）</li>
</ul>
<span id="more"></span>
<p>迁移学习常见的使用方式：</p>
<ol>
<li>冻结预训练模型的大部分参数，仅训练全连接层（FC 层），这样做的优点是训练快，适合小数据集，缺点是预训练模型的特征可能不完全适用于新任务。</li>
<li>解冻部分或全部预训练层，使其适应新任务，优点是特征提取灵活，能学到更多任务相关的特征，缺点是训练时间长，需要手动调节学习率。</li>
</ol>
<p>下面通过一个小样本的花卉识别来介绍一下迁移学习的训练流程。</p>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h2><h3 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1.数据结构"></a>1.数据结构</h3><p>训练集和验证集都是图片，每一个类型的花放在一个文件夹中，文件夹的名称可以通过<code>cat_to_name.json</code>文件匹配对应的花名称。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250306163312.png" alt="训练集和验证集结构" width="300"></p>
<h3 id="2-数据加载与预处理"><a href="#2-数据加载与预处理" class="headerlink" title="2.数据加载与预处理"></a>2.数据加载与预处理</h3><p>由于本次任务训练集数据比较少，为了提高模型的泛化能力和训练效果，需要在做数据预处理的时候做下增强操作。<br>预处理：</p>
<ul>
<li><strong>transforms.Resize([96, 96])</strong>：将图片缩放到 96x96 的大小，统一输入尺寸，保证模型输入一致</li>
<li><strong>transforms.ToTensor()</strong>：将图像从 PIL 图像或 NumPy 数组转换为 PyTorch 的 Tensor 格式<br>增强：</li>
<li><strong>transforms.RandomRotation(45)</strong>：对图像进行随机旋转，角度范围是 -45 到 45 度之间。目的是增加模型对旋转变化的鲁棒性</li>
<li><strong>transforms.CenterCrop(64)</strong>：从图像中心裁剪出 64x64 的区域。减少输入图像的多余部分，增强模型对图像的中心部分的学习</li>
<li><strong>transforms.RandomHorizontalFlip(p&#x3D;0.5)</strong>：有 50% 的概率对图像进行水平翻转，能提高模型对图像左右方向不对称的适应能力</li>
<li><strong>transforms.RandomVerticalFlip(p&#x3D;0.5)</strong>：有 50% 的概率对图像进行垂直翻转，进一步增强模型对图像的多样化学习</li>
<li><strong>transforms.ColorJitter(brightness&#x3D;0.2, contrast&#x3D;0.1, saturation&#x3D;0.1, hue&#x3D;0.1)</strong>：对图像的亮度、对比度、饱和度和色调进行随机调整，增强模型对不同光照条件和颜色变化的鲁棒性</li>
<li><strong>transforms.RandomGrayscale(p&#x3D;0.025)</strong>：有 2.5% 的概率将图像转为灰度图，这样模型能学到更多的图像特征，而不仅仅依赖颜色信息</li>
<li><strong>transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</strong>：标准化图像数据，使用 ImageNet 数据集的均值和标准差。标准化可以加速模型训练并提高收敛速度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据预处理和增强</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_transforms</span>():  </span><br><span class="line">    <span class="keyword">return</span> &#123;  </span><br><span class="line">        <span class="string">&#x27;train&#x27;</span>:  </span><br><span class="line">            transforms.Compose([  </span><br><span class="line">                transforms.Resize([<span class="number">96</span>, <span class="number">96</span>]),  <span class="comment"># 转化成96*96大小的图像数据  </span></span><br><span class="line">                transforms.RandomRotation(<span class="number">45</span>),  <span class="comment"># 数据增强，-45到45度之间随机旋转  </span></span><br><span class="line">                transforms.CenterCrop(<span class="number">64</span>),  <span class="comment"># 数据增强，从中心开始裁剪为64*64  </span></span><br><span class="line">                transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 数据增强，选择一个概率概率随机水平翻转  </span></span><br><span class="line">                transforms.RandomVerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 数据增强，选择一个概率概率随机水平翻转  </span></span><br><span class="line">                <span class="comment"># 数据增强，亮度，对比度，饱和度，色相调整  </span></span><br><span class="line">                transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.1</span>, saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>),  </span><br><span class="line">                transforms.RandomGrayscale(p=<span class="number">0.025</span>),  <span class="comment"># 数据增强，灰度调整  </span></span><br><span class="line">                transforms.ToTensor(),  <span class="comment"># 转化为tensor结构  </span></span><br><span class="line">                <span class="comment"># ImageNet提供的均值，标准差  </span></span><br><span class="line">                transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  </span><br><span class="line">            ]),  </span><br><span class="line">        <span class="string">&#x27;valid&#x27;</span>:  </span><br><span class="line">            transforms.Compose([  </span><br><span class="line">                transforms.Resize([<span class="number">64</span>, <span class="number">64</span>]),  </span><br><span class="line">                transforms.ToTensor(),  </span><br><span class="line">                <span class="comment"># ImageNet提供的均值，标准差  </span></span><br><span class="line">                transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  </span><br><span class="line">            ]),  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_loader</span>():  </span><br><span class="line">    batch_size = <span class="number">128</span>  </span><br><span class="line">    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(Path(<span class="string">&quot;./data/&quot;</span>), x), data_transforms()[x]) <span class="keyword">for</span> x <span class="keyword">in</span>  </span><br><span class="line">                      [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;  </span><br><span class="line">    dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=<span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span>  </span><br><span class="line">                   [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;  </span><br><span class="line">    <span class="keyword">return</span> dataloaders[<span class="string">&#x27;train&#x27;</span>], dataloaders[<span class="string">&#x27;valid&#x27;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练数据 验证数据  </span></span><br><span class="line">train_dl, valid_dl = load_data_loader()</span><br></pre></td></tr></table></figure>

<h3 id="3-绘制部分预处理数据"><a href="#3-绘制部分预处理数据" class="headerlink" title="3.绘制部分预处理数据"></a>3.绘制部分预处理数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 反标准化（恢复原始图像）  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">denormalize</span>(<span class="params">image</span>):  </span><br><span class="line">    mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])  </span><br><span class="line">    std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  </span><br><span class="line">    image = image.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))  <span class="comment"># 转换为 HWC 格式  </span></span><br><span class="line">    image = std * image + mean  <span class="comment"># 反标准化  </span></span><br><span class="line">    image = np.clip(image, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># 限制在 [0,1] 之间  </span></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制部分预处理后的数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_dl_8img</span>(<span class="params">data_loader</span>):  </span><br><span class="line">    images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(data_loader))  </span><br><span class="line">    fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">4</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>))  <span class="comment"># 创建 2x4 的子图网格  </span></span><br><span class="line">    axes = axes.flatten()  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):  </span><br><span class="line">        img = denormalize(images[i])  <span class="comment"># 反标准化  </span></span><br><span class="line">        axes[i].imshow(img)  <span class="comment"># 显示图片  </span></span><br><span class="line">        axes[i].axis(<span class="string">&quot;off&quot;</span>)  <span class="comment"># 关闭坐标轴  </span></span><br><span class="line">        axes[i].set_title(<span class="string">f&quot;Label: <span class="subst">&#123;labels[i].item()&#125;</span>&quot;</span>)  <span class="comment"># 显示标签  </span></span><br><span class="line">    plt.tight_layout()  </span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">draw_dl_8img(train_dl)</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250306171732.png"></p>
<h2 id="3-模型配置"><a href="#3-模型配置" class="headerlink" title="3.模型配置"></a>3.模型配置</h2><h3 id="1-ResNet-18"><a href="#1-ResNet-18" class="headerlink" title="1.ResNet-18"></a>1.ResNet-18</h3><p><strong>ResNet-18</strong>可以用在别的任务上是因为它在 <strong>ImageNet</strong> 这样的超大规模数据集上训练过，学习到了通用的特征。<br>在深度学习模型训练中前几层通常学习 <strong>通用的低级特征</strong>（比如边缘、纹理、形状等），而后几层学习 <strong>高级的特定特征</strong>（比如猫的耳朵、人脸的结构）。前几层的特征对不同任务是通用的，因此可以在其他数据集上直接使用，只需调整最后几层（或者不调整）就能适应新的任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;ResNet 的基本残差块（适用于 ResNet-18 和 ResNet-34）&quot;&quot;&quot;</span></span><br><span class="line">    expansion = <span class="number">1</span>  <span class="comment"># 该块不会改变通道数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        <span class="variable language_">self</span>.downsample = downsample  <span class="comment"># 是否使用 1×1 卷积调整通道数和尺寸</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = <span class="variable language_">self</span>.downsample(x)</span><br><span class="line">        out = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn1(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.conv2(out)</span><br><span class="line">        out = <span class="variable language_">self</span>.bn2(out)</span><br><span class="line">        out += identity  <span class="comment"># 残差连接</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;ResNet-18 模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># ResNet 的四个层，每个包含 2 个 BasicBlock</span></span><br><span class="line">        <span class="variable language_">self</span>.layer1 = <span class="variable language_">self</span>._make_layer(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.layer2 = <span class="variable language_">self</span>._make_layer(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.layer3 = <span class="variable language_">self</span>._make_layer(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.layer4 = <span class="variable language_">self</span>._make_layer(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">512</span>, num_classes)  <span class="comment"># 最终的全连接层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, in_channels, out_channels, blocks, stride</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;构建一个 ResNet 层&quot;&quot;&quot;</span></span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != out_channels:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels),</span><br><span class="line">            )</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(BasicBlock(in_channels, out_channels, stride, downsample))</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(BasicBlock(out_channels, out_channels))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.bn1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.layer4(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>上面是ResNet-18 模型的结构，了解即可。因为ResNet-18 已经被 <strong>PyTorch 的 torchvision.models</strong> 模块包含并预定义了，我们无需手动定义整个模型结构，可直接使用它。</p>
<h3 id="2-自定义ResNet-18"><a href="#2-自定义ResNet-18" class="headerlink" title="2.自定义ResNet-18"></a>2.自定义ResNet-18</h3><p>初始化一个预训练的 ResNet-18 模型，并修改它用于新的分类任务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">num_classes</span>):  </span><br><span class="line">    <span class="comment"># torch自带的18层训练好的模型  </span></span><br><span class="line">    model_ft = models.resnet18(weights=<span class="string">&quot;DEFAULT&quot;</span>)  </span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> model_ft.parameters():  </span><br><span class="line">        param.requires_grad = <span class="literal">False</span>  <span class="comment"># 冻结参数，使其在训练过程中 不会被优化  </span></span><br><span class="line">    model_ft.fc = nn.Linear(model_ft.fc.in_features, num_classes)  <span class="comment"># 替换ResNet18的最后全连接层  </span></span><br><span class="line">    model_ft.to(get_device())  <span class="comment"># 使用GPU or CPU训练</span></span><br><span class="line">    <span class="keyword">return</span> model_ft</span><br></pre></td></tr></table></figure>
<ul>
<li><code>models.resnet18(weights=&quot;DEFAULT&quot;</code>：加载 ResNet-18 预训练模型</li>
<li><code>param.requires_grad = False</code>: 冻结 ResNet-18 的所有层，防止其参数被训练</li>
<li><code>nn.Linear(model_ft.fc.in_features, num_classes)</code>：修改 ResNet 的最后一层，让它适应新的分类任务，因为当前训练集是102分类，<code>num_classes</code>为102，表示最后全连接层输出102个类别</li>
<li><code>model_ft.to(get_device())</code>:让模型运行在 GPU 或 CPU上</li>
</ul>
<p>经过这样自定义后， ResNet-18模型只会训练最后的全连接层。</p>
<h3 id="3-优化器"><a href="#3-优化器" class="headerlink" title="3.优化器"></a>3.优化器</h3><p>优化器还是使用<code>Adam</code></p>
<blockquote>
<p><strong>Adam</strong> 是一种常用的优化算法，全名为 <strong>Adaptive Moment Estimation</strong>，它结合了 <strong>Momentum</strong> 和 <strong>RMSprop</strong> 的优点，能够自动调整学习率来提高训练效果，Adam 优化器会通过计算一阶矩（梯度的均值）和二阶矩（梯度的平方均值）来动态调整每个参数的学习率，从而提高训练的效率和稳定性。  </p>
</blockquote>
<p>适用范围：一种自适应优化算法，非常适用于大多数任务，尤其是当模型参数多，训练过程复杂的时候。</p>
<p>在定义<code>Adam</code>优化器的时候需要注意，只有未冻结的参数才需要训练，冻结的参数不会被训练优化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_optimizer</span>(<span class="params">_model_resnet</span>):  </span><br><span class="line">    params_to_update = []  </span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> _model_resnet.named_parameters():  </span><br><span class="line">        <span class="keyword">if</span> param.requires_grad:  </span><br><span class="line">            params_to_update.append(param)  </span><br><span class="line">    <span class="keyword">return</span> optim.Adam(params_to_update, lr=<span class="number">1e-2</span>) <span class="comment"># 初始学习率 lr=0.01</span></span><br></pre></td></tr></table></figure>

<h3 id="4-学习率"><a href="#4-学习率" class="headerlink" title="4.学习率"></a>4.学习率</h3><p>在训练过程中，随着 epoch 增加，模型可能会 <strong>收敛变慢</strong>，也就是训练准确度会提升，如果还是保持原有的 <strong>步长(step_size)</strong> 往往会使训练效果下降，为了提高模型训练精度需要后期小步调整， Loss 下降变慢时，自动降低学习率。<br>例如，前 10 轮学习率 0.01，第 10 轮后变 0.001，第20轮后变0.0001，依次类推</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">10</span>, gamma=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>step_size=10</code>：每 10 个epoch让学习率衰减一次</li>
<li><code>gamma=0.1</code>：每次衰减时，学习率乘以0.1（缩小10倍）</li>
</ul>
<h3 id="5-损失函数"><a href="#5-损失函数" class="headerlink" title="5.损失函数"></a>5.损失函数</h3><blockquote>
<p><code>CrossEntropyLoss</code>是PyTorch 中一个常用的损失函数，专门用于 <strong>分类任务</strong>，尤其是多类别分类。它结合了 <strong>Softmax</strong> 函数和 <strong>负对数似然损失</strong>（Negative Log-Likelihood Loss），用于处理分类任务中 <strong>概率输出</strong> 的问题</p>
</blockquote>
<p>适用范围：真实标签应该是一个 <strong>整数</strong>，表示每个样本的真实类别索引（而不是 one-hot 编码）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
<h2 id="4-模型训练和评估"><a href="#4-模型训练和评估" class="headerlink" title="4.模型训练和评估"></a>4.模型训练和评估</h2><h3 id="1-训练"><a href="#1-训练" class="headerlink" title="1.训练"></a>1.训练</h3><p><code>train_one_epoch</code>方法定义了一个完整的<strong>训练轮次（epoch）</strong>，包括 <strong>前向传播、损失计算、反向传播、参数更新</strong>，并计算 <strong>训练损失和准确率</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">_model, dataloader, optimizer, _criterion, device, _scheduler</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    训练一个 epoch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    </span><br><span class="line">    _model.train()  <span class="comment"># 设置为训练模式  </span></span><br><span class="line">    running_loss = <span class="number">0.0</span>  <span class="comment"># 累计 batch 损失值</span></span><br><span class="line">    running_corrects = <span class="number">0</span>  <span class="comment"># 累计正确预测的样本数</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloader:  <span class="comment"># 遍历每个batch（批量数据）</span></span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)  <span class="comment"># 转移到GPU/CPU，加速训练  </span></span><br><span class="line">  </span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清空梯度  </span></span><br><span class="line">        outputs = _model(inputs)  <span class="comment"># 模型前向传播计算输出  </span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)  <span class="comment"># 取最大概率的类别作为预测值 </span></span><br><span class="line">        loss = _criterion(outputs, labels)  <span class="comment"># 计算损失  </span></span><br><span class="line">  </span><br><span class="line">        loss.backward()  <span class="comment"># 计算梯度（反向传播） </span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新模型参数 </span></span><br><span class="line">  </span><br><span class="line">        running_loss += loss.item() * inputs.size(<span class="number">0</span>)  <span class="comment"># batch损失*batch_size</span></span><br><span class="line">	    running_corrects += torch.<span class="built_in">sum</span>((predicted == labels).<span class="built_in">int</span>())  <span class="comment"># 统计正确预测的个数</span></span><br><span class="line">    epoch_loss = running_loss / <span class="built_in">len</span>(dataloader.dataset)  <span class="comment"># 平均损失（总损失/样本数）</span></span><br><span class="line">    epoch_acc = running_corrects / <span class="built_in">len</span>(dataloader.dataset)  <span class="comment"># 准确率（正确预测数/总样本数）</span></span><br><span class="line">    <span class="keyword">return</span> epoch_loss, epoch_acc</span><br></pre></td></tr></table></figure>

<h3 id="2-评估"><a href="#2-评估" class="headerlink" title="2.评估"></a>2.评估</h3><p><code>validate_one_epoch</code> 方法 执行了一次完整的验证（evaluation），其核心功能是 <strong>前向传播、计算损失、计算准确率</strong>，但不会进行 <strong>反向传播和参数更新</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">validate_one_epoch</span>(<span class="params">_model, dataloader, _criterion, device</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    进行一个 epoch 的验证  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    </span><br><span class="line">    _model.<span class="built_in">eval</span>()  <span class="comment"># 设置为评估模式  </span></span><br><span class="line">    running_loss = <span class="number">0.0</span>  <span class="comment"># 累计 batch 损失值</span></span><br><span class="line">    running_corrects = <span class="number">0</span>  <span class="comment"># 累计正确预测的样本数</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 不计算梯度，加速计算  </span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloader:  <span class="comment"># 遍历每个batch（批量数据）</span></span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)  <span class="comment"># 转移到GPU/CPU，加速训练</span></span><br><span class="line">            outputs = _model(inputs)  <span class="comment"># 模型前向计算输出</span></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)  <span class="comment"># 取最大概率的类别作为预测值</span></span><br><span class="line">            loss = _criterion(outputs, labels)  <span class="comment"># 计算损失</span></span><br><span class="line">  </span><br><span class="line">            running_loss += loss.item() * inputs.size(<span class="number">0</span>)  <span class="comment"># batch损失*batch_size</span></span><br><span class="line">            running_corrects += torch.<span class="built_in">sum</span>((predicted == labels).<span class="built_in">int</span>())  <span class="comment"># 统计正确预测的个数 </span></span><br><span class="line">  </span><br><span class="line">    epoch_loss = running_loss / <span class="built_in">len</span>(dataloader.dataset)  <span class="comment"># 平均损失（总损失/样本数）</span></span><br><span class="line">    epoch_acc = running_corrects / <span class="built_in">len</span>(dataloader.dataset)  <span class="comment"># 准确率（正确预测数/总样本数）</span></span><br><span class="line">    <span class="keyword">return</span> epoch_loss, epoch_acc</span><br></pre></td></tr></table></figure>
<h3 id="3-筛选与保存"><a href="#3-筛选与保存" class="headerlink" title="3.筛选与保存"></a>3.筛选与保存</h3><p><code>train_model</code>方法就是一个完整的模型训练过程了，包括</p>
<ul>
<li>训练多个 epoch（循环多轮数据集）</li>
<li>对每个 epoch 进行训练和验证</li>
<li>记录并打印损失、准确率、学习率变化</li>
<li>保存最佳模型权重到本地</li>
<li>在训练结束后，返回最佳模型参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">_model, train_loader, valid_loader, _criterion, optimizer, _scheduler, num_epochs, device, _model_name</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    训练完整模型  </span></span><br><span class="line"><span class="string">    return 最终模型、损失 &amp; 准确率历史、学习率变化</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    </span><br><span class="line">    start_time = time.time()  <span class="comment"># 记录训练开始时间</span></span><br><span class="line">    best_acc = <span class="number">0.0</span>  <span class="comment"># 记录最高的验证准确率，用于保存最佳模型</span></span><br><span class="line">    best_model_wts = copy.deepcopy(_model.state_dict())  <span class="comment"># 保存最佳模型的参数</span></span><br><span class="line">  </span><br><span class="line">    train_acc_history = []  <span class="comment"># 训练集的准确率</span></span><br><span class="line">    train_losses = []  <span class="comment"># 训练集的损失  </span></span><br><span class="line">    valid_acc_history = []  <span class="comment"># 验证集的准确率</span></span><br><span class="line">    valid_losses = []  <span class="comment"># 验证集的损失</span></span><br><span class="line">  </span><br><span class="line">    learning_rates = [optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]]  <span class="comment"># 学习率</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch:<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>&#x27;</span>)  <span class="comment"># 循环epoch</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 训练 记录训练损失和准确率</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(_model, train_loader, optimizer, _criterion, device, _scheduler)  </span><br><span class="line">        train_losses.append(train_loss)  </span><br><span class="line">        train_acc_history.append(train_acc)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 验证 记录验证损失和准确率</span></span><br><span class="line">        valid_loss, valid_acc = validate_one_epoch(_model, valid_loader, _criterion, device)  </span><br><span class="line">        valid_losses.append(valid_loss)  </span><br><span class="line">        valid_acc_history.append(valid_acc)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录&amp;打印本轮训练和验证的损失、准确率</span></span><br><span class="line">        time_elapsed = time.time() - start_time  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Time elapsed: <span class="subst">&#123;time_elapsed // <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>m <span class="subst">&#123;time_elapsed % <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>s&quot;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Train Loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;train_acc:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Valid Loss: <span class="subst">&#123;valid_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;valid_acc:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 记录最佳模型  </span></span><br><span class="line">        <span class="keyword">if</span> valid_acc &gt; best_acc:  </span><br><span class="line">            best_acc = valid_acc  </span><br><span class="line">            best_model_wts = copy.deepcopy(_model.state_dict())  </span><br><span class="line">            state = &#123;  </span><br><span class="line">                <span class="string">&#x27;state_dict&#x27;</span>: _model.state_dict(),  </span><br><span class="line">                <span class="string">&#x27;best_acc&#x27;</span>: best_acc,  </span><br><span class="line">                <span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),  </span><br><span class="line">            &#125;  </span><br><span class="line">            torch.save(state, model_name)  <span class="comment"># 保存最佳模型</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 记录学习率  </span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Optimizer learning rate : &#123;:.7f&#125;&#x27;</span>.<span class="built_in">format</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]))  </span><br><span class="line">        learning_rates.append(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>])  </span><br><span class="line">        _scheduler.step()  <span class="comment"># 调整学习率 学习率衰减</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练完成 打印 训练总时长 最佳验证准确率</span></span><br><span class="line">    time_elapsed = time.time() - start_time  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Training complete in <span class="subst">&#123;time_elapsed // <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>m <span class="subst">&#123;time_elapsed % <span class="number">60</span>:<span class="number">.0</span>f&#125;</span>s&#x27;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Best validation Acc: <span class="subst">&#123;best_acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 用最佳模型的参数作为最终模型  </span></span><br><span class="line">    _model.load_state_dict(best_model_wts)  </span><br><span class="line">    <span class="keyword">return</span> _model, train_losses, train_acc_history, valid_losses, valid_acc_history, learning_rates</span><br></pre></td></tr></table></figure>
<h3 id="4-一次训练"><a href="#4-一次训练" class="headerlink" title="4.一次训练"></a>4.一次训练</h3><p>一次训练20个epoch，训练完把模型保存到本地</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_model(model, train_dl, valid_dl, criterion, optimizer_ft, scheduler, <span class="number">20</span>, get_device(), model_name)</span><br></pre></td></tr></table></figure>
<p>结果输出</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Epoch:<span class="number">19</span>/<span class="number">20</span></span><br><span class="line">Time elapsed: 33m 37s</span><br><span class="line">Train Loss: <span class="number">1.6936</span> Acc: <span class="number">0.5911</span></span><br><span class="line">Valid Loss: <span class="number">3.2956</span> Acc: <span class="number">0.3912</span></span><br><span class="line">Optimizer learning rate : <span class="number">0.0000100</span></span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Epoch:<span class="number">20</span>/<span class="number">20</span></span><br><span class="line">Time elapsed: 34m 52s</span><br><span class="line">Train Loss: <span class="number">1.7088</span> Acc: <span class="number">0.5882</span></span><br><span class="line">Valid Loss: <span class="number">3.2838</span> Acc: <span class="number">0.3704</span></span><br><span class="line">Optimizer learning rate : <span class="number">0.0000100</span></span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Training complete <span class="keyword">in</span> 35m 1s</span><br><span class="line">Best validation Acc: <span class="number">0.392421</span></span><br></pre></td></tr></table></figure>
<p>训练完后当前模块文件夹下会有一个<code>best.pt</code>刚训练好的模型文件，准备二次训练</p>
<h3 id="5-二次训练"><a href="#5-二次训练" class="headerlink" title="5.二次训练"></a>5.二次训练</h3><p>加载第一次训练的模型后，解冻模型的所有层，然后使用较小的学习率继续训练 10 轮，更新模型权重。这样做可以让模型达到更好的准确率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">second_train</span>(<span class="params">_model_name, _train_dl, _valid_dl, _criterion</span>):  </span><br><span class="line">    <span class="comment"># 初始化一个新模型，类别数 num_classes=102</span></span><br><span class="line">    <span class="comment"># 加载已有模型的权重，恢复之前训练好的参数</span></span><br><span class="line">    _model = init_model(num_classes=<span class="number">102</span>)  </span><br><span class="line">    checkpoint = torch.load(_model_name, weights_only=<span class="literal">True</span>)  </span><br><span class="line">    _model.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解冻所有层的参数，让整个模型都可以,参与训练</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> _model.parameters():  </span><br><span class="line">        param.requires_grad = <span class="literal">True</span>  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调低学习率</span></span><br><span class="line">    _optimizer_next = optim.Adam(_model.parameters(), lr=<span class="number">1e-3</span>)  </span><br><span class="line">    <span class="comment"># 每7个epoch让学习率衰减一次（*0.1）</span></span><br><span class="line">    _scheduler_next = optim.lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)  </span><br><span class="line">    <span class="comment"># 重新训练</span></span><br><span class="line">    train_model(_model, _train_dl, _valid_dl, _criterion, _optimizer_next, _scheduler_next, <span class="number">10</span>, get_device(), _model_name)</span><br></pre></td></tr></table></figure>

<p>二次训练较一次模型训练结果有改善</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Epoch:<span class="number">9</span>/<span class="number">10</span></span><br><span class="line">Time elapsed: 16m 47s</span><br><span class="line">Train Loss: <span class="number">0.6153</span> Acc: <span class="number">0.8155</span></span><br><span class="line">Valid Loss: <span class="number">1.6921</span> Acc: <span class="number">0.6051</span></span><br><span class="line">Optimizer learning rate : <span class="number">0.0010000</span></span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Epoch:<span class="number">10</span>/<span class="number">10</span></span><br><span class="line">Time elapsed: 18m 36s</span><br><span class="line">Train Loss: <span class="number">0.5529</span> Acc: <span class="number">0.8361</span></span><br><span class="line">Valid Loss: <span class="number">1.6800</span> Acc: <span class="number">0.5941</span></span><br><span class="line">Optimizer learning rate : <span class="number">0.0010000</span></span><br><span class="line">---------------------------------------------------------------------------------</span><br><span class="line">Training complete <span class="keyword">in</span> 18m 36s</span><br><span class="line">Best validation Acc: <span class="number">0.6051</span></span><br></pre></td></tr></table></figure>

<p>两轮训练完最终对于测试集的验证正确率是59.41%</p>
<h2 id="5-模型测试"><a href="#5-模型测试" class="headerlink" title="5.模型测试"></a>5.模型测试</h2><p>展示真实标签和模型预测的对比图，如果预测错误标题显示红色</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_predicted</span>(<span class="params">_model_name</span>):</span><br><span class="line">    <span class="comment"># 初始化一个新模型，类别数 num_classes=102</span></span><br><span class="line">    <span class="comment"># 加载已有模型的权重，恢复之前训练好的参数</span></span><br><span class="line">    _model = init_model(num_classes=<span class="number">102</span>)  </span><br><span class="line">    checkpoint = torch.load(_model_name, weights_only=<span class="literal">True</span>)  </span><br><span class="line">    _model.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 花的名称</span></span><br><span class="line">    label_name = load_label_name()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取一批验证集的数据</span></span><br><span class="line">    images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(valid_dl))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行预测</span></span><br><span class="line">    _model.<span class="built_in">eval</span>()  </span><br><span class="line">    output = _model(images)  </span><br><span class="line">    _, predicted_tensor = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理预测结果</span></span><br><span class="line">    train_on_gpu = torch.cuda.is_available()  </span><br><span class="line">    predicted = np.squeeze(predicted_tensor.numpy()) <span class="keyword">if</span> <span class="keyword">not</span> train_on_gpu <span class="keyword">else</span> np.squeeze(predicted_tensor.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 画出8张预测图</span></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">4</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>))  <span class="comment"># 创建 2x4 的子图网格  </span></span><br><span class="line">    axes = axes.flatten()  </span><br><span class="line">    <span class="comment"># 显示每张图像及预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):  </span><br><span class="line">        img = denormalize(images[i])  <span class="comment"># 反标准化  </span></span><br><span class="line">        axes[i].imshow(img)  <span class="comment"># 显示图片  </span></span><br><span class="line">        axes[i].axis(<span class="string">&quot;off&quot;</span>)  <span class="comment"># 关闭坐标轴  </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置标题：真实vs预测</span></span><br><span class="line">        predicted_label = label_name.get(<span class="built_in">str</span>(predicted[i]), <span class="string">&quot;Unknown&quot;</span>)  </span><br><span class="line">        true_label = label_name.get(<span class="built_in">str</span>(labels[i].item()), <span class="string">&quot;Unknown&quot;</span>)  </span><br><span class="line">        title_color = <span class="string">&quot;green&quot;</span> <span class="keyword">if</span> predicted_label == true_label <span class="keyword">else</span> <span class="string">&quot;red&quot;</span>  </span><br><span class="line">        axes[i].set_title(<span class="string">&quot;&#123;&#125; (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(predicted_label, true_label), color=( </span><br><span class="line">            title_color))  <span class="comment"># 显示标签  </span></span><br><span class="line">    plt.tight_layout()  </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250307155124.png"></p>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><p>本文主要讲的是如何利用预训练模型（ResNet-18）在新数据集上做微调。先冻结大部分网络层，只留最后一层全连接层，再经过训练集训练后解冻全部参数，继续训练，以适应新数据集。<br>完整流程：</p>
<ol>
<li>加载 ResNet-18 预训练模型</li>
<li>修改 fc 层，适配新任务</li>
<li>冻结特征层，仅训练 fc 层（特征提取模式）</li>
<li>设置优化器，仅更新 fc 层参数</li>
<li>使用 StepLR 进行学习率衰减</li>
<li>训练（前向传播 + 反向传播 + 梯度更新）</li>
<li>验证模型性能（不更新梯度）</li>
<li>保存最佳模型（防止过拟合）</li>
<li>微调（解冻全部参数，降低学习率）</li>
<li>可视化预测结果，检查分类准确率</li>
</ol>
<h2 id="7-模型优化"><a href="#7-模型优化" class="headerlink" title="7.模型优化"></a>7.模型优化</h2><p>八张图片中有两张识别错误，模型的识别准确率还有提升的空间，如何要进一步提高准确率该怎样做？查了一下，大致可以有以下几种方法：</p>
<ol>
<li>使用ResNet-50，ResNet-50由于参数更多，可以学习更复杂的特征，分类效果通常更好</li>
<li>采用更好的优化器，例如<strong>AdamW</strong>（更稳定，L2 正则化）、<strong>SGD + Momentum</strong>（更适合 Fine-tuning）等</li>
<li>优化学习率调度策略，例如<strong>ReduceLROnPlateau</strong>（监控验证集 Loss 下降才调整学习率）、<strong>CosineAnnealingLR</strong>（余弦退火，适用于 Fine-tuning）、<strong>OneCycleLR</strong>（加速收敛）等</li>
<li>冻结更多层后逐步解冻，先只训练 fc 层，再解冻 ResNet 最后 1-2 个 block，最后解冻整个 ResNet 进行 Fine-tuning</li>
<li>增加 Dropout 防止过拟合</li>
<li>使用 Label Smoothing，目前的 CrossEntropyLoss 过于严格，可以用 <strong>Label Smoothing</strong>，防止过拟合</li>
<li>使用混合精度训练（加速 + 提高泛化能力）</li>
<li>使用 Early Stopping，训练更久的同时还能防止过拟合</li>
</ol>
<h2 id="8-备注"><a href="#8-备注" class="headerlink" title="8.备注"></a>8.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>matplotlib: 3.8.4</li>
<li>numpy: 1.26.4</li>
</ul>
<p>数据集：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/004_cnn_classification_flowers/data">https://github.com/keychankc/dl_code_for_blog/tree/main/004_cnn_classification_flowers/data</a></p>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/blob/main/004_cnn_classification_flowers/main.py">https://github.com/keychankc/dl_code_for_blog/blob/main/004_cnn_classification_flowers/main.py</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>模型训练</tag>
        <tag>matplotlib</tag>
        <tag>卷积神经网络</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>基于循环神经网络的文本分类实践</title>
    <url>/2025/03/14/005-rnn-classification-text/</url>
    <content><![CDATA[<h2 id="1-循环神经网络-RNN"><a href="#1-循环神经网络-RNN" class="headerlink" title="1.循环神经网络(RNN)"></a>1.循环神经网络(RNN)</h2><p>环神经网络（<strong>Recurrent Neural Network, RNN</strong>）也叫递归神经网络，是专门处理<strong>序列数据</strong>的神经网络架构，其核心思想是通过<strong>循环连接</strong>使网络具备“记忆”能力，从而构建序列中时序之间的依赖关系。而处理具有<strong>时序或顺序关系</strong>的数据（如语言、语音、基因序列等）的核心挑战是<strong>理解序列中的上下文依赖关系</strong>。<br>RNN有<strong>隐藏状态（hidden state）</strong>，可以保留和传递之前时刻的信息，也就是有记忆功能，从而可实现有<strong>上下文依赖性</strong>的数据处理：<br>通俗一点就像是人在读一句话：</p>
<ul>
<li>读到 “我” → 记住</li>
<li>读到 “今天” → 结合前面的信息</li>
<li>读到 “很” → 继续理解上下文</li>
<li>读到 “开心” → 知道整体含义”我今天很开心“</li>
</ul>
<h3 id="1-RNN结构"><a href="#1-RNN结构" class="headerlink" title="1.RNN结构"></a>1.RNN结构</h3><p>RNN 通过<strong>隐藏状态(Hidden State)</strong> 存储历史信息，并通过时间步(Time Step)进行递归计算</p>
<ul>
<li><strong>输入层</strong>：接收当前时间步的输入 $x_t$</li>
<li><strong>隐藏层</strong>：包含一个循环连接，用于存储历史信息：$h_t &#x3D; f(W_h h_{t-1} + W_x x_t + b)$</li>
<li><strong>输出层</strong>：根据隐藏状态计算输出 $y_t$</li>
</ul>
<span id="more"></span>
<h3 id="2-RNN-处理流程"><a href="#2-RNN-处理流程" class="headerlink" title="2.RNN 处理流程"></a>2.RNN 处理流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入序列 → RNN单元（时间步t=1）→ RNN单元（时间步t=2）→ ... → 输出</span><br></pre></td></tr></table></figure>
<h3 id="1-与卷积神经网络-CNN-对比"><a href="#1-与卷积神经网络-CNN-对比" class="headerlink" title="1.与卷积神经网络(CNN)对比"></a>1.与卷积神经网络(CNN)对比</h3><p>CNN是通过“卷积操作”提取图片中的局部特征，比如边缘、颜色、形状等，逐步构建对整个图像的理解。每个“卷积核”只看局部区域，不会直接处理整个图片。<br>CNN就像人类的大脑看图片时的处理方式：</p>
<ul>
<li><strong>第一层</strong> 识别边缘 </li>
<li><strong>第二层</strong> 识别形状 </li>
<li><strong>第三层</strong> 识别复杂的物体 </li>
<li>最后输出 <strong>“这是一只猫🐱”</strong>！</li>
</ul>
<h4 id="1-CNN结构"><a href="#1-CNN结构" class="headerlink" title="1.CNN结构"></a>1.CNN结构</h4><ul>
<li><strong>卷积层（Convolutional Layer）</strong>：使用卷积核（filter）提取图像局部特征</li>
<li><strong>激活函数（ReLU）</strong>：引入非线性，使网络可以学习复杂模式</li>
<li><strong>池化层（Pooling Layer）</strong>：减少特征维度，提高计算效率（如最大池化）</li>
<li><strong>全连接层（Fully Connected Layer, FC）</strong>：将特征映射到最终输出（如分类）</li>
</ul>
<h4 id="2-CNN处理流程"><a href="#2-CNN处理流程" class="headerlink" title="2.CNN处理流程"></a>2.CNN处理流程</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入图像 → 卷积层 → ReLU → 池化层 → 卷积层 → ReLU → 池化层 → 全连接层 → 输出</span><br></pre></td></tr></table></figure>
<h4 id="3-CNN和RNN对比"><a href="#3-CNN和RNN对比" class="headerlink" title="3.CNN和RNN对比"></a>3.CNN和RNN对比</h4><table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th>卷积神经网络(CNN)</th>
<th>循环神经网络(RNN)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>主要用途</strong></td>
<td>主要用于处理图像和空间数据</td>
<td>主要用于处理序列数据和时间依赖数据</td>
</tr>
<tr>
<td><strong>数据类型</strong></td>
<td>适用于静态数据（如图像）</td>
<td>适用于动态数据（如时间序列、文本、语音）</td>
</tr>
<tr>
<td><strong>架构特点</strong></td>
<td>采用卷积层和池化层提取局部特征</td>
<td>采用循环连接保持时间序列依赖性</td>
</tr>
<tr>
<td><strong>计算方式</strong></td>
<td>并行计算（卷积运算可并行化）</td>
<td>依赖前序计算，难以并行化</td>
</tr>
<tr>
<td><strong>长期依赖性</strong></td>
<td>无长期依赖性，每个输入独立处理</td>
<td>具有记忆能力，可以捕捉长期依赖关系</td>
</tr>
<tr>
<td><strong>梯度消失问题</strong></td>
<td>无梯度消失问题</td>
<td>可能会遇到梯度消失（尤其是普通 RNN）</td>
</tr>
<tr>
<td><strong>训练难度</strong></td>
<td>计算高效，易训练</td>
<td>计算较复杂，可能需要 LSTM&#x2F;GRU 解决梯度问题</td>
</tr>
</tbody></table>
<h3 id="2-长短期记忆网络-LSTM"><a href="#2-长短期记忆网络-LSTM" class="headerlink" title="2.长短期记忆网络(LSTM)"></a>2.长短期记忆网络(LSTM)</h3><p>RNN <strong>本质上有“记忆”能力</strong>，但由于 <strong>梯度消失问题</strong>，它很难记住 <strong>较长时间前的信息</strong>。LSTM 通过 <strong>引入“门控机制”</strong>，可以 <strong>有效记住长期信息</strong>，避免梯度消失，使其能处理更长的序列数据。</p>
<h4 id="1-通俗理解LSTM-vs-RNN"><a href="#1-通俗理解LSTM-vs-RNN" class="headerlink" title="1. 通俗理解LSTM vs. RNN"></a>1. 通俗理解<strong>LSTM vs. RNN</strong></h4><p>想象一下，你是一名学生，要上 <strong>一整天的课</strong>，然后参加 <strong>测验</strong>。</p>
<h5 id="1-RNN"><a href="#1-RNN" class="headerlink" title="1.RNN"></a>1.RNN</h5><p>RNN就像是一个只有“短期记忆”的学生:</p>
<ul>
<li><strong>上午 8:00 上数学课</strong>，学了 <strong>微积分</strong>，你记住了一些公式。</li>
<li><strong>上午 10:00 上英语课</strong>，学了 <strong>语法规则</strong>，你还记得大部分内容。</li>
<li><strong>下午 2:00 上历史课</strong>，学了 <strong>第二次世界大战</strong>，但你开始<strong>忘记上午学的微积分</strong>。</li>
<li><strong>下午 4:00 上物理课</strong>，学了 <strong>电磁学</strong>，但你基本已经<strong>忘了微积分和语法规则</strong>。</li>
</ul>
<p>当 <strong>测验</strong> 需要你用 <strong>微积分</strong> 来解物理题时，RNN 学生发现：<strong>“糟糕！我已经不记得微积分怎么用了！”</strong> ，RNN <strong>只能记住最近的知识</strong>，对于较早学的内容，信息会逐渐丢失（梯度消失问题）。</p>
<h5 id="2-LSTM"><a href="#2-LSTM" class="headerlink" title="2.LSTM"></a>2.LSTM</h5><p>LSTM 就像是一个擅长做笔记的学生，有一本“记忆笔记本”</p>
<ul>
<li><strong>上午 8:00 上数学课</strong>，你在笔记本上<strong>记录微积分公式</strong>。</li>
<li><strong>上午 10:00 上英语课</strong>，你继续做<strong>语法笔记</strong>。</li>
<li><strong>下午 2:00 上历史课</strong>，你决定<strong>删掉不重要的细节，但保留关键事件</strong>。</li>
<li><strong>下午 4:00 上物理课</strong>，当你看到电磁学需要用微积分时，你<strong>翻开笔记本，找到微积分公式</strong>。</li>
</ul>
<p>当 <strong>测验</strong> 要求你用微积分解物理题时，LSTM 学生发现：<strong>“太好了！我有笔记！我可以回忆起微积分！”</strong> </p>
<h5 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h5><ul>
<li>LSTM <strong>有“记忆笔记本”（细胞状态）</strong>，可以长期保存重要信息。</li>
<li>LSTM <strong>有“遗忘门”</strong>，可以丢弃不重要的信息（比如历史课不相关的细节）。</li>
<li>LSTM <strong>有“输入门”</strong>，可以选择性存入新知识（物理课需要微积分）。</li>
<li>LSTM <strong>有“输出门”</strong>，可以从记忆中提取正确的信息（在考试时用微积分解题）。</li>
</ul>
<h5 id="4-对比"><a href="#4-对比" class="headerlink" title="4.对比"></a>4.对比</h5><table>
<thead>
<tr>
<th><strong>对比点</strong></th>
<th><strong>RNN（普通学生）</strong></th>
<th><strong>LSTM（做笔记的学生）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>能记住的信息量</strong></td>
<td>只能记住最近的信息</td>
<td>可以记住更久的信息</td>
</tr>
<tr>
<td><strong>信息丢失</strong></td>
<td>早期学的知识逐渐遗忘</td>
<td>重要信息可以长时间保存</td>
</tr>
<tr>
<td><strong>遇到复杂问题</strong></td>
<td>可能忘记关键点</td>
<td>可以回忆笔记，找到答案</td>
</tr>
<tr>
<td><strong>适合的任务</strong></td>
<td>短文本、短时间序列</td>
<td>长文本、长时间序列</td>
</tr>
</tbody></table>
<h2 id="2-概述"><a href="#2-概述" class="headerlink" title="2.概述"></a>2.概述</h2><h3 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1.数据集"></a>1.数据集</h3><p>现有<code>train.txt</code>(18万条)、<code>dev.txt</code>(1万条)和<code>test.txt</code>(1万条)三个数据集，分别对应训练集、验证集和测试集，每条数据格式都一样，下面是训练集前6条数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">金证顾问：过山车行情意味着什么	2</span><br><span class="line">中华女子学院：本科层次仅1专业招男生	3</span><br><span class="line">两天价网站背后重重迷雾：做个网站究竟要多少钱	4</span><br><span class="line">东5环海棠公社230-290平2居准现房98折优惠	1</span><br><span class="line">卡佩罗：告诉你德国脚生猛的原因 不希望英德战踢点球	7</span><br><span class="line">82岁老太为学生做饭扫地44年获授港大荣誉院士	5</span><br></pre></td></tr></table></figure>

<p><code>金证顾问：过山车行情意味着什么</code>为新闻标题，<code>2</code>为这个新闻对应的类别，对应<code>class.txt</code>中10类别的<code>stocks</code>。</p>
<p>目标：通过训练<code>train.txt</code>中的数据，生成模型，再推理<code>test.txt</code>中新闻标题对应类别，并计算准确度。</p>
<h3 id="2-词汇表"><a href="#2-词汇表" class="headerlink" title="2.词汇表"></a>2.词汇表</h3><p><code>vocab.pkl</code>是词汇表，存储词汇到索引的映射，用于将文本转换为神经网络可处理的数字格式，有两个作用：</p>
<ol>
<li>模型训练时，它用于将文本转换为索引（tokenization）</li>
<li>模型预测时，它用于将索引转换回单词（解码）</li>
</ol>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27; &#x27;<span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> &#x27;<span class="number">0</span>&#x27;<span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> &#x27;<span class="number">1</span>&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;<span class="number">2</span>&#x27;<span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span> &#x27;：&#x27;<span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span> &#x27;大&#x27;<span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span> &#x27;国&#x27;<span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> &#x27;图&#x27;<span class="punctuation">:</span> <span class="number">7</span><span class="punctuation">,</span> &#x27;(&#x27;<span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span> &#x27;)&#x27;<span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span> &#x27;<span class="number">3</span>&#x27;<span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span> &#x27;人&#x27;<span class="punctuation">:</span> <span class="number">11</span><span class="punctuation">,</span> &#x27;年&#x27;<span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span> &#x27;<span class="number">5</span>&#x27;<span class="punctuation">:</span> <span class="number">13</span><span class="punctuation">,</span> &#x27;中&#x27;<span class="punctuation">:</span> <span class="number">14</span><span class="punctuation">,</span> &#x27;新&#x27;<span class="punctuation">:</span> <span class="number">15</span><span class="punctuation">,</span> &#x27;<span class="number">9</span>&#x27;<span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span> &#x27;生&#x27;<span class="punctuation">:</span> <span class="number">17</span><span class="punctuation">,</span> &#x27;金&#x27;<span class="punctuation">:</span> <span class="number">18</span><span class="punctuation">,</span> &#x27;高&#x27;<span class="punctuation">:</span> <span class="number">19</span><span class="punctuation">,</span> &#x27;《&#x27;<span class="punctuation">:</span> <span class="number">20</span><span class="punctuation">,</span> &#x27;》&#x27;<span class="punctuation">:</span> <span class="number">21</span><span class="punctuation">,</span> &#x27;<span class="number">4</span>&#x27;<span class="punctuation">:</span> <span class="number">22</span><span class="punctuation">,</span> &#x27;上&#x27;<span class="punctuation">:</span> <span class="number">23</span><span class="punctuation">,</span> &#x27;<span class="number">8</span>&#x27;<span class="punctuation">:</span> <span class="number">24</span><span class="punctuation">,</span> &#x27;不&#x27;<span class="punctuation">:</span> <span class="number">25</span><span class="punctuation">,</span> &#x27;考&#x27;<span class="punctuation">:</span> <span class="number">26</span><span class="punctuation">,</span> &#x27;一&#x27;<span class="punctuation">:</span> <span class="number">27</span><span class="punctuation">,</span> &#x27;<span class="number">6</span>&#x27;<span class="punctuation">:</span> <span class="number">28</span><span class="punctuation">,</span> &#x27;日&#x27;<span class="punctuation">:</span> <span class="number">29</span><span class="punctuation">,</span> &#x27;元&#x27;<span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span> &#x27;开&#x27;<span class="punctuation">:</span> <span class="number">31</span><span class="punctuation">,</span> &#x27;美&#x27;<span class="punctuation">:</span> <span class="number">32</span><span class="punctuation">,</span> ...</span><br></pre></td></tr></table></figure>
<h3 id="3-预训练词向量"><a href="#3-预训练词向量" class="headerlink" title="3.预训练词向量"></a>3.预训练词向量</h3><p><strong>预训练词向量</strong>（如 word2vec、GloVe）是在 <strong>海量文本数据</strong>（如 Wikipedia、新闻）上训练得到的，它们能够：</p>
<ul>
<li><strong>捕捉单词的语义关系</strong>（如 “king” - “man” + “woman” ≈ “queen”）</li>
<li><strong>处理语境相似的单词</strong>（如 “big” 和 “large” 词向量相近）</li>
<li><strong>减少训练数据对模型性能的影响</strong>（少量数据也能学得不错的表示）</li>
</ul>
<p>预训练词向量 &#x3D; 语言理解的“知识库”，能跨任务共享信息。<code>embedding_SougouNews.npz</code>和<code>embedding_Tencent.npz</code>是搜狗和腾讯提供的两个预训练词向量库。</p>
<h3 id="4-训练数据转化流程"><a href="#4-训练数据转化流程" class="headerlink" title="4.训练数据转化流程"></a>4.训练数据转化流程</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"># <span class="number">1.</span>训练集数据 (新闻标题 对应分类)</span><br><span class="line">金证顾问：过山车行情意味着什么 <span class="number">2</span></span><br><span class="line"></span><br><span class="line"># <span class="number">2.</span>对应词索引 (<span class="punctuation">[</span>列表<span class="punctuation">,</span> 标签<span class="punctuation">,</span> 序列长度<span class="punctuation">]</span>)  </span><br><span class="line"><span class="punctuation">[</span>(<span class="punctuation">[</span><span class="number">18</span><span class="punctuation">,</span> <span class="number">249</span><span class="punctuation">,</span> <span class="number">1086</span><span class="punctuation">,</span> <span class="number">438</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">268</span><span class="punctuation">,</span> <span class="number">169</span><span class="punctuation">,</span> <span class="number">121</span><span class="punctuation">,</span> <span class="number">46</span><span class="punctuation">,</span> <span class="number">143</span><span class="punctuation">,</span> <span class="number">274</span><span class="punctuation">,</span> <span class="number">1342</span><span class="punctuation">,</span> <span class="number">1068</span><span class="punctuation">,</span> <span class="number">1046</span><span class="punctuation">,</span> <span class="number">1081</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">15</span>)<span class="punctuation">]</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3.</span> to tensor (batch_size = <span class="number">128</span>)</span><br><span class="line">tensor(<span class="punctuation">[</span><span class="punctuation">[</span><span class="number">18</span><span class="punctuation">,</span>  <span class="number">249</span><span class="punctuation">,</span> <span class="number">1086</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line">	    <span class="punctuation">[</span><span class="number">14</span><span class="punctuation">,</span>  <span class="number">125</span><span class="punctuation">,</span>   <span class="number">55</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">,</span>    </span><br><span class="line">	       ...<span class="punctuation">,</span>    </span><br><span class="line">	    <span class="punctuation">[</span><span class="number">160</span><span class="punctuation">,</span> <span class="number">1667</span><span class="punctuation">,</span> <span class="number">1147</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">	    <span class="punctuation">[</span><span class="number">31</span><span class="punctuation">,</span>   <span class="number">75</span><span class="punctuation">,</span>    <span class="number">4</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">,</span>    </span><br><span class="line">	    <span class="punctuation">[</span><span class="number">321</span><span class="punctuation">,</span>  <span class="number">566</span><span class="punctuation">,</span>  <span class="number">130</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">,</span> <span class="number">4760</span><span class="punctuation">]</span><span class="punctuation">]</span>)<span class="punctuation">,</span> </span><br><span class="line">tensor(<span class="punctuation">[</span><span class="number">15</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">17</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">16</span><span class="punctuation">,</span> <span class="number">11</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span>  <span class="number">7</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span>  </span><br><span class="line">    <span class="number">15</span><span class="punctuation">,</span>  <span class="number">9</span><span class="punctuation">,</span> <span class="number">17</span><span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> <span class="number">24</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">17</span><span class="punctuation">,</span> <span class="number">17</span><span class="punctuation">,</span> ...<span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">14</span><span class="punctuation">,</span> <span class="number">19</span><span class="punctuation">,</span> <span class="number">13</span><span class="punctuation">,</span> <span class="number">29</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">16</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">]</span>))<span class="punctuation">,</span> </span><br><span class="line">tensor(<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">7</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">9</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">7</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">6</span><span class="punctuation">,</span> <span class="number">7</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span>  </span><br><span class="line">    <span class="number">9</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">9</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">9</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">,</span> ...<span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">9</span><span class="punctuation">]</span>)</span><br><span class="line"></span><br><span class="line"># <span class="number">4.</span> 映射为词向量</span><br><span class="line">tensor(<span class="punctuation">[</span><span class="punctuation">[</span><span class="punctuation">[</span> <span class="number">3.0235e-01</span><span class="punctuation">,</span>  <span class="number">2.0894e-01</span><span class="punctuation">,</span> <span class="number">-8.0932e-02</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">-4.3194e-02</span><span class="punctuation">,</span>  </span><br><span class="line">      <span class="number">-3.1051e-01</span><span class="punctuation">,</span>  <span class="number">1.8790e-01</span><span class="punctuation">]</span><span class="punctuation">,</span>     <span class="punctuation">[</span> <span class="number">3.7446e-02</span><span class="punctuation">,</span> <span class="number">-5.7123e-02</span><span class="punctuation">,</span> <span class="number">-2.5790e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span> <span class="number">-2.9264e-01</span><span class="punctuation">,</span>       <span class="number">1.8909e-01</span><span class="punctuation">,</span> <span class="number">-5.4846e-01</span><span class="punctuation">]</span><span class="punctuation">,</span>     <span class="punctuation">[</span><span class="number">-2.5890e-02</span><span class="punctuation">,</span>  <span class="number">1.3263e-01</span><span class="punctuation">,</span> <span class="number">-4.0175e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">3.4654e-01</span><span class="punctuation">,</span>      <span class="number">-5.0803e-01</span><span class="punctuation">,</span> <span class="number">-1.8250e-01</span><span class="punctuation">]</span><span class="punctuation">,</span>     ...<span class="punctuation">,</span>     <span class="punctuation">[</span> <span class="number">5.0378e-01</span><span class="punctuation">,</span>  <span class="number">6.4967e-01</span><span class="punctuation">,</span>  <span class="number">4.0962e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">6.4058e-01</span><span class="punctuation">,</span>       <span class="number">2.7467e-01</span><span class="punctuation">,</span>  <span class="number">7.9185e-01</span><span class="punctuation">]</span><span class="punctuation">,</span>     <span class="punctuation">[</span> <span class="number">5.0378e-01</span><span class="punctuation">,</span>  <span class="number">6.4967e-01</span><span class="punctuation">,</span>  <span class="number">4.0962e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">6.4058e-01</span><span class="punctuation">,</span>       <span class="number">2.7467e-01</span><span class="punctuation">,</span>  <span class="number">7.9185e-01</span><span class="punctuation">]</span><span class="punctuation">,</span>     <span class="punctuation">[</span> <span class="number">5.0378e-01</span><span class="punctuation">,</span>  <span class="number">6.4967e-01</span><span class="punctuation">,</span>  <span class="number">4.0962e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">6.4058e-01</span><span class="punctuation">,</span>       <span class="number">2.7467e-01</span><span class="punctuation">,</span>  <span class="number">7.9185e-01</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span>   </span><br><span class="line">    <span class="punctuation">[</span><span class="punctuation">[</span> <span class="number">3.1487e-01</span><span class="punctuation">,</span> <span class="number">-3.2435e-01</span><span class="punctuation">,</span>  <span class="number">1.3675e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">1.9030e-01</span><span class="punctuation">,</span>       <span class="number">1.3956e-01</span><span class="punctuation">,</span>  <span class="number">7.8458e-02</span><span class="punctuation">]</span><span class="punctuation">,</span>     <span class="punctuation">[</span><span class="number">-1.5683e-02</span><span class="punctuation">,</span>  <span class="number">9.9436e-02</span><span class="punctuation">,</span> <span class="number">-4.0968e-01</span><span class="punctuation">,</span>  ...<span class="punctuation">,</span>  <span class="number">2.0924e-01</span><span class="punctuation">,</span>      ...<span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span> grad_fn=&lt;EmbeddingBackward0&gt;)</span><br></pre></td></tr></table></figure>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h2><h3 id="1-命令行参数配置"><a href="#1-命令行参数配置" class="headerlink" title="1.命令行参数配置"></a>1.命令行参数配置</h3><p>因为本次文本分类定义了两个模型，<code>Text_CNN</code>和<code>Text_RNN</code>，同时词向量映射支持搜狗和腾讯的预训练词向量和随机词向量，排列组合后有6种训练方式，为了方便可以使用命令行的方式配置参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python run.py --model text_rnn --embedding sougou</span><br></pre></td></tr></table></figure>

<p>如果想在<code>PyCharm</code>中配置，<code>Edit Configurations...</code> -&gt; <code>Script parameters</code>中添加:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--model text_cnn --embedding tencent</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过命令行的方式指定参数  </span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&quot;Classification Text&quot;</span>)  </span><br><span class="line">parser.add_argument(<span class="string">&#x27;--model&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&quot;choose model：Text_CNN, Text_RNN&quot;</span>)  </span><br><span class="line">parser.add_argument(<span class="string">&#x27;--embedding&#x27;</span>, default=<span class="string">&#x27;sogou&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;random or sogou、tencent&#x27;</span>)  </span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>

<p><code>args.model</code>和<code>args.embedding</code>就可以拿到对应参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_name = args.model  </span><br><span class="line">embedding = args.embedding  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;args model:<span class="subst">&#123;model_name&#125;</span>, embedding:<span class="subst">&#123;embedding&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># args model:Text_RNN, embedding:tencent  </span></span><br></pre></td></tr></table></figure>
<h3 id="2-资源配置"><a href="#2-资源配置" class="headerlink" title="2.资源配置"></a>2.资源配置</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SourceConfig</span>(<span class="title class_ inherited__">object</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, _embedding</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.train_path = dataset + <span class="string">&#x27;/data/train.txt&#x27;</span>  <span class="comment"># 训练集路径  </span></span><br><span class="line">        <span class="variable language_">self</span>.dev_path = dataset + <span class="string">&#x27;/data/dev.txt&#x27;</span>  <span class="comment"># 验证集路径  </span></span><br><span class="line">        <span class="variable language_">self</span>.test_path = dataset + <span class="string">&#x27;/data/test.txt&#x27;</span>  <span class="comment"># 测试集路径  </span></span><br><span class="line">        <span class="variable language_">self</span>.class_list = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">open</span>(dataset + <span class="string">&#x27;/data/class.txt&#x27;</span>).readlines()]  <span class="comment"># 分类类别  </span></span><br><span class="line">        <span class="variable language_">self</span>.vocab_path = dataset + <span class="string">&#x27;/data/vocab.pkl&#x27;</span>  <span class="comment"># 词表路径  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_classes = <span class="built_in">len</span>(<span class="variable language_">self</span>.class_list)  <span class="comment"># 类别个数  </span></span><br><span class="line">        <span class="variable language_">self</span>.embedding_pretrained = (torch.tensor(  <span class="comment"># 词向量  </span></span><br><span class="line">            np.load(dataset + <span class="string">&#x27;/data/&#x27;</span> + _embedding)[<span class="string">&quot;embeddings&quot;</span>].astype(<span class="string">&#x27;float32&#x27;</span>))  </span><br><span class="line">            <span class="keyword">if</span> _embedding != <span class="string">&#x27;random&#x27;</span> <span class="keyword">else</span> <span class="literal">None</span>  <span class="comment"># random返回None  </span></span><br><span class="line">        )  <span class="comment"># 词向量  </span></span><br><span class="line">        <span class="variable language_">self</span>.embed = (  <span class="comment"># 字向量维度, 若使用了预训练词向量，则维度统一  </span></span><br><span class="line">            <span class="variable language_">self</span>.embedding_pretrained.size(<span class="number">1</span>)  </span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.embedding_pretrained <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="number">300</span>  <span class="comment"># 等于None返回300  </span></span><br><span class="line">        )  </span><br><span class="line">        <span class="variable language_">self</span>.device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)  <span class="comment"># 设备类型</span></span><br></pre></td></tr></table></figure>
<p>词向量参数如果设置为了<code>random</code>，词向量会在训练模型初始化的时候随机初始化词向量。</p>
<h3 id="3-随机种子"><a href="#3-随机种子" class="headerlink" title="3.随机种子"></a>3.随机种子</h3><p>在深度学习中，很多地方都会用到随机性，比如随机初始化模型参数、数据加载时的随机打乱、Dropout 层的随机性、优化器中的随机梯度下降等。<br>为了保证每次运行代码都会得到相同的结果，需要设置随机种子，保证每次运行代码时生成的随机数是相同的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.random.rand(<span class="number">3</span>)) <span class="comment"># 每次运行输出都是：[4.17022005e-01 7.20324493e-01 1.14374817e-04]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">keep_seed</span>():  </span><br><span class="line">    <span class="comment"># 固定种子，保证在运行时的随机性和计算过程是可重复的  </span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)  </span><br><span class="line">    torch.manual_seed(<span class="number">1</span>)  </span><br><span class="line">    torch.cuda.manual_seed_all(<span class="number">1</span>)  </span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h3 id="4-加载dataset"><a href="#4-加载dataset" class="headerlink" title="4.加载dataset"></a>4.加载dataset</h3><p>在<code>SourceConfig</code>中添加了训练集、验证集和测试集的路径，还需要加载对应的训练集数据并通过词汇表转换为对应的索引映射。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MAX_VOCAB_SIZE = <span class="number">10000</span>  <span class="comment"># 词表长度限制  </span></span><br><span class="line">UNK, PAD = <span class="string">&#x27;&lt;UNK&gt;&#x27;</span>, <span class="string">&#x27;&lt;PAD&gt;&#x27;</span>  <span class="comment"># 未知字，padding符号  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_time_dif</span>(<span class="params">start_time</span>):  </span><br><span class="line">    <span class="comment"># 获取已使用时间  </span></span><br><span class="line">    end_time = time.time()  </span><br><span class="line">    time_dif = end_time - start_time  </span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=<span class="built_in">int</span>(<span class="built_in">round</span>(time_dif)))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_load_dataset</span>(<span class="params">path, vocab, pad_size=<span class="number">32</span></span>):  </span><br><span class="line">    contents = []  </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f):  <span class="comment"># 自动打印进度信息  </span></span><br><span class="line">            lin = line.strip()  <span class="comment"># 去除收尾空格  </span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> lin:  <span class="comment"># 跳过空行  </span></span><br><span class="line">                <span class="keyword">continue</span>  </span><br><span class="line">            content, label = lin.split(<span class="string">&#x27;\t&#x27;</span>)  </span><br><span class="line">            words_line = []  </span><br><span class="line">            token = [y <span class="keyword">for</span> y <span class="keyword">in</span> content]  <span class="comment"># 分字  </span></span><br><span class="line">            seq_len = <span class="built_in">len</span>(token)  </span><br><span class="line">            <span class="keyword">if</span> pad_size:  </span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(token) &lt; pad_size:  </span><br><span class="line">                    <span class="comment"># 不足补PAD</span></span><br><span class="line">                    token.extend([vocab.get(PAD)] * (pad_size - <span class="built_in">len</span>(token)))</span><br><span class="line">                 <span class="keyword">else</span>:  </span><br><span class="line">                    token = token[:pad_size]  <span class="comment"># 超过最大长度就截断  </span></span><br><span class="line">                    seq_len = pad_size  <span class="comment"># 重新设定序列长度  </span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> token:  <span class="comment"># 将单词/字符转换为索引  </span></span><br><span class="line">                words_line.append(vocab.get(word, vocab.get(UNK))) <span class="comment"># UNK代表未知词</span></span><br><span class="line">            contents.append((words_line, <span class="built_in">int</span>(label), seq_len))  </span><br><span class="line">    <span class="keyword">return</span> contents  <span class="comment"># 结构：[(词索引列表, 标签, 序列长度)]  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">model, config</span>):  </span><br><span class="line">    vocab = pkl.load(<span class="built_in">open</span>(config.vocab_path, <span class="string">&#x27;rb&#x27;</span>))  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Vocab size: <span class="subst">&#123;<span class="built_in">len</span>(vocab)&#125;</span>&quot;</span>)  </span><br><span class="line">    train = _load_dataset(config.train_path, vocab, model.pad_size)  </span><br><span class="line">    dev = _load_dataset(config.dev_path, vocab, model.pad_size)  </span><br><span class="line">    test = _load_dataset(config.test_path, vocab, model.pad_size)  </span><br><span class="line">    <span class="keyword">return</span> vocab, train, dev, test</span><br></pre></td></tr></table></figure>
<p>目前<code>pad_size</code>的大小设置是32，如果文本长度小于32的部分补齐<code>PAD</code>，超过部分则截断。如果文本中有字不在词汇表中无法映射，则用<code>UNK</code>替代，<code>UNK</code>和<code>PAD</code>分别对应的词汇表映射是4760和4761。<br>转换前的文本:<br><code>金证顾问：过山车行情意味着什么</code><br>转换后的文本:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[18, 249, 1086, 438, 4, 268, 169, 121, 46, 143, 274, 1342, 1068, 1046, 1081, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760, 4760]</span><br></pre></td></tr></table></figure>

<h3 id="5-迭代器和toTensor"><a href="#5-迭代器和toTensor" class="headerlink" title="5.迭代器和toTensor"></a>5.迭代器和toTensor</h3><h4 id="1-迭代器"><a href="#1-迭代器" class="headerlink" title="1.迭代器"></a>1.迭代器</h4><p>可用于遍历可迭代对象（如列表、元组、字典、集合等）。<code>Iterator</code> 通过 <code>__iter__()</code> 和 <code>__next__()</code> 方法实现，允许我们逐个访问元素，也可以自定义一次遍历多个元素，举个简单例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyRange</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line">        <span class="variable language_">self</span>.start = start</span><br><span class="line">        <span class="variable language_">self</span>.end = end</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.start &gt;= <span class="variable language_">self</span>.end:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        current = <span class="variable language_">self</span>.start</span><br><span class="line">        <span class="variable language_">self</span>.start += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> current</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义迭代器</span></span><br><span class="line">my_range = MyRange(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> my_range:</span><br><span class="line">    <span class="built_in">print</span>(num)  <span class="comment"># 输出: 1 2 3 4</span></span><br></pre></td></tr></table></figure>

<p>自定义<code>DatasetIterator</code>迭代器，一次返回<code>batch_size</code>个元素，如果不满足<code>batch_size</code>则返回剩余元素</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DatasetIterator</span>(<span class="title class_ inherited__">object</span>):  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, batch_size, device</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.dataset = dataset  </span><br><span class="line">        <span class="variable language_">self</span>.batch_size = batch_size  </span><br><span class="line">        <span class="variable language_">self</span>.device = device  </span><br><span class="line">        <span class="variable language_">self</span>.index = <span class="number">0</span>  </span><br><span class="line">        <span class="variable language_">self</span>.num_batches = <span class="built_in">len</span>(dataset) // batch_size  <span class="comment"># batch数量  </span></span><br><span class="line">        <span class="variable language_">self</span>.residue = <span class="built_in">len</span>(<span class="variable language_">self</span>.dataset) % <span class="variable language_">self</span>.num_batches != <span class="number">0</span>  <span class="comment"># batch数量是否正好为整数  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):  <span class="comment"># 迭代器  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.residue <span class="keyword">and</span> <span class="variable language_">self</span>.index == <span class="variable language_">self</span>.num_batches:  </span><br><span class="line">            <span class="comment"># 取最后非batch_size大小段  </span></span><br><span class="line">            batches = <span class="variable language_">self</span>.dataset[<span class="variable language_">self</span>.index * <span class="variable language_">self</span>.batch_size: <span class="built_in">len</span>(<span class="variable language_">self</span>.dataset)]  </span><br><span class="line">            <span class="variable language_">self</span>.index += <span class="number">1</span>  </span><br><span class="line">            batches = <span class="variable language_">self</span>._to_tensor(batches)  </span><br><span class="line">            <span class="keyword">return</span> batches  </span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.index &gt; <span class="variable language_">self</span>.num_batches:  </span><br><span class="line">            <span class="variable language_">self</span>.index = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">raise</span> StopIteration  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 取batch_size下一段  </span></span><br><span class="line">            batches = <span class="variable language_">self</span>.dataset[<span class="variable language_">self</span>.index * <span class="variable language_">self</span>.batch_size: (<span class="variable language_">self</span>.index + <span class="number">1</span>) * <span class="variable language_">self</span>.batch_size]  </span><br><span class="line">            <span class="variable language_">self</span>.index += <span class="number">1</span>  </span><br><span class="line">            batches = <span class="variable language_">self</span>._to_tensor(batches)  </span><br><span class="line">            <span class="keyword">return</span> batches  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):  <span class="comment"># 可迭代对象  </span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  <span class="comment"># 容器对象  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.residue:  </span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.num_batches + <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.num_batches  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_iterator</span>(<span class="params">dataset, batch_size, device</span>):  </span><br><span class="line">    <span class="keyword">return</span> DatasetIterator(dataset, batch_size, device)</span><br></pre></td></tr></table></figure>

<h4 id="2-Tensor"><a href="#2-Tensor" class="headerlink" title="2.Tensor"></a>2.Tensor</h4><p> 将数据转换为 PyTorch 的张量（Tensor），并移动到指定的设备（CPU&#x2F;GPU）以备模型训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_to_tensor</span>(<span class="params">self, datas</span>):  </span><br><span class="line">    x = torch.LongTensor([_[<span class="number">0</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(<span class="variable language_">self</span>.device)  </span><br><span class="line">    y = torch.LongTensor([_[<span class="number">1</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(<span class="variable language_">self</span>.device)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># pad前的长度(超过pad_size的设为pad_size)  </span></span><br><span class="line">    seq_len = torch.LongTensor([_[<span class="number">2</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(<span class="variable language_">self</span>.device)  </span><br><span class="line">    <span class="keyword">return</span> (x, seq_len), y  </span><br></pre></td></tr></table></figure>

<p>这一步可同时完成训练集验证集和测试集的Tensor数据准备</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_iter = build_iterator(train_data, model.batch_size, source_config.device)  </span><br><span class="line">dev_iter = build_iterator(dev_data, model.batch_size, source_config.device)  </span><br><span class="line">test_iter = build_iterator(test_data, model.batch_size, source_config.device)</span><br></pre></td></tr></table></figure>
<h2 id="3-模型定义"><a href="#3-模型定义" class="headerlink" title="3.模型定义"></a>3.模型定义</h2><h3 id="1-RNN模型"><a href="#1-RNN模型" class="headerlink" title="1.RNN模型"></a>1.RNN模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, dataset</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Model, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.model_name = <span class="string">&#x27;TextRNN&#x27;</span>  </span><br><span class="line">        <span class="variable language_">self</span>.save_path = dataset + <span class="string">&#x27;/saved_dict/&#x27;</span> + <span class="variable language_">self</span>.model_name + <span class="string">&#x27;.ckpt&#x27;</span>  <span class="comment"># 模型训练结果  </span></span><br><span class="line">        <span class="variable language_">self</span>.log_path = dataset + <span class="string">&#x27;/log/&#x27;</span> + <span class="variable language_">self</span>.model_name  <span class="comment"># 日志路径  </span></span><br><span class="line">        <span class="variable language_">self</span>.pad_size = <span class="number">32</span>  <span class="comment"># 每句话处理成的长度(短填长切)  </span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = <span class="number">0.5</span>  <span class="comment"># 随机失活  </span></span><br><span class="line">        <span class="variable language_">self</span>.require_improvement = <span class="number">1000</span>  <span class="comment"># 若超过1000batch效果还没提升，则提前结束训练  </span></span><br><span class="line">        <span class="variable language_">self</span>.n_vocab = <span class="number">0</span>  <span class="comment"># 词表大小，运行时赋值  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_epochs = <span class="number">10</span>  <span class="comment"># epoch数  </span></span><br><span class="line">        <span class="variable language_">self</span>.batch_size = <span class="number">128</span>  <span class="comment"># mini-batch大小  </span></span><br><span class="line">        <span class="variable language_">self</span>.learning_rate = <span class="number">1e-3</span>  <span class="comment"># 学习率  </span></span><br><span class="line">        <span class="variable language_">self</span>.hidden_size = <span class="number">128</span>  <span class="comment"># lstm隐藏层  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_layers = <span class="number">2</span>  <span class="comment"># lstm层数  </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1.初始化词嵌入层</span></span><br><span class="line">        <span class="keyword">if</span> config.embedding_pretrained <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=<span class="literal">False</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            vocab = pkl.load(<span class="built_in">open</span>(config.vocab_path, <span class="string">&#x27;rb&#x27;</span>))  </span><br><span class="line">            <span class="variable language_">self</span>.n_vocab = <span class="built_in">len</span>(vocab)  </span><br><span class="line">            <span class="variable language_">self</span>.embedding = nn.Embedding(<span class="variable language_">self</span>.n_vocab, config.embed, padding_idx=<span class="variable language_">self</span>.n_vocab - <span class="number">1</span>)  </span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 2. LSTM</span></span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(config.embed, <span class="variable language_">self</span>.hidden_size, <span class="variable language_">self</span>.num_layers, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>, dropout=<span class="variable language_">self</span>.dropout)</span><br><span class="line">        <span class="comment"># 3. 全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="variable language_">self</span>.hidden_size * <span class="number">2</span>, config.num_classes)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x, _ = x  <span class="comment"># 解包输入  </span></span><br><span class="line">        out = <span class="variable language_">self</span>.embedding(x)</span><br><span class="line">        out, _ = <span class="variable language_">self</span>.lstm(out)  <span class="comment"># LSTM处理  </span></span><br><span class="line">        out = <span class="variable language_">self</span>.fc(out[:, -<span class="number">1</span>, :]) <span class="comment"># 取最后时间步的输出，传入全连接层  </span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h4 id="1-模型属性"><a href="#1-模型属性" class="headerlink" title="1.模型属性"></a>1.模型属性</h4><h5 id="1-初始化词嵌入层"><a href="#1-初始化词嵌入层" class="headerlink" title="1.初始化词嵌入层"></a>1.初始化词嵌入层</h5><p>在初始化词嵌入层的时候，如果<code>config.embedding_pretrained</code>参数有设置，则使用<strong>预训练词向量</strong>，否则使用<strong>随机初始化的词向量</strong></p>
<h5 id="2-LSTM-1"><a href="#2-LSTM-1" class="headerlink" title="2.LSTM"></a>2.LSTM</h5><p>用于处理 <strong>文本序列</strong>，捕捉 <strong>长期依赖信息</strong></p>
<table>
<thead>
<tr>
<th><strong>参数</strong></th>
<th><strong>作用</strong></th>
</tr>
</thead>
<tbody><tr>
<td>config.embed</td>
<td>词向量的维度（每个单词的向量表示大小，例如 300）</td>
</tr>
<tr>
<td>self.hidden_size</td>
<td>LSTM 隐藏层的维度（影响 LSTM 记忆能力，例如 128）</td>
</tr>
<tr>
<td>self.num_layers</td>
<td>LSTM 堆叠的层数（如 2，表示有 2 层 LSTM）</td>
</tr>
<tr>
<td>bidirectional&#x3D;True</td>
<td><strong>双向 LSTM</strong>（前向和后向 LSTM）</td>
</tr>
<tr>
<td>batch_first&#x3D;True</td>
<td>输入数据格式为 (batch_size, seq_len, input_dim)，即 batch 维度在第一位</td>
</tr>
<tr>
<td>dropout&#x3D;self.dropout</td>
<td>LSTM 层之间的 dropout 率，防止过拟合</td>
</tr>
</tbody></table>
<p>双向 LSTM可以同时从 <strong>前向和后向</strong> 处理句子，增强了对前后文的理解，提高文本分类、命名实体识别等任务的效果</p>
<h5 id="3-全连接层"><a href="#3-全连接层" class="headerlink" title="3.全连接层"></a>3.全连接层</h5><p>因为使用了双向 LSTM (bidirectional&#x3D;True)，隐藏层的输出维度是 <strong>正向 LSTM 输出 + 反向 LSTM 输出</strong>，所以最终LSTM的输出维度是<code>hidden_size * 2</code>。<br>全连接层的输入维度必须是 256，最后将数据映射到 num_classes 个类别</p>
<h4 id="2-前向传播"><a href="#2-前向传播" class="headerlink" title="2.前向传播"></a>2.前向传播</h4><p>主要包括：解包输入、词嵌入、LSTM 处理、取最后时间步的输出、通过全连接层</p>
<ul>
<li><code>x, _ = x</code>，<strong>输入 x</strong> 是一个 <strong>元组</strong>，包含 (x, seq_len)只取x</li>
<li><code>out = self.embedding(x)</code>，把 x 中的词索引转换成词向量</li>
<li><code>out, _ = self.lstm(out)</code>，将词向量输入 LSTM，提取序列特征</li>
<li><code>out = self.fc(out[:, -1, :])</code>，<code>out[:, -1, :]</code>取序列的最后一个时间步的隐藏状态，形状变为 (batch_size, hidden_size * 2)，为什么要取最后时间步？<ul>
<li>在文本分类任务中，我们通常只关心整个句子的表示，而不需要每个时间步的输出</li>
<li><strong>方法</strong>：用 LSTM 处理整个句子，取最后的隐藏状态作为句子表示，再进行分类</li>
</ul>
</li>
</ul>
<h4 id="3-模型参数"><a href="#3-模型参数" class="headerlink" title="3.模型参数"></a>3.模型参数</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">	(embedding): Embedding(4762, 300) </span><br><span class="line">	(lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True) </span><br><span class="line">	(fc): Linear(in_features=256, out_features=10, bias=True) </span><br><span class="line"><span class="meta prompt_">)&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-CNN模型"><a href="#2-CNN模型" class="headerlink" title="2.CNN模型"></a>2.CNN模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv_and_pool</span>(<span class="params">x, conv</span>):  </span><br><span class="line">    x = F.relu(conv(x)).squeeze(<span class="number">3</span>)  </span><br><span class="line">    x = F.max_pool1d(x, x.size(<span class="number">2</span>)).squeeze(<span class="number">2</span>)  </span><br><span class="line">    <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, dataset</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Model, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.model_name = <span class="string">&#x27;TextCNN&#x27;</span>  </span><br><span class="line">        <span class="variable language_">self</span>.save_path = dataset + <span class="string">&#x27;/saved_dict/&#x27;</span> + <span class="variable language_">self</span>.model_name + <span class="string">&#x27;.ckpt&#x27;</span>  <span class="comment"># 模型训练结果  </span></span><br><span class="line">        <span class="variable language_">self</span>.log_path = dataset + <span class="string">&#x27;/log/&#x27;</span> + <span class="variable language_">self</span>.model_name  <span class="comment"># 日志  </span></span><br><span class="line">        <span class="variable language_">self</span>.pad_size = <span class="number">32</span>  <span class="comment"># 每句话处理成的长度(短填长切)  </span></span><br><span class="line">        <span class="variable language_">self</span>.batch_size = <span class="number">128</span>  </span><br><span class="line">        <span class="variable language_">self</span>.dropout = <span class="number">0.5</span>  <span class="comment"># 随机失活  </span></span><br><span class="line">        <span class="variable language_">self</span>.require_improvement = <span class="number">1000</span>  <span class="comment"># 若超过1000batch效果还没提升，则提前结束训练  </span></span><br><span class="line">        <span class="variable language_">self</span>.n_vocab = <span class="number">0</span>  <span class="comment"># 词表大小，在运行时赋值  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_epochs = <span class="number">20</span>  <span class="comment"># epoch数  </span></span><br><span class="line">        <span class="variable language_">self</span>.learning_rate = <span class="number">1e-3</span>  <span class="comment"># 学习率  </span></span><br><span class="line">        <span class="variable language_">self</span>.filter_sizes = (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)  <span class="comment"># 卷积核尺寸  </span></span><br><span class="line">        <span class="variable language_">self</span>.num_filters = <span class="number">256</span>  <span class="comment"># 卷积核数量(channels数)  </span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> config.embedding_pretrained <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=<span class="literal">False</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            vocab = pkl.load(<span class="built_in">open</span>(config.vocab_path, <span class="string">&#x27;rb&#x27;</span>))  </span><br><span class="line">            <span class="variable language_">self</span>.n_vocab = <span class="built_in">len</span>(vocab)  </span><br><span class="line">            <span class="variable language_">self</span>.embedding = nn.Embedding(<span class="variable language_">self</span>.n_vocab, config.embed, padding_idx=<span class="variable language_">self</span>.n_vocab - <span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.ModuleList(  </span><br><span class="line">            [nn.Conv2d(<span class="number">1</span>, <span class="variable language_">self</span>.num_filters, (k, config.embed)) <span class="keyword">for</span> k <span class="keyword">in</span> <span class="variable language_">self</span>.filter_sizes])  </span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(<span class="variable language_">self</span>.dropout)  </span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="variable language_">self</span>.num_filters * <span class="built_in">len</span>(<span class="variable language_">self</span>.filter_sizes), config.num_classes)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        out = <span class="variable language_">self</span>.embedding(x[<span class="number">0</span>])  </span><br><span class="line">        out = out.unsqueeze(<span class="number">1</span>)  </span><br><span class="line">        out = torch.cat([conv_and_pool(out, conv) <span class="keyword">for</span> conv <span class="keyword">in</span> <span class="variable language_">self</span>.conv], <span class="number">1</span>)  </span><br><span class="line">        out = <span class="variable language_">self</span>.dropout(out)  </span><br><span class="line">        out = <span class="variable language_">self</span>.fc(out)  </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h4 id="1-模型属性-1"><a href="#1-模型属性-1" class="headerlink" title="1.模型属性"></a>1.模型属性</h4><h5 id="1-初始化词嵌入层-1"><a href="#1-初始化词嵌入层-1" class="headerlink" title="1.初始化词嵌入层"></a>1.初始化词嵌入层</h5><p>在初始化词嵌入层的时候，如果<code>config.embedding_pretrained</code>参数有设置，则使用<strong>预训练词向量</strong>，否则使用<strong>随机初始化的词向量</strong>（同RNN模型）</p>
<h5 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2.卷积层"></a>2.卷积层</h5><p><code>Conv2d(1, self.num_filters, (k, config.embed))</code></p>
<ul>
<li>1 表示单通道输入（即词向量维度不变）</li>
<li><code>self.num_filters</code> 是 <strong>每种卷积核的数量</strong>，每个 filter 提取不同的 k-gram 组合（如 bi-gram、tri-gram）</li>
<li><code>(k, config.embed)</code> <strong>卷积核尺寸</strong>，k 控制窗口大小，embed 让每个 filter 作用于整个词向量</li>
</ul>
<h5 id="3-全连接层-Dropout"><a href="#3-全连接层-Dropout" class="headerlink" title="3.全连接层 &amp; Dropout"></a>3.全连接层 &amp; Dropout</h5><ul>
<li><code>self.dropout</code>：防止过拟合。</li>
<li><code>self.fc</code>：将所有 filter 提取的特征拼接，然后进行分类：</li>
<li><code>self.num_filters * len(self.filter_sizes)</code>：每个 filter 贡献 num_filters 维，多个 filter 拼接在一起</li>
</ul>
<h4 id="2-前向传播-1"><a href="#2-前向传播-1" class="headerlink" title="2.前向传播"></a>2.前向传播</h4><ul>
<li><code>out = self.embedding(x[0])</code>：输入x是 (batch_size, seq_len)，其中每个值是词索引</li>
<li><code>out = out.unsqueeze(1)</code>： 变成四维，1 代表通道数（适配 Conv2d）</li>
<li><code>out = torch.cat([conv_and_pool(out, conv) for conv in self.conv], 1)</code>：进行卷积和池化操作，对每个 filter 进行 <code>conv_and_pool</code>，拼接不同 filter 提取的特征</li>
<li><code>out = self.dropout(out)</code>：防止过拟合</li>
<li><code>out = self.fc(out)</code>：全连接层，最终输出 out 形状 <code>(batch_size, num_classes)</code>，即每个样本的分类得分</li>
</ul>
<h4 id="3-模型参数-1"><a href="#3-模型参数-1" class="headerlink" title="3.模型参数"></a>3.模型参数</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;bound method Module.parameters of Model(  </span><br><span class="line">	(embedding): Embedding(4762, 300) </span><br><span class="line">	(conv): ModuleList(</span><br><span class="line">		(0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))     </span><br><span class="line">		(1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))     </span><br><span class="line">		(2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1)) </span><br><span class="line">	) </span><br><span class="line">	(dropout): Dropout(p=0.5, inplace=False) </span><br><span class="line">	(fc): Linear(in_features=768, out_features=10, bias=True)</span><br><span class="line"><span class="meta prompt_">)&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="4-训练模型"><a href="#4-训练模型" class="headerlink" title="4.训练模型"></a>4.训练模型</h2><h3 id="1-权重初始化"><a href="#1-权重初始化" class="headerlink" title="1.权重初始化"></a>1.权重初始化</h3><p>初始化神经网络中的参数，以提高训练的稳定性和收敛速度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_network</span>(<span class="params">model, method=<span class="string">&#x27;xavier&#x27;</span>, exclude=<span class="string">&#x27;embedding&#x27;</span></span>):  </span><br><span class="line">    <span class="keyword">for</span> name, w <span class="keyword">in</span> model.named_parameters():  </span><br><span class="line">        <span class="keyword">if</span> exclude <span class="keyword">not</span> <span class="keyword">in</span> name:  </span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;weight&#x27;</span> <span class="keyword">in</span> name:  </span><br><span class="line">                <span class="keyword">if</span> method == <span class="string">&#x27;xavier&#x27;</span>:  </span><br><span class="line">                    nn.init.xavier_normal_(w)  <span class="comment"># 适用于 sigmoid/tanh/RNN 网络，保持输入和输出的方差一致  </span></span><br><span class="line">                <span class="keyword">elif</span> method == <span class="string">&#x27;kaiming&#x27;</span>:  </span><br><span class="line">                    nn.init.kaiming_normal_(w)  <span class="comment"># 适用于 ReLU 及其变种，避免梯度消失  </span></span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    nn.init.normal_(w)  <span class="comment"># 一般情况，但不如 Xavier 或 Kaiming 稳定  </span></span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;bias&#x27;</span> <span class="keyword">in</span> name:  </span><br><span class="line">                nn.init.constant_(w, <span class="number">0</span>)  <span class="comment"># 偏置一般不需要复杂初始化，设为 0 即可</span></span><br></pre></td></tr></table></figure>
<p>如果 name 包含 ‘embedding’，则跳过，不进行初始化。原因：</p>
<ul>
<li>词嵌入层通常使用 <strong>预训练词向量</strong>（如 word2vec 或 GloVe）。</li>
<li>直接初始化可能会破坏预训练好的词向量结构</li>
</ul>
<p>只对 <strong>权重 (weight)</strong> 进行特殊初始化。偏置 (bias) 一般设为 0，避免影响梯度更新。原因是bias 主要用于调整激活函数的输入值，不需要随机初始化。</p>
<p><strong>Xavier 初始化</strong>：作用是保证输入和输出的方差一致，防止梯度消失或爆炸。<br><strong>Kaiming 初始化</strong>：作用是避免 ReLU 可能导致的梯度消失问题。<br><code>nn.init.normal_(w)</code>：使用正态分布随机初始化（均值 &#x3D; 0，标准差 &#x3D; 1），但不如 Xavier 或 Kaiming 稳定。</p>
<h3 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2.模型训练"></a>2.模型训练</h3><p>大致过程：</p>
<ul>
<li>计算损失和准确率</li>
<li>使用验证集评估模型</li>
<li>动态调整学习率</li>
<li>保存最优模型</li>
<li>支持早停（early stopping）</li>
<li>记录训练日志到 TensorBoard</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">config, model, train_iter, dev_iter, test_iter, writer</span>): </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1️⃣ 初始化，记录开始时间，模型为训练模式，使用Adam优化器初始化模型参数</span></span><br><span class="line">    start_time = time.time()  </span><br><span class="line">    model.train()  </span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=model.learning_rate)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2️⃣ 学习率调度器，验证集损失不下降时才调整学习率，避免不必要的衰减  </span></span><br><span class="line">    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.5</span>, patience=<span class="number">2</span>)  <span class="comment"># patience=2如果验证损失 **2 个周期没下降**，就调整学习率</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3️⃣ 训练参数</span></span><br><span class="line">    total_batch = <span class="number">0</span>  <span class="comment"># 记录进行到多少 batch    </span></span><br><span class="line">    dev_best_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)  <span class="comment"># 记录最优验证 loss    </span></span><br><span class="line">    last_improve = <span class="number">0</span>  <span class="comment"># 记录上次验证集 loss 下降的 batch 数  </span></span><br><span class="line">    flag = <span class="literal">False</span>  <span class="comment"># 记录是否长时间未提升  </span></span><br><span class="line">    train_loss_sum, train_acc_sum, batch_count = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>  <span class="comment"># 累积 loss 和 acc 计算整个 epoch 的平均值  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4️⃣ 训练循环epoch</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(model.num_epochs):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;model.num_epochs&#125;</span>]&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 5️⃣ 训练每个批次,每次取 batch_size 批量数据</span></span><br><span class="line">        <span class="keyword">for</span> _, (trains, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):  </span><br><span class="line">            outputs = model(trains)  <span class="comment"># 前向传播，计算输出结果</span></span><br><span class="line">  </span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 梯度清空，防止累计导致的梯度混合  </span></span><br><span class="line">  </span><br><span class="line">            loss = F.cross_entropy(outputs, labels)  <span class="comment"># 计算损失  </span></span><br><span class="line">            loss.backward()  <span class="comment"># 反向传播 计算损失相对于模型参数的梯度  </span></span><br><span class="line">            optimizer.step()  <span class="comment"># 更新模型参数 </span></span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 6️⃣ 计算 batch 级别的训练准确率  </span></span><br><span class="line">            labels_cpu = labels.data.cpu()  </span><br><span class="line">            predict = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu()  <span class="comment"># 获取预测类别索引  </span></span><br><span class="line">            train_acc = metrics.accuracy_score(labels_cpu, predict)  <span class="comment"># 计算准确率  </span></span><br><span class="line">            <span class="comment"># 7️⃣ 记录训练数据 累计loss和acc计算整个epoch的平均值  </span></span><br><span class="line">            train_loss_sum += loss.item()  </span><br><span class="line">            train_acc_sum += train_acc  </span><br><span class="line">            batch_count += <span class="number">1</span>  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 8️⃣ 每100个batch进行一次验证</span></span><br><span class="line">            <span class="keyword">if</span> total_batch % <span class="number">100</span> == <span class="number">0</span>: </span><br><span class="line">                dev_acc, dev_loss = evaluate(config, model, dev_iter)  </span><br><span class="line">  </span><br><span class="line">                <span class="keyword">if</span> dev_loss &lt; dev_best_loss:  <span class="comment"># 早停策略</span></span><br><span class="line">                    dev_best_loss = dev_loss  </span><br><span class="line">                    torch.save(model.state_dict(), model.save_path)  <span class="comment"># 保存最优模型</span></span><br><span class="line">                    improve = <span class="string">&#x27;*&#x27;</span>  <span class="comment"># 记录模型有提升  </span></span><br><span class="line">                    last_improve = total_batch  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    improve = <span class="string">&#x27;&#x27;</span>  </span><br><span class="line">  </span><br><span class="line">                time_dif = get_time_dif(start_time)  </span><br><span class="line">                msg = (<span class="string">&#x27;Iter: &#123;0:&gt;6&#125;,  Train Loss: &#123;1:&gt;5.2f&#125;,  Train Acc: &#123;2:&gt;6.2%&#125;,&#x27;</span><span class="string">&#x27;Val Loss: &#123;3:&gt;5.2f&#125;,  Val Acc: &#123;4:&gt;6.2%&#125;,  Time: &#123;5&#125; &#123;6&#125;&#x27;</span>)  </span><br><span class="line">                <span class="built_in">print</span>(msg.<span class="built_in">format</span>(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 记录 loss 和 acc 到 TensorBoard</span></span><br><span class="line">                writer.add_scalar(<span class="string">&quot;loss/train&quot;</span>, loss.item(), total_batch)  </span><br><span class="line">                writer.add_scalar(<span class="string">&quot;loss/dev&quot;</span>, dev_loss, total_batch)  </span><br><span class="line">                writer.add_scalar(<span class="string">&quot;acc/train&quot;</span>, train_acc, total_batch)  </span><br><span class="line">                writer.add_scalar(<span class="string">&quot;acc/dev&quot;</span>, dev_acc, total_batch)  </span><br><span class="line">  </span><br><span class="line">                model.train()  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 调整学习率 (基于 dev_loss)          </span></span><br><span class="line">                scheduler.step(dev_loss)  <span class="comment"># ReduceLROnPlateau 需要 loss 作为输入  </span></span><br><span class="line">  </span><br><span class="line">            total_batch += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 9️⃣ 早停策略 如果long time no improvement，则early stop   </span></span><br><span class="line">            <span class="keyword">if</span> total_batch - last_improve &gt; model.require_improvement:  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;No optimization for a long time, auto-stopping...&quot;</span>)  </span><br><span class="line">                flag = <span class="literal">True</span>  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line">        <span class="keyword">if</span> flag:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 🔟 计算整个epoch平均训练loss和acc</span></span><br><span class="line">        avg_train_loss = train_loss_sum / batch_count  </span><br><span class="line">        avg_train_acc = train_acc_sum / batch_count  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;model.num_epochs&#125;</span>] - Avg Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span>,&quot;</span>  <span class="string">f&quot; Avg Train Acc: <span class="subst">&#123;avg_train_acc:<span class="number">.4</span>%&#125;</span>&quot;</span>)  </span><br><span class="line">        <span class="comment"># 记录epoch级别指标到TensorBoard</span></span><br><span class="line">        writer.add_scalar(<span class="string">&quot;epoch_loss/train&quot;</span>, avg_train_loss, epoch)  </span><br><span class="line">        writer.add_scalar(<span class="string">&quot;epoch_acc/train&quot;</span>, avg_train_acc, epoch)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 结束训练</span></span><br><span class="line">    writer.close()  </span><br><span class="line">    _eval_result(config, model, test_iter)</span><br></pre></td></tr></table></figure>
<h3 id="3-可视化训练过程"><a href="#3-可视化训练过程" class="headerlink" title="3.可视化训练过程"></a>3.可视化训练过程</h3><p>SummaryWriter 是 PyTorch 中 ​TensorBoard 的一个接口，用于记录和可视化训练过程中的各种信息（如损失、准确率、模型权重分布、图像、音频等），它可以帮助你更好地理解和调试模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入</span></span><br><span class="line"><span class="keyword">from</span> dataset_Iterator <span class="keyword">import</span> build_iterator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建</span></span><br><span class="line">writer = SummaryWriter(log_dir=model.log_path + <span class="string">&#x27;/&#x27;</span> + time.strftime(<span class="string">&#x27;%m-%d_%H.%M&#x27;</span>, time.localtime()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录loss和acc到TensorBoard </span></span><br><span class="line">writer.add_scalar(<span class="string">&quot;loss/train&quot;</span>, loss.item(), total_batch)  </span><br><span class="line">writer.add_scalar(<span class="string">&quot;loss/dev&quot;</span>, dev_loss, total_batch)  </span><br><span class="line">writer.add_scalar(<span class="string">&quot;acc/train&quot;</span>, train_acc, total_batch)  </span><br><span class="line">writer.add_scalar(<span class="string">&quot;acc/dev&quot;</span>, dev_acc, total_batch)</span><br><span class="line"><span class="comment"># 记录epoch级别指标到TensorBoard</span></span><br><span class="line">writer.add_scalar(<span class="string">&quot;epoch_loss/train&quot;</span>, avg_train_loss, epoch)  </span><br><span class="line">writer.add_scalar(<span class="string">&quot;epoch_acc/train&quot;</span>, avg_train_acc, epoch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>下面是对模型<code>CNN</code>和<code>RNN</code>的训练过程可视化展示：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-14_14-49-18.jpg"></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-14_14-48-28.jpg"></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-14_14-48-55.jpg"></p>
<h2 id="5-评估模型"><a href="#5-评估模型" class="headerlink" title="5.评估模型"></a>5.评估模型</h2><h3 id="1-评估函数"><a href="#1-评估函数" class="headerlink" title="1.评估函数"></a>1.评估函数</h3><p>用于配合模型训练</p>
<p>如果 <code>_test=False</code>，只返回准确率 (accuracy) 和 损失 (loss)<br>如果 <code>_test=True</code>，返回 <strong>完整的分类报告和混淆矩阵</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">config, model, data_iter, _test=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 1️⃣ 评估模式，冻结Dropout和BatchNorm影响，确保预测稳定</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2️⃣ 初始化变量</span></span><br><span class="line">    loss_total = <span class="number">0</span>  <span class="comment"># 累计损失，用于计算平均损失</span></span><br><span class="line">    predict_all = np.array([], dtype=<span class="built_in">int</span>)  <span class="comment"># 存储所有预测标签</span></span><br><span class="line">    labels_all = np.array([], dtype=<span class="built_in">int</span>)  <span class="comment"># 存储所有真实标签</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 不计算梯度，减少显存占用，提高计算效率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3️⃣ 逐批处理数据</span></span><br><span class="line">        <span class="keyword">for</span> texts, labels <span class="keyword">in</span> data_iter:  </span><br><span class="line">            outputs = model(texts)  </span><br><span class="line">            loss = F.cross_entropy(outputs, labels)  </span><br><span class="line">            loss_total += loss  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4️⃣ 处理预测结果</span></span><br><span class="line">            labels = labels.data.cpu().numpy()</span><br><span class="line">            <span class="comment"># 取出最大概率对应的类别索引（即预测类别）</span></span><br><span class="line">            predict = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu().numpy()  </span><br><span class="line">            labels_all = np.append(labels_all, labels)</span><br><span class="line">            predict_all = np.append(predict_all, predict)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5️⃣ 计算准确率</span></span><br><span class="line">    acc = metrics.accuracy_score(labels_all, predict_all)  </span><br><span class="line">    <span class="keyword">if</span> _test:  <span class="comment"># 测试模式</span></span><br><span class="line">        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=<span class="number">4</span>)  </span><br><span class="line">        confusion = metrics.confusion_matrix(labels_all, predict_all)  </span><br><span class="line">        <span class="keyword">return</span> acc, loss_total / <span class="built_in">len</span>(data_iter), report, confusion  </span><br><span class="line">    <span class="keyword">return</span> acc, loss_total / <span class="built_in">len</span>(data_iter)</span><br></pre></td></tr></table></figure>
<h3 id="2-评估模型"><a href="#2-评估模型" class="headerlink" title="2.评估模型"></a>2.评估模型</h3><p>用于在测试集上评估模型的最终表现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_eval_result</span>(<span class="params">config, model, test_iter</span>):</span><br><span class="line">    <span class="comment"># 1️⃣ 加载训练好的模型参数</span></span><br><span class="line">    model.load_state_dict(torch.load(model.save_path, weights_only=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2️⃣ 切换为评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3️⃣ 计算测试集上的评估指标</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="comment"># 测试集准确率 测试集平均损失 分类报告 混淆矩阵</span></span><br><span class="line">    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, _test=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4️⃣ 打印测试结果</span></span><br><span class="line">    msg = <span class="string">&#x27;Test Loss: &#123;0:&gt;5.2&#125;,  Test Acc: &#123;1:&gt;6.2%&#125;&#x27;</span>  </span><br><span class="line">    <span class="built_in">print</span>(msg.<span class="built_in">format</span>(test_loss, test_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5️⃣ 打印分类报告</span></span><br><span class="line">    <span class="comment"># Precision(精确率)，Recall(召回率)，F1-Score（F1分数）</span></span><br><span class="line">    <span class="comment"># Precision 关注的是“预测为正类的样本中，有多少是真正的正类”</span></span><br><span class="line">    <span class="comment"># Recall 关注的是“所有真实正类的样本中，有多少被正确识别出来”</span></span><br><span class="line">    <span class="comment"># F1-Score Precision 和 Recall 有时候会相互矛盾，为了找到平衡点</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Precision, Recall and F1-Score...&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(test_report)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6️⃣ 打印混淆矩阵，显示真实类别和预测类别的对应关系，横轴：预测类别。纵轴：真实类别</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix...&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(test_confusion)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7️⃣ 计算测试时间</span></span><br><span class="line">    time_dif = get_time_dif(start_time)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Time usage:&quot;</span>, time_dif)</span><br></pre></td></tr></table></figure>
<p>RNN模型评估结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">args model:text_rnn, embedding:sougou</span><br><span class="line">Test Loss:  0.28,  Test Acc: 91.16%  </span><br><span class="line">Precision, Recall and F1-Score...  </span><br><span class="line">                precision    recall   f1-score   support  </span><br><span class="line">finance            0.9113    0.8840    0.8975      1000       </span><br><span class="line">realty             0.9077    0.9340    0.9207      1000       </span><br><span class="line">stocks             0.8617    0.8290    0.8451      1000    </span><br><span class="line">education          0.9327    0.9570    0.9447      1000      </span><br><span class="line">science            0.8635    0.8600    0.8617      1000      </span><br><span class="line">society            0.9002    0.9200    0.9100      1000     </span><br><span class="line">politics           0.8841    0.8850    0.8846      1000       </span><br><span class="line">sports             0.9809    0.9760    0.9784      1000         </span><br><span class="line">game               0.9356    0.9300    0.9328      1000</span><br><span class="line">entertainment      0.9363    0.9410    0.9387      1000  </span><br><span class="line">  </span><br><span class="line">accuracy                               0.9116     10000    </span><br><span class="line">macro avg          0.9114    0.9116    0.9114     10000 </span><br><span class="line">weighted avg       0.9114    0.9116    0.9114     10000  </span><br><span class="line">Confusion Matrix...  </span><br><span class="line">[[ 884  26  55   6   9   5  11   1   0   3]  </span><br><span class="line"> [ 10 934  14   2   5  17   6   2   2   8] </span><br><span class="line"> [ 54  27 829   3  44   3  33   0   5   2] </span><br><span class="line"> [  1   2   0 957   7  17   7   0   1   8] </span><br><span class="line"> [  4   8  29  10 860  17  21   1  40  10] </span><br><span class="line"> [  2  13   0  20   7 920  22   0   5  11] </span><br><span class="line"> [  8   9  23  14  19  29 885   3   2   8] </span><br><span class="line"> [  1   1   2   2   1   3   7 976   0   7] </span><br><span class="line"> [  1   2   8   5  36   5   3   3 930   7] </span><br><span class="line"> [  5   7   2   7   8   6   6   9   9 941]]</span><br><span class="line"> Time usage: 0:00:03</span><br></pre></td></tr></table></figure>
<p>CNN模型评估结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">args model:text_cnn, embedding:sougou</span><br><span class="line">Test Loss:  0.28,  Test Acc: 91.35%  </span><br><span class="line">Precision, Recall and F1-Score...  </span><br><span class="line">                 precision    recall  f1-score   support  </span><br><span class="line">finance            0.9205    0.8920    0.9060      1000       </span><br><span class="line">realty             0.9202    0.9450    0.9324      1000       </span><br><span class="line">stocks             0.8801    0.8590    0.8694      1000    </span><br><span class="line">education          0.9539    0.9520    0.9530      1000      </span><br><span class="line">science            0.8626    0.8730    0.8678      1000      </span><br><span class="line">society            0.8873    0.9210    0.9038      1000     </span><br><span class="line">politics           0.9039    0.9030    0.9035      1000       </span><br><span class="line">sports             0.9468    0.9610    0.9538      1000         </span><br><span class="line">game               0.9267    0.9100    0.9183      1000</span><br><span class="line">entertainment      0.9339    0.9190    0.9264      1000  </span><br><span class="line">  </span><br><span class="line">accuracy                               0.9135     10000    </span><br><span class="line">macro avg          0.9136    0.9135    0.9134     10000 </span><br><span class="line">weighted avg       0.9136    0.9135    0.9134     10000  </span><br><span class="line">Confusion Matrix...  </span><br><span class="line">[[ 892  17  48   2  11  12   9   5   2   2]  </span><br><span class="line"> [  9 945  11   1   3  16   4   3   2   6] </span><br><span class="line"> [ 47  22 859   1  29   4  30   3   5   0] </span><br><span class="line"> [  1   3   1 952   5  16   6   5   3   8] </span><br><span class="line"> [  4   9  24   5 873  16  18   2  35  14] </span><br><span class="line"> [  3  19   1  17  10 921  21   1   2   5] </span><br><span class="line"> [  9   5  21   7  18  30 903   3   0   4] </span><br><span class="line"> [  2   1   2   2   4   6   4 961   5  13]</span><br><span class="line"> [  1   1   6   4  49   4   1  11 910  13] </span><br><span class="line"> [  1   5   3   7  10  13   3  21  18 919]]</span><br><span class="line">Time usage: 0:00:03</span><br></pre></td></tr></table></figure>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><p>本文涉及到的知识点：</p>
<ol>
<li>torch<ul>
<li>torch.nn：用于构建神经网络，如 Embedding、Conv2d、LSTM、Linear、Dropout 等</li>
<li>torch.nn.functional：用于计算relu、cross_entropy、max_pool1d 等操作</li>
<li>torch.optim：Adam 优化器和 torch.optim.lr_scheduler.ReduceLROnPlateau 进行动态学习率调整</li>
<li>torch.Tensor：数据处理，包括 to(device) 用于 GPU 计算</li>
</ul>
</li>
<li>文本处理<ul>
<li>词嵌入 nn.Embedding 处理文本数据，支持 sogou、tencent 预训练词向量</li>
<li>LSTM 和 CNN 进行文本分类 (TextRNN vs TextCNN)</li>
<li>词表 vocab.pkl的加载和构建 (pickle 序列化)</li>
<li>文本填充 (pad_size 处理变长文本)</li>
</ul>
</li>
<li>数据处理<ul>
<li>DatasetIterator 设计了数据迭代器，支持 batch 训练，并进行 to(device) 加速计算</li>
<li>build_iterator() 生成数据加载器，并支持 train&#x2F;dev&#x2F;test 迭代</li>
</ul>
</li>
<li>训练与验证<ul>
<li>训练 (train 函数)，采用 Adam 优化器， ReduceLROnPlateau 进行学习率动态调整cross_entropy 计算损失，accuracy_score 计算准确率，早停机制 (require_improvement 防止长期无提升)</li>
<li>验证 (evaluate 函数)：计算 loss 和 accuracy，在 test 评估时，输出 classification_report 和 confusion_matrix</li>
</ul>
</li>
<li>日志可视化<ul>
<li>SummaryWriter 记录 loss 和 accuracy，支持 TensorBoard 可视化</li>
</ul>
</li>
<li>命令行参数<ul>
<li>argparse 解析用户输入的 –model 和 –embedding选项</li>
</ul>
</li>
</ol>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>numpy: 1.26.4</li>
<li>tensorBoard : 2.19.0</li>
</ul>
<p>数据集：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/005_rnn_classification_text/THUCNews/data">https://github.com/keychankc/dl_code_for_blog/tree/main/005_rnn_classification_text/THUCNews/data</a></p>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/005_rnn_classification_text">https://github.com/keychankc/dl_code_for_blog/tree/main/005_rnn_classification_text</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>模型训练</tag>
        <tag>卷积神经网络</tag>
        <tag>循环神经网络</tag>
        <tag>TensorBoard</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV之全景图像拼接</title>
    <url>/2025/03/24/007-opencv-image-stitching/</url>
    <content><![CDATA[<h2 id="1-实现流程"><a href="#1-实现流程" class="headerlink" title="1.实现流程"></a>1.实现流程</h2><p>通过提取图像中的特征点并匹配这些特征点来找到图像间的对应关系，再通过透视变换（Homography）将两幅图像拼接成一幅完整的图像，大致流程：</p>
<ol>
<li>特征点检测与描述<ul>
<li>使用 <strong>SIFT</strong> 算法检测两张图像中的关键点，并计算特征描述子（局部特征向量）</li>
</ul>
</li>
<li>特征匹配<ul>
<li>采用 <strong>KNN 近邻匹配</strong>（k&#x3D;2）找到两张图像间的最佳匹配点对</li>
<li>使用 <strong>比值测试（ratio test）</strong> 过滤掉低质量的匹配点，减少误匹配</li>
</ul>
</li>
<li>单应性矩阵计算<ul>
<li>通过 <strong>RANSAC 算法</strong> 计算 <strong>单应性矩阵 (Homography, H)</strong>，剔除误匹配点</li>
<li>单应性矩阵用于 <strong>透视变换</strong>，使一张图像对齐另一张图像</li>
</ul>
</li>
<li>图像变换与拼接<ul>
<li>利用 cv2.warpPerspective() <strong>对图像A进行透视变换</strong>，使其尽可能与图像B对齐</li>
<li>将<strong>图像B放入最终结果中</strong>，合成拼接图像</li>
</ul>
</li>
<li>可视化匹配结果<ul>
<li>在两张图像上绘制匹配点连线，帮助观察特征匹配的效果</li>
</ul>
</li>
</ol>
<h2 id="2-相关算法"><a href="#2-相关算法" class="headerlink" title="2.相关算法"></a>2.相关算法</h2><h3 id="1-SIFT（尺度不变特征变换）"><a href="#1-SIFT（尺度不变特征变换）" class="headerlink" title="1.SIFT（尺度不变特征变换）"></a>1.SIFT（尺度不变特征变换）</h3><p>SIFT (<strong>Scale-Invariant Feature Transform</strong>) 是一种 <strong>关键点检测和描述算法</strong>，能够在 <strong>不同尺度、旋转、光照变化</strong> 下仍然保持稳定的特征匹配。</p>
<span id="more"></span>
<p><strong>主要步骤</strong>：</p>
<ol>
<li><strong>尺度空间构造</strong>：<ul>
<li>采用 <strong>高斯模糊（Gaussian Blur）</strong> 生成不同尺度的图像（高斯金字塔）</li>
<li>计算 <strong>DoG（Difference of Gaussian, 差分高斯）</strong> 以找到特征点</li>
</ul>
</li>
<li><strong>关键点检测与精细定位</strong>：<ul>
<li>通过 <strong>极值检测</strong> 在不同尺度下找到潜在特征点</li>
<li>过滤掉低对比度点和边缘响应点，提高鲁棒性</li>
</ul>
</li>
<li><strong>方向分配</strong>：<ul>
<li>计算特征点周围的 <strong>梯度方向直方图</strong>，分配主要方向，使其具备<strong>旋转不变性</strong></li>
</ul>
</li>
<li><strong>特征描述</strong>：<ul>
<li>计算每个关键点周围的 <strong>梯度直方图</strong>，形成 <strong>128 维特征向量</strong>（局部描述子）</li>
<li>这些特征向量用于匹配不同图像中的关键点</li>
</ul>
</li>
</ol>
<p><strong>特点</strong>：</p>
<ul>
<li><strong>尺度、旋转、光照不变性</strong>：可用于不同大小、旋转角度和亮度变化的图像匹配</li>
<li><strong>抗噪性强</strong>：在复杂背景下仍能准确提取关键点</li>
<li><strong>计算复杂度高</strong>：比其他方法（如 ORB）慢，但匹配效果更稳定</li>
</ul>
<h3 id="2-KNN-近邻匹配"><a href="#2-KNN-近邻匹配" class="headerlink" title="2.KNN 近邻匹配"></a>2.KNN 近邻匹配</h3><p>KNN (<strong>K-Nearest Neighbors</strong>) 是一种用于 <strong>特征点匹配</strong> 的方法，它基于<strong>欧几里得距离</strong>计算两个图像之间的相似特征点</p>
<p><strong>工作原理</strong>：</p>
<ol>
<li><strong>计算欧几里得距离</strong>：<ul>
<li>计算图像A中的每个特征点与图像B中所有特征点的<strong>欧几里得距离</strong>，找到最相似的 K 个点（通常 K&#x3D;2）</li>
</ul>
</li>
<li><strong>比值测试（Ratio Test）</strong>：<ul>
<li>计算最近邻 D1 和次近邻 D2 之间的距离比 D1&#x2F;D2</li>
<li>如果 D1&#x2F;D2 &lt; 设定阈值（通常 0.75），则认为匹配有效，否则丢弃该匹配点</li>
<li>这样可以过滤掉误匹配点，提高匹配精度</li>
</ul>
</li>
</ol>
<p><strong>特点</strong>：</p>
<ul>
<li><strong>简单高效</strong>：直接基于欧几里得距离计算匹配点</li>
<li><strong>容易受噪声干扰</strong>：误匹配点较多，因此需要 <strong>比值测试</strong> 或 <strong>RANSAC</strong> 进行筛选</li>
</ul>
<h3 id="3-RANSAC（随机抽样一致性算法）"><a href="#3-RANSAC（随机抽样一致性算法）" class="headerlink" title="3.RANSAC（随机抽样一致性算法）"></a>3.RANSAC（随机抽样一致性算法）</h3><p>RANSAC (<strong>RANdom SAmple Consensus, 随机抽样一致算法</strong>) 是一种 <strong>鲁棒的误匹配去除方法</strong>，用于筛选正确的匹配点，提高拼接精度</p>
<p><strong>工作原理</strong>：</p>
<ol>
<li><strong>随机采样</strong>：<ul>
<li>在匹配点集中 <strong>随机选取 4 对匹配点</strong>，计算一个变换模型（如单应性矩阵 H）。</li>
</ul>
</li>
<li><strong>计算内点数</strong>：<ul>
<li>通过该变换模型，将所有匹配点进行投影，并计算它们与目标点的误差。</li>
<li>误差小于阈值（如 4 像素）的点称为 <strong>内点（Inliers）</strong>。</li>
</ul>
</li>
<li><strong>重复迭代</strong>：<ul>
<li>反复进行 <strong>随机抽样+计算内点数</strong> 的过程，找到拥有最多内点的模型。</li>
<li>最终使用这些内点 <strong>重新计算一个更精确的变换矩阵</strong>。</li>
</ul>
</li>
</ol>
<p><strong>特点</strong>：</p>
<ul>
<li><strong>能够过滤掉错误匹配点</strong>，提高拼接的精度。</li>
<li><strong>适用于特征匹配、物体识别、立体视觉</strong>等任务。</li>
<li><strong>计算复杂度较高</strong>，但效果很好。</li>
</ul>
<h3 id="4-透视变换（Homography）"><a href="#4-透视变换（Homography）" class="headerlink" title="4.透视变换（Homography）"></a>4.透视变换（Homography）</h3><p>透视变换 (<strong>Homography Transformation</strong>) 主要用于<strong>将一张图像变换到与另一张图像对齐的视角</strong>，从而实现图像拼接。</p>
<p><strong>数学模型</strong>：<br>透视变换矩阵 H 是一个 <strong>3×3 矩阵</strong>，用于描述两张图像之间的映射关系：</p>
<p>$\begin{bmatrix} x{\prime} \ y{\prime} \ w{\prime} \end{bmatrix} &#x3D; H \cdot \begin{bmatrix} x \ y \ 1 \end{bmatrix}$</p>
<p>其中：</p>
<ul>
<li>$(x, y)$是原始图像中的坐标。</li>
<li>$(x{\prime}, y{\prime})$ 是变换后图像的坐标。</li>
<li>cv2.findHomography() 通过匹配点计算 H，并用 cv2.warpPerspective() 对图像进行变换。</li>
</ul>
<p><strong>特点</strong>：</p>
<ul>
<li><strong>适用于拼接、增强现实（AR）、目标跟踪</strong> 等任务。</li>
<li>需要 <strong>至少 4 对匹配点</strong> 才能计算出 H 矩阵。</li>
<li>如果匹配点不够准确，会导致变换失败。</li>
</ul>
<h2 id="3-实现过程"><a href="#3-实现过程" class="headerlink" title="3.实现过程"></a>3.实现过程</h2><h3 id="1-获取特征点"><a href="#1-获取特征点" class="headerlink" title="1.获取特征点"></a>1.获取特征点</h3><p>检测图像中的特征点并计算这些特征点的描述子，使用 <strong>SIFT</strong> 算法来实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_detect_describe</span>(<span class="params">image</span>):  </span><br><span class="line">    <span class="comment"># 创建SIFT特征检测器  </span></span><br><span class="line">    descriptor = cv2.SIFT_create()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 寻找图像中的特征点，计算这些关键点的特征描述子，用于后续的匹配</span></span><br><span class="line">    <span class="comment"># kps 包含图像中所有关键点的信息（例如位置、尺度等）</span></span><br><span class="line">    <span class="comment"># features 每个关键点的描述子，它用于描述关键点的外观特征</span></span><br><span class="line">    (kps, features) = descriptor.detectAndCompute(image, <span class="literal">None</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 关键点的坐标（x, y）</span></span><br><span class="line">    num_kps = np.float32([kp.pt <span class="keyword">for</span> kp <span class="keyword">in</span> kps])  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 关键点的坐标，关键点的描述子，关键点对象  </span></span><br><span class="line">    <span class="keyword">return</span> num_kps, features, kps  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-匹配特征点"><a href="#2-匹配特征点" class="headerlink" title="2.匹配特征点"></a>2.匹配特征点</h3><p>用于匹配两幅图像的特征点，使用暴力匹配器（BFMatcher）和 k 最近邻（KNN）算法来找到两幅图像之间的特征点对应关系</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_match_key_points</span>(<span class="params">kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh</span>):  </span><br><span class="line">    <span class="comment"># 创建暴力匹配器，基于欧几里得距离来进行特征点匹配</span></span><br><span class="line">    matcher = cv2.BFMatcher()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 为每个特征点找到两个最接近的匹配点（最近邻和次最近邻） </span></span><br><span class="line">    raw_matches = matcher.knnMatch(featuresA, featuresB, <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">    matches = []  </span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> raw_matches:  </span><br><span class="line">        <span class="comment"># 检查最近的匹配点与次近的匹配点的距离比是否满足ratio阈值</span></span><br><span class="line">        <span class="comment"># 如果是，则认为这两个特征点匹配成功</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(m) == <span class="number">2</span> <span class="keyword">and</span> m[<span class="number">0</span>].distance &lt; m[<span class="number">1</span>].distance * ratio:  </span><br><span class="line">            <span class="comment"># 存储两个点在featuresA, featuresB中的索引值  </span></span><br><span class="line">            matches.append((m[<span class="number">0</span>].trainIdx, m[<span class="number">0</span>].queryIdx))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 当筛选后的匹配对大于4时，计算视角变换矩阵  </span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(matches) &gt; <span class="number">4</span>:  </span><br><span class="line">        <span class="comment"># 获取匹配对的点坐标  </span></span><br><span class="line">        pts_a = np.float32([kpsA[i] <span class="keyword">for</span> (_, i) <span class="keyword">in</span> matches])  </span><br><span class="line">        pts_b = np.float32([kpsB[i] <span class="keyword">for</span> (i, _) <span class="keyword">in</span> matches])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 通过RANSAC筛选出更准确的匹配点对，减少误匹配的影响  </span></span><br><span class="line">        (H, status) = cv2.findHomography(pts_a, pts_b, cv2.RANSAC, reprojThresh) </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 返回结果  </span></span><br><span class="line">        <span class="keyword">return</span> matches, H, status  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 如果匹配对小于4时，返回None  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span>  </span><br></pre></td></tr></table></figure>

<h3 id="3-图像拼接"><a href="#3-图像拼接" class="headerlink" title="3.图像拼接"></a>3.图像拼接</h3><p>这里将两张图片横向拼接，并在匹配点之间绘制红色直线，帮助可视化匹配效果  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_draw_matches</span>(<span class="params">imageA, imageB, kpsA, kpsB, matches, status</span>):  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 初始化可视化图片，将A、B图左右连接到一起  </span></span><br><span class="line">    (hA, wA) = imageA.shape[:<span class="number">2</span>]  </span><br><span class="line">    (hB, wB) = imageB.shape[:<span class="number">2</span>]  </span><br><span class="line">    vis = np.zeros((<span class="built_in">max</span>(hA, hB), wA + wB, <span class="number">3</span>), dtype=<span class="string">&quot;uint8&quot;</span>)  </span><br><span class="line">    vis[<span class="number">0</span>:hA, <span class="number">0</span>:wA] = imageA  </span><br><span class="line">    vis[<span class="number">0</span>:hB, wA:] = imageB  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 联合遍历，画出匹配对  </span></span><br><span class="line">    <span class="keyword">for</span> ((trainIdx, queryIdx), s) <span class="keyword">in</span> <span class="built_in">zip</span>(matches, status):  </span><br><span class="line">        <span class="comment"># 当点对匹配成功时，画到可视化图上  </span></span><br><span class="line">        <span class="keyword">if</span> s == <span class="number">1</span>:  </span><br><span class="line">            pt_a = (<span class="built_in">int</span>(kpsA[queryIdx].pt[<span class="number">0</span>]), <span class="built_in">int</span>(kpsA[queryIdx].pt[<span class="number">1</span>]))  </span><br><span class="line">            pt_b = (<span class="built_in">int</span>(kpsB[trainIdx].pt[<span class="number">0</span>]) + wA, <span class="built_in">int</span>(kpsB[trainIdx].pt[<span class="number">1</span>]))</span><br><span class="line">            <span class="comment"># 在两幅图像之间的匹配特征点之间绘制红色线段，便于查看哪些点在两幅图像中是匹配的  </span></span><br><span class="line">            cv2.line(vis, pt_a, pt_b, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)  </span><br><span class="line">    <span class="keyword">return</span> vis  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="4-调用"><a href="#4-调用" class="headerlink" title="4.调用"></a>4.调用</h3><p>原图<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-24_11-38-47.jpg"><br>最终效果<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-24_11-32-12.jpg"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stitch</span>(<span class="params">imageB, imageA, ratio=<span class="number">0.75</span>, reprojThresh=<span class="number">4.0</span></span>):  </span><br><span class="line">    <span class="comment"># 提取SIFT特征：对两张图像分别检测特征点和计算描述子  </span></span><br><span class="line">    (num_kpsA, featuresA, kpsA) = _detect_describe(imageA)  </span><br><span class="line">    (num_kpsB, featuresB, kpsB) = _detect_describe(imageB)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 找到匹配点对，并计算 单应性矩阵 H    </span></span><br><span class="line">    m = _match_key_points(num_kpsA, num_kpsB, featuresA, featuresB, ratio, reprojThresh)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 如果返回结果为空，没有匹配成功的特征点，退出算法  </span></span><br><span class="line">    <span class="keyword">if</span> m <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># H是3x3视角变换矩阵  </span></span><br><span class="line">    (matches, H, status) = m  </span><br><span class="line">    <span class="comment"># 透视变换，使两张图像对齐</span></span><br><span class="line">    result = cv2.warpPerspective(imageA, H, (imageA.shape[<span class="number">1</span>] + imageB.shape[<span class="number">1</span>], imageA.shape[<span class="number">0</span>])) </span><br><span class="line">    utils.cv_show(<span class="string">&#x27;result imageA&#x27;</span>, result) <span class="comment"># 如下图</span></span><br><span class="line">    <span class="comment"># 将图片B传入result图片最左端，最终形成一张拼接后的大图</span></span><br><span class="line">    result[<span class="number">0</span>:imageB.shape[<span class="number">0</span>], <span class="number">0</span>:imageB.shape[<span class="number">1</span>]] = imageB  </span><br><span class="line">    utils.cv_show(<span class="string">&#x27;result imageB&#x27;</span>, result) <span class="comment"># 如下图</span></span><br><span class="line">    <span class="comment"># 生成匹配图片  </span></span><br><span class="line">    vis = _draw_matches(imageA, imageB, kpsA, kpsB, matches, status)  </span><br><span class="line">    utils.cv_show(<span class="string">&#x27;draw matches&#x27;</span>, vis)  <span class="comment"># 如下图</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-24_11-31-22.jpg"></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-24_11-31-40.jpg"></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-24_11-31-56.jpg"></p>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><p>关键步骤包括：</p>
<ol>
<li>检测并描述图像中的特征点    </li>
<li>匹配特征点并计算单应性矩阵</li>
<li>通过透视变换将图像对齐，并拼接成一张新图像</li>
</ol>
<h2 id="5-备注"><a href="#5-备注" class="headerlink" title="5.备注"></a>5.备注</h2><h3 id="环境："><a href="#环境：" class="headerlink" title="环境："></a>环境：</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
</ul>
<h3 id="资源和代码："><a href="#资源和代码：" class="headerlink" title="资源和代码："></a>资源和代码：</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/007_opencv_image_stitching
</code></pre>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>计算机视觉</tag>
        <tag>图像识别</tag>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV之目标追踪</title>
    <url>/2025/04/08/009-opencv-tracking/</url>
    <content><![CDATA[<h2 id="1-目标追踪"><a href="#1-目标追踪" class="headerlink" title="1.目标追踪"></a>1.目标追踪</h2><p>目标追踪（Object Tracking）是指在视频序列中持续追踪目标的位置，这是计算机视觉中的核心难点，其核心挑战包括遮挡、光照变化和快速运动。在视频分析、自动驾驶、智能监控、人机交互等领域中应用广泛。</p>
<h3 id="1-按任务类型分类"><a href="#1-按任务类型分类" class="headerlink" title="1.按任务类型分类"></a>1.按任务类型分类</h3><ol>
<li>单目标追踪（SOT, Single Object Tracking）：只追踪一个初始帧中给定的目标，典型方法如：<ol>
<li>Siamese-based Tracking（孪生网络）</li>
<li>Transformer-based Tracking</li>
</ol>
</li>
<li>多目标追踪（MOT, Multi-Object Tracking）：同时追踪多个目标，通常包括目标检测与数据关联两个阶段，典型方法如：<ol>
<li>基于检测的跟踪（Tracking-by-Detection）</li>
<li>端到端方法</li>
</ol>
</li>
<li>多摄像头追踪（MTMC, Multi-Camera Multi-Object Tracking）：跨视角数据关联，更复杂的特征匹配，常结合ReID、时空建模、图神经网络等</li>
</ol>
<h2 id="2-传统目标追踪算法"><a href="#2-传统目标追踪算法" class="headerlink" title="2.传统目标追踪算法"></a>2.传统目标追踪算法</h2><p>除了基于深度学习的追踪算法，还有依赖传统的机器学习的目标追踪算法，它们适用于某些轻量级、实时或资源受限的场景（如嵌入式设备）。</p>
<span id="more"></span>
<p>OpenCV中常用的目标追踪算法：</p>
<ol>
<li>Boosting Tracker<br> • <strong>原理</strong>：使用在线Boosting分类器，从背景中区分出目标<br> • <strong>优点</strong>：适应性强，适合光照变化的情况<br> • <strong>缺点</strong>：对遮挡敏感，易漂移</li>
<li>MIL (Multiple Instance Learning) Tracker<br> • <strong>原理</strong>：目标不是单个样本表示，而是多个候选区域的集合；只要集合中包含目标就算正例<br> • <strong>优点</strong>：缓解标签不确定问题，增强鲁棒性<br> • <strong>缺点</strong>：对遮挡还是不太稳，精度一般</li>
<li>KCF (Kernelized Correlation Filter)<br> • <strong>原理</strong>：使用核技巧加速的相关滤波器，训练和测试都在频域完成<br> • <strong>优点</strong>：非常快，速度极高（可达上百帧&#x2F;秒），适合实时追踪<br> • <strong>缺点</strong>：对尺度变化、遮挡、快速运动敏感</li>
<li>TLD (Tracking-Learning-Detection)<br> • <strong>原理</strong>：将追踪、检测、学习分成三个模块协同工作。追踪失败时，检测器会重新识别目标<br> • <strong>优点</strong>：鲁棒性强，能处理遮挡后的恢复<br> • <strong>缺点</strong>：复杂度高，速度慢，容易累积错误</li>
<li>MedianFlow<br> • <strong>原理</strong>：跟踪局部块（点），计算前后帧之间的点的光流；中位数流用于稳定估计<br> • <strong>优点</strong>：平滑、稳定，适合小运动<br> • <strong>缺点</strong>：对快速运动、遮挡很不鲁棒；会直接失败而不是漂移</li>
<li>MOSSE (Minimum Output Sum of Squared Error Filter)<br> • <strong>原理</strong>：训练一个滤波器，使得卷积后的响应图和期望响应（高斯峰）最接近<br> • <strong>优点</strong>：非常快（轻量、实时）；对照明变化有一定鲁棒性<br> • <strong>缺点</strong>：定位不够准，易受背景干扰</li>
<li>CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability)<br> • <strong>原理</strong>：在KCF基础上改进，引入通道可靠性和空间可靠性来增强鲁棒性<br> • <strong>优点</strong>：比KCF更准确，适合尺度变化、部分遮挡<br> • <strong>缺点</strong>：比KCF慢，实时性稍差</li>
</ol>
<h2 id="3-OpenCV目标追踪"><a href="#3-OpenCV目标追踪" class="headerlink" title="3.OpenCV目标追踪"></a>3.OpenCV目标追踪</h2><p>下面是一个可以在视频中实时添加跟踪目标的代码示例：</p>
<h3 id="1-支持算法"><a href="#1-支持算法" class="headerlink" title="1.支持算法"></a>1.支持算法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_tracker</span>(<span class="params">name</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;根据OpenCV的版本自动获取跟踪器的构造函数&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(cv2.legacy, name + <span class="string">&quot;_create&quot;</span>):  </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">getattr</span>(cv2.legacy, name + <span class="string">&quot;_create&quot;</span>)  </span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">hasattr</span>(cv2, name + <span class="string">&quot;_create&quot;</span>):  </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">getattr</span>(cv2, name + <span class="string">&quot;_create&quot;</span>)  </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># opencv支持的跟踪算法</span></span><br><span class="line">opencv_object_trackers = &#123;  </span><br><span class="line">    <span class="string">&quot;boosting&quot;</span>: get_tracker(<span class="string">&quot;TrackerBoosting&quot;</span>),  <span class="comment"># 基于AdaBoost的传统算法，性能较差  </span></span><br><span class="line">    <span class="string">&quot;mil&quot;</span>: get_tracker(<span class="string">&quot;TrackerMIL&quot;</span>),  <span class="comment"># 比Boosting鲁棒，但仍有局限性  </span></span><br><span class="line">    <span class="string">&quot;kcf&quot;</span>: get_tracker(<span class="string">&quot;TrackerKCF&quot;</span>),  <span class="comment"># 速度快，但对遮挡敏感  </span></span><br><span class="line">    <span class="string">&quot;tld&quot;</span>: get_tracker(<span class="string">&quot;TrackerTLD&quot;</span>),  <span class="comment"># 处理目标遮挡和消失，但易漂移  </span></span><br><span class="line">    <span class="string">&quot;medianflow&quot;</span>: get_tracker(<span class="string">&quot;TrackerMedianFlow&quot;</span>),  <span class="comment"># 适用于匀速运动的小目标，失败时会自我检测  </span></span><br><span class="line">    <span class="string">&quot;mosse&quot;</span>: get_tracker(<span class="string">&quot;TrackerMOSSE&quot;</span>),  <span class="comment"># 极快，适合实时应用，但精度较低  </span></span><br><span class="line">    <span class="string">&quot;csrt&quot;</span>: get_tracker(<span class="string">&quot;TrackerCSRT&quot;</span>)  <span class="comment"># 高精度，但速度较慢  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-主函数"><a href="#2-主函数" class="headerlink" title="2.主函数"></a>2.主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tracking</span>(<span class="params">video_path, tracker_type=<span class="string">&quot;kcf&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个多目标追踪器对象（MultiTracker），可以同时追踪多个对象</span></span><br><span class="line">    trackers = cv2.legacy.MultiTracker_create()  </span><br><span class="line">    vs = cv2.VideoCapture(video_path)  <span class="comment"># 读取视频流</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="comment"># 取当前帧  </span></span><br><span class="line">        frame = vs.read()  </span><br><span class="line">        frame = frame[<span class="number">1</span>]  </span><br><span class="line">        <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 读取视频帧并缩放（这里统一宽度为 600 像素）</span></span><br><span class="line">        (h, w) = frame.shape[:<span class="number">2</span>]  </span><br><span class="line">        width = <span class="number">600</span>  </span><br><span class="line">        r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">        dim = (width, <span class="built_in">int</span>(h * r))  </span><br><span class="line">        frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 更新所有跟踪目标</span></span><br><span class="line">        (success, boxes) = trackers.update(frame)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 绘制区域  </span></span><br><span class="line">        <span class="keyword">for</span> box <span class="keyword">in</span> boxes:  </span><br><span class="line">            (x, y, w, h) = [<span class="built_in">int</span>(v) <span class="keyword">for</span> v <span class="keyword">in</span> box]  </span><br><span class="line">            cv2.rectangle(frame, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 显示  </span></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Frame&quot;</span>, frame)  </span><br><span class="line">        key = cv2.waitKey(<span class="number">100</span>) &amp; <span class="number">0xFF</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> key == <span class="built_in">ord</span>(<span class="string">&quot;s&quot;</span>):  </span><br><span class="line">            <span class="comment"># 选择一个区域，按s  </span></span><br><span class="line">            box = cv2.selectROI(<span class="string">&quot;Frame&quot;</span>, frame, fromCenter=<span class="literal">False</span>,  </span><br><span class="line">                                showCrosshair=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 创建一个新的追踪器  </span></span><br><span class="line">            tracker = opencv_object_trackers[tracker_type]()  </span><br><span class="line">            trackers.add(tracker, frame, box)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 退出  </span></span><br><span class="line">        <span class="keyword">elif</span> key == <span class="number">27</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">    vs.release()  </span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<h3 id="3-调用"><a href="#3-调用" class="headerlink" title="3.调用"></a>3.调用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">multi_object_tracking.tracking(<span class="string">&quot;videos/soccer_01.mp4&quot;</span>, <span class="string">&quot;medianflow&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/select_track.mov" controls="controls" width="500"></video><br>按<strong>s</strong>键，框出需要追踪的区域，再按任意键继续</p>
<h2 id="4-DNN-Dlib的实时视频追踪"><a href="#4-DNN-Dlib的实时视频追踪" class="headerlink" title="4.DNN+Dlib的实时视频追踪"></a>4.DNN+Dlib的实时视频追踪</h2><p>下面是一个先检测再追踪的代码示例：</p>
<h3 id="1-单个目标追踪"><a href="#1-单个目标追踪" class="headerlink" title="1.单个目标追踪"></a>1.单个目标追踪</h3><p><code>dlib.correlation_tracker</code> 是 <code>Dlib</code> 库中基于相关滤波（correlation filter）算法的目标追踪器，可以用来在视频中持续追踪一个物体。</p>
<p>它属于 <strong>单目标追踪器（Single Object Tracker）</strong>，不是检测器，不会识别物体类型，只能追踪一开始指定的区域。</p>
<p>实现原理：<br>利用初始帧中的目标图像作为“模板”，在后续每一帧中，通过相关匹配来寻找与这个模板最相似的区域，更新模板以适应外观的小变化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_tracker</span>(<span class="params">box, label, rgb, inputQueue, outputQueue</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化一个dlib的追踪器，并设置初始位置（start_track）</span></span><br><span class="line">    t = dlib.correlation_tracker()  </span><br><span class="line">    rect = dlib.rectangle(<span class="built_in">int</span>(box[<span class="number">0</span>]), <span class="built_in">int</span>(box[<span class="number">1</span>]), <span class="built_in">int</span>(box[<span class="number">2</span>]), <span class="built_in">int</span>(box[<span class="number">3</span>]))  </span><br><span class="line">    t.start_track(rgb, rect)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="comment"># 持续从 inputQueue 中获取下一帧图像</span></span><br><span class="line">        rgb = inputQueue.get()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 非空就开始处理  </span></span><br><span class="line">        <span class="keyword">if</span> rgb <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="comment"># 每来一帧就更新追踪器的位置</span></span><br><span class="line">            t.update(rgb)  </span><br><span class="line">            pos = t.get_position()  </span><br><span class="line">  </span><br><span class="line">            startX = <span class="built_in">int</span>(pos.left())  </span><br><span class="line">            startY = <span class="built_in">int</span>(pos.top())  </span><br><span class="line">            endX = <span class="built_in">int</span>(pos.right())  </span><br><span class="line">            endY = <span class="built_in">int</span>(pos.bottom())  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 将新的位置通过outputQueue发回主进程 </span></span><br><span class="line">            outputQueue.put((label, (startX, startY, endX, endY))) </span><br></pre></td></tr></table></figure>
<p>多进程的好处是：多个对象可以并行追踪，不会互相影响，CPU 利用率高</p>
<h3 id="2-主函数-1"><a href="#2-主函数-1" class="headerlink" title="2.主函数"></a>2.主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 类别定义 用于检测输出中的label索引对应类别名</span></span><br><span class="line">classes = [<span class="string">&quot;background&quot;</span>, <span class="string">&quot;aeroplane&quot;</span>, <span class="string">&quot;bicycle&quot;</span>, <span class="string">&quot;bird&quot;</span>, <span class="string">&quot;boat&quot;</span>, <span class="string">&quot;bottle&quot;</span>, <span class="string">&quot;bus&quot;</span>, <span class="string">&quot;car&quot;</span>, <span class="string">&quot;cat&quot;</span>, <span class="string">&quot;chair&quot;</span>, <span class="string">&quot;cow&quot;</span>,  </span><br><span class="line">           <span class="string">&quot;diningtable&quot;</span>, <span class="string">&quot;dog&quot;</span>, <span class="string">&quot;horse&quot;</span>, <span class="string">&quot;motorbike&quot;</span>, <span class="string">&quot;person&quot;</span>, <span class="string">&quot;pottedplant&quot;</span>, <span class="string">&quot;sheep&quot;</span>, <span class="string">&quot;sofa&quot;</span>, <span class="string">&quot;train&quot;</span>, <span class="string">&quot;tvmonitor&quot;</span>]   </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tracking</span>(<span class="params">video_path, model, proto_txt, output, confidence_value</span>):  </span><br><span class="line">    inputQueues = []  </span><br><span class="line">    outputQueues = []  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载Caffe格式的深度学习模型</span></span><br><span class="line">    net = cv2.dnn.readNetFromCaffe(proto_txt, model)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] starting video stream...&quot;</span>)</span><br><span class="line">    vs = cv2.VideoCapture(video_path)  <span class="comment"># 打开视频流</span></span><br><span class="line">    writer = <span class="literal">None</span>  </span><br><span class="line">    fps = FPS().start()  <span class="comment"># 启动FPS计数器</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="comment"># 读取并预处理每一帧</span></span><br><span class="line">        (grabbed, frame) = vs.read()  </span><br><span class="line">        <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">        (h, w) = frame.shape[:<span class="number">2</span>]  </span><br><span class="line">        width = <span class="number">600</span>  </span><br><span class="line">        r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">        dim = (width, <span class="built_in">int</span>(h * r))  </span><br><span class="line">        frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)  </span><br><span class="line">        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化视频保存器</span></span><br><span class="line">        <span class="keyword">if</span> output <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> writer <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            fourcc = cv2.VideoWriter_fourcc(*<span class="string">&quot;mp4v&quot;</span>)  </span><br><span class="line">            writer = cv2.VideoWriter(output, fourcc, <span class="number">30</span>,  </span><br><span class="line">                                     (frame.shape[<span class="number">1</span>], frame.shape[<span class="number">0</span>]), <span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 检测并启动追踪器（只在第一帧执行）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(inputQueues) == <span class="number">0</span>:  </span><br><span class="line">            (h, w) = frame.shape[:<span class="number">2</span>]</span><br><span class="line">            <span class="comment"># 使用OpenCV DNN执行一次前向推理</span></span><br><span class="line">            blob = cv2.dnn.blobFromImage(frame, <span class="number">0.007843</span>, (w, h), <span class="number">127.5</span>)  </span><br><span class="line">            net.setInput(blob)  </span><br><span class="line">            detections = net.forward()  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>, detections.shape[<span class="number">2</span>]):  </span><br><span class="line">                confidence = detections[<span class="number">0</span>, <span class="number">0</span>, i, <span class="number">2</span>]  </span><br><span class="line">                <span class="comment"># 过滤置信度大于confidence_value 且类别为 &quot;person&quot; 的结果</span></span><br><span class="line">                <span class="keyword">if</span> confidence &gt; confidence_value:  </span><br><span class="line">                    idx = <span class="built_in">int</span>(detections[<span class="number">0</span>, <span class="number">0</span>, i, <span class="number">1</span>])  </span><br><span class="line">                    label = classes[idx]  </span><br><span class="line">                    <span class="keyword">if</span> classes[idx] != <span class="string">&quot;person&quot;</span>:  </span><br><span class="line">                        <span class="keyword">continue</span>  </span><br><span class="line">                    box = detections[<span class="number">0</span>, <span class="number">0</span>, i, <span class="number">3</span>:<span class="number">7</span>] * np.array([w, h, w, h])  </span><br><span class="line">                    (startX, startY, endX, endY) = box.astype(<span class="string">&quot;int&quot;</span>)  </span><br><span class="line">                    <span class="comment"># 得到目标框</span></span><br><span class="line">                    bb = (startX, startY, endX, endY)  </span><br><span class="line">  </span><br><span class="line">                    <span class="comment"># 创建输入q和输出q  </span></span><br><span class="line">                    iq = multiprocessing.Queue()  </span><br><span class="line">                    oq = multiprocessing.Queue()  </span><br><span class="line">                    inputQueues.append(iq)  </span><br><span class="line">                    outputQueues.append(oq)  </span><br><span class="line">  </span><br><span class="line">                    <span class="comment"># 创建一个 multiprocessing.Queue 输入输出队列  </span></span><br><span class="line">                    p = multiprocessing.Process(target=start_tracker, args=(bb, label, rgb, iq, oq))  </span><br><span class="line">                    p.daemon = <span class="literal">True</span>  </span><br><span class="line">                    p.start()  </span><br><span class="line">  </span><br><span class="line">                    cv2.rectangle(frame, (startX, startY), (endX, endY),  </span><br><span class="line">                                  (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)  </span><br><span class="line">                    cv2.putText(frame, label, (startX, startY - <span class="number">15</span>),  </span><br><span class="line">                                cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.45</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)  </span><br><span class="line">		  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 更新追踪器 </span></span><br><span class="line">            <span class="keyword">for</span> iq <span class="keyword">in</span> inputQueues:  </span><br><span class="line">                iq.put(rgb)  <span class="comment"># 所有追踪器共享相同帧</span></span><br><span class="line">  </span><br><span class="line">            <span class="keyword">for</span> oq <span class="keyword">in</span> outputQueues:  </span><br><span class="line">                <span class="comment"># 得到更新结果  </span></span><br><span class="line">                (label, (startX, startY, endX, endY)) = oq.get()  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 绘图  </span></span><br><span class="line">                cv2.rectangle(frame, (startX, startY), (endX, endY),  </span><br><span class="line">                              (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)  </span><br><span class="line">                cv2.putText(frame, label, (startX, startY - <span class="number">15</span>),  </span><br><span class="line">                            cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.45</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            writer.write(frame)  </span><br><span class="line">  </span><br><span class="line">        cv2.imshow(<span class="string">&quot;Frame&quot;</span>, frame)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># FPS更新+按键控制</span></span><br><span class="line">        key = cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span>  </span><br><span class="line">        <span class="keyword">if</span> key == <span class="number">27</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">        fps.update()  </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] elapsed time: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(fps.elapsed()))  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] approx. FPS: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(fps.fps()))  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 清理资源</span></span><br><span class="line">    fps.stop() </span><br><span class="line">    <span class="keyword">if</span> writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">        writer.release()  </span><br><span class="line">    cv2.destroyAllWindows()  </span><br><span class="line">    vs.release()</span><br></pre></td></tr></table></figure>
<h3 id="3-调用-1"><a href="#3-调用-1" class="headerlink" title="3.调用"></a>3.调用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">multi_object_tracking_fast.tracking(<span class="string">&quot;videos/race.mp4&quot;</span>,  </span><br><span class="line">                            <span class="string">&quot;mobilenet_ssd/MobileNetSSD_deploy.caffemodel&quot;</span>,  </span><br><span class="line">                            <span class="string">&quot;mobilenet_ssd/MobileNetSSD_deploy.prototxt&quot;</span>,  </span><br><span class="line">                            <span class="string">&quot;output/race_fast.mp4&quot;</span>,  </span><br><span class="line">                            <span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<p>主要功能点：</p>
<ol>
<li>用 OpenCV 的 DNN 模块加载 Caffe 模型检测“person”</li>
<li>每个目标分配一个子进程进行独立追踪</li>
<li>利用 multiprocessing 提升处理性能</li>
<li>使用 FPS 类打印处理速度</li>
</ol>
<p><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/race_fast.mov" controls="controls" width="500"></video></p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><table>
<thead>
<tr>
<th>​<strong>方法类型</strong>​</th>
<th>​<strong>优势</strong>​</th>
<th>​<strong>局限</strong>​</th>
<th>​<strong>适用场景</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>传统算法</strong>​</td>
<td>轻量、高速，适合嵌入式设备</td>
<td>对复杂变化（遮挡、尺度）敏感</td>
<td>实时监控、资源受限环境</td>
</tr>
<tr>
<td>​<strong>深度学习+Dlib</strong>​</td>
<td>高精度，支持多目标并行</td>
<td>计算资源要求较高</td>
<td>复杂场景（如人流密集、遮挡频繁）</td>
</tr>
<tr>
<td>​<strong>端到端模型</strong>​</td>
<td>检测与追踪联合优化，简化流程</td>
<td>需大量标注数据，训练成本高</td>
<td>高精度需求（如自动驾驶）</td>
</tr>
</tbody></table>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
<li>dlib: 19.24.6</li>
</ul>
<h3 id="资源和代码"><a href="#资源和代码" class="headerlink" title="资源和代码"></a>资源和代码</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/009_opencv_tracking
</code></pre>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>OpenCV</tag>
        <tag>目标追踪</tag>
        <tag>dlib</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV之停车场车位识别</title>
    <url>/2025/03/31/008-opencv-park/</url>
    <content><![CDATA[<h2 id="1-实现流程"><a href="#1-实现流程" class="headerlink" title="1.实现流程"></a>1.实现流程</h2><ol>
<li>训练基于VGG16的迁移学习图像分类模型，使其能够分类每个车位有车或者没车</li>
<li>通过OpenCV处理停车场图片，分割成单个车位图像数据</li>
<li>基于训练模型识别并绘制出空车位</li>
</ol>
<h2 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2.模型训练"></a>2.模型训练</h2><h3 id="1-VGG16"><a href="#1-VGG16" class="headerlink" title="1.VGG16"></a>1.VGG16</h3><p><strong>VGG16</strong> 是由牛津大学 Visual Geometry Group（VGG）在 2014 年提出的经典卷积神经网络（CNN）模型，主要用于图像分类任务。其核心特点是：</p>
<ul>
<li>​<strong>结构简单但深度大</strong>：由 ​<strong>16 层</strong>​（13 个卷积层 + 3 个全连接层）组成，使用 ​<strong>3x3 小卷积核堆叠</strong>​（通过多层小卷积核模拟大感受野）。</li>
<li>​<strong>ImageNet 竞赛的里程碑</strong>：在 2014 年 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得第二名（Top-5 错误率 7.3%），证明了深度网络对视觉任务的重要性。</li>
<li>​<strong>标准化设计</strong>：所有卷积层使用相同配置（3x3 卷积核，步长 1，填充 same），全连接层统一为 4096 个神经元。</li>
</ul>
<span id="more"></span>
<h4 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">输入层 (224x224x3)</span><br><span class="line">→ 2层卷积 (64通道) → 最大池化</span><br><span class="line">→ 2层卷积 (128通道) → 最大池化</span><br><span class="line">→ 3层卷积 (256通道) → 最大池化</span><br><span class="line">→ 3层卷积 (512通道) → 最大池化</span><br><span class="line">→ 3层卷积 (512通道) → 最大池化</span><br><span class="line">→ 全连接层 (4096神经元) → Dropout</span><br><span class="line">→ 全连接层 (4096神经元) → Dropout</span><br><span class="line">→ 输出层 (1000神经元，对应ImageNet的1000类)</span><br></pre></td></tr></table></figure>
<h4 id="2-迁移学习"><a href="#2-迁移学习" class="headerlink" title="2.迁移学习"></a>2.迁移学习</h4><p>迁移学习（Transfer Learning）的核心思想是：​<strong>利用在大规模数据集（如 ImageNet）上预训练的网络，提取通用视觉特征，迁移到新任务中</strong>。VGG16 成为迁移学习经典选择的原因：</p>
<ol>
<li>强大的特征提取能力<ul>
<li>​<strong>通用底层特征</strong>：VGG16 的浅层卷积层（前几层）学习到的是边缘、颜色、纹理等<strong>通用视觉特征</strong>，这些特征对大多数图像任务（如物体检测、分类）都有效</li>
<li>​<strong>深层语义特征</strong>：深层卷积层（后几层）捕捉的是更高层次的语义特征（如车轮、车窗、车身结构等），适用于复杂任务</li>
</ul>
</li>
<li>预训练权重优势<ul>
<li>​<strong>大规模数据训练</strong>：VGG16 在 ImageNet（1400万张图片，1000类别）上训练，学习到了丰富的视觉模式</li>
<li>​<strong>参数有效性</strong>：其 3x3 卷积核堆叠的方式，能高效提取特征，且权重分布稳定</li>
</ul>
</li>
<li>迁移学习适配性<ul>
<li>​<strong>冻结部分层</strong>：可以冻结前几层（保留通用特征），只微调深层（适配特定任务），如在本文中冻结前 10 层</li>
<li><strong>灵活替换顶层</strong>：移除原模型的分类层（ImageNet 的 1000 类输出），替换为自定义分类层（如示例中的二分类）</li>
</ul>
</li>
</ol>
<h4 id="3-局限性"><a href="#3-局限性" class="headerlink" title="3.局限性"></a>3.局限性</h4><p>尽管VGG16适合迁移学习，但也有明显缺点：</p>
<ul>
<li>​<strong>参数量大</strong>：全连接层占用大量参数（约 1.38 亿），容易过拟合</li>
<li>​<strong>计算成本高</strong>：较深的网络导致训练和推理速度较慢</li>
<li>​<strong>被新模型超越</strong>：后续模型（如 ResNet、EfficientNet）在性能和效率上更优</li>
</ul>
<h3 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h3><p><code>_load_data_generator</code>用于加载和预处理图像数据，以便用于训练深度学习模型。它使用 ImageDataGenerator 进行数据增强和归一化，并返回训练集和验证集的数据生成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_load_data_generator</span>(<span class="params">_train_data_dir, _valid_data_dir, _img_width, _img_height, _batch_size</span>):</span><br><span class="line">    <span class="comment"># 1️⃣ 移除 .DS_Store 文件（仅适用于 macOS)</span></span><br><span class="line">    <span class="keyword">for</span> directory <span class="keyword">in</span> [_train_data_dir, _valid_data_dir]:  </span><br><span class="line">        ds_store_path = os.path.join(directory, <span class="string">&quot;.DS_Store&quot;</span>)  </span><br><span class="line">        <span class="keyword">if</span> os.path.exists(ds_store_path):  </span><br><span class="line">            os.remove(ds_store_path)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2️⃣ 数据增强器,对训练数据进行增强，防止过拟合，提高模型的泛化能力</span></span><br><span class="line">    train_datagen = ImageDataGenerator(  </span><br><span class="line">        rescale=<span class="number">1.0</span> / <span class="number">255</span>,       <span class="comment"># 将像素值归一化到 [0,1]（原始范围[0,255]）        </span></span><br><span class="line">        horizontal_flip=<span class="literal">True</span>,    <span class="comment"># 随机水平翻转，适用于左右对称的物体（如汽车、动物）  </span></span><br><span class="line">        fill_mode=<span class="string">&quot;nearest&quot;</span>,     <span class="comment"># 在图像转换时，缺失的像素用最近的像素填充  </span></span><br><span class="line">        zoom_range=<span class="number">0.1</span>,          <span class="comment"># 图像随机缩放 10%</span></span><br><span class="line">        width_shift_range=<span class="number">0.1</span>,   <span class="comment"># 10% 随机水平平移  </span></span><br><span class="line">        height_shift_range=<span class="number">0.1</span>,  <span class="comment"># 10% 随机垂直平移  </span></span><br><span class="line">        rotation_range=<span class="number">5</span>         <span class="comment"># 随机旋转图像 ±5 度 </span></span><br><span class="line">    )  </span><br><span class="line">    <span class="comment"># 3️⃣ 验证集数据只进行归一化，不使用数据增强  </span></span><br><span class="line">    valid_datagen = ImageDataGenerator(rescale=<span class="number">1.</span> / <span class="number">255</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4️⃣ 生成数据集和验证数据</span></span><br><span class="line">    train_generator = train_datagen.flow_from_directory(  </span><br><span class="line">        _train_data_dir,  </span><br><span class="line">        target_size=(_img_height, _img_width),  <span class="comment"># 调整图像大小</span></span><br><span class="line">        batch_size=_batch_size,  </span><br><span class="line">        class_mode=<span class="string">&quot;categorical&quot;</span>  <span class="comment"># 适用于多类别分类问题（独热编码，如 [1,0,0]）  </span></span><br><span class="line">    )  </span><br><span class="line">    validation_generator = valid_datagen.flow_from_directory(  </span><br><span class="line">        _valid_data_dir,  </span><br><span class="line">        target_size=(_img_height, _img_width),  </span><br><span class="line">        batch_size=_batch_size,  </span><br><span class="line">        class_mode=<span class="string">&quot;categorical&quot;</span>  </span><br><span class="line">    )  </span><br><span class="line">    <span class="keyword">return</span> train_generator, validation_generator</span><br></pre></td></tr></table></figure>
<h3 id="3-模型自定义"><a href="#3-模型自定义" class="headerlink" title="3.模型自定义"></a>3.模型自定义</h3><p>使用<code>VGG16</code>并添加自定义的全连接层，以构建一个<strong>用于多类别分类</strong>（停车&#x2F;不停车）的深度学习模型，同时对部分层进行微调</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">_img_width, _img_height, _num_classes</span>):  </span><br><span class="line">    <span class="comment"># 1️⃣ 加载 VGG16 预训练模型（weights 在ImageNet数据集上训练好的权重）  </span></span><br><span class="line">    <span class="comment"># include_top=False：去掉 VGG16 的全连接层，只保留卷积部分（用于特征提取）  </span></span><br><span class="line">    <span class="comment"># input_shape 3表示RGB颜色通道</span></span><br><span class="line">    model = applications.VGG16(weights=<span class="string">&#x27;imagenet&#x27;</span>, include_top=<span class="literal">False</span>, input_shape=(_img_width, _img_height, <span class="number">3</span>))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2️⃣ 让前10层的参数不参与训练，只使用它们的预训练权重，避免过拟合，并且加快训练速度  </span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">10</span>]:  </span><br><span class="line">        layer.trainable = <span class="literal">False</span>  <span class="comment"># 冻结VGG16的前10层  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3️⃣ 展平特征图</span></span><br><span class="line">    x = model.output  <span class="comment"># VGG16最后的卷积层的输出特征图 </span></span><br><span class="line">    x = Flatten()(x)  <span class="comment"># 展平数据（变成一维向量)以便用于全连接层</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4️⃣ 添加自定义全连接层  </span></span><br><span class="line">    <span class="comment"># 全连接层，输出 num_classes 个类别</span></span><br><span class="line">    <span class="comment"># softmax激活函数：用于分类任务，输出每个类别的概率  </span></span><br><span class="line">    predictions = Dense(_num_classes, activation=<span class="string">&quot;softmax&quot;</span>)(x)  <span class="comment"># 输出层（2 分类）  </span></span><br><span class="line">    <span class="comment"># 5️⃣ 构建完整模型</span></span><br><span class="line">    <span class="comment"># 输入:VGG16的输入层  输出:自定义的分类层predictions  </span></span><br><span class="line">    model = Model(inputs=model.<span class="built_in">input</span>, outputs=predictions)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6️⃣ 编译模型</span></span><br><span class="line">    <span class="comment"># loss=&quot;categorical_crossentropy&quot;, 用于多类别分类任务</span></span><br><span class="line">    <span class="comment"># optimizer 随机梯度下降（SGD）优化器 learning_rate=0.0001 控制学习步长（较小的学习率有助于稳定训练） momentum=0.9 让优化器记住之前的梯度，减少震荡，提高收敛速度</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&quot;categorical_crossentropy&quot;</span>,  <span class="comment"># 用于多类别分类任务  </span></span><br><span class="line">                  optimizer=optimizers.SGD(learning_rate=<span class="number">0.0001</span>, momentum=<span class="number">0.9</span>), </span><br><span class="line">                  metrics=[<span class="string">&quot;accuracy&quot;</span>])  <span class="comment"># 训练时监控准确率  </span></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h3 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4.模型训练"></a>4.模型训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():  </span><br><span class="line">    <span class="comment"># 1️⃣ 设置训练参数</span></span><br><span class="line">    train_data_dir = <span class="string">&quot;data/train&quot;</span>  <span class="comment"># 训练集文件夹</span></span><br><span class="line">    valid_data_dir = <span class="string">&quot;data/valid&quot;</span>  <span class="comment"># 验证集文件夹</span></span><br><span class="line">    train_files_count = _files_count(train_data_dir)  <span class="comment"># 图片数量</span></span><br><span class="line">    valid_files_count = _files_count(valid_data_dir)  </span><br><span class="line">    batch_size = <span class="number">32</span>  <span class="comment"># 每批次训练32张图片</span></span><br><span class="line">    epochs = <span class="number">15</span>  <span class="comment"># 训练15轮</span></span><br><span class="line">    num_classes = <span class="number">2</span>  <span class="comment"># 二分类任务（停车/不停车）</span></span><br><span class="line">    img_width = <span class="number">32</span>  <span class="comment"># 图片大小（VGG16预处理需要固定尺寸）</span></span><br><span class="line">    img_height = <span class="number">32</span>  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2️⃣ 加载模型</span></span><br><span class="line">    model = load_model(img_width, img_height, num_classes)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3️⃣ 加载数据</span></span><br><span class="line">    train_generator, validation_generator = _load_data_generator(train_data_dir, valid_data_dir, img_width, img_height, batch_size)  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4️⃣ 训练回调  </span></span><br><span class="line">    <span class="comment"># 模型检查点</span></span><br><span class="line">    <span class="comment"># val_accuracy最高时自动保存最佳模型car1.keras</span></span><br><span class="line">    <span class="comment"># save_best_only=True 只保存最佳模型</span></span><br><span class="line">    <span class="comment"># save_weights_only=False 保存完整模型（结构+权重）</span></span><br><span class="line">    checkpoint = ModelCheckpoint(<span class="string">&quot;car1.keras&quot;</span>, monitor=<span class="string">&#x27;val_accuracy&#x27;</span>, verbose=<span class="number">1</span>, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 早停机制  </span></span><br><span class="line">    early = EarlyStopping(monitor=<span class="string">&#x27;val_accuracy&#x27;</span>,  <span class="comment"># 10轮内没有提升，停止训练</span></span><br><span class="line">                          min_delta=<span class="number">0</span>,  </span><br><span class="line">                          patience=<span class="number">10</span>,  <span class="comment"># 最多等待10轮</span></span><br><span class="line">                          verbose=<span class="number">1</span>,  </span><br><span class="line">                          mode=<span class="string">&#x27;max&#x27;</span>)  <span class="comment"># val_accuracy最大化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5️⃣ 计算步数 计算每轮训练的批次数</span></span><br><span class="line">    steps_per_epoch = np.ceil(train_files_count / batch_size).astype(<span class="built_in">int</span>)  </span><br><span class="line">    validation_steps = np.ceil(valid_files_count / batch_size).astype(<span class="built_in">int</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6️⃣ 训练模型</span></span><br><span class="line">    model.fit(  </span><br><span class="line">        train_generator,  <span class="comment"># 训练数据  </span></span><br><span class="line">        steps_per_epoch=steps_per_epoch,  <span class="comment"># 每个epoch运行多少个batch（训练批次）  </span></span><br><span class="line">        epochs=epochs,  <span class="comment"># 训练 15 轮  </span></span><br><span class="line">        validation_data=validation_generator,  <span class="comment"># 验证数据集  </span></span><br><span class="line">        validation_steps=validation_steps,  <span class="comment"># 验证批次数  </span></span><br><span class="line">        callbacks=[checkpoint, early]  </span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>model.fit() 训练过程中自动生成的日志信息，如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Epoch 13/15</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 0s 452ms/step - accuracy: 0.9705 - loss: 0.0595</span><br><span class="line">Epoch 13: val_accuracy did not improve from 0.94512</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 6s 546ms/step - accuracy: 0.9712 - loss: 0.0587 - val_accuracy: 0.9451 - val_loss: 0.1267</span><br><span class="line">Epoch 14/15</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 0s 444ms/step - accuracy: 0.9904 - loss: 0.0406</span><br><span class="line">Epoch 14: val_accuracy improved from 0.94512 to 0.95122, saving model to car1.keras</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 7s 547ms/step - accuracy: 0.9905 - loss: 0.0403 - val_accuracy: 0.9512 - val_loss: 0.1178</span><br><span class="line">Epoch 15/15</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 0s 458ms/step - accuracy: 0.9963 - loss: 0.0310</span><br><span class="line">Epoch 15: val_accuracy did not improve from 0.95122</span><br><span class="line">12/12 ━━━━━━━━━━━━━━━━━━━━ 7s 552ms/step - accuracy: 0.9960 - loss: 0.0314 - val_accuracy: 0.9390 - val_loss: 0.1335</span><br></pre></td></tr></table></figure>
<p>模型训练完会生成一个<code>car1.keras</code>文件</p>
<h2 id="3-车位分割"><a href="#3-车位分割" class="headerlink" title="3.车位分割"></a>3.车位分割</h2><h3 id="1-图像预处理"><a href="#1-图像预处理" class="headerlink" title="1.图像预处理"></a>1.图像预处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取出白色和黄色的区域(车位线)，并返回一个掩码后的图像  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_rgb_white_yellow</span>(<span class="params">image</span>):  </span><br><span class="line">    lower = np.uint8([<span class="number">120</span>, <span class="number">120</span>, <span class="number">120</span>])  </span><br><span class="line">    upper = np.uint8([<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>])  </span><br><span class="line">    <span class="comment"># 提取lower和upper之间颜色  </span></span><br><span class="line">    <span class="comment"># mask是一个二值图像，白色区域表示符合颜色范围的像素，黑色区域表示不符合的像素  </span></span><br><span class="line">    mask = cv2.inRange(image, lower, upper)  </span><br><span class="line">    <span class="comment"># 保留掩码中白色区域对应的像素，其余区域置为黑色  </span></span><br><span class="line">    masked = cv2.bitwise_and(image, image, mask=mask)  </span><br><span class="line">    <span class="keyword">return</span> masked  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 转灰度图，便于后续边缘检测</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_gray</span>(<span class="params">image</span>):  </span><br><span class="line">    <span class="keyword">return</span> cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Canny算法检测图像边缘，返回二值化的边缘图像</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detect_edges</span>(<span class="params">image, low_threshold=<span class="number">50</span>, high_threshold=<span class="number">200</span></span>):  </span><br><span class="line">    <span class="comment"># low_threshold：低阈值，用于边缘连接  high_threshold：高阈值，用于强边缘检测  </span></span><br><span class="line">    <span class="comment"># 二值图像，其中边缘像素为白色（255），非边缘像素为黑色（0）  </span></span><br><span class="line">    <span class="keyword">return</span> cv2.Canny(image, low_threshold, high_threshold)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">white_yellow_image = parking.select_rgb_white_yellow(_image)  </span><br><span class="line">cv_show(<span class="string">&quot;white_yellow_images&quot;</span>, white_yellow_image)  </span><br><span class="line">gray_image = parking.convert_gray(white_yellow_image)  </span><br><span class="line">cv_show(<span class="string">&quot;gray_image&quot;</span>, gray_image)  </span><br><span class="line">edges_image = parking.detect_edges(gray_image)  </span><br><span class="line">cv_show(<span class="string">&quot;edges_image&quot;</span>, edges_image)</span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-02-45.jpg"><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-02-54.jpg"><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-03-03.jpg"></p>
<h3 id="2-车位区域选择"><a href="#2-车位区域选择" class="headerlink" title="2.车位区域选择"></a>2.车位区域选择</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义停车场的多边形区域顶点（通过手动标定），返回顶点坐标和标记顶点后的图像</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_region</span>(<span class="params">image</span>):  </span><br><span class="line">    rows, cols = image.shape[:<span class="number">2</span>]  </span><br><span class="line">    pt_1 = [<span class="built_in">int</span>(cols * <span class="number">0.05</span>), <span class="built_in">int</span>(rows * <span class="number">0.90</span>)]  </span><br><span class="line">    pt_2 = [<span class="built_in">int</span>(cols * <span class="number">0.05</span>), <span class="built_in">int</span>(rows * <span class="number">0.70</span>)]  </span><br><span class="line">    pt_3 = [<span class="built_in">int</span>(cols * <span class="number">0.30</span>), <span class="built_in">int</span>(rows * <span class="number">0.55</span>)]  </span><br><span class="line">    pt_4 = [<span class="built_in">int</span>(cols * <span class="number">0.6</span>), <span class="built_in">int</span>(rows * <span class="number">0.13</span>)]  </span><br><span class="line">    pt_5 = [<span class="built_in">int</span>(cols * <span class="number">0.90</span>), <span class="built_in">int</span>(rows * <span class="number">0.15</span>)]  </span><br><span class="line">    pt_6 = [<span class="built_in">int</span>(cols * <span class="number">0.90</span>), <span class="built_in">int</span>(rows * <span class="number">0.95</span>)]  </span><br><span class="line">  </span><br><span class="line">    vertices = np.array([pt_1, pt_2, pt_3, pt_4, pt_5, pt_6], dtype=np.int32)  </span><br><span class="line">    cv_vertices = [vertices.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)]  <span class="comment"># 转换为OpenCV多边形格式  </span></span><br><span class="line">  </span><br><span class="line">    point_img = image.copy()  </span><br><span class="line">    point_img = cv2.cvtColor(point_img, cv2.COLOR_GRAY2RGB)  </span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> vertices:  </span><br><span class="line">        cv2.circle(point_img, (point[<span class="number">0</span>], point[<span class="number">1</span>]), <span class="number">5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> point_img, cv_vertices  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据顶点坐标生成掩码，过滤出停车区域，忽略无关背景</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">filter_region</span>(<span class="params">image, vertices</span>):  </span><br><span class="line">    mask = np.zeros_like(image)  </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(mask.shape) == <span class="number">2</span>:  </span><br><span class="line">        cv2.fillPoly(mask, vertices, <span class="number">255</span>)  <span class="comment"># 绘制停车区域  </span></span><br><span class="line">    <span class="keyword">return</span> cv2.bitwise_and(image, mask)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(point_img, vertices) = parking.select_region(edges_image)  </span><br><span class="line">cv_show(<span class="string">&quot;point_img&quot;</span>, point_img)</span><br><span class="line">filter_region_image = parking.filter_region(edges_image, vertices)  </span><br><span class="line">cv_show(<span class="string">&quot;filter_region_image&quot;</span>, filter_region_image)</span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-10-04.jpg"><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-10-14.jpg"></p>
<h3 id="3-车位线检测与聚类"><a href="#3-车位线检测与聚类" class="headerlink" title="3.车位线检测与聚类"></a>3.车位线检测与聚类</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用霍夫变换检测直线（车位线），返回线段的起点和终点坐标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hough_lines</span>(<span class="params">image</span>):  </span><br><span class="line">    <span class="comment"># 能够检测出图像中的线段，并返回每条线段的起点和终点坐标  </span></span><br><span class="line">    <span class="comment"># image 输入图像，必须是单通道的二值图像（通常是经过边缘检测后的图像，如 Canny 边缘检测的结果  </span></span><br><span class="line">    <span class="comment"># rho 直线检测的精度（以像素为单位），默认值：0.1。值越小，检测精度越高  </span></span><br><span class="line">    <span class="comment"># theta 直线检测的角度精度（以弧度为单位）。默认值：np.pi / 10（即 18 度）。值越小，检测角度越精细  </span></span><br><span class="line">    <span class="comment"># threshold 累加器阈值，用于确定检测到的直线。默认值：15。值越小，检测到的直线越多；值越大，检测到的直线越少  </span></span><br><span class="line">    <span class="comment"># minLineLength 线段的最小长度。默认值：9 小于此长度的线段会被忽略  </span></span><br><span class="line">    <span class="comment"># maxLineGap 线段之间的最大间隙 默认值：4 如果两条线段之间的间隙小于此值，它们会被合并为一条线段  </span></span><br><span class="line">    <span class="keyword">return</span> cv2.HoughLinesP(image, rho=<span class="number">0.1</span>, theta=np.pi / <span class="number">10</span>, threshold=<span class="number">15</span>, minLineLength=<span class="number">9</span>, maxLineGap=<span class="number">4</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤并绘制符合条件的线段（水平且长度在25-55像素之间）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_lines</span>(<span class="params">image, lines</span>):  </span><br><span class="line">    <span class="comment"># 过滤霍夫变换检测到直线  </span></span><br><span class="line">    image = np.copy(image)  </span><br><span class="line">    cleaned = []  </span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:  </span><br><span class="line">        <span class="keyword">for</span> x1, y1, x2, y2 <span class="keyword">in</span> line:  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(y2 - y1) &lt;= <span class="number">1</span> <span class="keyword">and</span> <span class="number">25</span> &lt;= <span class="built_in">abs</span>(x2 - x1) &lt;= <span class="number">55</span>:  </span><br><span class="line">                cleaned.append((x1, y1, x2, y2))  </span><br><span class="line">                cv2.line(image, (x1, y1), (x2, y2), [<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="number">1</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;No lines detected: &quot;</span>, <span class="built_in">len</span>(cleaned))  </span><br><span class="line">    <span class="keyword">return</span> image  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 对检测到的线段按列聚类（每列为一排车位），计算每列的矩形边界框</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">identify_blocks</span>(<span class="params">image, lines</span>):  </span><br><span class="line">    _new_image = np.copy(image)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 1️⃣ 过滤部分直线  </span></span><br><span class="line">    cleaned = []  </span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:  </span><br><span class="line">        <span class="keyword">for</span> x1, y1, x2, y2 <span class="keyword">in</span> line:  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(y2 - y1) &lt;= <span class="number">1</span> <span class="keyword">and</span> <span class="number">25</span> &lt;= <span class="built_in">abs</span>(x2 - x1) &lt;= <span class="number">55</span>:  </span><br><span class="line">                cleaned.append((x1, y1, x2, y2))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2️⃣ 对直线按照x1进行排序  </span></span><br><span class="line">    <span class="keyword">import</span> operator  </span><br><span class="line">    list1 = <span class="built_in">sorted</span>(cleaned, key=operator.itemgetter(<span class="number">0</span>, <span class="number">1</span>))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3️⃣ 找到多个列，相当于每列是一排车  </span></span><br><span class="line">    clusters = &#123;&#125;  </span><br><span class="line">    d_index = <span class="number">0</span>  </span><br><span class="line">    clus_dist = <span class="number">10</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list1) - <span class="number">1</span>):  </span><br><span class="line">        distance = <span class="built_in">abs</span>(list1[i + <span class="number">1</span>][<span class="number">0</span>] - list1[i][<span class="number">0</span>])  </span><br><span class="line">        <span class="keyword">if</span> distance &lt;= clus_dist:  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> d_index <span class="keyword">in</span> clusters.keys():  </span><br><span class="line">                clusters[d_index] = []  </span><br><span class="line">            clusters[d_index].append(list1[i])  </span><br><span class="line">            clusters[d_index].append(list1[i + <span class="number">1</span>])  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            d_index += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4️⃣ 得到坐标  </span></span><br><span class="line">    rects = &#123;&#125;  </span><br><span class="line">    i = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> clusters:  </span><br><span class="line">        all_list = clusters[key]  </span><br><span class="line">        cleaned = <span class="built_in">list</span>(<span class="built_in">set</span>(all_list))  </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(cleaned) &gt; <span class="number">5</span>:  </span><br><span class="line">            cleaned = <span class="built_in">sorted</span>(cleaned, key=<span class="keyword">lambda</span> tup: tup[<span class="number">1</span>])  </span><br><span class="line">            avg_y1 = cleaned[<span class="number">0</span>][<span class="number">1</span>]  </span><br><span class="line">            avg_y2 = cleaned[-<span class="number">1</span>][<span class="number">1</span>]  </span><br><span class="line">            avg_x1 = <span class="number">0</span>  </span><br><span class="line">            avg_x2 = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">for</span> tup <span class="keyword">in</span> cleaned:  </span><br><span class="line">                avg_x1 += tup[<span class="number">0</span>]  </span><br><span class="line">                avg_x2 += tup[<span class="number">2</span>]  </span><br><span class="line">            avg_x1 = avg_x1 / <span class="built_in">len</span>(cleaned)  </span><br><span class="line">            avg_x2 = avg_x2 / <span class="built_in">len</span>(cleaned)  </span><br><span class="line">            rects[i] = (avg_x1, avg_y1, avg_x2, avg_y2)  </span><br><span class="line">            i += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Num Parking Lanes: &quot;</span>, <span class="built_in">len</span>(rects))  </span><br><span class="line">    <span class="comment"># 5️⃣ 把列矩形画出来  </span></span><br><span class="line">    buff = <span class="number">7</span>  </span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> rects:  </span><br><span class="line">        tup_top_left = (<span class="built_in">int</span>(rects[key][<span class="number">0</span>] - buff), <span class="built_in">int</span>(rects[key][<span class="number">1</span>]))  </span><br><span class="line">        tup_bot_right = (<span class="built_in">int</span>(rects[key][<span class="number">2</span>] + buff), <span class="built_in">int</span>(rects[key][<span class="number">3</span>]))  </span><br><span class="line">        cv2.rectangle(_new_image, tup_top_left, tup_bot_right, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)  </span><br><span class="line">    <span class="keyword">return</span> _new_image, rects</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = parking.hough_lines(filter_region_image)  </span><br><span class="line">line_image = parking.draw_lines(_image, lines)  </span><br><span class="line">cv_show(<span class="string">&quot;line_image&quot;</span>, line_image)  </span><br><span class="line">rect_image, rects = parking.identify_blocks(_image, lines)  </span><br><span class="line">cv_show(<span class="string">&quot;rect_image&quot;</span>, rect_image)</span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-16-20.jpg"><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-16-27.jpg"></p>
<h3 id="4-车位划分与编号"><a href="#4-车位划分与编号" class="headerlink" title="4.车位划分与编号"></a>4.车位划分与编号</h3><p>根据矩形边界框划分车位：</p>
<ul>
<li>在每列内按固定间距（<code>gap=15.5</code>）绘制水平线，表示车位分隔</li>
<li>对中间列添加垂直线，将车位分为左右两部分</li>
<li>微调坐标（<code>adj_x1</code>, <code>adj_y1</code>等）以适配实际场景</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">draw_parking</span>(<span class="params">image, rects, thickness=<span class="number">1</span>, save=<span class="literal">False</span></span>):  </span><br><span class="line">    color = [<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>]  </span><br><span class="line">    new_image = np.copy(image)  </span><br><span class="line">    gap = <span class="number">15.5</span>  </span><br><span class="line">    cur_len = <span class="number">0</span>  </span><br><span class="line">    spot_dict = &#123;&#125;  <span class="comment"># 字典：一个车位对应一个位置  </span></span><br><span class="line">    tot_spots = <span class="number">0</span>  </span><br><span class="line">    <span class="comment"># 微调  </span></span><br><span class="line">    adj_y1 = &#123;<span class="number">0</span>: <span class="number">20</span>, <span class="number">1</span>: -<span class="number">10</span>, <span class="number">2</span>: <span class="number">0</span>, <span class="number">3</span>: -<span class="number">11</span>, <span class="number">4</span>: <span class="number">28</span>, <span class="number">5</span>: <span class="number">5</span>, <span class="number">6</span>: -<span class="number">15</span>, <span class="number">7</span>: -<span class="number">15</span>, <span class="number">8</span>: -<span class="number">10</span>, <span class="number">9</span>: -<span class="number">30</span>, <span class="number">10</span>: <span class="number">9</span>, <span class="number">11</span>: -<span class="number">32</span>&#125;  </span><br><span class="line">    adj_y2 = &#123;<span class="number">0</span>: <span class="number">30</span>, <span class="number">1</span>: <span class="number">50</span>, <span class="number">2</span>: <span class="number">15</span>, <span class="number">3</span>: <span class="number">10</span>, <span class="number">4</span>: -<span class="number">15</span>, <span class="number">5</span>: <span class="number">15</span>, <span class="number">6</span>: <span class="number">15</span>, <span class="number">7</span>: -<span class="number">20</span>, <span class="number">8</span>: <span class="number">15</span>, <span class="number">9</span>: <span class="number">15</span>, <span class="number">10</span>: <span class="number">0</span>, <span class="number">11</span>: <span class="number">30</span>&#125;  </span><br><span class="line">  </span><br><span class="line">    adj_x1 = &#123;<span class="number">0</span>: -<span class="number">8</span>, <span class="number">1</span>: -<span class="number">15</span>, <span class="number">2</span>: -<span class="number">15</span>, <span class="number">3</span>: -<span class="number">15</span>, <span class="number">4</span>: -<span class="number">15</span>, <span class="number">5</span>: -<span class="number">15</span>, <span class="number">6</span>: -<span class="number">15</span>, <span class="number">7</span>: -<span class="number">15</span>, <span class="number">8</span>: -<span class="number">10</span>, <span class="number">9</span>: -<span class="number">10</span>, <span class="number">10</span>: -<span class="number">10</span>, <span class="number">11</span>: <span class="number">0</span>&#125;  </span><br><span class="line">    adj_x2 = &#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">1</span>: <span class="number">15</span>, <span class="number">2</span>: <span class="number">15</span>, <span class="number">3</span>: <span class="number">15</span>, <span class="number">4</span>: <span class="number">15</span>, <span class="number">5</span>: <span class="number">15</span>, <span class="number">6</span>: <span class="number">15</span>, <span class="number">7</span>: <span class="number">15</span>, <span class="number">8</span>: <span class="number">10</span>, <span class="number">9</span>: <span class="number">10</span>, <span class="number">10</span>: <span class="number">10</span>, <span class="number">11</span>: <span class="number">0</span>&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> rects:  </span><br><span class="line">        tup = rects[key]  </span><br><span class="line">        <span class="comment"># 使用 dict.get 方法，为不存在的键提供默认值 0        </span></span><br><span class="line">        x1 = <span class="built_in">int</span>(tup[<span class="number">0</span>] + adj_x1.get(key, <span class="number">0</span>))  </span><br><span class="line">        x2 = <span class="built_in">int</span>(tup[<span class="number">2</span>] + adj_x2.get(key, <span class="number">0</span>))  </span><br><span class="line">        y1 = <span class="built_in">int</span>(tup[<span class="number">1</span>] + adj_y1.get(key, <span class="number">0</span>))  </span><br><span class="line">        y2 = <span class="built_in">int</span>(tup[<span class="number">3</span>] + adj_y2.get(key, <span class="number">0</span>))  </span><br><span class="line">        cv2.rectangle(new_image, (x1, y1), (x2, y2), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)  </span><br><span class="line">        num_splits = <span class="built_in">int</span>(<span class="built_in">abs</span>(y2 - y1) // gap)  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_splits + <span class="number">1</span>):  </span><br><span class="line">            y = <span class="built_in">int</span>(y1 + i * gap)  </span><br><span class="line">            cv2.line(new_image, (x1, y), (x2, y), color, thickness)  </span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt; key &lt; <span class="built_in">len</span>(rects) - <span class="number">1</span>:  </span><br><span class="line">            <span class="comment"># 竖直线  </span></span><br><span class="line">            x = <span class="built_in">int</span>((x1 + x2) / <span class="number">2</span>)  </span><br><span class="line">            cv2.line(new_image, (x, y1), (x, y2), color, thickness)  </span><br><span class="line">        <span class="comment"># 计算数量  </span></span><br><span class="line">        <span class="keyword">if</span> key == <span class="number">0</span> <span class="keyword">or</span> key == (<span class="built_in">len</span>(rects) - <span class="number">1</span>):  </span><br><span class="line">            tot_spots += num_splits + <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            tot_spots += <span class="number">2</span> * (num_splits + <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 字典对应好  </span></span><br><span class="line">        <span class="keyword">if</span> key == <span class="number">0</span> <span class="keyword">or</span> key == (<span class="built_in">len</span>(rects) - <span class="number">1</span>):  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_splits + <span class="number">1</span>):  </span><br><span class="line">                cur_len = <span class="built_in">len</span>(spot_dict)  </span><br><span class="line">                y = <span class="built_in">int</span>(y1 + i * gap)  </span><br><span class="line">                spot_dict[(x1, y, x2, y + gap)] = cur_len + <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_splits + <span class="number">1</span>):  </span><br><span class="line">                cur_len = <span class="built_in">len</span>(spot_dict)  </span><br><span class="line">                y = <span class="built_in">int</span>(y1 + i * gap)  </span><br><span class="line">                x = <span class="built_in">int</span>((x1 + x2) / <span class="number">2</span>)  </span><br><span class="line">                spot_dict[(x1, y, x, y + gap)] = cur_len + <span class="number">1</span>  </span><br><span class="line">                spot_dict[(x, y, x2, y + gap)] = cur_len + <span class="number">2</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;total parking spaces: <span class="subst">&#123;tot_spots&#125;</span>, len: <span class="subst">&#123;cur_len&#125;</span> &quot;</span>)  </span><br><span class="line">    <span class="keyword">if</span> save:  </span><br><span class="line">        filename = <span class="string">f&#x27;with_parking_<span class="subst">&#123;<span class="built_in">str</span>(random.randint(<span class="number">1000</span>, <span class="number">9999</span>))&#125;</span>.jpg&#x27;</span>  </span><br><span class="line">        cv2.imwrite(filename, new_image)  </span><br><span class="line">    <span class="keyword">return</span> new_image, spot_dict</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_parking_image, _spot_dict = parking.draw_parking(_image, rects)  </span><br><span class="line">cv_show(<span class="string">&quot;draw_parking_image&quot;</span>, draw_parking_image)</span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-19-42.jpg"><br>最终生成车位字典 <code>spot_dict</code>，记录每个车位的坐标和编号</p>
<h2 id="4-车位状态预测"><a href="#4-车位状态预测" class="headerlink" title="4.车位状态预测"></a>4.车位状态预测</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用预训练模型，预测车位状态empty或occupied</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_prediction</span>(<span class="params">image, model, class_dictionary</span>):  </span><br><span class="line">    <span class="comment"># 预处理  </span></span><br><span class="line">    img = image / <span class="number">255.</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 转换成4D tensor  </span></span><br><span class="line">    image = np.expand_dims(img, axis=<span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 用训练好的模型进行训练  </span></span><br><span class="line">    class_predicted = model.predict(image)  </span><br><span class="line">    in_id = np.argmax(class_predicted[<span class="number">0</span>])  </span><br><span class="line">    label = class_dictionary[in_id]  </span><br><span class="line">    <span class="keyword">return</span> label  </span><br></pre></td></tr></table></figure>
<h3 id="1-图片预测"><a href="#1-图片预测" class="headerlink" title="1.图片预测"></a>1.图片预测</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 遍历所有车位，调用模型预测状态，并在图像上标记空车位（绿色半透明矩形）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_on_image</span>(<span class="params">image, spot_dict, model, class_dictionary, color=<span class="literal">None</span>, alpha=<span class="number">0.5</span></span>):  </span><br><span class="line">    <span class="keyword">if</span> color <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">        color = [<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>]  </span><br><span class="line">    new_image = np.copy(image)  </span><br><span class="line">    overlay = np.copy(image)  </span><br><span class="line">    cnt_empty = <span class="number">0</span>  </span><br><span class="line">    all_spots = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">for</span> spot <span class="keyword">in</span> spot_dict.keys():  </span><br><span class="line">        all_spots += <span class="number">1</span>  </span><br><span class="line">        (x1, y1, x2, y2) = spot  </span><br><span class="line">        (x1, y1, x2, y2) = (<span class="built_in">int</span>(x1), <span class="built_in">int</span>(y1), <span class="built_in">int</span>(x2), <span class="built_in">int</span>(y2))  </span><br><span class="line">        spot_img = image[y1:y2, x1:x2]  </span><br><span class="line">        spot_img = cv2.resize(spot_img, (<span class="number">32</span>, <span class="number">32</span>))  </span><br><span class="line">  </span><br><span class="line">        label = make_prediction(spot_img, model, class_dictionary)  </span><br><span class="line">        <span class="keyword">if</span> label == <span class="string">&#x27;empty&#x27;</span>:  </span><br><span class="line">            cv2.rectangle(overlay, (<span class="built_in">int</span>(x1), <span class="built_in">int</span>(y1)), (<span class="built_in">int</span>(x2), <span class="built_in">int</span>(y2)), color, -<span class="number">1</span>)  </span><br><span class="line">            cnt_empty += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    cv2.addWeighted(overlay, alpha, new_image, <span class="number">1</span> - alpha, <span class="number">0</span>, new_image)  </span><br><span class="line">  </span><br><span class="line">    cv2.putText(new_image, <span class="string">&quot;Available: %d spots&quot;</span> % cnt_empty, (<span class="number">30</span>, <span class="number">95</span>),  </span><br><span class="line">                cv2.FONT_HERSHEY_SIMPLEX,  </span><br><span class="line">                <span class="number">0.7</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">    cv2.putText(new_image, <span class="string">&quot;Total: %d spots&quot;</span> % all_spots, (<span class="number">30</span>, <span class="number">125</span>),  </span><br><span class="line">                cv2.FONT_HERSHEY_SIMPLEX,  </span><br><span class="line">                <span class="number">0.7</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">    <span class="keyword">return</span> new_image  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-视频预测"><a href="#2-视频预测" class="headerlink" title="2.视频预测"></a>2.视频预测</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对视频隔帧处理，实时检测车位状态并输出结果视频</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_on_video</span>(<span class="params">video_name, spot_dict, model, class_dictionary, output_name=<span class="string">&quot;parking_video_output.mp4&quot;</span></span>):  </span><br><span class="line">    cap = cv2.VideoCapture(video_name)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 获取视频帧率、分辨率  </span></span><br><span class="line">    fps = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FPS))  </span><br><span class="line">    frame_width = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  </span><br><span class="line">    frame_height = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 设置视频写入器（MP4 格式）  </span></span><br><span class="line">    fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>)  <span class="comment"># 编码格式  </span></span><br><span class="line">    out = cv2.VideoWriter(output_name, fourcc, fps, (frame_width, frame_height))  </span><br><span class="line">  </span><br><span class="line">    frame_count = <span class="number">0</span>  </span><br><span class="line">    alpha = <span class="number">0.5</span>  <span class="comment"># 透明度  </span></span><br><span class="line">    color = (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>)  <span class="comment"># 绿色  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> cap.isOpened():  </span><br><span class="line">        ret, frame = cap.read()  </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ret:  </span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 读取失败，退出循环  </span></span><br><span class="line">  </span><br><span class="line">        frame_count += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">if</span> frame_count % <span class="number">20</span> != <span class="number">0</span>:  <span class="comment"># 每20帧处理一次，提高性能  </span></span><br><span class="line">            out.write(frame)  <span class="comment"># 直接写入原始帧  </span></span><br><span class="line">            <span class="keyword">continue</span>  </span><br><span class="line">  </span><br><span class="line">        overlay = frame.copy()  </span><br><span class="line">        empty_spots = <span class="number">0</span>  </span><br><span class="line">        total_spots = <span class="built_in">len</span>(spot_dict)  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">for</span> (x1, y1, x2, y2) <span class="keyword">in</span> spot_dict.keys():  </span><br><span class="line">            x1, y1, x2, y2 = <span class="built_in">map</span>(<span class="built_in">int</span>, [x1, y1, x2, y2])  <span class="comment"># 确保坐标为整数  </span></span><br><span class="line">            spot_img = frame[y1:y2, x1:x2]  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span> spot_img.size == <span class="number">0</span>:  </span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># 避免无效的裁剪区域  </span></span><br><span class="line">  </span><br><span class="line">            spot_img = cv2.resize(spot_img, (<span class="number">32</span>, <span class="number">32</span>))  </span><br><span class="line">            label = make_prediction(spot_img, model, class_dictionary)  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span> label == <span class="string">&#x27;empty&#x27;</span>:  </span><br><span class="line">                cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -<span class="number">1</span>)  </span><br><span class="line">                empty_spots += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 叠加透明遮罩  </span></span><br><span class="line">        cv2.addWeighted(overlay, alpha, frame, <span class="number">1</span> - alpha, <span class="number">0</span>, frame)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 显示车位信息  </span></span><br><span class="line">        cv2.putText(frame, <span class="string">f&quot;Available: <span class="subst">&#123;empty_spots&#125;</span> spots&quot;</span>, (<span class="number">30</span>, <span class="number">95</span>),  </span><br><span class="line">                    cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">        cv2.putText(frame, <span class="string">f&quot;Total: <span class="subst">&#123;total_spots&#125;</span> spots&quot;</span>, (<span class="number">30</span>, <span class="number">125</span>),  </span><br><span class="line">                    cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">        out.write(frame)  <span class="comment"># 将帧写入输出视频文件  </span></span><br><span class="line">        <span class="comment"># cv_show(&#x27;Parking Detection&#x27;, frame)  </span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">10</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">    cap.release()  </span><br><span class="line">    out.release()  </span><br><span class="line">    cv2.destroyAllWindows()  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Processed video saved as <span class="subst">&#123;output_name&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-主方法调用"><a href="#3-主方法调用" class="headerlink" title="3.主方法调用"></a>3.主方法调用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试单张图片，显示原始图片&amp;预测结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_test</span>(<span class="params">_image, _area_dict, _model, _class_dict</span>):  </span><br><span class="line">    cv_show(<span class="string">&quot;image&quot;</span>, _image)  </span><br><span class="line">    predicted_image = parking.predict_on_image(_image, _area_dict, _model, _class_dict)  </span><br><span class="line">    cv_show(<span class="string">&quot;predicted_image&quot;</span>, predicted_image)  <span class="comment"># 显示预测后的图片</span></span><br><span class="line">    filename = <span class="string">f&#x27;with_marking_<span class="subst">&#123;<span class="built_in">str</span>(random.randint(<span class="number">1000</span>, <span class="number">9999</span>))&#125;</span>.jpg&#x27;</span>  </span><br><span class="line">    cv2.imwrite(filename, predicted_image)  <span class="comment"># 保存标记后的图片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试视频</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">video_test</span>(<span class="params">video_name, _area_dict, _model, _class_dict</span>):  </span><br><span class="line">    parking.predict_on_video(video_name, _area_dict, _model, _class_dict)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 1.模型训练，生成car1.keras  </span></span><br><span class="line">    <span class="comment"># train_model.train()    </span></span><br><span class="line">    model = load_model(<span class="string">&quot;car1.keras&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2.获取停车场车位区域  </span></span><br><span class="line">    image = cv2.imread(<span class="string">&quot;images/frame_0006.jpg&quot;</span>)  </span><br><span class="line">    area_dict = get_parking_area(image)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3.图片（标出空车位）  </span></span><br><span class="line">    class_dict = &#123;<span class="number">0</span>: <span class="string">&#x27;empty&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;occupied&#x27;</span>&#125;  </span><br><span class="line">    image_test(image, area_dict, model, class_dict)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4.视频（标出空车位）  </span></span><br><span class="line">    <span class="comment"># video_test(&#x27;parking_video.mp4&#x27;, area_dict, model, class_dict)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-03-31_15-59-43.jpg"><br>视频效果可以自己跑下看看</p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><h3 id="1-模型训练"><a href="#1-模型训练" class="headerlink" title="1.模型训练"></a>1.模型训练</h3><ul>
<li>使用 VGG16 预训练模型，去除全连接层，仅保留卷积部分用于特征提取</li>
<li>迁移学习：冻结前 10 层，仅微调深层，提高泛化能力</li>
<li>数据预处理：<ul>
<li>数据增强（翻转、缩放、平移、旋转）防止过拟合</li>
<li>归一化（像素值缩放至 [0,1]）</li>
</ul>
</li>
<li>自定义分类层：<ul>
<li>全连接层 + softmax 激活函数进行二分类（空&#x2F;占）</li>
</ul>
</li>
<li>模型训练：<ul>
<li><code>categorical_crossentropy</code>作为损失函数，SGD 作为优化器</li>
<li>早停机制 + 最优模型保存 (car1.keras)</li>
</ul>
</li>
</ul>
<h3 id="2-车位分割"><a href="#2-车位分割" class="headerlink" title="2.车位分割"></a>2.车位分割</h3><ul>
<li>图像预处理：<ul>
<li>选取 <strong>白色&#x2F;黄色车位线</strong>，转换为灰度图</li>
<li>Canny 边缘检测提取车位边缘</li>
</ul>
</li>
<li>车位区域选择：<ul>
<li>手动标定停车场区域，提取有效部分</li>
<li>生成 <strong>掩码</strong>，忽略背景干扰</li>
</ul>
</li>
<li>车位线检测与聚类：<ul>
<li>霍夫变换检测水平车位线</li>
<li>聚类分析划分停车列，计算每列矩形边界框</li>
</ul>
</li>
</ul>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
<li>keras: 3.9.0</li>
</ul>
<h3 id="资源和代码"><a href="#资源和代码" class="headerlink" title="资源和代码"></a>资源和代码</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/008_opencv_park
</code></pre>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>计算机视觉</tag>
        <tag>图像识别</tag>
        <tag>OpenCV</tag>
        <tag>图像分割</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV之人脸疲劳检测</title>
    <url>/2025/04/15/010-opencv-face-fatigue-detection/</url>
    <content><![CDATA[<h2 id="1-dlib"><a href="#1-dlib" class="headerlink" title="1.dlib"></a>1.dlib</h2><p><a href="https://dlib.net/">dlib</a> 是一个用 C++ 编写的开源机器学习库，同时也提供了 Python 接口，它被广泛应用于计算机视觉和机器学习领域：</p>
<h3 id="1-​人脸识别与生物特征分析"><a href="#1-​人脸识别与生物特征分析" class="headerlink" title="1.​人脸识别与生物特征分析"></a>1.​人脸识别与生物特征分析</h3><p>dlib 的人脸检测和关键点定位功能是其最突出的应用方向。通过预训练模型（如 HOG + SVM 或深度学习模型），dlib 可实现高效的人脸检测、68 个面部关键点定位（如眼睛、嘴唇、下巴等）</p>
<span id="more"></span>
<p>。例如：</p>
<ul>
<li>​<strong>安全系统</strong>​：用于门禁、身份验证，结合活体检测技术（如眨眼识别）防止照片或视频伪造</li>
<li>​<strong>社交媒体</strong>​：支持美颜滤镜、表情分析（如情绪识别）和虚拟试妆</li>
</ul>
<h3 id="2-计算机视觉任务​"><a href="#2-计算机视觉任务​" class="headerlink" title="2.计算机视觉任务​"></a>2.计算机视觉任务​</h3><p>dlib 提供多种图像处理算法，支持以下场景：</p>
<ul>
<li>​<strong>物体检测与跟踪</strong>：利用 HOG 特征和 SVM 分类器检测车辆、行人等目标，适用于智能交通系统中的车牌识别或违规行为监控，如 <a href="https://keychankc.github.io/2025/04/08/009-opencv-tracking/">OpenCV之目标追踪</a></li>
<li>​<strong>图像增强与分割</strong>​：包括降噪、边缘检测和图像对齐功能，提升医学影像分析（如肿瘤检测）的准确性</li>
</ul>
<h3 id="3-机器学习算法集成​"><a href="#3-机器学习算法集成​" class="headerlink" title="3.机器学习算法集成​"></a>3.机器学习算法集成​</h3><p>dlib 实现了多种经典和现代算法，如：</p>
<ul>
<li>​<strong>分类与回归</strong>​：支持向量机（SVM）、决策树、线性回归等，适用于数据分类和预测任务</li>
<li>​<strong>深度学习</strong>​：结合预训练模型处理复杂任务（如姿态估计），兼容实时计算需求</li>
</ul>
<h3 id="4-实时系统开发​"><a href="#4-实时系统开发​" class="headerlink" title="4.实时系统开发​"></a>4.实时系统开发​</h3><p>其优化的内存管理和高效算法使其适合嵌入式设备和实时处理：</p>
<ul>
<li>​<strong>摄像头监控</strong>​：实时人脸跟踪、驾驶员疲劳检测（通过眼部闭合频率判断）</li>
<li>​<strong>交互式应用</strong>​：如虚拟现实中的面部动作捕捉</li>
</ul>
<h3 id="5-跨领域创新应用​"><a href="#5-跨领域创新应用​" class="headerlink" title="5.跨领域创新应用​"></a>5.跨领域创新应用​</h3><ul>
<li>​<strong>医疗保健</strong>​：辅助康复训练监测（如关节活动分析）、医疗影像中的器官识别</li>
<li>​<strong>智能交通</strong>​：交通流量监控、违法行为记录（如未系安全带检测）</li>
</ul>
<h3 id="6-​跨平台与多语言支持​"><a href="#6-​跨平台与多语言支持​" class="headerlink" title="6.​跨平台与多语言支持​"></a>6.​跨平台与多语言支持​</h3><p>dlib 兼容 Windows、Linux、macOS 等系统，并提供 Python 接口，便于集成到不同项目中</p>
<h3 id="7-预训练模型"><a href="#7-预训练模型" class="headerlink" title="7.预训练模型"></a>7.预训练模型</h3><table>
<thead>
<tr>
<th>模型</th>
<th>用途</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><code>mmod_human_face_detector.dat</code></td>
<td>高精度 CNN 人脸检测</td>
<td>安防、监控</td>
</tr>
<tr>
<td><code>shape_predictor_68_face_landmarks.dat</code></td>
<td>68 点关键点检测</td>
<td>美颜、AR、疲劳检测</td>
</tr>
<tr>
<td><code>shape_predictor_5_face_landmarks.dat</code></td>
<td>5 点关键点检测</td>
<td>人脸对齐、移动端</td>
</tr>
<tr>
<td><code>dlib_face_recognition_resnet_model_v1.dat</code></td>
<td>人脸特征提取</td>
<td>人脸识别、身份验证</td>
</tr>
<tr>
<td><code>hand_landmark_detector.dat</code></td>
<td>手部关键点检测</td>
<td>手势交互</td>
</tr>
</tbody></table>
<h2 id="2-人脸关键点检测"><a href="#2-人脸关键点检测" class="headerlink" title="2.人脸关键点检测"></a>2.人脸关键点检测</h2><p>如何用<code>shape_predictor_68_face_landmarks.dat</code>来做人脸检测，并可视化人脸的关键部位，如眼睛、鼻子、嘴巴等。</p>
<h3 id="1-人脸关键点"><a href="#1-人脸关键点" class="headerlink" title="1.人脸关键点"></a>1.人脸关键点</h3><p>定义了68个关键点，如下分布：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/figure_68_markup_face.jpg" width="500"></p>
<p>按关键点索引可分成以下7类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">facial_landmarks = OrderedDict([</span><br><span class="line">	(<span class="string">&quot;mouth&quot;</span>, (<span class="number">48</span>, <span class="number">68</span>)),  <span class="comment"># 嘴</span></span><br><span class="line">	(<span class="string">&quot;right_eyebrow&quot;</span>, (<span class="number">17</span>, <span class="number">22</span>)), <span class="comment"># 右眉毛</span></span><br><span class="line">	(<span class="string">&quot;left_eyebrow&quot;</span>, (<span class="number">22</span>, <span class="number">27</span>)),  <span class="comment"># 左眉毛</span></span><br><span class="line">	(<span class="string">&quot;right_eye&quot;</span>, (<span class="number">36</span>, <span class="number">42</span>)), <span class="comment"># 右眼</span></span><br><span class="line">	(<span class="string">&quot;left_eye&quot;</span>, (<span class="number">42</span>, <span class="number">48</span>)),  <span class="comment"># 左眼</span></span><br><span class="line">	(<span class="string">&quot;nose&quot;</span>, (<span class="number">27</span>, <span class="number">36</span>)), <span class="comment"># 鼻子</span></span><br><span class="line">	(<span class="string">&quot;jaw&quot;</span>, (<span class="number">0</span>, <span class="number">17</span>))  <span class="comment"># 下巴</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>为何代码中的左右和图片中的左右是相反的？<br>当我们说右眉毛，我们通常指的是图片中人的右眉毛（也就是图像左边的眉毛），但在数据结构中，“right_eyebrow” 指的是我们从屏幕看的左边，这也是左右的定义在视觉上和数据上的差异。</p>
<h3 id="2-shape-to-np"><a href="#2-shape-to-np" class="headerlink" title="2.shape to np"></a>2.shape to np</h3><p>将 dlib 的 shape 转换成 <code>numpy</code> 数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_shape_to_np</span>(<span class="params">shape, dtype=<span class="string">&quot;int&quot;</span></span>):</span><br><span class="line">	coors = np.zeros((shape.num_parts, <span class="number">2</span>), dtype=dtype)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, shape.num_parts):</span><br><span class="line">		coors[i] = (shape.part(i).x, shape.part(i).y)</span><br><span class="line">	<span class="keyword">return</span> coors</span><br></pre></td></tr></table></figure>
<p>将 <code>dlib.full_object_detection</code> 类型的 shape，转成一个 (68, 2) 的 <code>numpy</code> 数组，方便后续处理。</p>
<h3 id="3-主流程函数"><a href="#3-主流程函数" class="headerlink" title="3.主流程函数"></a>3.主流程函数</h3><p>使用 dlib 进行人脸检测与关键点定位，使用 OpenCV 对每个面部区域进行可视化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detect_face_part</span>(<span class="params">image_path</span>):  </span><br><span class="line">    <span class="comment"># 1.加载人脸检测与关键点定位  </span></span><br><span class="line">    detector = dlib.get_frontal_face_detector()  </span><br><span class="line">    predictor = dlib.shape_predictor(<span class="string">&quot;shape_predictor_68_face_landmarks.dat&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2.读取输入数据，预处理  </span></span><br><span class="line">    image = cv2.imread(image_path)  </span><br><span class="line">    (h, w) = image.shape[:<span class="number">2</span>]  </span><br><span class="line">    width = <span class="number">500</span>  </span><br><span class="line">    r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">    dim = (width, <span class="built_in">int</span>(h * r))  </span><br><span class="line">    image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)  </span><br><span class="line">    <span class="comment"># 图像统一缩放到宽500px，并转成灰度图以便处理</span></span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3.人脸检测  </span></span><br><span class="line">    rects = detector(gray, <span class="number">1</span>)  <span class="comment"># rects是一个包含所有检测到人脸的列表 </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4.遍历检测到的框  </span></span><br><span class="line">    <span class="keyword">for</span> (_, rect) <span class="keyword">in</span> <span class="built_in">enumerate</span>(rects):  </span><br><span class="line">       <span class="comment"># 对人脸框进行关键点定位  </span></span><br><span class="line">       shape = predictor(gray, rect)  </span><br><span class="line">       shape = _shape_to_np(shape)  <span class="comment"># 转换成ndarray  </span></span><br><span class="line">  </span><br><span class="line">       <span class="comment"># 遍历每一个部分  </span></span><br><span class="line">       <span class="keyword">for</span> (name, (i, j)) <span class="keyword">in</span> facial_landmarks.items():  </span><br><span class="line">          clone = image.copy()  </span><br><span class="line">          cv2.putText(clone, name, (<span class="number">10</span>, <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">          <span class="comment"># 根据位置画点  </span></span><br><span class="line">          <span class="keyword">for</span> (x, y) <span class="keyword">in</span> shape[i:j]:  </span><br><span class="line">             cv2.circle(clone, (x, y), <span class="number">3</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), -<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">          <span class="comment"># 提取每个区域的 ROI（感兴趣区域）</span></span><br><span class="line">          (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))  </span><br><span class="line">  </span><br><span class="line">          roi = image[y:y + h, x:x + w]  </span><br><span class="line">          (h, w) = roi.shape[:<span class="number">2</span>]  </span><br><span class="line">          width = <span class="number">250</span>  </span><br><span class="line">          r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">          dim = (width, <span class="built_in">int</span>(h * r))  </span><br><span class="line">          roi = cv2.resize(roi, dim, interpolation=cv2.INTER_AREA)  </span><br><span class="line">  </span><br><span class="line">          <span class="comment"># 显示每一部分  </span></span><br><span class="line">          cv2.imshow(<span class="string">&quot;ROI&quot;</span>, roi)  </span><br><span class="line">          cv2.imshow(<span class="string">&quot;Image&quot;</span>, clone)  </span><br><span class="line">          cv2.waitKey(<span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">       <span class="comment"># 5.展示所有区域  </span></span><br><span class="line">       output = _visualize_facial_landmarks(image, shape)  </span><br><span class="line">       cv2.imshow(<span class="string">&quot;Image&quot;</span>, output)  </span><br><span class="line">       cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>OpenCV可视化如下：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250414145650.png"></p>
<h3 id="4-可视化面部区域"><a href="#4-可视化面部区域" class="headerlink" title="4.可视化面部区域"></a>4.可视化面部区域</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_visualize_facial_landmarks</span>(<span class="params">image, shape, colors=<span class="literal">None</span>, alpha=<span class="number">0.75</span></span>):  </span><br><span class="line">    <span class="comment"># 用于绘制半透明的彩色区域</span></span><br><span class="line">    overlay = image.copy()  </span><br><span class="line">    output = image.copy()  </span><br><span class="line">    <span class="comment"># 如果没有指定颜色，则使用预设的7种颜色</span></span><br><span class="line">    <span class="keyword">if</span> colors <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">       colors = [(<span class="number">19</span>, <span class="number">199</span>, <span class="number">109</span>), (<span class="number">79</span>, <span class="number">76</span>, <span class="number">240</span>), (<span class="number">230</span>, <span class="number">159</span>, <span class="number">23</span>), (<span class="number">168</span>, <span class="number">100</span>, <span class="number">168</span>), (<span class="number">158</span>, <span class="number">163</span>, <span class="number">32</span>), (<span class="number">163</span>, <span class="number">38</span>, <span class="number">32</span>), (<span class="number">180</span>, <span class="number">42</span>, <span class="number">220</span>)]  </span><br><span class="line">    <span class="comment"># 对每个部位进行处理</span></span><br><span class="line">    <span class="keyword">for</span> (i, name) <span class="keyword">in</span> <span class="built_in">enumerate</span>(facial_landmarks.keys()):  </span><br><span class="line">       (j, k) = facial_landmarks[name]  </span><br><span class="line">       pts = shape[j:k]  </span><br><span class="line">       <span class="comment"># jaw（下巴轮廓），用线段依次连接  </span></span><br><span class="line">       <span class="keyword">if</span> name == <span class="string">&quot;jaw&quot;</span>:  </span><br><span class="line">          <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(pts)):  </span><br><span class="line">             ptA = <span class="built_in">tuple</span>(pts[l - <span class="number">1</span>])  </span><br><span class="line">             ptB = <span class="built_in">tuple</span>(pts[l])  </span><br><span class="line">             cv2.line(overlay, ptA, ptB, colors[i], <span class="number">2</span>)  </span><br><span class="line">       <span class="comment"># 其余对其关键点构建凸包（convex hull）并填充颜色  </span></span><br><span class="line">       <span class="keyword">else</span>:  </span><br><span class="line">          hull = cv2.convexHull(pts)  </span><br><span class="line">          cv2.drawContours(overlay, [hull], -<span class="number">1</span>, colors[i], -<span class="number">1</span>)  </span><br><span class="line">    <span class="comment"># 把绘制的overlay和原图按一定比例融合  </span></span><br><span class="line">    cv2.addWeighted(overlay, alpha, output, <span class="number">1</span> - alpha, <span class="number">0</span>, output)  </span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250414143141.png"  width="300"/>

<h2 id="3-眨眼检测"><a href="#3-眨眼检测" class="headerlink" title="3.眨眼检测"></a>3.眨眼检测</h2><p>原理：使用dlib进行人脸关键点识别，通过计算眼睛长宽比<code>EAR</code>（Eye Aspect Ratio）来判断是否闭眼，闭眼时间 &gt; 1秒判定为疲劳。</p>
<h3 id="1-计算眼睛长宽比（EAR）"><a href="#1-计算眼睛长宽比（EAR）" class="headerlink" title="1.计算眼睛长宽比（EAR）"></a>1.计算眼睛长宽比（EAR）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_eye_aspect_ratio</span>(<span class="params">eye</span>):</span><br><span class="line">    A = dist.euclidean(eye[<span class="number">1</span>], eye[<span class="number">5</span>])</span><br><span class="line">    B = dist.euclidean(eye[<span class="number">2</span>], eye[<span class="number">4</span>])</span><br><span class="line">    C = dist.euclidean(eye[<span class="number">0</span>], eye[<span class="number">3</span>])</span><br><span class="line">    ear = (A + B) / (<span class="number">2.0</span> * C)</span><br><span class="line">    <span class="keyword">return</span> ear</span><br></pre></td></tr></table></figure>
<p>EAR值越小，表示眼睛越闭合。当 EAR &lt; 0.3 且持续几帧，就认为眨了一次眼。</p>
<h3 id="2-主流程函数"><a href="#2-主流程函数" class="headerlink" title="2.主流程函数"></a>2.主流程函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detect_blinks</span>(<span class="params">path</span>):  </span><br><span class="line">    eye_ar_thresh = <span class="number">0.3</span>  <span class="comment"># 低于0.3EAR值认为眼睛闭合</span></span><br><span class="line">    eye_ar_consec_frames = <span class="number">3</span>  <span class="comment"># 连续闭合超过3帧，才算一次眨眼</span></span><br><span class="line">  </span><br><span class="line">    counter = <span class="number">0</span>  </span><br><span class="line">    total = <span class="number">0</span>  </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] loading facial landmark predictor...&quot;</span>)  </span><br><span class="line">    <span class="comment"># 使用dlib加载人脸检测器和68个点的预测器模型</span></span><br><span class="line">    detector = dlib.get_frontal_face_detector()  </span><br><span class="line">    predictor = dlib.shape_predictor(<span class="string">&quot;shape_predictor_68_face_landmarks.dat&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 分别取两个眼睛区域  </span></span><br><span class="line">    (lStart, lEnd) = facial_landmarks[<span class="string">&quot;left_eye&quot;</span>]  </span><br><span class="line">    (rStart, rEnd) = facial_landmarks[<span class="string">&quot;right_eye&quot;</span>]  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] starting video stream thread...&quot;</span>)  </span><br><span class="line">    <span class="comment"># 读取视频  </span></span><br><span class="line">    vs = cv2.VideoCapture(path)  </span><br><span class="line">    time.sleep(<span class="number">1.0</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 遍历每一帧  </span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        frame = vs.read()[<span class="number">1</span>]  <span class="comment"># 读取帧</span></span><br><span class="line">        <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        (h, w) = frame.shape[:<span class="number">2</span>]  </span><br><span class="line">        width = <span class="number">1200</span>  </span><br><span class="line">        r = width / <span class="built_in">float</span>(w)  </span><br><span class="line">        dim = (width, <span class="built_in">int</span>(h * r))  </span><br><span class="line">        frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)  </span><br><span class="line">        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转成灰度</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 检测人脸  </span></span><br><span class="line">        rects = detector(gray, <span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 遍历每一个检测到的人脸  </span></span><br><span class="line">        <span class="keyword">for</span> rect <span class="keyword">in</span> rects:  </span><br><span class="line">            <span class="comment"># 获取坐标  </span></span><br><span class="line">            shape = predictor(gray, rect)  </span><br><span class="line">            shape = _shape_to_np(shape)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 分别计算ear值  </span></span><br><span class="line">            leftEye = shape[lStart:lEnd]  </span><br><span class="line">            rightEye = shape[rStart:rEnd]  </span><br><span class="line">            leftEAR = _eye_aspect_ratio(leftEye)  </span><br><span class="line">            rightEAR = _eye_aspect_ratio(rightEye)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 算一个平均的  </span></span><br><span class="line">            ear = (leftEAR + rightEAR) / <span class="number">2.0</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 绘制眼睛区域  </span></span><br><span class="line">            leftEyeHull = cv2.convexHull(leftEye)  </span><br><span class="line">            rightEyeHull = cv2.convexHull(rightEye)  </span><br><span class="line">            cv2.drawContours(frame, [leftEyeHull], -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)  </span><br><span class="line">            cv2.drawContours(frame, [rightEyeHull], -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 检查是否满足阈值  </span></span><br><span class="line">            <span class="keyword">if</span> ear &lt; eye_ar_thresh:  </span><br><span class="line">                counter += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="comment"># 如果连续几帧都是闭眼的，总数算一次  </span></span><br><span class="line">                <span class="keyword">if</span> counter &gt;= eye_ar_consec_frames:  </span><br><span class="line">                    total += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 重置  </span></span><br><span class="line">                counter = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 显示  </span></span><br><span class="line">            cv2.putText(frame, <span class="string">&quot;Blinks: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(total), (<span class="number">10</span>, <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">            cv2.putText(frame, <span class="string">&quot;EAR: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(ear), (<span class="number">300</span>, <span class="number">30</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.7</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  </span><br><span class="line">  </span><br><span class="line">        cv2.imshow(<span class="string">&quot;Frame&quot;</span>, frame)  </span><br><span class="line">        key = cv2.waitKey(<span class="number">10</span>) &amp; <span class="number">0xFF</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 按下ESC键退出</span></span><br><span class="line">        <span class="keyword">if</span> key == <span class="number">27</span>:  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">    vs.release()  </span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/output_blinks.mp4" controls="controls" width="500"></video></p>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><h3 id="1-人脸关键点检测"><a href="#1-人脸关键点检测" class="headerlink" title="1.人脸关键点检测"></a>1.人脸关键点检测</h3><ul>
<li>使用 shape_predictor_68_face_landmarks.dat 实现 68 点人脸关键点定位</li>
<li>分区域提取面部部位（如眼睛、嘴、鼻子等），并通过 OrderedDict 定义索引范围</li>
<li>利用 OpenCV 可视化每个面部区域，包括点、轮廓和半透明区域高亮显示</li>
</ul>
<h3 id="2-眨眼检测原理"><a href="#2-眨眼检测原理" class="headerlink" title="2.眨眼检测原理"></a>2.眨眼检测原理</h3><p>使用 EAR（Eye Aspect Ratio）判断眼睛是否闭合，当 EAR &lt; 0.3 且连续超过 3 帧，视为一次眨眼</p>
<h3 id="3-其它动作识别"><a href="#3-其它动作识别" class="headerlink" title="3.其它动作识别"></a>3.其它动作识别</h3><p>除了眨眼识别，dlib还支持其它面部相关动作识别</p>
<table>
<thead>
<tr>
<th><strong>动作</strong></th>
<th><strong>方法或指标</strong></th>
<th><strong>场景用途</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>打哈欠</strong></td>
<td>MAR（嘴巴长宽比）</td>
<td>注意力检测、驾驶监控</td>
</tr>
<tr>
<td><strong>张嘴说话</strong></td>
<td>连续 MAR 变化</td>
<td>音视频同步、语音识别辅助</td>
</tr>
<tr>
<td><strong>微笑识别</strong></td>
<td>嘴角抬起 + 脸部肌肉张力</td>
<td>表情识别、用户反馈分析</td>
</tr>
<tr>
<td><strong>头部点头&#x2F;摇头</strong></td>
<td>检测面部关键点相对移动轨迹</td>
<td>手势交互、虚拟现实</td>
</tr>
<tr>
<td><strong>睁眼&#x2F;闭眼识别</strong></td>
<td>EAR 静态阈值 + 多帧验证</td>
<td>活体识别、疲劳监测</td>
</tr>
</tbody></table>
<h2 id="5-备注"><a href="#5-备注" class="headerlink" title="5.备注"></a>5.备注</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
<li>dlib: 19.24.6</li>
</ul>
<h3 id="资源和代码"><a href="#资源和代码" class="headerlink" title="资源和代码"></a>资源和代码</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/010_opencv_face_fatigue_detection
</code></pre>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>OpenCV</tag>
        <tag>目标追踪</tag>
        <tag>dlib</tag>
        <tag>人脸检测</tag>
      </tags>
  </entry>
  <entry>
    <title>[YOLO系列①] 物体检测评估指标和YOLO-v1实现思路</title>
    <url>/2025/04/17/011-yolo-eval-metrics-yolov1/</url>
    <content><![CDATA[<h2 id="1-物体检测评估指标"><a href="#1-物体检测评估指标" class="headerlink" title="1.物体检测评估指标"></a>1.物体检测评估指标</h2><h3 id="1-TP-FP-FN-TN"><a href="#1-TP-FP-FN-TN" class="headerlink" title="1.TP &#x2F; FP &#x2F; FN &#x2F; TN"></a>1.TP &#x2F; FP &#x2F; FN &#x2F; TN</h3><p>这四个指标是分类任务的基础：<br>• <strong>TP（True Positive）</strong>：预测为正，且是真正的正样本（比如检测到了一个人，且确实是人）<br>• <strong>FP（False Positive）</strong>：预测为正，但实际上是负样本（检测到了人，但其实是背景或别的物体）<br>• <strong>FN（False Negative）</strong>：实际是正样本，但没检测出来（图里有人，模型没发现）<br>• <strong>TN（True Negative）</strong>：负样本预测为负（对物体检测来说，通常不关注 TN）</p>
<p>举个例子</p>
<span id="more"></span>

<table>
<thead>
<tr>
<th><strong>名称</strong></th>
<th><strong>含义</strong></th>
<th><strong>举例（检测“猫”）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>TP</strong></td>
<td>正确地检测出了一个猫</td>
<td>模型框住了图中的一只猫</td>
</tr>
<tr>
<td><strong>FP</strong></td>
<td>错误地检测出一个猫（其实没有猫）</td>
<td>背景被误判为猫</td>
</tr>
<tr>
<td><strong>FN</strong></td>
<td>有猫但模型没检测出来</td>
<td>图里明明有猫，但模型漏掉了</td>
</tr>
<tr>
<td><strong>TN</strong></td>
<td>正确地没检测出负样本</td>
<td>背景没有猫，模型也没检测到</td>
</tr>
</tbody></table>
<p>为何对物体检测来说，通常不关注 TN？<br>因为背景太多了，一张图中，除了少数目标区域，剩下都是背景（负样本）。比如整张图只有2只猫，剩下的几百万像素都是“不是猫”。所以 TN 的数量巨大无比，关注TN就没啥意义。</p>
<p>所以在物体检测中，正因为背景（负样本）太多且没明确边界，所以我们更关注的是<strong>检测出来的东西是否准确（TP &#x2F; FP）</strong>，和<strong>有没有漏检（FN）</strong>。</p>
<h3 id="2-IoU（Intersection-over-Union）"><a href="#2-IoU（Intersection-over-Union）" class="headerlink" title="2.IoU（Intersection over Union）"></a>2.IoU（Intersection over Union）</h3><p>预测框与真实框的重叠程度，<strong>IoU &gt; 某个阈值（比如 0.5）</strong> 就认为检测成功（TP），否则认为是误报（FP）或漏检（FN）。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250410142350.png" width="400"/></p>
<h3 id="3-Confidence（置信度）"><a href="#3-Confidence（置信度）" class="headerlink" title="3.Confidence（置信度）"></a>3.Confidence（置信度）</h3><p>模型对<strong>这个框里确实有物体</strong>的信心程度，通常是一个介于 <strong>0 到 1</strong> 之间的小数，是模型对检测框中存在目标物体及其预测类别准确性的综合评判指标。</p>
<p>物体检测输出是：[类名, 置信度, 边界框坐标]。</p>
<p>作用：<br>	1. 控制预测数量（过滤阈值），我们通常会设置一个阈值，比如 confidence &gt; 0.5，只保留“自信”的预测。低于这个阈值的预测会被忽略，减少 FP（误报）<br>	2. 用来画 PR 曲线、计算 AP，通过调整置信度阈值，我们会得到不同的：TP &#x2F; FP &#x2F; FN &#x2F; Precision &#x2F; Recall，画出 PR 曲线后还可以求AP（PR 曲线下的面积）<br>	3. 排序时使用非极大值抑制，在非极大值抑制（<strong>NMS</strong>）中，为了去掉重复框，模型会：按置信度从高到低排序，保留最“自信”的框，去掉重叠度高的（IoU高）低置信度框</p>
<h3 id="4-Precision（精度）"><a href="#4-Precision（精度）" class="headerlink" title="4.Precision（精度）"></a>4.Precision（精度）</h3><p>$$\text{Precision} &#x3D; \frac{TP}{TP + FP}$$</p>
<p>预测为正的里面有多少是真的。</p>
<h3 id="5-Recall（召回率）"><a href="#5-Recall（召回率）" class="headerlink" title="5. Recall（召回率）"></a>5. Recall（召回率）</h3><p>$$\text{Recall} &#x3D; \frac{TP}{TP + FN}$$</p>
<p>所有正样本中被预测出来了多少。</p>
<h3 id="6-PR-曲线"><a href="#6-PR-曲线" class="headerlink" title="6.PR 曲线"></a>6.PR 曲线</h3><p>通过<strong>调整置信度阈值</strong>，会得到一组 Precision 和 Recall 值，对这些点画图就得到了 <strong>PR 曲线</strong>。<br>高置信度：Precision 高，Recall 低，低置信度：Recall 高，Precision 低。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250410145622.png" width="400"/></p>
<h3 id="7-AP（Average-Precision）"><a href="#7-AP（Average-Precision）" class="headerlink" title="7.AP（Average Precision）"></a>7.AP（Average Precision）</h3><p>PR 曲线下的面积，也可以理解为对这条曲线的“积分”。不同的任务对 AP 的计算方法略有不同（见 VOC 和 COCO）。</p>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250410145729.png" width="400"/>

<h3 id="8-mAP（mean-Average-Precision）"><a href="#8-mAP（mean-Average-Precision）" class="headerlink" title="8.mAP（mean Average Precision）"></a>8.mAP（mean Average Precision）</h3><p>平均的AP，AP是对每一个类别算一个 AP，mAP 就是所有类别的 AP 的平均值</p>
<h3 id="9-评估标准（VOC-COCO）"><a href="#9-评估标准（VOC-COCO）" class="headerlink" title="9.评估标准（VOC &#x2F; COCO）"></a>9.评估标准（VOC &#x2F; COCO）</h3><h4 id="1-PASCAL-VOC（早期标准）"><a href="#1-PASCAL-VOC（早期标准）" class="headerlink" title="1. PASCAL VOC（早期标准）"></a>1. PASCAL VOC（早期标准）</h4><p>来自 PASCAL VOC 挑战赛（2007 ~ 2012），经典但相对简单</p>
<h4 id="2-COCO（更严格的现代标准）"><a href="#2-COCO（更严格的现代标准）" class="headerlink" title="2.COCO（更严格的现代标准）"></a>2.COCO（更严格的现代标准）</h4><p>来自 Microsoft 的 COCO 数据集。2015 后成为主流评估标准（比如 YOLOv5 默认用 COCO）</p>
<p>VOC vs COCO：</p>
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>VOC</strong></th>
<th><strong>COCO</strong></th>
</tr>
</thead>
<tbody><tr>
<td>IoU 阈值</td>
<td>固定 0.5</td>
<td>0.5 ~ 0.95（步长 0.05）</td>
</tr>
<tr>
<td>AP 计算</td>
<td>简单插值</td>
<td>更精细插值</td>
</tr>
<tr>
<td>小物体评估</td>
<td>不考虑</td>
<td>特别考虑小&#x2F;中&#x2F;大物体性能</td>
</tr>
<tr>
<td>难度</td>
<td>相对简单</td>
<td>更严格全面</td>
</tr>
<tr>
<td>应用</td>
<td>早期模型测试</td>
<td>当前工业&#x2F;学术主流（如 YOLO 系列）</td>
</tr>
</tbody></table>
<h3 id="10-举个例子"><a href="#10-举个例子" class="headerlink" title="10.举个例子"></a>10.举个例子</h3><h4 id="1-示例场景"><a href="#1-示例场景" class="headerlink" title="1.示例场景"></a>1.示例场景</h4><p>一张图中有 2 只猫（Ground Truth），使用VOC评估，模型预测了 3 个框，带有类别和置信度：</p>
<table>
<thead>
<tr>
<th><strong>预测编号</strong></th>
<th><strong>预测框位置</strong></th>
<th><strong>类别</strong></th>
<th><strong>置信度</strong></th>
<th><strong>IoU with GT</strong></th>
</tr>
</thead>
<tbody><tr>
<td>P1</td>
<td>猫1的位置</td>
<td>猫</td>
<td>0.9</td>
<td>0.75</td>
</tr>
<tr>
<td>P2</td>
<td>猫2的位置</td>
<td>猫</td>
<td>0.7</td>
<td>0.55</td>
</tr>
<tr>
<td>P3</td>
<td>没有猫的区域</td>
<td>猫</td>
<td>0.8</td>
<td>0.2（背景）</td>
</tr>
</tbody></table>
<h4 id="2-先算-IoU，判断-TP-FP-FN"><a href="#2-先算-IoU，判断-TP-FP-FN" class="headerlink" title="2.先算 IoU，判断 TP &#x2F; FP &#x2F; FN"></a>2.先算 IoU，判断 TP &#x2F; FP &#x2F; FN</h4><p>• P1：IoU 0.75 &gt; 0.5 → <strong>TP</strong><br>• P2：IoU 0.55 &gt; 0.5 → <strong>TP</strong><br>• P3：IoU 0.2 &lt; 0.5 → <strong>FP</strong><br>还有 Ground Truth 2 只猫都被命中，所以 <strong>FN &#x3D; 0</strong></p>
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>值</strong></th>
</tr>
</thead>
<tbody><tr>
<td>TP</td>
<td>2</td>
</tr>
<tr>
<td>FP</td>
<td>1</td>
</tr>
<tr>
<td>FN</td>
<td>0</td>
</tr>
</tbody></table>
<h4 id="3-计算-Precision-和-Recall"><a href="#3-计算-Precision-和-Recall" class="headerlink" title="3.计算 Precision 和 Recall"></a>3.计算 Precision 和 Recall</h4><p>$$\text{Precision} &#x3D; \frac{2}{2 + 1} &#x3D; \frac{2}{3} \approx 0.67$$</p>
<p>$$\text{Recall} &#x3D; \frac{2}{2 + 0} &#x3D; 1.0$$</p>
<h4 id="4-PR曲线"><a href="#4-PR曲线" class="headerlink" title="4.PR曲线"></a>4.PR曲线</h4><ol>
<li>只保留置信度 &gt; 0.85 → 只有 P1：TP&#x3D;1, FP&#x3D;0 → P&#x3D;1.0, R&#x3D;0.5</li>
<li>置信度 &gt; 0.65 → P1+P2：TP&#x3D;2, FP&#x3D;0 → P&#x3D;1.0, R&#x3D;1.0</li>
<li>置信度 &gt; 0.6 → P1+P2+P3：TP&#x3D;2, FP&#x3D;1 → P&#x3D;2&#x2F;3, R&#x3D;1.0</li>
</ol>
<p>将这些点连接起来形成 <strong>PR 曲线</strong><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Xnip2025-04-10_15-29-57.jpg" width="600"/></p>
<h4 id="5-计算-AP-和-mAP"><a href="#5-计算-AP-和-mAP" class="headerlink" title="5.计算 AP 和 mAP"></a>5.计算 AP 和 mAP</h4><p>对这条 PR 曲线下的面积求和，就是这张图“猫”这一类的 <strong>AP</strong>，如果还有“狗”“人”等类别，每个类别都算一个 AP，再平均得到 <strong>mAP</strong>。</p>
<h4 id="6-VOC-vs-COCO"><a href="#6-VOC-vs-COCO" class="headerlink" title="6.VOC vs COCO"></a>6.VOC vs COCO</h4><p>在 VOC 中，IoU &gt; 0.5 就算 TP，所以我们这里算的是 <code>AP@0.5</code>，在 COCO 中，还会算<code>AP@0.5</code>、<code>AP@0.75</code>、<code>AP@0.95</code>等，再平均得到更严格的 mAP。</p>
<h2 id="2-YOLO-V1"><a href="#2-YOLO-V1" class="headerlink" title="2.YOLO-V1"></a>2.YOLO-V1</h2><h3 id="1-目标检测方法"><a href="#1-目标检测方法" class="headerlink" title="1.目标检测方法"></a>1.目标检测方法</h3><h4 id="1-两阶段检测（Two-Stage）​"><a href="#1-两阶段检测（Two-Stage）​" class="headerlink" title="1.两阶段检测（Two-Stage）​"></a>1.两阶段检测（Two-Stage）​</h4><p>​代表模型​：Faster R-CNN、Mask R-CNN<br>​核心思想​：​<strong>​“先粗选再精修”​</strong>，就像选秀节目：</p>
<ol>
<li>​<strong>海选阶段（Region Proposal）​</strong>​，用RPN（Region Proposal Network）快速生成约2k个候选框（可能含物体的区域）。特点是高召回率（宁可多选不错过），但框不准。</li>
<li>​<strong>决赛阶段（RoI分类与回归）​</strong>​，对每个候选框精细调整位置，并分类（如“猫”“狗”）。<br>​优点​是精度高（适合复杂场景，如小物体或密集目标），适合需要实例分割的任务（如Mask R-CNN），​缺点是​计算量大，速度慢（通常5~20 FPS），训练流程复杂（分阶段训练或端到端调参难）。典型应用​有医学影像分析（肿瘤检测需高精度）、自动驾驶（高精度3D检测）、竞赛刷榜（COCO数据集冠军常客）等。</li>
</ol>
<h4 id="2-单阶段检测（One-Stage）​​"><a href="#2-单阶段检测（One-Stage）​​" class="headerlink" title="2. 单阶段检测（One-Stage）​​"></a>2. 单阶段检测（One-Stage）​​</h4><p>​代表模型​：YOLO系列、SSD、RetinaNet<br>​核心思想​：​<strong>​“一步到位”​</strong>，像快餐点单：</p>
<ol>
<li>​<strong>直接输出</strong>​，对图像网格化，每个格子同时预测边界框和类别（无候选框步骤）。特点是速度快（YOLOv8可达100+ FPS）但易漏检小物体，部署简单（适合端侧设备如手机、无人机）。缺点是​精度略低（尤其小物体检测），密集物体易重叠（如人群中的个体）。典型应用有实时视频分析（安防监控、直播质检）、移动端APP（手机AR贴纸、扫商品）、工业质检（快速检测缺陷）等。</li>
</ol>
<h4 id="3-技术演进趋势​"><a href="#3-技术演进趋势​" class="headerlink" title="3.技术演进趋势​"></a>3.技术演进趋势​</h4><ul>
<li>​<strong>两阶段的改进</strong>​：<ul>
<li>更高效的候选框生成（如Cascade R-CNN）</li>
</ul>
</li>
<li>​<strong>单阶段的突破</strong>​：<ul>
<li>提升小物体检测（YOLOv5的FPN+PAN结构）</li>
<li>动态标签分配（如OTA策略）</li>
</ul>
</li>
<li>​<strong>跨界融合</strong>​：<ul>
<li>单阶段模型通过蒸馏技术逼近两阶段精度（如YOLOv7）</li>
</ul>
</li>
</ul>
<h3 id="2-YOLO产生背景"><a href="#2-YOLO产生背景" class="headerlink" title="2.YOLO产生背景"></a>2.YOLO产生背景</h3><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102311.jpg" width="600"/>

<p>在 YOLO 出现之前，目标检测主流方法是两阶段的，例如<br>	• <strong>R-CNN（2013）</strong>：通过选择性搜索（Selective Search）生成候选框，然后再用 CNN 对每个框分类，mAP可达58.5，但速度慢<br>	• <strong>Fast R-CNN（2015）</strong>：引入 ROI Pooling 提高效率，但候选框还是靠外部生成（如选择性搜索），mAP 提升到 70，但 FPS 只有 0.5<br>	• <strong>Faster R-CNN（2015）</strong>：引入 Region Proposal Network（RPN），第一次实现了端到端训练，mAP 达到 73.2，速度提升到 7 FPS</p>
<p>这些方法虽然精度高，但速度较慢，难以应对实时场景。</p>
<p>YOLO（You Only Look Once）于 2015 年提出，核心思想是将目标检测转化为一个 <strong>回归问题</strong>，在一张图上直接预测边界框和类别：<br>特点：</p>
<ol>
<li><strong>单阶段、端到端架构</strong>：无需外部提议区域，整个检测过程一次完成</li>
<li><strong>统一模型结构</strong>：整个网络是一个神经网络，直接从图像输入到边界框和类别输出</li>
<li><strong>速度快</strong>：达到了 <strong>45 FPS</strong>，远高于前代方法，首次真正实现“实时目标检测”</li>
<li><strong>简化流程</strong>：不依赖选择性搜索等复杂的预处理</li>
</ol>
<p>虽然 YOLO-v1 的精度不如 Faster R-CNN，但胜在<strong>速度极快、部署简单</strong>，特别适合实时系统（如自动驾驶、监控等）</p>
<h3 id="2-核心思想"><a href="#2-核心思想" class="headerlink" title="2.核心思想"></a>2.核心思想</h3><p>YOLOv1的核心思想是将目标检测问题转化为一个单一的回归问题，一次性预测图像中所有目标的位置和类别，又叫一张图只看一次（You Only Look Once），也是YOLO名称的由来。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102312.jpg" width="600"/></p>
<h4 id="1-图像划分"><a href="#1-图像划分" class="headerlink" title="1.图像划分"></a>1.图像划分</h4><p>如上左图将输入图像划分为 <strong>S × S 的网格</strong>（例如 S&#x3D;7）。每个网格只负责预测其内部中心点落入该网格的物体。</p>
<h4 id="2-预测多个边界框"><a href="#2-预测多个边界框" class="headerlink" title="2.预测多个边界框"></a>2.预测多个边界框</h4><p>每个网格单元预测 <strong>B 个边界框</strong>（通常 B&#x3D;2），每个框包含：<br>• 坐标信息 (x, y, w, h)<br>• 置信度（confidence）&#x3D; 物体存在概率 × IOU（预测框与真实框的重合程度）<br>上图中上部分显示了所有网格预测的大量框 + confidence。</p>
<h4 id="3-预测概率"><a href="#3-预测概率" class="headerlink" title="3.预测概率"></a>3.预测概率</h4><p>每个网格预测一个<strong>类别概率分布</strong>，即 C 个类别的概率（如图中下方的彩色 class map）。这些类别概率是与该网格是否包含物体无关的<strong>条件概率</strong>。</p>
<h4 id="4-输出组合（Final-Prediction）"><a href="#4-输出组合（Final-Prediction）" class="headerlink" title="4.输出组合（Final Prediction）"></a>4.输出组合（Final Prediction）</h4><p>对每个预测框，其最终得分 &#x3D; 类别概率 × 置信度。最后利用 <strong>非极大值抑制（NMS）</strong> 去除冗余框，得到最终检测结果（如图最右侧）。</p>
<blockquote>
<p>NMS（Non-Maximum Suppression）是目标检测中的一种后处理算法，用于<strong>从多个重叠的预测框中选择最靠谱的一个</strong>，去掉冗余和低质量的框。</p>
</blockquote>
<h3 id="3-模型结构"><a href="#3-模型结构" class="headerlink" title="3.模型结构"></a>3.模型结构</h3><p>YOLOv1 架构由一个基于 GoogLeNet 的深层卷积网络 + 全连接层组成，最终将目标检测任务转化为一个 <strong>7×7×30 的张量预测问题</strong>，实现端到端的快速检测。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102313.jpg" width="600"/></p>
<h4 id="1-输入图像"><a href="#1-输入图像" class="headerlink" title="1.输入图像"></a>1.输入图像</h4><p>输入尺寸为 <strong>448 × 448 × 3</strong> 的彩色图像</p>
<h4 id="2-特征提取网络（Backbone）"><a href="#2-特征提取网络（Backbone）" class="headerlink" title="2.特征提取网络（Backbone）"></a>2.特征提取网络（Backbone）</h4><p>• 使用了修改后的 <strong>GoogLeNet（Inception）结构</strong>，共 <strong>24 个卷积层 + 2 个全连接层</strong>，图中简化了<br>• 每个 “C, R” 代表一组卷积 + ReLU（激活）操作，特征图尺寸逐渐减小。<br>• 输出特征图尺寸为 <strong>7 × 7 × 1024</strong>。</p>
<h4 id="3-全连接层-输出层"><a href="#3-全连接层-输出层" class="headerlink" title="3.全连接层 + 输出层"></a>3.全连接层 + 输出层</h4><p>• 接上两个全连接层（如图所示）：<br>• 第一个 FC 层：4096 单元<br>• 第二个 FC 层输出 <strong>1470 个值</strong>（对应 7×7×30）</p>
<p>YOLOv1 最终输出为一个大小为 <strong>7 × 7 × 30</strong> 的张量：每个 <strong>7×7 的网格单元</strong>（grid cell）输出 <strong>30 个值</strong>，具体为：</p>
<ol>
<li>每个 grid cell 预测 <strong>2 个边界框</strong>（bounding box）</li>
<li>每个 bounding box 含有 <strong>5 个值</strong>：中心位置 (x, y)、宽高 (w, h)、置信度</li>
<li>每个 cell 还预测图像中包含各类别的概率，共 <strong>20 个类（Pascal VOC）</strong></li>
</ol>
<h4 id="4-后处理（Post-processing）"><a href="#4-后处理（Post-processing）" class="headerlink" title="4.后处理（Post-processing）"></a>4.后处理（Post-processing）</h4><p>将输出 reshape 为 7×7×30 后，使用 <strong>置信度 × 类别概率</strong> 得出每个 box 的最终得分，最后进行 <strong>Non-Maximum Suppression（非极大值抑制）</strong> 来去重并得到最终检测结果。</p>
<h3 id="4-损失函数"><a href="#4-损失函数" class="headerlink" title="4.损失函数"></a>4.损失函数</h3><p>YOLOv1 的损失函数是用在训练模型的时候，需要确保：</p>
<ul>
<li>​<strong>合理置信度</strong>​（预测的置信度反映框内是否有物体）</li>
<li>​<strong>准确定位</strong>​（预测框的 <code>x, y, w, h</code> 接近真实框）</li>
<li>​<strong>正确分类</strong>​（预测的类别概率匹配真实标签）</li>
</ul>
<p>通俗一点就是，你得准确地告诉我哪有东西（有置信度），框得要准（坐标误差小），别瞎说哪有东西（背景区域别胡说），而且你得看得出来这是只狗，不是猫（分类准确）。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102315.jpg" width="600"/><br>大致可以拆分为四部分，分别对应于：</p>
<h4 id="1-位置误差（坐标损失）"><a href="#1-位置误差（坐标损失）" class="headerlink" title="1.位置误差（坐标损失）"></a>1.位置误差（坐标损失）</h4><p>只对负责某个 object 的那个 <strong>bbox</strong>（bounding box）进行惩罚</p>
<ul>
<li>仅对<strong>有物体</strong>的 cell 中，<strong>负责预测的那个 bbox</strong> 计算位置误差</li>
<li>用了 $\sqrt{w}$ 和 $\sqrt{h}$ 来降低大尺寸物体的影响</li>
<li>$\lambda_{\text{coord}}$ 是位置损失的权重系数（论文中设为 5）</li>
</ul>
<p>位置误差主要作用就是看框得准不准，框的位置和真实位置差多少。如果模型说「猫在这里」，那就要检查它预测的位置(x, y)、宽高(w, h)和真实的差多少。注意一点，位置误差只对真正有东西的格子负责。比如，猫在左下角，我预测在右上角，那我就要被扣分。</p>
<h4 id="2-置信度误差（含有-object-的）"><a href="#2-置信度误差（含有-object-的）" class="headerlink" title="2.置信度误差（含有 object 的）"></a>2.置信度误差（含有 object 的）</h4><p>仅对包含目标的 cell 中，负责的 bbox 的置信度损失</p>
<ul>
<li>$C_i$ 是预测置信度，$\hat{C}_i$ 是 ground truth 的 IOU（即真实的）</li>
</ul>
<p>如果格子里真的有东西（比如狗），你要给出一个高的「我很确定这有东西」的分数。如果你没信心，说“我不确定”，那也要被惩罚。</p>
<h4 id="3-置信度误差（不含-object-的）"><a href="#3-置信度误差（不含-object-的）" class="headerlink" title="3.置信度误差（不含 object 的）"></a>3.置信度误差（不含 object 的）</h4><p>对没有目标的 cell 的所有 bbox 计算置信度损失</p>
<ul>
<li>$\lambda_{\text{noobj}}$ 通常设置为 0.5，防止大量背景区域主导损失</li>
</ul>
<p>对于没东西的格子，如果你说「这有只猫」，那就太离谱了，要扣分！所以对于 <strong>背景区域（没目标）</strong>，要特别注意别乱喊有目标。</p>
<h4 id="4-分类误差"><a href="#4-分类误差" class="headerlink" title="4.分类误差"></a>4.分类误差</h4><p>分类误差只对每个包含目标的 cell 进行，不涉及具体哪个 bbox。如果你预测框里有只猫，结果那是只狗，那也要扣分。所以还要学会看清楚「是猫还是狗」。</p>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h2><h3 id="1-物体检测评估指标总结"><a href="#1-物体检测评估指标总结" class="headerlink" title="1.物体检测评估指标总结"></a>1.物体检测评估指标总结</h3><ol>
<li>​<strong>TP&#x2F;FP&#x2F;FN&#x2F;TN</strong>​：<ul>
<li>​<strong>TP</strong>​：正确检测到正样本</li>
<li>​<strong>FP</strong>​：误将负样本检测为正</li>
<li>​<strong>FN</strong>​：漏检正样本</li>
<li>​<strong>TN</strong>​：物体检测中通常忽略，因背景像素过多，计算无实际意义</li>
</ul>
</li>
<li>​<strong>IoU</strong>​：<ul>
<li>预测框与真实框的交并比，IoU≥阈值（如0.5）判定为TP，否则为FP</li>
</ul>
</li>
<li>​<strong>Confidence</strong>​：<ul>
<li>模型对检测框的置信度，用于过滤低置信预测和NMS排序</li>
</ul>
</li>
<li>​<strong>Precision与Recall</strong>​：<ul>
<li>​<strong>Precision</strong>​ &#x3D; TP &#x2F; (TP + FP)，衡量预测准确性</li>
<li>​<strong>Recall</strong>​ &#x3D; TP &#x2F; (TP + FN)，衡量检出率</li>
</ul>
</li>
<li>​<strong>PR曲线与AP</strong>​：<ul>
<li>调整置信度阈值生成PR曲线，AP为曲线下面积，反映模型综合性能</li>
</ul>
</li>
<li>​<strong>VOC vs COCO</strong>​：<ul>
<li>​<strong>VOC</strong>​：固定IoU&#x3D;0.5，计算简单</li>
<li>​<strong>COCO</strong>​：多IoU阈值（0.5-0.95），评估更严格，考虑小&#x2F;中&#x2F;大物体</li>
</ul>
</li>
</ol>
<h3 id="2-YOLO-V1核心解析"><a href="#2-YOLO-V1核心解析" class="headerlink" title="2.YOLO-V1核心解析"></a>2.YOLO-V1核心解析</h3><ol>
<li>核心思想​<ul>
<li>​<strong>单阶段端到端检测</strong>​：将检测转化为回归问题，直接输出边界框和类别</li>
<li>​<strong>网格划分</strong>​：图像分为7×7网格，每个网格预测2个边界框及20类概率</li>
<li>​<strong>输出张量</strong>​：7×7×30，其中每网格含：<ul>
<li>2个边界框（各5参数：x, y, w, h, confidence）</li>
<li>20类概率（共享于网格内所有框）</li>
</ul>
</li>
</ul>
</li>
<li>模型结构​<ul>
<li>​<strong>Backbone</strong>​：基于GoogLeNet的24层卷积+2层全连接</li>
<li>​<strong>输出层</strong>​：全连接层输出1470节点，重组为7×7×30张量</li>
</ul>
</li>
<li>​损失函数​<ul>
<li>​<strong>坐标损失</strong>​：仅计算负责物体的框，使用平方误差，λ_coord&#x3D;5平衡权重$λcoord​∑(x−x^)2+(y−y^​)2+(w​−w^​)2+(h​−h^​)2$</li>
<li>​<strong>置信度损失</strong>​：<ul>
<li>​<strong>含物体</strong>​：预测置信度接近IoU（平方误差）</li>
<li>​<strong>不含物体</strong>​：置信度趋近0，λ_noobj&#x3D;0.5降低背景权重</li>
</ul>
</li>
<li>​<strong>分类损失</strong>​：交叉熵损失，确保类别预测正确</li>
</ul>
</li>
<li>局限性​<ul>
<li>每个网格仅预测固定数量框，密集小物体检测效果差</li>
<li>全连接层导致空间信息丢失，后续版本改用全卷积结构改进</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>[YOLO系列②] YOLOv2十大改进点解析</title>
    <url>/2025/04/21/012-yolo-yolov2/</url>
    <content><![CDATA[<h2 id="1-YOLOv2改进概述"><a href="#1-YOLOv2改进概述" class="headerlink" title="1.YOLOv2改进概述"></a>1.YOLOv2改进概述</h2><p>YOLOv2 的改进围绕 ​<strong>稳定性</strong>​（BN、位置预测）、<strong>灵活性</strong>​（全卷积、多尺度）、<strong>数据驱动</strong>​（锚框聚类）展开，同时通过<strong>结构优化</strong>（Darknet-19、Passthrough）平衡速度与精度，为后续YOLO版本再改进奠定基础。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504161606.jpg"><br>如上图是YOLOv2的新特性和mAP（mean Average Precision，平均精度均值）之间的相关性。</p>
<span id="more"></span>
<h2 id="2-Batch-Normalization（批量归一化）"><a href="#2-Batch-Normalization（批量归一化）" class="headerlink" title="2.Batch Normalization（批量归一化）"></a>2.Batch Normalization（批量归一化）</h2><h3 id="1-归一化"><a href="#1-归一化" class="headerlink" title="1.归一化"></a>1.归一化</h3><p><strong>归一化</strong>​ 是把一组数据“按比例缩放”到统一的范围​内（比如 0到1 或 -1到1），就像把不同单位的尺子换成同一把尺子来测量，让数据之间可以公平比较。</p>
<h3 id="2-BN的优势"><a href="#2-BN的优势" class="headerlink" title="2.BN的优势"></a>2.BN的优势</h3><p>在YOLO的深度网络中，前面层的权重改变会影响后面层的输入分布，这叫做<strong>协变量偏移（Internal Covariate Shift）</strong>。这种偏移会导致网络训练不稳定，甚至训练失败。而对每一层的输入上，进行归一化处理（均值为0，方差为1）吼，就可以在每个 mini-batch 中，把每个特征的数值拉回到一个「正常」的分布范围，这样做有很多好处：</p>
<ol>
<li><strong>加快训练速度</strong>：因为每层的输入更稳定，网络收敛更快</li>
<li><strong>允许更大学习率</strong>：降低了爆炸&#x2F;梯度消失的风险</li>
<li><strong>减少对初始化的依赖</strong>：不用精心设置初始权重也能正常训练</li>
<li><strong>具有轻微的正则化效果</strong>：可以减少对 Dropout 的依赖</li>
<li><strong>提升最终精度</strong>：尤其是对像 YOLO 这样的大型模型，效果非常明显</li>
</ol>
<h3 id="3-应用"><a href="#3-应用" class="headerlink" title="3.应用"></a>3.应用</h3><p>Batch Normalization在现代神经网络中应用还是非常广泛的。</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>网络名称</strong></th>
<th><strong>是否使用 BN</strong></th>
</tr>
</thead>
<tbody><tr>
<td>图像分类</td>
<td>ResNet &#x2F; VGG-BN &#x2F; Inception &#x2F; DenseNet</td>
<td>✅</td>
</tr>
<tr>
<td>检测</td>
<td>YOLOv2&#x2F;3&#x2F;4&#x2F;5, SSD (部分)</td>
<td>✅</td>
</tr>
<tr>
<td>混合模型</td>
<td>CNN+Transformer（如 Conformer）</td>
<td>✅（CNN 部分）</td>
</tr>
<tr>
<td>生成模型</td>
<td>DCGAN &#x2F; StyleGAN</td>
<td>✅</td>
</tr>
<tr>
<td>强化学习</td>
<td>DQN &#x2F; PPO &#x2F; A3C（图像部分）</td>
<td>✅</td>
</tr>
</tbody></table>
<h2 id="3-hi-res-classifier（高分辨率分类器）"><a href="#3-hi-res-classifier（高分辨率分类器）" class="headerlink" title="3.hi-res classifier（高分辨率分类器）"></a>3.hi-res classifier（高分辨率分类器）</h2><h3 id="1-问题点"><a href="#1-问题点" class="headerlink" title="1.问题点"></a>1.问题点</h3><p>目标检测任务通常需要处理 <strong>高分辨率图像</strong>，而YOLOV1是先在 <strong>ImageNet（224×224）上预训练的</strong>，如果直接将这种低分辨率训练出的模型用于检测，会导致它对高分图像中的细节“视力不够”，表现不佳。就像一个人习惯了在小手机屏幕上看照片，突然换成大屏电视，他一开始会看不过来，需要重新适应，才能看清更多细节。所以，在分类预训练之后，YOLO 需要<strong>在更高分辨率（如 448×448）上再次训练这个分类器</strong>，以让网络更适应高分辨率输入。</p>
<h3 id="2-实现"><a href="#2-实现" class="headerlink" title="2.实现"></a>2.实现</h3><ol>
<li>使用 ImageNet 预训练的分类器（输入为 224×224）</li>
<li>把输入分辨率调整为 448×448</li>
<li>用 ImageNet 数据再微调一次网络（10次448×448 ）</li>
<li>得到适合高分辨率输入的分类器，作为目标检测的 backbone</li>
</ol>
<h3 id="3-为什么不直接用高分辨率训练？"><a href="#3-为什么不直接用高分辨率训练？" class="headerlink" title="3.为什么不直接用高分辨率训练？"></a>3.为什么不直接用高分辨率训练？</h3><p>既然目标检测最终就是用 448×448 的输入，为什么一开始不就用这个分辨率训练 ImageNet 分类器呢？</p>
<ol>
<li>计算成本太高<br> ImageNet 有 <strong>上百万张图片</strong>，训练一个分类模型已经很耗资源了：<ul>
<li>使用 224×224 的图像时，一次前向&#x2F;反向传播的内存和计算就已经很重</li>
<li>如果一开始就用 <strong>448×448 的输入尺寸</strong>，计算量将是原来的 <strong>4 倍</strong>（因为面积是×4）</li>
<li>在 2016 年 YOLOv2 发布的时候，硬件远没有现在这么强，训练成本很高<br> 所以，先在小图上训练，再在高分辨率上微调，是<strong>更划算、也更现实</strong>的做法。</li>
</ul>
</li>
<li>迁移学习的效率更高<br> 深度学习的常见套路是：<br> <strong>先在大数据上训练一个通用模型，然后在特定任务或分辨率上做微调（fine-tune）</strong><br>  好处是：<ul>
<li>低分辨率上已经能学到很多通用的图像特征（边缘、纹理、形状等）</li>
<li>只需要在高分辨率上再调整几轮，就可以适配检测任务</li>
<li>微调速度远快于从头训练，效果也不差</li>
</ul>
</li>
<li>ImageNet 本身就是低分辨率构建的<br> ImageNet 的原始训练流程和竞赛标准就是用 <strong>224×224 的裁剪图像</strong>：<ul>
<li>这是标准的数据输入格式，所有主流模型（ResNet、VGG、Darknet 等）都默认这个尺寸</li>
<li>如果用 448×448 去训练，等于是自己“重新做一版”ImageNet，很不现实</li>
<li>一些图像原本分辨率就没那么高，强行放大反而可能带来噪声</li>
</ul>
</li>
<li>分类和检测的侧重点不同<ul>
<li>分类任务关心的是 “图里有没有猫”</li>
<li>检测任务关心的是 “猫在哪”，更依赖<strong>空间信息</strong></li>
<li>所以在高分辨率上微调，更像是<strong>给模型增强空间感知能力</strong>，而不是重头学所有特征</li>
</ul>
</li>
</ol>
<h2 id="4-convolutional（全卷积）"><a href="#4-convolutional（全卷积）" class="headerlink" title="4.convolutional（全卷积）"></a>4.convolutional（全卷积）</h2><p>用卷积层代替全连接层，让网络可以接受任意大小的输入图像</p>
<h3 id="1-全连接层"><a href="#1-全连接层" class="headerlink" title="1.全连接层"></a>1.全连接层</h3><p>全连接层（FC）的本质是啥？<br>全连接层是一个<strong>矩阵乘法</strong>：输入是一个固定长度的向量 → 输出是另一个固定长度的向量。比如输入是 4096 个数，输出是 1000 类，那这个 FC 层的权重矩阵大小就是 1000×4096。所以你必须保证前一层的输出 <strong>是 4096 个数</strong>，否则就乘不了。</p>
<p>YOLO v1 的最后几层是这样的：</p>
<ul>
<li>前面是卷积层 → 提取特征</li>
<li>最后是 <strong>全连接层（FC）</strong> → 输出预测框（比如：7x7x30 的 tensor）</li>
<li>这就把整个网络“定死”只能接收某一种大小的图像，比如 448×448</li>
</ul>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102313.jpg" width="600"/>

<h3 id="2-全卷积层"><a href="#2-全卷积层" class="headerlink" title="2.全卷积层"></a>2.全卷积层</h3><p>而卷积层是<strong>滑动窗口操作</strong>，它并不关心图像多大：</p>
<ul>
<li>不管输入是 224×224，还是 448×448，卷积核都能滑动</li>
<li>输出特征图的尺寸会自动“缩放”，不会出错</li>
<li>所以卷积结构天然支持“可变大小输入”<br>这也是为什么 YOLOv2 改成全卷积后，就可以支持多尺度图像输入了。</li>
</ul>
<p>全卷积层的好处：</p>
<ol>
<li>输入尺寸灵活，可以输入任意分辨率的图片（比如：320×320、416×416、608×608）</li>
<li>更高效，少了大量 FC 层参数，网络更轻、更快</li>
<li>可以多尺度训练，后续的 multi-scale training（多尺度训练）正是建立在全卷积的基础之上</li>
<li>更强的空间感知能力，卷积层保留了图像的空间结构，FC 层则丢失了这些信息</li>
</ol>
<h2 id="5-anchor-boxes（锚框）"><a href="#5-anchor-boxes（锚框）" class="headerlink" title="5.anchor boxes（锚框）"></a>5.anchor boxes（锚框）</h2><h3 id="1-先验框"><a href="#1-先验框" class="headerlink" title="1.先验框"></a>1.先验框</h3><p>在目标检测中，模型要预测物体的 <strong>位置和大小</strong>，如果从零开始“随便猜一个框”，训练难度非常大。<br>为此，YOLOv2 引入了 <strong>Anchor Boxes</strong> ——一组预定义的“候选框模板”，<strong>帮助模型从一个合理的参考框出发进行微调</strong>。</p>
<p>假设图片中有一只狗，它大概是一个宽 100、高 50 的长方形。模型在这个位置预设了 5 个 anchor 框，比如：</p>
<ol>
<li>(120, 40) → 和狗最接近 ✅</li>
<li>(80, 80) → 太正方形 ❌</li>
<li>(50, 100) → 竖着的 ❌<br> ⋯⋯</li>
</ol>
<p>模型会选出最接近目标的 anchor（这里是第一个），然后在它的基础上稍作调整，预测出更加精确的边界框，这样比从头猜，更快、更准、收敛更稳定。</p>
<h3 id="2-框结构"><a href="#2-框结构" class="headerlink" title="2.框结构"></a>2.框结构</h3><p>每个 cell 会对应 <strong>K 个 anchor 框</strong>（如 K&#x3D;5），每个 anchor 都会预测：</p>
<ul>
<li>边界框位置（tx, ty, tw, th）</li>
<li>目标存在的置信度（objectness）</li>
<li>各类别的概率（class probs）</li>
</ul>
<h3 id="3-K-Means-聚类方法"><a href="#3-K-Means-聚类方法" class="headerlink" title="3.K-Means 聚类方法"></a>3.K-Means 聚类方法</h3><p>为了让 Anchor 框更贴近真实物体的尺寸分布，YOLOv2 不再手动设定，而是通过聚类方法自动学习得到。步骤如下：</p>
<ol>
<li><strong>收集所有真实框的宽高</strong>（w, h）作为聚类输入</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[(<span class="number">40</span>, <span class="number">60</span>), (<span class="number">100</span>, <span class="number">120</span>), (<span class="number">30</span>, <span class="number">30</span>), (<span class="number">50</span>, <span class="number">80</span>), ...]</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>归一化</strong>，通常会除以图像尺寸，变成相对比例，比如 (0.25, 0.5)</li>
<li><strong>使用 K-Means 聚类</strong>得到 K 个代表框，作为 Anchor<ul>
<li>YOLOv2 用的是 <strong>IOU 距离</strong> 而不是欧几里得距离</li>
<li>IOU 距离定义为：distance &#x3D; 1 - IOU(真实框, anchor框)</li>
<li>IOU 越大，两个框越像，距离就越小，聚类效果更贴合目标检测的需求</li>
</ul>
</li>
</ol>
<h2 id="6-new-network（新网络结构）"><a href="#6-new-network（新网络结构）" class="headerlink" title="6.new network（新网络结构）"></a>6.new network（新网络结构）</h2><h3 id="1-Darknet-19"><a href="#1-Darknet-19" class="headerlink" title="1.Darknet-19"></a>1.Darknet-19</h3><p>Darknet-19在YOLOv2中充当主干网络（backbone），负责从输入图像中提取多层次的特征，能够捕捉物体的边缘、纹理、形状等关键信息，然后在此之上再集成检测组件，形成高效的目标检测模型。</p>
<p>YOLOv1 用的 GoogLeNet，但GoogLeNet有以下几个问题：</p>
<ol>
<li>太复杂，用的 Inception 模块，不好修改和扩展</li>
<li>准确率不高，在分类和检测上都被别的模型（如 Faster R-CNN）完爆</li>
<li>输入太小，只能处理 224×224 图，导致检测精度低（物体太小了）</li>
</ol>
<p>于是就有了Darknet-19，Darknet-19有如下特点：</p>
<ol>
<li>19 个卷积层 + 5 个 max pooling 层</li>
<li>统一用 3×3，小卷积核（类似 VGG）</li>
<li>全卷积设计，没用 Inception、ResNet 这些复杂模块</li>
<li>用了 Leaky ReLU（相比普通 ReLU 更稳定）</li>
<li>每层后面都加了 Batch Normalization，加速收敛</li>
</ol>
<h3 id="2-YOLOv2-中Darknet-19的网络结构"><a href="#2-YOLOv2-中Darknet-19的网络结构" class="headerlink" title="2.YOLOv2 中Darknet-19的网络结构"></a>2.YOLOv2 中Darknet-19的网络结构</h3><p>YOLOv2 中的 Darknet-19 是一个纯卷积网络，没有 FC 和 Softmax，结构共 19 个卷积层 + 5 个池化层，输出特征图给检测头做目标预测：</p>
<table>
<thead>
<tr>
<th><strong>层级</strong></th>
<th><strong>类型</strong></th>
<th><strong>卷积核</strong></th>
<th><strong>步长</strong></th>
<th><strong>输出通道数</strong></th>
<th><strong>输出尺寸（以输入 224×224 为例）</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>32</td>
<td>224×224</td>
</tr>
<tr>
<td>2</td>
<td>MaxPool</td>
<td>2×2</td>
<td>2</td>
<td>-</td>
<td>112×112</td>
</tr>
<tr>
<td>3</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>64</td>
<td>112×112</td>
</tr>
<tr>
<td>4</td>
<td>MaxPool</td>
<td>2×2</td>
<td>2</td>
<td>-</td>
<td>56×56</td>
</tr>
<tr>
<td>5</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>128</td>
<td>56×56</td>
</tr>
<tr>
<td>6</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>64</td>
<td>56×56</td>
</tr>
<tr>
<td>7</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>128</td>
<td>56×56</td>
</tr>
<tr>
<td>8</td>
<td>MaxPool</td>
<td>2×2</td>
<td>2</td>
<td>-</td>
<td>28×28</td>
</tr>
<tr>
<td>9</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>256</td>
<td>28×28</td>
</tr>
<tr>
<td>10</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>128</td>
<td>28×28</td>
</tr>
<tr>
<td>11</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>256</td>
<td>28×28</td>
</tr>
<tr>
<td>12</td>
<td>MaxPool</td>
<td>2×2</td>
<td>2</td>
<td>-</td>
<td>14×14</td>
</tr>
<tr>
<td>13</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>512</td>
<td>14×14</td>
</tr>
<tr>
<td>14</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>256</td>
<td>14×14</td>
</tr>
<tr>
<td>15</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>512</td>
<td>14×14</td>
</tr>
<tr>
<td>16</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>256</td>
<td>14×14</td>
</tr>
<tr>
<td>17</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>512</td>
<td>14×14</td>
</tr>
<tr>
<td>18</td>
<td>MaxPool</td>
<td>2×2</td>
<td>2</td>
<td>-</td>
<td>7×7</td>
</tr>
<tr>
<td>19</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>1024</td>
<td>7×7</td>
</tr>
<tr>
<td>20</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>512</td>
<td>7×7</td>
</tr>
<tr>
<td>21</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>1024</td>
<td>7×7</td>
</tr>
<tr>
<td>22</td>
<td>Conv</td>
<td>1×1</td>
<td>1</td>
<td>512</td>
<td>7×7</td>
</tr>
<tr>
<td>23</td>
<td>Conv</td>
<td>3×3</td>
<td>1</td>
<td>1024</td>
<td>7×7</td>
</tr>
</tbody></table>
<ul>
<li>卷积层（Conv）：是“特征提取器”，负责处理边缘、角落、图案等视觉元素</li>
<li>池化层（MaxPool）：是“特征压缩器”，帮助压缩尺寸、保留最重要信息</li>
</ul>
<h3 id="3-YOLOv2的检测头"><a href="#3-YOLOv2的检测头" class="headerlink" title="3.YOLOv2的检测头"></a>3.YOLOv2的检测头</h3><p>在 Darknet-19 后，YOLOv2 加了以下部分（检测头）：</p>
<table>
<thead>
<tr>
<th><strong>层级</strong></th>
<th><strong>类型</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>24</td>
<td>Conv</td>
<td>3×3, 1024 filters</td>
</tr>
<tr>
<td>25</td>
<td>Conv</td>
<td>3×3, 1024 filters</td>
</tr>
<tr>
<td>26</td>
<td>Conv</td>
<td>3×3, 1024 filters</td>
</tr>
<tr>
<td>27</td>
<td>跳接（passthrough）</td>
<td>从 14×14 的中间层取特征图（高分辨率），拼接</td>
</tr>
<tr>
<td>28</td>
<td>Conv</td>
<td>3×3, 输出为 B × (5 + C) 的特征图，进行目标检测</td>
</tr>
</tbody></table>
<ul>
<li>跳接（passthrough）：把早期层（空间分辨率高）提取的细粒度信息拼接到后面层中，提升小目标检测效果</li>
</ul>
<h2 id="7-dimension-priors（维度先验）"><a href="#7-dimension-priors（维度先验）" class="headerlink" title="7.dimension priors（维度先验）"></a>7.dimension priors（维度先验）</h2><p>主要是解决了 YOLOv1 中 bounding box 回归不稳定的问题，大幅提升了检测效果。</p>
<h3 id="1-步骤"><a href="#1-步骤" class="headerlink" title="1.步骤"></a>1.步骤</h3><p>dimension priors 是一组在训练前从数据集中统计出来的、常见的 bounding box 宽高比例（w, h）模板，用来作为预测的起点（即 anchor boxes）。也就是不要让网络从零开始学会‘框’出物体的大小，而是给它几个常见的框，让它基于这些‘模板’微调。”<br>具体步骤：</p>
<ol>
<li>从训练集所有真实框中提取宽高（w, h）</li>
<li>对这些框做 <strong>K-means 聚类</strong>（使用 IOU 距离而不是欧式距离）</li>
<li>找到最能代表训练数据分布的 K 个宽高组合</li>
<li>将这些组合作为 <strong>anchor boxes（dimension priors）</strong></li>
</ol>
<h3 id="2-与anchor-boxes关系"><a href="#2-与anchor-boxes关系" class="headerlink" title="2. 与anchor boxes关系"></a>2. 与anchor boxes关系</h3><p>dimension priors VS anchor boxes:</p>
<table>
<thead>
<tr>
<th><strong>术语</strong></th>
<th><strong>定义</strong></th>
<th><strong>解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>dimension priors</strong></td>
<td>基于训练数据用 K-means 聚出来的常见框的宽高</td>
<td>是 “<strong>设计 anchor 的依据</strong>”</td>
</tr>
<tr>
<td><strong>anchor boxes</strong></td>
<td>模型中在每个 grid cell 固定放置的框模板，用于预测目标</td>
<td>是 “<strong>模型里实际使用的东西</strong>”</td>
</tr>
</tbody></table>
<p>关键步骤：<br>训练数据的框 → [K-means 聚类] → 得到 dimension priors → 用作 anchor boxes 尺寸</p>
<h2 id="8-location-prediction（位置预测优化）"><a href="#8-location-prediction（位置预测优化）" class="headerlink" title="8.location prediction（位置预测优化）"></a>8.location prediction（位置预测优化）</h2><h3 id="1-问题点-1"><a href="#1-问题点-1" class="headerlink" title="1.问题点"></a>1.问题点</h3><p>在 YOLOv1 中，网络直接预测目标框的位置（中心点 x, y 和宽高 w, h），但这样有两个大问题：</p>
<ol>
<li><strong>不稳定</strong> —— 网络一开始预测的位置可能离目标很远，训练效果差</li>
<li><strong>容易越界</strong> —— 容易预测到 cell 外面，导致损失很难收敛</li>
</ol>
<h3 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2.解决方法"></a>2.解决方法</h3><p>而YOLOv2 不再直接预测位置，而是直接预测一组偏移量（tx, ty, tw, th），然后用一个规则公式把它转换成真实框的位置。大致做法是将输入图像划分为 S×S 网格；</p>
<ul>
<li>每个 grid cell 预测多个 anchor boxes；</li>
<li>对于每个 anchor box，网络输出：$t_x,\ t_y,\ t_w,\ t_h,\ \text{objectness},\ \text{class scores}$<br>然后预测偏移量（tx, ty, tw, th），再通过 sigmoid + exp + anchor box 解码出预测框的真实位置</li>
</ul>
<h2 id="9-passthrough（通道连接）"><a href="#9-passthrough（通道连接）" class="headerlink" title="9.passthrough（通道连接）"></a>9.passthrough（通道连接）</h2><h3 id="1-问题点-2"><a href="#1-问题点-2" class="headerlink" title="1.问题点"></a>1.问题点</h3><p>为何需要通道连接？</p>
<ul>
<li>网络越深，特征越抽象，感受野大，但<strong>分辨率低</strong>，对小目标不友好</li>
<li>网络越浅，特征细节多，分辨率高，但语义弱</li>
</ul>
<h3 id="2-解决思路"><a href="#2-解决思路" class="headerlink" title="2.解决思路"></a>2.解决思路</h3><p>如果把前面网络层（分辨率高，细节多）的特征图拿回来用一下，和后面的粗特征图<strong>拼接</strong>在一起，就可以显著提升小目标的感知能力。YOLOv2 把 <strong>14×14 的中间层</strong>（细节丰富）和 <strong>7×7 的深层特征图</strong>（语义强）结合在一起！</p>
<p>Passthrough Layer实现细节：</p>
<ol>
<li>找到中间层某个较高分辨率的 feature map（比如 26×26×512）</li>
<li>把它做一个 reshape（空间变换）：<ul>
<li>把邻近的 2×2 像素拉平堆到通道维度</li>
<li>变成 13×13×2048（空间减小，通道增加）</li>
<li>类似 Pixel Shuffle 的反操作</li>
</ul>
</li>
<li>把 reshape 后的特征图和深层的 13×13×1024 的主特征图 <strong>在通道维度拼接</strong></li>
<li>得到一个更厚的 feature map（比如 13×13×3072），后面用来预测框</li>
</ol>
<h2 id="10-multi-scale（多尺度训练）"><a href="#10-multi-scale（多尺度训练）" class="headerlink" title="10.multi-scale（多尺度训练）"></a>10.multi-scale（多尺度训练）</h2><p>模型在训练过程中会每隔一段时间改变输入图像尺寸</p>
<h3 id="1-实现逻辑"><a href="#1-实现逻辑" class="headerlink" title="1.实现逻辑"></a>1.实现逻辑</h3><ul>
<li>每隔 <strong>10 个 batch</strong>，就 <strong>随机更换一次输入图片大小</strong></li>
<li>尺寸从 <strong>320 到 608</strong>，每次变化为 <strong>32 的倍数</strong></li>
<li>网络结构本身是完全卷积的（没有全连接），所以可以自适应输入大小</li>
<li>输出特征图大小会跟着输入变，但预测方式一样</li>
</ul>
<h3 id="2-优点"><a href="#2-优点" class="headerlink" title="2.优点"></a>2.优点</h3><ol>
<li>增强泛化能力，网络学会了适应不同分辨率的图，对实际应用（比如摄像头视频、各种输入源）更鲁棒</li>
<li><strong>小图（320×320）</strong> → 检测速度快，适合实时；<strong>大图（608×608）</strong> → 精度高，适合离线分析；一个模型搞定，不用单独训练多个</li>
<li>兼容不同尺寸输入</li>
</ol>
<h2 id="11-hi-res-detector（高分辨率检测器）"><a href="#11-hi-res-detector（高分辨率检测器）" class="headerlink" title="11.hi-res detector（高分辨率检测器）"></a>11.hi-res detector（高分辨率检测器）</h2><p>先用低分辨率训练模型，再切换高分辨率继续训练，提升最终检测精度，训练更高效。</p>
<h3 id="1-两段式流程"><a href="#1-两段式流程" class="headerlink" title="1.两段式流程"></a>1.两段式流程</h3><p>第一步：先用低分辨率训练</p>
<ul>
<li>比如 224×224 或 288×288</li>
<li>好处是：训练速度快，参数收敛快</li>
<li>网络学到了 <strong>粗结构、目标定位、分类特征</strong><br>第二步：切换成高分辨率继续训练</li>
<li>最后阶段，把输入图放大到 448×448 或 416×416（YOLOv2 默认是 416）</li>
<li>网络继续 fine-tune，学会适应更多细节</li>
</ul>
<h3 id="2-有效果"><a href="#2-有效果" class="headerlink" title="2.有效果"></a>2.有效果</h3><p>为什么后期再切换高分辨率很有效？</p>
<ul>
<li>之前低分辨率已经训练好了“看大概轮廓”的能力</li>
<li>高分辨率训练能学到 <strong>更准确的边界框和细节特征</strong></li>
<li>不需要从零开始，就能大幅提升检测效果，尤其是对 <strong>小目标</strong></li>
</ul>
<p>它和 <strong>multi-scale training</strong> 是互补的：</p>
<ul>
<li>hi-res 是训练流程中“先小后大”的策略</li>
<li>multi-scale 是在整个训练过程中“不断随机切换尺寸”的策略</li>
</ul>
<h2 id="12-总结"><a href="#12-总结" class="headerlink" title="12.总结"></a>12.总结</h2><h3 id="1-Batch-Normalization（批量归一化）​​"><a href="#1-Batch-Normalization（批量归一化）​​" class="headerlink" title="1.Batch Normalization（批量归一化）​​"></a>1.Batch Normalization（批量归一化）​​</h3><ul>
<li>​<strong>作用</strong>​：解决深度网络中的协变量偏移问题，稳定训练过程</li>
<li>​<strong>优势</strong>​：加速收敛、允许更大学习率、减少对初始化的依赖、轻微正则化效果</li>
<li>​<strong>应用</strong>​：在卷积层后普遍添加 BN，提升 mAP 约 2%</li>
</ul>
<h3 id="2-Hi-Res-Classifier（高分辨率分类器）​​"><a href="#2-Hi-Res-Classifier（高分辨率分类器）​​" class="headerlink" title="2.Hi-Res Classifier（高分辨率分类器）​​"></a>2.Hi-Res Classifier（高分辨率分类器）​​</h3><ul>
<li>​<strong>问题</strong>​：YOLOv1 使用低分辨率（224×224）预训练，导致检测时细节丢失</li>
<li>​<strong>改进</strong>​：先在 ImageNet（224×224）预训练，再微调至高分辨率（448×448），提升特征提取能力</li>
<li>​<strong>效果</strong>​：mAP 提升约 4%</li>
</ul>
<h3 id="3-Convolutional（全卷积结构）​​"><a href="#3-Convolutional（全卷积结构）​​" class="headerlink" title="3.Convolutional（全卷积结构）​​"></a>3.Convolutional（全卷积结构）​​</h3><ul>
<li>​<strong>替换全连接层</strong>​：改用卷积层支持任意输入尺寸，增强灵活性</li>
<li>​<strong>优势</strong>​：<ul>
<li>输入尺寸可变（如 320×320、416×416、608×608）</li>
<li>减少参数量，提升速度</li>
<li>为多尺度训练奠定基础</li>
</ul>
</li>
</ul>
<h3 id="4-Anchor-Boxes（锚框机制）​"><a href="#4-Anchor-Boxes（锚框机制）​" class="headerlink" title="4. Anchor Boxes（锚框机制）​"></a>4. Anchor Boxes（锚框机制）​</h3><ul>
<li>​<strong>改进点</strong>​：引入预定义的锚框模板（通过 K-Means 聚类得到），替代 YOLOv1 的随机预测</li>
<li>​<strong>优势</strong>​：<ul>
<li>提升边界框预测稳定性</li>
<li>通过聚类得到的锚框更贴合数据分布（如 VOC 数据集的常见物体宽高比）</li>
</ul>
</li>
<li>​<strong>效果</strong>​：召回率显著提升，mAP 小幅提高</li>
</ul>
<h3 id="5-New-Network-Darknet-19"><a href="#5-New-Network-Darknet-19" class="headerlink" title="5. New Network: Darknet-19"></a>5. New Network: Darknet-19</h3><ul>
<li>​<strong>结构</strong>​：19 层卷积 + 5 层池化，全卷积设计，无全连接层</li>
<li>​<strong>特点</strong>​：<ul>
<li>使用 3×3 小卷积核（类似 VGG）</li>
<li>每层后接 BN 和 Leaky ReLU</li>
<li>轻量高效，适合实时检测</li>
</ul>
</li>
<li>​<strong>对比</strong>​：比 YOLOv1 的 GoogLeNet 更简洁，精度更高</li>
</ul>
<h3 id="6-Dimension-Priors（维度先验）​​"><a href="#6-Dimension-Priors（维度先验）​​" class="headerlink" title="6. Dimension Priors（维度先验）​​"></a>6. Dimension Priors（维度先验）​​</h3><ul>
<li>​<strong>方法</strong>​：通过 K-Means 聚类统计训练集中真实框的宽高分布，作为锚框尺寸的初始化</li>
<li>​<strong>距离度量</strong>​：使用 IOU 而非欧式距离，更贴合检测任务需求</li>
<li>​<strong>效果</strong>​：提升边界框回归的准确性</li>
</ul>
<h3 id="7-Location-Prediction（位置预测优化）​"><a href="#7-Location-Prediction（位置预测优化）​" class="headerlink" title="7. Location Prediction（位置预测优化）​"></a>7. Location Prediction（位置预测优化）​</h3><ul>
<li>​<strong>问题</strong>​：YOLOv1 直接预测坐标，易导致训练不稳定</li>
<li>​<strong>改进</strong>​：<ul>
<li>预测相对于锚框的偏移量（tx, ty, tw, th）</li>
<li>通过 Sigmoid 限制中心点不超出当前网格，避免越界</li>
</ul>
</li>
<li>​<strong>效果</strong>​：训练更稳定，定位更精准</li>
</ul>
<h3 id="8-Passthrough-Layer（通道连接）​​"><a href="#8-Passthrough-Layer（通道连接）​​" class="headerlink" title="8. Passthrough Layer（通道连接）​​"></a>8. Passthrough Layer（通道连接）​​</h3><ul>
<li>​<strong>作用</strong>​：融合浅层高分辨率特征（细节）和深层语义特征，提升小目标检测能力</li>
<li>​<strong>实现</strong>​：将中间层（如 26×26）的特征图重塑后与深层（13×13）特征拼接</li>
<li>​<strong>效果</strong>​：mAP 提升约 1%</li>
</ul>
<h3 id="9-Multi-Scale-Training（多尺度训练）​​"><a href="#9-Multi-Scale-Training（多尺度训练）​​" class="headerlink" title="9. Multi-Scale Training（多尺度训练）​​"></a>9. Multi-Scale Training（多尺度训练）​​</h3><ul>
<li>​<strong>方法</strong>​：每 10 个 batch 随机切换输入尺寸（320×320 到 608×608，步长 32）</li>
<li>​<strong>优势</strong>​：<ul>
<li>增强模型对不同尺寸输入的鲁棒性</li>
<li>单一模型适配多种分辨率需求（小图快，大图准）</li>
</ul>
</li>
</ul>
<h3 id="10-Hi-Res-Detector（高分辨率检测器）​​"><a href="#10-Hi-Res-Detector（高分辨率检测器）​​" class="headerlink" title="10. Hi-Res Detector（高分辨率检测器）​​"></a>10. Hi-Res Detector（高分辨率检测器）​​</h3><ul>
<li>​<strong>策略</strong>​：先低分辨率（224×224）预训练，再切换至高分辨率（如 416×416）微调</li>
<li>​<strong>效果</strong>​：平衡训练效率与最终精度，尤其提升小目标检测能力</li>
</ul>
<h3 id="11-整体改进效果​"><a href="#11-整体改进效果​" class="headerlink" title="11. 整体改进效果​"></a>11. 整体改进效果​</h3><ul>
<li>​<strong>精度</strong>​：mAP 从 YOLOv1 的 63.4% 提升至 78.6%（VOC 2007）</li>
<li>​<strong>速度</strong>​：保持实时性（67 FPS on Titan X）</li>
<li>​<strong>灵活性</strong>​：支持多尺度输入，适应不同应用场景</li>
</ul>
<p>YOLOv2 的改进围绕 ​<strong>稳定性</strong>​（BN、位置预测）、<strong>灵活性</strong>​（全卷积、多尺度）、<strong>数据驱动</strong>​（锚框聚类）展开，同时通过结构优化（Darknet-19、Passthrough）平衡速度与精度，奠定了后续 YOLO 系列的基础设计理念。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>[YOLO系列③] YOLOv3和YOLOv4优化策略</title>
    <url>/2025/04/29/013-yolo-yolov3-yolov4/</url>
    <content><![CDATA[<h2 id="1-YOLO-V3"><a href="#1-YOLO-V3" class="headerlink" title="1.YOLO-V3"></a>1.YOLO-V3</h2><h3 id="1-网络架构改进"><a href="#1-网络架构改进" class="headerlink" title="1.网络架构改进"></a>1.网络架构改进</h3><p>提升特征提取能力和训练稳定性​​</p>
<h4 id="1-残差连接（Residual-Connections）​"><a href="#1-残差连接（Residual-Connections）​" class="headerlink" title="1.残差连接（Residual Connections）​"></a>1.残差连接（Residual Connections）​</h4><p><strong>残差连接</strong> 是指在神经网络中将<strong>输入 x 直接跳跃连接（shortcut）加到输出 F(x) 上</strong>的那一条路径。数学形式如下：<br>$$<br>y &#x3D; F(x) + x<br>$$</p>
<ul>
<li>其中：<ul>
<li>x：输入</li>
<li>F(x)：一系列卷积层后的输出（即“主干路径”）</li>
<li>x 是“旁路路径”或称“跳跃连接”</li>
<li>两者相加形成最终输出 y<br>这条连接就是 “残差连接”，它是 <strong>结构中的一条数据路径</strong>。</li>
</ul>
</li>
</ul>
<span id="more"></span>
<p>为什么要加残差连接？</p>
<ol>
<li><strong>解决梯度消失</strong>：深层网络容易出现梯度消失，导致前层参数无法有效更新。残差连接可以让梯度直接从后向前传播，缓解这个问题</li>
<li><strong>避免退化问题</strong>：当网络加深后，理论上精度应该更好，但实际上常常出现“深层网络比浅层表现差”的现象，残差连接能避免这个问题</li>
<li><strong>更容易收敛</strong>：训练时网络更快收敛，训练更稳定</li>
<li><strong>允许更深的网络</strong>：有了残差结构，能够训练出 <strong>50层、101层甚至1000多层</strong> 的深度神经网络</li>
</ol>
<p><strong>残差结构</strong>是指包含<strong>残差连接</strong>的整个网络子模块（block）。它通常包括：</p>
<ol>
<li>一条主路径：由几层卷积、BN、ReLU 等组成，用来提取特征；</li>
<li>一条旁路径：直接跳过主路径，将输入 x 加到输出；</li>
<li>一个加法操作：将主路径和旁路径的结果合并。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入 x</span><br><span class="line"> ├─ Conv（卷积）</span><br><span class="line"> ├─ BatchNorm（归一化）</span><br><span class="line"> ├─ ReLU（激活）</span><br><span class="line"> ├─ Conv（卷积）</span><br><span class="line"> ├─ BatchNorm（归一化）</span><br><span class="line"> └─ 加上输入 x（残差连接 / Shortcut）</span><br><span class="line">输出 y = F(x) + x</span><br></pre></td></tr></table></figure>
<p>总结：残差结构其实就是“包含残差连接的子网络结构”</p>
<h4 id="2-Backbone-升级：Darknet-19-→-Darknet-53"><a href="#2-Backbone-升级：Darknet-19-→-Darknet-53" class="headerlink" title="2.Backbone 升级：Darknet-19 → Darknet-53"></a>2.Backbone 升级：Darknet-19 → Darknet-53</h4><p>YOLOv2 使用的是 <strong>Darknet-19</strong>，它结构简单、推理速度快，但在复杂场景中容易丢失细节信息，YOLOv3 需要一个更深、更强的特征提取网络来增强对小目标的检测能力，于是作者提出了<strong>Darknet-53</strong>特点：</p>
<ul>
<li>“53” 代表网络共有 53 层具有可学习参数的层（大多是卷积层）</li>
<li>引入了 <strong>残差结构（Residual Block）</strong>，类似于 ResNet，使得更深层的网络更容易训练</li>
<li>全部使用了 <strong>3x3 和 1x1 卷积核</strong>，保持运算高效</li>
<li>没有使用全连接层，利于保持空间信息</li>
</ul>
<p>Darknet-53 的网络层次可以分为多个阶段，每个阶段都包含若干个残差块，具体结构如下：</p>
<table>
<thead>
<tr>
<th><strong>Stage</strong></th>
<th><strong>Output Size</strong></th>
<th><strong>Layers（简写）</strong></th>
<th><strong>残差块数量</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>256×256</td>
<td>Conv1: 3×3, 32</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>128×128</td>
<td>Conv2: 3×3, 64 &#x2F; stride&#x3D;2</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>64×64</td>
<td>Conv3: 3×3, 128 &#x2F; stride&#x3D;2</td>
<td>2</td>
</tr>
<tr>
<td>4</td>
<td>32×32</td>
<td>Conv4: 3×3, 256 &#x2F; stride&#x3D;2</td>
<td>8</td>
</tr>
<tr>
<td>5</td>
<td>16×16</td>
<td>Conv5: 3×3, 512 &#x2F; stride&#x3D;2</td>
<td>8</td>
</tr>
<tr>
<td>6</td>
<td>8×8</td>
<td>Conv6: 3×3, 1024 &#x2F; stride&#x3D;2</td>
<td>4</td>
</tr>
</tbody></table>
<blockquote>
<p>注：每个“残差块”都包含 1 个 1×1 卷积 + 1 个 3×3 卷积，并带有残差连接。</p>
</blockquote>
<h3 id="2-检测机制优化"><a href="#2-检测机制优化" class="headerlink" title="2.检测机制优化"></a>2.检测机制优化</h3><p>提升多尺度目标检测和定位精度​</p>
<h4 id="1-多尺度预测（Feature-Pyramid）"><a href="#1-多尺度预测（Feature-Pyramid）" class="headerlink" title="1.多尺度预测（Feature Pyramid）"></a>1.多尺度预测（Feature Pyramid）</h4><p>在目标检测中，一个主要挑战是：<strong>目标大小不一</strong>，有的目标很小（比如鸟、行人），有的很大（比如卡车、建筑），为了同时检测这些不同尺寸的物体，YOLOv3 引入了多尺度预测机制，灵感来源于 <strong>FPN（Feature Pyramid Network）</strong>。<br><strong>核心思想：</strong></p>
<blockquote>
<p>在不同分辨率的特征图上分别进行检测，每个尺度都负责检测特定大小的目标。</p>
</blockquote>
<p>YOLOv3 使用 <strong>Darknet-53</strong> 主干网络来提取特征，并构建多尺度输出。流程如下：</p>
<ol>
<li>从主干网络中间层获取三个特征图（多尺度预测）<ul>
<li><strong>ResBlock8 输出 → 52×52</strong></li>
<li><strong>ResBlock15 输出 → 26×26</strong></li>
<li><strong>最终输出 → 13×13</strong></li>
</ul>
</li>
<li>上采样 + 拼接（​细粒度特征融合）<ul>
<li>高层特征通过 <strong>上采样（Nearest Neighbour）</strong> 放大</li>
<li>与来自浅层的特征图进行 <strong>拼接（concat）</strong></li>
<li>然后再通过卷积层提取融合后的特征</li>
</ul>
</li>
</ol>
<p>多尺度预测带来的好处：</p>
<ol>
<li><strong>增强小目标检测能力</strong>，如行人、人脸、交通标志</li>
<li><strong>适应多种目标大小</strong>，从小狗到大卡车都能检测</li>
<li><strong>信息融合更充分</strong>，深层语义 + 浅层细节互补</li>
<li><strong>检测性能全面提升</strong>，尤其在 COCO 数据集上表现优异</li>
</ol>
<h4 id="2-​细粒度特征融合（Fine-Grained-Features）​"><a href="#2-​细粒度特征融合（Fine-Grained-Features）​" class="headerlink" title="2.​细粒度特征融合（Fine-Grained Features）​"></a>2.​细粒度特征融合（Fine-Grained Features）​</h4><p>为什么要融合细粒度特征？<br>神经网络在不断向下采样、加深层数的过程中：</p>
<ul>
<li><strong>低层特征（浅层）</strong>：保留了<strong>空间位置和纹理细节信息</strong>，但语义抽象能力弱</li>
<li><strong>高层特征（深层）</strong>：具有很强的<strong>语义理解能力</strong>，但空间分辨率低、细节丢失<br>这种深层特征虽然对“看懂物体”很强，但：</li>
<li>对<strong>小目标的位置、边界感知能力弱</strong>；</li>
<li>容易出现目标边界模糊、定位不准等问题。<br>所以，<strong>细粒度特征融合</strong>的目标就是：<strong>结合低层的“清晰细节”与高层的“语义理解”</strong>，做到“看清楚 + 看懂了”。</li>
</ul>
<p>YOLOv3 借助类似 <strong>FPN（Feature Pyramid Network）</strong> 的思想，把不同层级的特征融合起来，具体策略如下：</p>
<ol>
<li>将高层的语义特征图（分辨率低）进行<strong>上采样</strong>（Nearest Neighbor）</li>
<li>与来自浅层网络的高分辨率特征图进行 <strong>拼接（concatenation）</strong></li>
<li>拼接后经过卷积进一步提取融合后的信息，得到更<strong>丰富的检测特征图</strong></li>
</ol>
<h4 id="3-Bounding-Box-预测方式改进"><a href="#3-Bounding-Box-预测方式改进" class="headerlink" title="3.Bounding Box 预测方式改进"></a>3.Bounding Box 预测方式改进</h4><p>YOLOv3 在 <strong>Bounding Box（边界框）预测方式</strong> 上也做了关键改进，这是 YOLOv3 能提升定位准确度、训练更稳定的重要原因之一。<br>早期 YOLO 系列的 bbox 预测有一些问题：</p>
<table>
<thead>
<tr>
<th><strong>问题</strong></th>
<th><strong>解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td>不够稳定</td>
<td>使用直接预测中心点 (x, y) 和宽高 (w, h)，对回归不敏感，尤其宽高变化大时梯度不稳定</td>
</tr>
<tr>
<td>容易偏移</td>
<td>预测中心点是绝对位置，对小目标偏移影响更大</td>
</tr>
<tr>
<td>有负数预测值</td>
<td>预测结果可为负数，导致框“跑出图像”或不合理</td>
</tr>
</tbody></table>
<p>YOLOv3 改进的核心是：<strong>用更稳定的相对形式来预测 bbox 参数，并通过激活函数限制其范围</strong>。具体改进包括：</p>
<ol>
<li><strong>使用 sigmoid 激活预测中心坐标偏移</strong>，始终在当前 grid cell 内，不会跑偏或跳出格子，更好学习“相对位移”，训练稳定、收敛更快</li>
<li><strong>宽高采用 anchor box 的缩放系数</strong>，YOLOv3 不直接预测宽高，而是基于 anchor box 尺寸进行缩放，这样做的好处是，保证宽高始终为正值，使用指数函数使得模型可以灵活地预测比 anchor 更大&#x2F;更小的物体</li>
</ol>
<p>与 YOLOv2 的预测方式对比：</p>
<table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>YOLOv2</strong></th>
<th><strong>YOLOv3</strong></th>
</tr>
</thead>
<tbody><tr>
<td>中心坐标预测方式</td>
<td>未归一化（线性偏移）</td>
<td>Sigmoid 激活后加上网格坐标</td>
</tr>
<tr>
<td>宽高预测方式</td>
<td>线性缩放</td>
<td>指数缩放（保证宽高为正）</td>
</tr>
<tr>
<td>激活函数</td>
<td>无限制</td>
<td>Sigmoid + exp 让预测值更合理、更稳定</td>
</tr>
<tr>
<td>框的位置稳定性</td>
<td>容易偏移</td>
<td>更准确、学习目标位置更加稳定</td>
</tr>
<tr>
<td>多标签支持</td>
<td>softmax 分类（互斥）</td>
<td>sigmoid 多标签（支持多标签分类场景）</td>
</tr>
</tbody></table>
<h4 id="4-先验框优化（Anchor-Box-Clustering）"><a href="#4-先验框优化（Anchor-Box-Clustering）" class="headerlink" title="4.先验框优化（Anchor Box Clustering）"></a>4.先验框优化（Anchor Box Clustering）</h4><p>先验框优化是 YOLOv3 在预测精度上提升的重要步骤，它直接影响模型预测框的 <strong>拟合能力和收敛速度</strong></p>
<p>为什么需要先验框（Anchor Box）优化？<br>在物体检测中，<strong>Anchor Box（先验框）</strong> 是预设的一组矩形框，用于引导模型预测目标的位置和尺寸。<br>YOLOv2 起首次引入 Anchor Box，每个格子默认设定多个尺度和比例的先验框，模型只需预测与 Anchor Box 的“偏移量”，这样可以提高定位精度，尤其是对于尺寸多变的目标。<br>但这样存在问题：</p>
<ul>
<li>不能很好地拟合训练集中真实目标的尺寸分布</li>
<li>对小目标或特殊形状的物体不友好</li>
<li>容易出现预测框与实际目标形状差距太大</li>
</ul>
<p>YOLOv3 使用 <strong>K-Means 聚类算法</strong> 在训练集上<strong>自动学习出合适的 Anchor Box 尺寸</strong>，替代人为设置，聚类过程如下：</p>
<ol>
<li><strong>收集训练集中的所有真实 bbox</strong>（宽、高）</li>
<li><strong>选择一个距离度量方式</strong><ul>
<li>通常用 <strong>IOU 距离（1 - IOU）</strong>，不是欧氏距离</li>
<li>这样更符合 bbox 匹配的实际逻辑</li>
</ul>
</li>
<li><strong>用 K-Means 对这些真实框做聚类</strong><ul>
<li>聚出 K 个“代表性 bbox 尺寸”作为 anchor</li>
</ul>
</li>
<li>得到一组尺寸不一但适配度高的 Anchor Boxes</li>
</ol>
<p>Anchor Box 优化的好处：</p>
<table>
<thead>
<tr>
<th><strong>优势</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>更匹配真实目标尺寸分布</td>
<td>聚类得出的 anchor 更符合数据分布</td>
</tr>
<tr>
<td>提升预测框与真实框匹配度</td>
<td>IOU 更高，正样本分配更准确</td>
</tr>
<tr>
<td>收敛速度更快</td>
<td>不会训练初期大量预测框 mismatch</td>
</tr>
<tr>
<td>提高小目标检测能力</td>
<td>某些 anchor 专门服务于小目标</td>
</tr>
<tr>
<td>泛化性更强</td>
<td>在新数据集上重新聚类即可快速适配</td>
</tr>
</tbody></table>
<h4 id="5-分类方式变化：Softmax-→-Sigmoid"><a href="#5-分类方式变化：Softmax-→-Sigmoid" class="headerlink" title="5.分类方式变化：Softmax → Sigmoid"></a>5.分类方式变化：Softmax → Sigmoid</h4><p>YOLOv3 抛弃 Softmax，采用 <strong>逐类别 Sigmoid 激活</strong>，实现了更灵活的 <strong>多标签分类能力</strong>，使模型可以适应更多复杂、多义、多标签的目标检测任务，是一个设计上的质变提升。</p>
<p>为什么 Softmax 不适合目标检测？<br>在真实检测任务中，存在以下情况：</p>
<table>
<thead>
<tr>
<th><strong>情况</strong></th>
<th><strong>举例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>多标签物体</td>
<td>一只“人骑在马”上，可能属于“人类”和“骑手”</td>
</tr>
<tr>
<td>模糊&#x2F;不确定类别</td>
<td>模糊图像同时可能是“猫”和“狸花猫”</td>
</tr>
<tr>
<td>需要支持多类可能性</td>
<td>一些检测任务，如医学影像、遥感图像，多类交叉</td>
</tr>
</tbody></table>
<p>因此 Softmax 会强行“排他”，不能表达“一个框可能属于多个类”的情况</p>
<p>YOLOv3 抛弃 Softmax，改用 <strong>逐类别的 Sigmoid 激活函数</strong>：<br>特点：</p>
<ul>
<li>每个类别都有一个独立的概率</li>
<li>类别之间互不干扰，不要求总和为 1</li>
<li>可以实现<strong>多标签分类</strong>（multi-label classification）</li>
</ul>
<h3 id="3-其它"><a href="#3-其它" class="headerlink" title="3.其它"></a>3.其它</h3><h4 id="1-训练策略增强​"><a href="#1-训练策略增强​" class="headerlink" title="1.训练策略增强​"></a>1.训练策略增强​</h4><ul>
<li>多尺度训练（Multi-Scale Training）：在训练时动态调整输入图像尺寸（如 320×320 → 608×608），提升模型尺度鲁棒性</li>
<li>数据增强：引入随机裁剪、色彩抖动等，提升泛化性</li>
</ul>
<h4 id="2-损失函数改进​"><a href="#2-损失函数改进​" class="headerlink" title="2.损失函数改进​"></a>2.损失函数改进​</h4><ul>
<li>用二元交叉熵（BCE）替代 MSE 计算分类损失，更适应多标签任务</li>
<li>对定位损失（IoU）和分类损失分开加权，平衡不同任务优化</li>
</ul>
<h4 id="3-细粒度特征融合（Fine-Grained-Features）​​"><a href="#3-细粒度特征融合（Fine-Grained-Features）​​" class="headerlink" title="3.细粒度特征融合（Fine-Grained Features）​​"></a>3.细粒度特征融合（Fine-Grained Features）​​</h4><ul>
<li>在 26×26 和 52×52 特征图中，通过跳跃连接（Concatenation）融合浅层细节信息（如边缘、纹理），提升小目标检测</li>
</ul>
<h4 id="4-动态阈值与非极大抑制（NMS）优化​"><a href="#4-动态阈值与非极大抑制（NMS）优化​" class="headerlink" title="4.动态阈值与非极大抑制（NMS）优化​"></a>4.动态阈值与非极大抑制（NMS）优化​</h4><ul>
<li>设置动态置信度阈值过滤低质量预测框</li>
<li>改进 NMS 算法，缓解密集场景下的重叠框误删问题</li>
</ul>
<h2 id="2-YOLO-V4"><a href="#2-YOLO-V4" class="headerlink" title="2.YOLO-V4"></a>2.YOLO-V4</h2><h3 id="1-Bag-of-freebies-BOF-训练优化"><a href="#1-Bag-of-freebies-BOF-训练优化" class="headerlink" title="1.Bag of freebies(BOF)训练优化"></a>1.Bag of freebies(BOF)训练优化</h3><h4 id="1-Mosaic数据增强（Mosaic-data-augmentation）"><a href="#1-Mosaic数据增强（Mosaic-data-augmentation）" class="headerlink" title="1.Mosaic数据增强（Mosaic data augmentation）"></a>1.Mosaic数据增强（Mosaic data augmentation）</h4><p><strong>Mosaic 数据增强</strong> 是由 YOLOv4 首次提出的一种图像增强方法是将4张不同的图像拼接成1张图像，并将目标框同时映射过来。相比传统的数据增强（如翻转、旋转、裁剪等），Mosaic 可以在一次训练样本中同时看到更多目标，<strong>显著增加了图像中目标的多样性、数量和尺度变化</strong>。</p>
<p>Mosaic实现过程：</p>
<ol>
<li>从数据集中随机选择 4 张图像</li>
<li>对每张图像分别进行缩放、裁剪等基本预处理</li>
<li>将这 4 张图像以 2×2 网格方式拼接成 1 张图像（可以是中心交汇，也可以是非对称拼接）</li>
<li>将原图中的标注框（bounding boxes）根据缩放和平移关系映射到拼接后的图像中<br>这样每张训练图像可以包含多个原始图像中的目标</li>
</ol>
<p>Mosaic 的优势：</p>
<ol>
<li>提高小目标检测能力，Mosaic 能让原本分布在不同图像中的小目标集中在一张图中，使模型能更好地学习小目标的特征</li>
<li>增强模型鲁棒性，通过随机组合不同图像内容，模型学到更丰富的背景、目标组合，从而提升泛化能力</li>
<li>类似于“批内增强”，它相当于将 4 张图片的信息融合进了 1 次前向传播中，某种程度上起到了提升 batch 多样性的作用。</li>
<li>无需大batch size，结合了 4 张图像的信息，有效缓解小 batch size 下样本多样性不足的问题</li>
</ol>
<h4 id="2-自对抗训练（Self-Adversarial-Training-SAT）"><a href="#2-自对抗训练（Self-Adversarial-Training-SAT）" class="headerlink" title="2.自对抗训练（Self-Adversarial Training, SAT）"></a>2.自对抗训练（Self-Adversarial Training, SAT）</h4><p>YOLOv4 中的 <strong>自对抗训练（Self-Adversarial Training, SAT）</strong> 是一个非常有趣、而且颇具创意的训练技巧。它首次将“对抗攻击”的概念用于数据增强，从而提升模型的鲁棒性和性能。</p>
<p>什么是自对抗训练？SAT 是一种分两步进行的训练方式，先“欺骗”模型，再“教训”模型。<br>它的核心思路是：</p>
<ol>
<li>利用模型本身生成“对抗性扰动”来修改输入图像，使其对模型变得更难识别</li>
<li>然后再用这些被“扰乱”的图像去训练模型，让模型学会“识破”这些对抗干扰<br>这就像模型自己“打一巴掌，再喂药”，最终变得更强。</li>
</ol>
<p>实现过程：<br>SAT 通常发生在每一个 mini-batch 的训练过程中，主要包括两个阶段：<br><strong>对抗扰动阶段</strong>：主要是找出模型当前最不容易处理的样本区域</p>
<ul>
<li>模型接收到一张原始图像</li>
<li>对其进行一次前向传播，计算损失</li>
<li>然后根据这个损失对输入图像计算梯度（类似 FGSM 方法）</li>
<li>利用这个梯度对图像进行微调（添加对抗扰动）</li>
<li>得到一张被“攻击过”的图像<br><strong>常规训练阶段</strong></li>
<li>用第一步生成的“被攻击图像”进行正常的训练</li>
<li>目标是让模型正确识别这些更具挑战性的样本，从而提升鲁棒性</li>
</ul>
<p>这样做有什么好处？</p>
<ol>
<li>提升模型鲁棒性：SAT 实际上是让模型暴露在“对抗样本”中，因此它在面对噪声、遮挡、低质量图像时，表现更稳健</li>
<li>模拟更复杂的样本分布：相比于普通数据增强，SAT 所生成的对抗图像具有“更真实的混乱”，更接近模型容易犯错的场景</li>
<li>不需要额外的数据或模型：自对抗训练完全基于当前模型自身，不需要额外的对抗网络（不像 GAN），训练成本可控</li>
</ol>
<h4 id="3-DropBlock"><a href="#3-DropBlock" class="headerlink" title="3.DropBlock"></a>3.DropBlock</h4><p>YOLOv4 中引入的 <strong>DropBlock</strong> 是一种比 Dropout 更高级的正则化方法，它专门针对 <strong>卷积神经网络（CNN）</strong> 中的特征图设计，能有效防止模型过拟合，效果非常实用且高效。<br>DropBlock 是一种针对 CNN 特征图的正则化方法，它会随机“抹掉”一个区域（Block）而不是单个点（像 Dropout 那样）。想象一下，把特征图中的一小块方形区域设为零，就像是图像上贴了一块“遮挡物”。这样训练时，模型就必须学会依赖更多元的上下文信息，而不是过度依赖某一个区域。</p>
<p>为什么要用 DropBlock（而不是 Dropout）？<br>在卷积网络中，普通的 Dropout 并不太有效，原因是：</p>
<ul>
<li>Dropout 是随机将单个像素设为 0</li>
<li>但在 CNN 的特征图中，相邻像素高度相关</li>
<li>所以即使“断”了一个点，其周围还会有类似信息，模型没太受影响<br>而 <strong>DropBlock 会将一整块区域同时设为 0</strong>，这更像是“局部信息丢失”，迫使模型从别的地方寻找信息，更有效防止过拟合。</li>
</ul>
<p>DropBlock 的工作机制<br>核心参数有两个：</p>
<ul>
<li><strong>block_size</strong>：要遮挡的方块区域的边长，比如 3 就是一个 3×3 的方块</li>
<li><strong>keep_prob &#x2F; drop_prob</strong>：保留或丢弃的概率，控制正则化强度<br>实现步骤如下：</li>
</ul>
<ol>
<li>随机选择特征图上的若干中心点</li>
<li>以这些点为中心，生成固定大小的 block 区域</li>
<li>将这些 block 区域内的值全部设为 0</li>
<li>保持整个特征图的均值不变（可选的 scale 操作）</li>
</ol>
<h4 id="4-标签平滑（Label-Smoothing）"><a href="#4-标签平滑（Label-Smoothing）" class="headerlink" title="4.标签平滑（Label Smoothing）"></a>4.标签平滑（Label Smoothing）</h4><p>标签平滑是一种防止模型过拟合的方法，核心思想是：不要把标签当作“100% 确定”的真理，而是给它留一点“模糊空间”。<br>传统分类任务中，标签是独热（one-hot）形式，比如对于 3 类任务中的第 2 类，标签为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[0, 1, 0]</span><br></pre></td></tr></table></figure>
<p>而标签平滑之后，就变成了类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[0.1, 0.8, 0.1]（当 smoothing=0.2 时）</span><br></pre></td></tr></table></figure>
<p>这样模型在训练时就不会把第二类“当作绝对真理”，而是会保持一些“不确定性”，从而减少过拟合。</p>
<p>为什么要用标签平滑？<br>在目标检测中，特别是像 YOLO 这样的大规模多类检测中，模型很容易：</p>
<ul>
<li>对于某一类过拟合（预测置信度接近1）</li>
<li>对其他类别完全“视而不见”<br>这会造成模型泛化性差，一旦测试图像稍有偏差，模型就“懵了”。<br>而标签平滑可以缓解这个问题，让模型在训练过程中更温和地“相信”标签，从而提升稳定性与鲁棒性。</li>
</ul>
<p>YOLOv4 使用标签平滑主要是用于：</p>
<ul>
<li><strong>类别置信度的预测部分</strong>（即 objectness + class probability）</li>
<li>搭配 <strong>CIoU Loss</strong>、Mosaic、SAT 等其他策略，形成一套完整的正则组合拳</li>
<li>特别有效于多类、小样本类别，能减少对“极端标签”的依赖</li>
</ul>
<p>注意事项</p>
<ul>
<li>smoothing 不宜过大，一般 $0.05 \sim 0.1$</li>
<li>在 label 极其干净且类别之间差异极大时，可能带来微弱负面影响（置信度下降）</li>
<li>对于检测模型来说，标签平滑只作用在分类标签上，不影响位置（bbox）回归</li>
</ul>
<h4 id="5-​IoU-GIoU-DIoU-CIoU-损失"><a href="#5-​IoU-GIoU-DIoU-CIoU-损失" class="headerlink" title="5.​IoU&#x2F;GIoU&#x2F;DIoU&#x2F;CIoU 损失"></a>5.​IoU&#x2F;GIoU&#x2F;DIoU&#x2F;CIoU 损失</h4><p>在 YOLO 系列（特别是 YOLOv3 之后）中，<strong>边界框回归（bounding box regression）</strong> 的损失函数经历了从 IoU 到 GIoU、DIoU、CIoU 的逐步演化。这些损失函数的目标是让预测框更准确地贴合真实框。</p>
<h5 id="IoU（Intersection-over-Union）"><a href="#IoU（Intersection-over-Union）" class="headerlink" title="IoU（Intersection over Union）"></a>IoU（Intersection over Union）</h5><p>$$<br>IoU &#x3D; \frac{Area\ of\ Overlap}{Area\ of\ Union}<br>$$</p>
<p>表示预测框和真实框重合部分与并集的比例，范围在 $[0, 1]$<br>问题点：</p>
<ul>
<li>如果两个框 <strong>没有重叠（IoU&#x3D;0）</strong>，就无法提供任何梯度信息，模型无法学习</li>
<li>只能衡量“重叠程度”，不能衡量位置差异或形状差异</li>
</ul>
<h5 id="GIoU（Generalized-IoU）"><a href="#GIoU（Generalized-IoU）" class="headerlink" title="GIoU（Generalized IoU）"></a>GIoU（Generalized IoU）</h5><p>$$<br>GIoU &#x3D; IoU - \frac{|C \setminus (A \cup B)|}{|C|}<br>$$</p>
<ul>
<li>$C$ 是预测框和真实框的最小闭包框（包含两者的最小矩形）</li>
<li>当 IoU &#x3D; 0 时，GIoU 仍然能产生梯度<br>优点：</li>
<li>即使两个框没有重叠，也能提供优化方向</li>
<li>更鲁棒地处理初始预测不准的情况</li>
</ul>
<h5 id="DIoU（Distance-IoU）"><a href="#DIoU（Distance-IoU）" class="headerlink" title="DIoU（Distance IoU）"></a>DIoU（Distance IoU）</h5><p>$$<br>DIoU &#x3D; IoU - \frac{\rho^2(\mathbf{b}, \mathbf{b}^{gt})}{c^2}<br>$$</p>
<ul>
<li>$\rho$：两个框中心点之间的欧几里得距离</li>
<li>$c$：包含两个框的最小闭包框的对角线长度<br>优点：</li>
<li>加入了 <strong>“中心点距离”惩罚项</strong>，促使预测框中心靠近真实框</li>
<li>收敛更快，回归效果更好</li>
<li>更适合快速定位目标</li>
</ul>
<h5 id="CIoU（Complete-IoU）"><a href="#CIoU（Complete-IoU）" class="headerlink" title="CIoU（Complete IoU）"></a>CIoU（Complete IoU）</h5><p>$$<br>CIoU &#x3D; IoU - \left( \frac{\rho^2(\mathbf{b}, \mathbf{b}^{gt})}{c^2} + \alpha v \right)<br>$$</p>
<p>其中：</p>
<ul>
<li>$\rho^2$ 是中心点距离；</li>
<li>$v$ 是宽高比一致性度量项；</li>
<li>$\alpha$ 是动态权重，依赖于 IoU 和 $v$；<br>其中：<br>$$v &#x3D; \frac{4}{\pi^2} \left( \arctan\frac{w^{gt}}{h^{gt}} - \arctan\frac{w}{h} \right)^2$$</li>
</ul>
<p>$$ \alpha &#x3D; \frac{v}{(1 - IoU) + v} $$</p>
<p>优点是同时考虑了，框的重叠程度（IoU）、中心点距离（定位）、 宽高比差异（形状匹配）。是目前目标检测中最全面、收敛最快、表现最优的一种 bbox 回归损失。</p>
<h3 id="2-Bag-of-specials-BOS-模型结构改进"><a href="#2-Bag-of-specials-BOS-模型结构改进" class="headerlink" title="2.Bag of specials(BOS)模型结构改进"></a>2.Bag of specials(BOS)模型结构改进</h3><h4 id="1-CSPDarknet53-Cross-Stage-Partial-Network"><a href="#1-CSPDarknet53-Cross-Stage-Partial-Network" class="headerlink" title="1.CSPDarknet53(Cross Stage Partial Network)"></a>1.CSPDarknet53(Cross Stage Partial Network)</h4><p><strong>CSPDarknet53</strong> 是 YOLOv4 的主干网络（Backbone），它是对 YOLOv3 中使用的 <strong>Darknet-53</strong> 的增强版本，引入了 <strong>CSPNet（Cross Stage Partial Network）</strong> 架构思想，大幅提升了网络的性能和效率。<br><strong>Darknet-53</strong> 是 YOLOv3 使用的主干网络，包含 53 层卷积结构，使用残差连接（Residual），特点是结构简单，速度快，适合实时检测。<br>但是Darknet-53 在高层容易<strong>冗余梯度</strong>，特征融合效率一般，在保持轻量的同时很难进一步提升精度。<br>CSPDarknet是将特征图通道分成两部分：一部分<strong>直接跳过残差块</strong>，另一部分<strong>通过残差块学习</strong>，最终在 stage 的末尾进行融合。也就是说，在传统残差块的基础上，把输入一分为二：<strong>一半走残差学习</strong>路径，<strong>一半直接传输</strong>；最后再 concat（拼接）。</p>
<p>YOLOv4 中 CSPDarknet53 使用了新的激活函数：<strong>Mish</strong>，Mish 的特点：平滑且非单调，梯度流通更顺畅，表现优于 ReLU、LeakyReLU（但推理速度略慢）。</p>
<p>CSPDarknet53 &#x3D; Darknet53 + CSPNet + Mish 激活函数，拥有更高的效率、更强的表示力，是 YOLOv4 实时检测的核心骨干网络。**</p>
<h4 id="2-SPPNet-Spatial-Pyramid-Pooling"><a href="#2-SPPNet-Spatial-Pyramid-Pooling" class="headerlink" title="2.SPPNet(Spatial Pyramid Pooling)"></a>2.SPPNet(Spatial Pyramid Pooling)</h4><p><strong>SPPNet</strong> 是一个非常经典的结构，被广泛应用于图像分类、目标检测等任务中。YOLOv4 也集成了它的思想，用来增强特征提取能力。<br>它的核心思想是：<strong>在一张特征图上，进行多尺度的最大池化，然后把这些池化结果拼接起来</strong>，从而提取多尺度上下文信息。</p>
<p>为什么要用 SPP？<br>YOLOv4 中的目标检测有两个难点：</p>
<ol>
<li><strong>目标尺寸不一致</strong> —— 同一张图里，大目标、小目标混杂</li>
<li><strong>感受野不够大</strong> —— 上层卷积只能看到局部<br>而 <strong>SPP</strong> 的优势是：</li>
</ol>
<ul>
<li>不改变输入图像尺寸</li>
<li>能提取 <strong>不同感受野下的特征</strong>（即多尺度上下文信息）</li>
<li>提升模型对大、小目标的适应能力</li>
</ul>
<p>SPP 的结构怎么做？<br>假设某一层输出了一个大小为 n × n 的特征图。<br>我们在这个特征图上做：</p>
<ul>
<li>1×1 最大池化（全局）</li>
<li>5×5 最大池化</li>
<li>9×9 最大池化</li>
<li>13×13 最大池化<br>然后对这些池化结果进行拼接（concat）。<br>通俗理解：就像把一个图像用不同大小的窗口去“扫”，每个窗口提取一个“全局摘要”特征，最后把这些不同尺度的摘要拼在一起，形成更全面的理解。</li>
</ul>
<h4 id="3-PANet-Path-Aggregation-Network"><a href="#3-PANet-Path-Aggregation-Network" class="headerlink" title="3.PANet(Path Aggregation Network)"></a>3.PANet(Path Aggregation Network)</h4><p>PANet &#x3D; FPN + Bottom-Up Path + Adaptive Feature Pooling</p>
<blockquote>
<p>由 <strong>Facebook AI</strong> 在 2018 年提出，最初是为了改进实例分割和目标检测中的多尺度融合结构。</p>
</blockquote>
<p>在 YOLOv4 中，PANet 被用作 <strong>Neck</strong>，连接主干网络（如 CSPDarknet53）和检测头（Head），增强信息流的双向传播。</p>
<p>PANet 的核心结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CSPDarknet53（Backbone）</span><br><span class="line">   ↓</span><br><span class="line">SPP 模块（增强感受野）</span><br><span class="line">   ↓</span><br><span class="line">FPN（top-down 路径）</span><br><span class="line">   ↓</span><br><span class="line">PANet（bottom-up 路径）</span><br><span class="line">   ↓</span><br><span class="line">YOLO Head（输出框和类别）</span><br></pre></td></tr></table></figure>
<p>这种顺序结构被称为 <strong>“SPP + FPN + PANet”</strong>，强化了语义 &amp; 位置特征融合，尤其对小目标检测非常有效。</p>
<p>PANet 的优势:</p>
<table>
<thead>
<tr>
<th><strong>优点</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>双向融合</td>
<td>结合 top-down 和 bottom-up 信息</td>
</tr>
<tr>
<td>强化定位</td>
<td>底层信息可回传，增强空间细节</td>
</tr>
<tr>
<td>小目标检测提升</td>
<td>多尺度增强对小物体识别更敏感</td>
</tr>
<tr>
<td>与 FPN 兼容</td>
<td>在 FPN 基础上增强，无需重构体系</td>
</tr>
</tbody></table>
<p>PANet &#x3D; FPN 的双向升级版，它让特征融合从“单向信息流”变成“双向协作”，是 YOLOv4 实现强小目标检测能力的重要模块。</p>
<h4 id="4-CBAM"><a href="#4-CBAM" class="headerlink" title="4.CBAM"></a>4.CBAM</h4><p>CBAM（<strong>Convolutional Block Attention Module</strong>）是一个轻量级的注意力机制模块，可以无缝嵌入到现有的 CNN 网络中，用于增强模型对<strong>有用特征的关注能力</strong>，提升特征表达效果。CBAM 在图像分类、目标检测、分割等任务中都非常实用。<br>它是一个模块化的注意力结构，由两个子模块组成：</p>
<ol>
<li><strong>Channel Attention Module（通道注意力）</strong></li>
<li><strong>Spatial Attention Module（空间注意力）</strong><br>这两个模块串联使用，用来从不同角度提升特征图的质量</li>
</ol>
<p>通道注意力模块（Channel Attention），关注哪些通道更重要，如边缘通道、纹理通道、颜色通道等。以达到强化重要的通道，抑制冗余信息的目的。<br>步骤：</p>
<ol>
<li>对输入特征图分别做 <strong>Global Avg Pooling 和 Max Pooling</strong>，得到两个通道描述向量（1×1×C）</li>
<li>将这两个向量送入 <strong>共享的 MLP（全连接层）</strong></li>
<li>输出经过 sigmoid 激活的权重向量</li>
<li>将该权重与原特征图逐通道相乘</li>
</ol>
<p>空间注意力模块（Spatial Attention），关注“图像上哪些位置更关键”，比如目标所在区域。<br>步骤：</p>
<ol>
<li>对通道维做 MaxPool 和 AvgPool，得到两个 1×H×W 特征图</li>
<li>将它们拼接在通道维上（2×H×W）</li>
<li>通过一个 7×7 的卷积核</li>
<li>经 sigmoid 激活后生成空间注意力图</li>
<li>与输入特征图逐元素相乘</li>
</ol>
<p>CBAM 的优势：</p>
<table>
<thead>
<tr>
<th><strong>优点</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>模块轻量</td>
<td>几乎不增加计算量</td>
</tr>
<tr>
<td>可插拔</td>
<td>可用于任何 CNN 模型后续模块</td>
</tr>
<tr>
<td>语义增强</td>
<td>强调关键通道和空间区域，提高准确率</td>
</tr>
<tr>
<td>对小目标友好</td>
<td>提升模型关注小区域信息的能力</td>
</tr>
<tr>
<td>适合多任务</td>
<td>分类、检测、分割任务都适用</td>
</tr>
</tbody></table>
<p>CBAM 是一个串联的“通道 + 空间”注意力模块，帮助 CNN 更聪明地理解“看哪”和“看什么”，在轻量化和性能之间取得了极佳的平衡。</p>
<h4 id="5-Mish-激活函数"><a href="#5-Mish-激活函数" class="headerlink" title="5.Mish 激活函数"></a>5.Mish 激活函数</h4><p>Mish 激活函数是一种新兴的非线性激活函数，在很多模型（包括 YOLOv4）中被应用，用于增强特征表达能力。它是 ReLU 和 Swish 的一种更平滑、性能更优的替代方案。</p>
<p>Mish 与其他激活函数的对比</p>
<table>
<thead>
<tr>
<th><strong>激活函数</strong></th>
<th><strong>数学表达</strong></th>
<th><strong>是否平滑</strong></th>
<th><strong>是否单调</strong></th>
<th><strong>输出范围</strong></th>
<th><strong>性能表现</strong></th>
</tr>
</thead>
<tbody><tr>
<td>ReLU</td>
<td>max(0, x)</td>
<td>否</td>
<td>是</td>
<td>[0, ∞)</td>
<td>基础款</td>
</tr>
<tr>
<td>LeakyReLU</td>
<td>max(αx, x)</td>
<td>否</td>
<td>是</td>
<td>(-∞, ∞)</td>
<td>较好</td>
</tr>
<tr>
<td>Swish</td>
<td>x * sigmoid(x)</td>
<td>是</td>
<td>否</td>
<td>(-∞, ∞)</td>
<td>好</td>
</tr>
<tr>
<td><strong>Mish</strong></td>
<td>x * tanh(softplus(x))</td>
<td>是</td>
<td>否</td>
<td>(-∞, ∞)</td>
<td>最优（很多场景）</td>
</tr>
</tbody></table>
<p>Mish 继承了 Swish 的非线性优势，输出在负区间更温和，利于梯度流动。</p>
<p>Mish 的优势总结：</p>
<table>
<thead>
<tr>
<th><strong>优势</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>更强特征表达</td>
<td>曲线光滑，非线性强，有利于建模复杂模式</td>
</tr>
<tr>
<td>梯度更稳定</td>
<td>相比 ReLU、LeakyReLU 梯度不会突变</td>
</tr>
<tr>
<td>不截断负值</td>
<td>在负区间仍有小的输出，有利于保留信息</td>
</tr>
<tr>
<td>实证有效</td>
<td>在 YOLOv4、EfficientNet 等网络上验证有效提升</td>
</tr>
</tbody></table>
<p>YOLOv4 将 Mish 激活广泛用于主干 CSPDarknet53，替换了传统的 LeakyReLU，配合其他模块（如 CSP、SPP、PANet）进一步提升准确率，对小目标检测尤其明显。</p>
<h4 id="6-Eliminate-grid-sensitivity"><a href="#6-Eliminate-grid-sensitivity" class="headerlink" title="6.Eliminate grid sensitivity"></a>6.Eliminate grid sensitivity</h4><p>主要用于改善目标检测中因网格划分导致的预测偏差问题，尤其是在小目标或边缘目标的检测上。</p>
<p>什么是 Grid Sensitivity（网格敏感性）？<br>在 YOLO 系列（尤其是 YOLOv1~v3）中，图像被划分为 S×S 个网格，每个网格预测其“负责”的目标框：</p>
<ul>
<li>每个目标只能被分配给其中心点所在的网格</li>
<li>假如目标刚好压在网格边缘，模型必须决定“左边网格负责”还是“右边负责”，这就容易产生波动（不稳定）</li>
<li>同样，小目标若跨多个网格，可能会出现预测位置偏差</li>
</ul>
<p>YOLOv4 对于位置回归的预测做了以下调整，特别是在预测框中心坐标 (x, y) 的计算方式上：<br>加上一个小常数 ε，以允许预测点略微“跳出”当前网格，突破 sigmoid 限制。</p>
<p>方法一：<strong>缩放输出范围</strong><br>    $$\hat{x} &#x3D; (\sigma(t_x) \cdot s + \epsilon) + c_x$$<br>	- $s \in (0,1.5)$，例如 1.2<br>    - ε 是微小偏移，用于平滑过渡</p>
<p>方法二：<strong>用更大的 sigmoid 控制区间</strong><br>	$$ \sigma(2 \cdot t_x) - 0.5 \ $$<br>    - 这样 sigmoid 的范围变成了约 (-0.5, 1.5)，可以适度超出网格边界<br>这种方式就允许中心坐标跨越网格边界，从而<strong>缓解边缘预测抖动</strong>，提升定位精度</p>
<p>通俗总结一下，网络把图像像井盖一样切成格子，以前每个“井盖”只能管它正中间的东西，现在我们说：<strong>井盖的手可以伸出去一点点，不用非得把人圈死在正中心</strong>，这样，就能“柔和地”预测落在格子边缘的目标了，不再出现抖动、漏检！</p>
<h3 id="3-后处理优化"><a href="#3-后处理优化" class="headerlink" title="3.后处理优化"></a>3.后处理优化</h3><h4 id="1-DIoU-NMS​-​Soft-NMS"><a href="#1-DIoU-NMS​-​Soft-NMS" class="headerlink" title="1.DIoU-NMS​&#x2F;​Soft-NMS"></a>1.DIoU-NMS​&#x2F;​Soft-NMS</h4><p>用来改进 YOLO 等目标检测器中 <strong>非极大值抑制（NMS）</strong> 的优化技术，目的是在去除冗余检测框时，更<strong>智能地保留真实目标框</strong>，尤其对密集目标检测、小目标检测有帮助。</p>
<p>Soft-NMS 更柔和、精细地处理框之间的重叠；DIoU-NMS 则更智能地结合了 IoU 与中心距离，更适合 YOLO 等实时检测器，对密集目标特别有效。</p>
<p>NMS 是什么？<br>在目标检测中，模型可能对同一个物体输出多个重叠框，需要做抑制，原始 <strong>NMS（Greedy NMS）</strong> 策略是：<br>    1. 选择当前得分最高的框<br>    2. 将与其 IoU &gt; 阈值 的其他框全部移除<br>    3. 重复以上步骤直到无框可选<br>这种做法简单暴力，但<strong>存在两个问题</strong>：</p>
<ul>
<li><strong>对密集目标不友好</strong>（比如人群、果堆）</li>
<li><strong>可能误删有效框</strong>（只因为 IoU 稍大）</li>
</ul>
<h5 id="Soft-NMS（Soft-Non-Maximum-Suppression）"><a href="#Soft-NMS（Soft-Non-Maximum-Suppression）" class="headerlink" title="Soft-NMS（Soft Non-Maximum Suppression）"></a>Soft-NMS（Soft Non-Maximum Suppression）</h5><p>不是直接删掉重叠框，而是“<strong>软处理</strong>”：随着 IoU 增加，逐渐降低其它框的置信度。<br>优点是更温和地处理重叠框；可以保留多个相邻目标，适合拥挤场景。</p>
<h5 id="DIoU-NMS（Distance-IoU-based-NMS）"><a href="#DIoU-NMS（Distance-IoU-based-NMS）" class="headerlink" title="DIoU-NMS（Distance IoU-based NMS）"></a>DIoU-NMS（Distance IoU-based NMS）</h5><p>除了考虑 IoU，还考虑 <strong>两个框中心点的距离</strong>，<strong>优先保留“离得远的”框</strong>，避免误删多个相邻目标。<br>优点是解决 NMS 对密集目标误删问题；对于同类目标密集区域（如行人、人脸）效果明显提升， 速度快，易于替换传统 NMS。</p>
<p>DIoU-NMS vs Soft-NMS 对比</p>
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>Soft-NMS</strong></th>
<th><strong>DIoU-NMS</strong></th>
</tr>
</thead>
<tbody><tr>
<td>保留重叠目标</td>
<td>更温和</td>
<td>更智能</td>
</tr>
<tr>
<td>抑制依据</td>
<td>IoU + 衰减函数</td>
<td>IoU + 距离</td>
</tr>
<tr>
<td>对密集目标</td>
<td>很有效</td>
<td>很有效</td>
</tr>
<tr>
<td>计算复杂度</td>
<td>较高（需要排序）</td>
<td>类似原始 NMS</td>
</tr>
<tr>
<td>是否去除框</td>
<td>不直接去除</td>
<td>直接去除（基于距离）</td>
</tr>
<tr>
<td>在 YOLO 中应用</td>
<td>默认未启用</td>
<td>YOLOv4 默认采用</td>
</tr>
</tbody></table>
<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h3><h4 id="YOLO-V3-改进"><a href="#YOLO-V3-改进" class="headerlink" title="YOLO-V3 改进"></a>YOLO-V3 改进</h4><ol>
<li>​<strong>网络架构改进</strong>​<ul>
<li>​<strong>残差连接（Residual Connections）​</strong>​：解决梯度消失和退化问题，允许训练更深的网络</li>
<li>​<strong>Darknet-53 主干网络</strong>​：引入残差块，提升特征提取能力，支持多尺度检测</li>
</ul>
</li>
<li>​<strong>检测机制优化</strong>​<ul>
<li>​<strong>多尺度预测</strong>​：通过三个不同尺度的特征图（13×13、26×26、52×52）检测不同大小的目标</li>
<li>​<strong>细粒度特征融合</strong>​：上采样深层特征并与浅层特征拼接，结合细节与语义信息</li>
<li>​<strong>边界框预测改进</strong>​：sigmoid处理中心坐标，基于anchor的指数缩放预测宽高，提升稳定性</li>
<li>​<strong>先验框优化</strong>​：K-means聚类生成更匹配数据分布的anchor尺寸</li>
<li>​<strong>分类方式</strong>​：用sigmoid替代softmax，支持多标签分类</li>
</ul>
</li>
<li>​<strong>训练策略</strong>​<ul>
<li>​<strong>多尺度训练</strong>​：动态调整输入尺寸，增强模型鲁棒性</li>
<li>​<strong>数据增强</strong>​：如随机裁剪、色彩抖动等</li>
<li>​<strong>损失函数</strong>​：二元交叉熵（分类）与改进的定位损失结合</li>
</ul>
</li>
</ol>
<h4 id="YOLO-V4-改进"><a href="#YOLO-V4-改进" class="headerlink" title="YOLO-V4 改进"></a>YOLO-V4 改进</h4><ol>
<li>​<strong>Bag of Freebies（训练优化）​</strong>​    <ul>
<li>​<strong>Mosaic数据增强</strong>​：拼接四张图像，增加目标多样性和尺度变化</li>
<li>​<strong>自对抗训练（SAT）​</strong>​：生成对抗样本并训练模型，提升鲁棒性</li>
<li>​<strong>DropBlock</strong>​：区域级正则化，防止过拟合</li>
<li>​<strong>标签平滑</strong>​：缓解分类标签的过拟合</li>
<li>​<strong>CIoU损失</strong>​：综合考虑重叠、中心距离和宽高比，提升定位精度</li>
</ul>
</li>
<li>​<strong>Bag of Specials（结构改进）​</strong>​<ul>
<li>​<strong>CSPDarknet53</strong>​：引入CSP结构和Mish激活函数，提升特征提取效率</li>
<li>​<strong>SPPNet</strong>​：多尺度池化增强感受野</li>
<li>​<strong>PANet</strong>​：双向特征金字塔，强化多尺度融合</li>
<li>​<strong>CBAM注意力机制</strong>​：通道与空间注意力结合，聚焦关键特征</li>
<li>​<strong>Mish激活函数</strong>​：平滑梯度，增强非线性表达能力</li>
<li>​<strong>消除网格敏感度</strong>​：允许预测框微调出网格，改善边缘目标检测</li>
</ul>
</li>
<li>​<strong>后处理优化</strong>​<ul>
<li>​<strong>DIoU-NMS</strong>​：结合IoU与中心距离，减少密集目标的误删</li>
</ul>
</li>
</ol>
<h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><table>
<thead>
<tr>
<th>​<strong>改进点</strong>​</th>
<th>​<strong>YOLO-V3</strong>​</th>
<th>​<strong>YOLO-V4</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>主干网络</strong>​</td>
<td>Darknet-53（残差连接）</td>
<td>CSPDarknet53（CSP结构 + Mish激活）</td>
</tr>
<tr>
<td>​<strong>多尺度检测</strong>​</td>
<td>三尺度特征图 + FPN思想</td>
<td>SPP + PANet（双向融合）</td>
</tr>
<tr>
<td>​<strong>数据增强</strong>​</td>
<td>多尺度训练、传统增强</td>
<td>Mosaic、自对抗训练（SAT）</td>
</tr>
<tr>
<td>​<strong>正则化</strong>​</td>
<td>残差连接、BatchNorm</td>
<td>DropBlock、标签平滑</td>
</tr>
<tr>
<td>​<strong>损失函数</strong>​</td>
<td>Sigmoid分类 + 定位损失</td>
<td>CIoU损失（综合重叠、距离、宽高比）</td>
</tr>
<tr>
<td>​<strong>注意力机制</strong>​</td>
<td>无</td>
<td>CBAM（通道与空间注意力）</td>
</tr>
<tr>
<td>​<strong>后处理</strong>​</td>
<td>传统NMS</td>
<td>DIoU-NMS（结合距离抑制冗余框）</td>
</tr>
<tr>
<td>​<strong>激活函数</strong>​</td>
<td>LeakyReLU</td>
<td>Mish（更平滑的梯度流）</td>
</tr>
</tbody></table>
<p><strong>YOLO-V3</strong>​：通过残差结构、多尺度预测和细粒度融合，解决了深层网络训练难题，提升小目标检测能力。<br>​<strong>YOLO-V4</strong>​：集成大量训练技巧（Mosaic、SAT）和结构优化（CSP、PANet、CBAM），结合CIoU损失和DIoU-NMS，显著提升精度与鲁棒性，尤其适合复杂场景和密集目标检测。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>[YOLO系列④] YOLOv5模型训练与流程解析</title>
    <url>/2025/05/07/014-yolo-yolov5-code-detail/</url>
    <content><![CDATA[<h2 id="1-基本使用"><a href="#1-基本使用" class="headerlink" title="1.基本使用"></a>1.基本使用</h2><h3 id="1-YOLOv5整体概述"><a href="#1-YOLOv5整体概述" class="headerlink" title="1.YOLOv5整体概述"></a>1.YOLOv5整体概述</h3><p>YOLOv5本质上是一个经过大量优化的<strong>工程项目</strong>，不像前几代那样有对应的学术论文。它主要是在YOLOv4的基础上做了更实用的工程改进，让使用者能更轻松地应用到实际场景中。主要有以下特点：</p>
<ol>
<li>​<strong>工程优化为主</strong>​<ul>
<li>没有官方论文，核心改进在于代码实现，比如训练效率、代码可读性</li>
<li>相比YOLOv4，工程结构更简洁，配置更直观，适合直接拿来训练自己的数据</li>
</ul>
</li>
<li>​<strong>使用体验升级</strong>​<ul>
<li>作者把数据增强、模型结构（如CSP、SPP模块）等复杂逻辑封装得很好，使用者几乎不用改代码</li>
<li>支持混合精度训练，训练速度更快，对硬件要求更友好</li>
</ul>
</li>
</ol>
<span id="more"></span>
<ol start="3">
<li>​<strong>简化训练自定义数据</strong>​<ul>
<li>不需要用庞大的COCO数据集，准备好自己的标注数据（格式和目录按规范整理）就能直接开跑</li>
<li>数据增强、模型配置都通过配置文件（YAML）管理，改几个参数就能适配不同任务</li>
</ul>
</li>
<li>​<strong>代码简洁</strong>​<ul>
<li>相比YOLOv3&#x2F;v4的“堆料式”代码，V5的代码结构清晰，模块化程度高，容易二次开发</li>
<li>项目文档详细，从安装到训练、测试都有现成指令，能快速上手</li>
</ul>
</li>
</ol>
<p>YOLOv5 的代码量虽然多一点，但设计非常细致、实用，并且持续更新维护，不同于很多“一发论文就停止维护”的学术项目。</p>
<h3 id="2-训练自定义数据集"><a href="#2-训练自定义数据集" class="headerlink" title="2.训练自定义数据集"></a>2.训练自定义数据集</h3><p>如何训练自定义数据集，可分为三步：</p>
<ol>
<li>下载（准备）标注好的数据集</li>
<li>按指定文件夹结构存放</li>
<li>改配置文件里的路径和类别数</li>
</ol>
<p>训练数据也可以从<a href="https://public.roboflow.com/">Roboflow</a>上下载，<strong>Roboflow</strong>​ 是一个面向开发者和企业的端到端计算机视觉（CV）开发平台，可以帮助用户高效构建、训练、部署和管理AI视觉模型，上面也有多个轻量级的目标检测数据集（如手写数字、象棋、扑克牌、口罩等），比较适合单机或低配置训练。</p>
<p>我们选择<a href="https://public.roboflow.com/object-detection/mask-wearing/4">口罩数据集</a>，下载的时候选择格式为 <strong>YOLOv5 PyTorch</strong>（.txt 标签格式），下载后将数据集解压到与 YOLOv5 源码（如 yolov5-master）同级目录下，例如：mask_wearing_data。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">mask<span class="emphasis">_wearing_</span>data/</span><br><span class="line">├── train/</span><br><span class="line">│   ├── images/  # 训练图片</span><br><span class="line">│   └── labels/  # 对应txt标注文件</span><br><span class="line">├── valid/       # 验证集（结构同train）</span><br><span class="line">├── test/        # 测试集（结构同train）</span><br><span class="line">└── data.yaml    # 配置文件（改路径和类别数就用它）</span><br></pre></td></tr></table></figure>
<p>配置文件（data.yaml）需要指定图像路径、标签路径、类别数（如口罩数据集为2类：戴口罩 &#x2F; 未戴口罩）。    </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">data.yaml/</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">../mask_wearing_data/train/images</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">../mask_wearing_data/valid/images</span></span><br><span class="line"><span class="attr">test:</span> <span class="string">../mask_wearing_data/test/images</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;mask&#x27;</span>, <span class="string">&#x27;no-mask&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>标签为 .txt 格式，第一列是类别编号，后四列是归一化后的边框坐标（YOLO格式）。标签文件需与图片文件名对应，如果想定义自己的数据集可以参考这个数据格式。</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">126202-untitled-design-13_jpg.rf.baa3d2e55d469ae5d5d4cd81c4603e1d.txt</span><br><span class="line"></span><br><span class="line">0 0.855119825708061 0.18280632411067194 0.15250544662309368 0.3458498023715415</span><br><span class="line">0 0.6726579520697168 0.48023715415019763 0.21895424836601307 0.5612648221343873</span><br><span class="line">0 0.48257080610021785 0.35276679841897235 0.1895424836601307 0.44861660079051385</span><br><span class="line">0 0.2587145969498911 0.5632411067193676 0.17973856209150327 0.41106719367588934</span><br><span class="line">0 0.09477124183006536 0.41699604743083 0.18082788671023964 0.5217391304347826</span><br></pre></td></tr></table></figure>
<p>YOLOv5 会在训练时自动生成缓存文件（如 .cache），提高后续训练速度。</p>
<h3 id="2-下载预训练模型与配置参数"><a href="#2-下载预训练模型与配置参数" class="headerlink" title="2.下载预训练模型与配置参数"></a>2.下载预训练模型与配置参数</h3><p>YOLOv5给我们提供了很多预训练模型，这些模型在参数量、计算量和性能上都有所区别，主要面向不同的应用场景和硬件需求。模型名称后缀越大，参数量越多，精度越高，但训练速度会越慢：</p>
<ul>
<li>​<strong>YOLOv5n</strong>​（Nano）<ul>
<li>参数量：约 1.9M</li>
<li>计算量：约 4.5 GFLOPs</li>
<li>适用场景：​<strong>移动端&#x2F;嵌入式设备</strong>​（如 Jetson Nano、树莓派）或对实时性要求极高的场景。</li>
</ul>
</li>
<li>​<strong>YOLOv5s</strong>​（Small）<ul>
<li>参数量：约 7.2M</li>
<li>计算量：约 16.5 GFLOPs</li>
<li>适用场景：​<strong>轻量级通用检测</strong>，平衡速度与精度，适合边缘计算设备（如 Jetson TX2）。</li>
</ul>
</li>
<li>​<strong>YOLOv5m</strong>​（Medium）<ul>
<li>参数量：约 21.2M</li>
<li>计算量：约 49.0 GFLOPs</li>
<li>适用场景：​<strong>通用场景下的实时检测</strong>​（如视频监控、无人机航拍）。</li>
</ul>
</li>
<li>​<strong>YOLOv5l</strong>​（Large）<ul>
<li>参数量：约 46.5M</li>
<li>计算量：约 109.1 GFLOPs</li>
<li>适用场景：​<strong>服务器端或高性能 GPU</strong>，对精度要求较高的任务。</li>
</ul>
</li>
<li>​<strong>YOLOv5x</strong>​（X-Large）<ul>
<li>参数量：约 86.7M</li>
<li>计算量：约 205.7 GFLOPs</li>
<li>适用场景：​<strong>研究或高精度需求场景</strong>​（如医学图像分析、卫星图像检测）。</li>
</ul>
</li>
</ul>
<p>一般我们在学习和测试的时候建议先用 yolov5s，好处是小模型、十几 MB，训练速度快一些。</p>
<p>使用<code>train.py</code>训练当前自定义数据集<code>mask_wearing_data</code>命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python train.py --data ../mask_wearing_data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --batch-size 16 --freeze 10 --epochs 10    </span><br></pre></td></tr></table></figure>

<p>如果命令在运行的时候判断如果指定模型结构还没有下载预训练模型就会自动下载到项目根目录。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>--data</code></td>
<td>指定数据配置文件 <code>data.yaml</code>，描述数据集路径、类别数、类别名称等信息</td>
</tr>
<tr>
<td><code>--cfg</code></td>
<td>指定模型结构配置文件 <code>yolov5s.yaml</code>，定义 YOLOv5s 的网络结构</td>
</tr>
<tr>
<td><code>--weight</code></td>
<td>使用yolov5s预训练权重，可加速收敛并提升精度</td>
</tr>
<tr>
<td><code>--batch-size</code></td>
<td>设置每个批次的样本数为 16，影响训练速度和显存占用</td>
</tr>
<tr>
<td><code>--freeze</code></td>
<td>冻结骨干网络的前 10 层，减少计算量</td>
</tr>
<tr>
<td><code>--epochs</code></td>
<td>训练轮数</td>
</tr>
</tbody></table>
<p>最后的一个Epoch+summary日志：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250503142232.png"></p>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h2><p>下面就来分析一下YOLOv5的代码，看看如何实现，如何加载数据集， 数据增强特别是 Mosaic 的实现逻辑，最终返回可用于训练的数据与标签</p>
<h3 id="1-数据加载"><a href="#1-数据加载" class="headerlink" title="1.数据加载"></a>1.数据加载</h3><p> <code>utils/dataloaders.py</code> 文件是 YOLOv5 的数据加载和处理模块，支持多种训练和推理场景，大致包含以下主要功能：</p>
<ol>
<li>​<strong>数据加载器</strong>​：支持图像&#x2F;视频文件、实时视频流、屏幕截图及分类数据集的加载（<code>LoadImages</code>&#x2F;<code>LoadStreams</code>&#x2F;<code>LoadImagesAndLabels</code>等）</li>
<li>​<strong>预处理与增强</strong>​：包含图像缩放、填充、Mosaic&#x2F;MixUp增强、随机透视变换、HSV调整等，支持训练时动态数据增强</li>
<li>​<strong>视频处理</strong>​：多线程处理本地视频、YouTube流和IP摄像头，实现高效帧读取</li>
<li>​<strong>数据集管理</strong>​：提供缓存机制、数据集验证、自动分割（训练&#x2F;验证&#x2F;测试）及统计信息生成（<code>HUBDatasetStats</code>）</li>
<li>​<strong>分布式训练支持</strong>​：通过<code>SmartDistributedSampler</code>实现多GPU数据分配，确保数据加载与并行训练协调</li>
<li>​<strong>格式转换工具</strong>​：自动转换图像路径到标签路径、处理EXIF信息、验证数据合法性（<code>verify_image_label</code>）</li>
<li>​<strong>性能优化</strong>​：采用内存&#x2F;磁盘缓存、多线程加载、批处理优化（如四合一拼接）加速数据流水线</li>
<li>​<strong>错误处理</strong>​：检测损坏图像&#x2F;标签，记录异常并跳过无效数据，保障训练稳定性</li>
<li>​<strong>分类任务扩展</strong>​：专用<code>ClassificationDataset</code>支持图像分类数据加载与增强</li>
<li>​<strong>导出与兼容性</strong>​：支持数据集压缩、格式转换及统计报告生成，便于模型部署和迁移</li>
</ol>
<p>如何取数据，来看看<code>create_dataloader</code>的各个参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">utils/dataloaders.py</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">  </span></span><br><span class="line"><span class="params">    path,  <span class="comment"># 数据集路径</span></span></span><br><span class="line"><span class="params">    imgsz,  <span class="comment"># 输入图像的尺寸（如640表示图像会被调整为 640x640）</span></span></span><br><span class="line"><span class="params">    batch_size,  <span class="comment"># 每个批次的样本数量</span></span></span><br><span class="line"><span class="params">    stride,  <span class="comment"># 模型的下采样步长（用于调整标签尺寸）</span></span></span><br><span class="line"><span class="params">    single_cls=<span class="literal">False</span>,  <span class="comment"># 是否将所有类别视为同一类别（用于单类别任务）</span></span></span><br><span class="line"><span class="params">    hyp=<span class="literal">None</span>,  <span class="comment"># 超参数字典（包含数据增强相关的参数）</span></span></span><br><span class="line"><span class="params">    augment=<span class="literal">False</span>,  <span class="comment"># 是否启用数据增强</span></span></span><br><span class="line"><span class="params">    cache=<span class="literal">False</span>,  <span class="comment"># 是否缓存图像到内存或磁盘（加速后续加载）</span></span></span><br><span class="line"><span class="params">    pad=<span class="number">0.0</span>,  <span class="comment"># 图像填充比例（用于矩形训练）</span></span></span><br><span class="line"><span class="params">    rect=<span class="literal">False</span>,  <span class="comment"># 是否使用矩形批次（非方形图像，减少填充）</span></span></span><br><span class="line"><span class="params">    rank=-<span class="number">1</span>,  <span class="comment"># 分布式训练的进程排名（-1表示非分布式）</span></span></span><br><span class="line"><span class="params">    workers=<span class="number">8</span>,  <span class="comment"># 数据加载的子进程数</span></span></span><br><span class="line"><span class="params">    image_weights=<span class="literal">False</span>,  <span class="comment"># 是否根据类别分布对图像进行加权采样</span></span></span><br><span class="line"><span class="params">    quad=<span class="literal">False</span>,  <span class="comment"># 是否使用四合一拼接的数据加载（用于更大的批次）</span></span></span><br><span class="line"><span class="params">    prefix=<span class="string">&quot;&quot;</span>,  <span class="comment"># 日志信息的前缀（用于调试）</span></span></span><br><span class="line"><span class="params">    shuffle=<span class="literal">False</span>,  <span class="comment"># 是否打乱数据顺序</span></span></span><br><span class="line"><span class="params">    seed=<span class="number">0</span>,  <span class="comment"># 随机种子</span></span></span><br><span class="line"><span class="params"></span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates and returns a configured DataLoader instance for loading and processing image datasets.&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="keyword">if</span> rect <span class="keyword">and</span> shuffle:</span><br><span class="line">        LOGGER.warning(<span class="string">&quot;WARNING ⚠️ --rect is incompatible with DataLoader shuffle, setting shuffle=False&quot;</span>)  </span><br><span class="line">        <span class="comment"># 如果启用矩形训练（rect=True），则强制关闭shuffle（因为矩形批次需要固定顺序）</span></span><br><span class="line">        shuffle = <span class="literal">False</span>  </span><br><span class="line">    <span class="comment">#  确保在分布式训练中，数据集缓存（如.cache文件）只由rank=0的进程生成一次</span></span><br><span class="line">    <span class="keyword">with</span> torch_distributed_zero_first(rank):</span><br><span class="line">	    <span class="comment"># 负责加载图像和标签，支持数据增强、缓存、矩形训练等功能，内部会解析标签文件（如 YOLO 格式的.txt），调整图像尺寸，并应用增强（如旋转、缩放等）</span></span><br><span class="line">        dataset = LoadImagesAndLabels(  </span><br><span class="line">            path,  </span><br><span class="line">            imgsz,  </span><br><span class="line">            batch_size,  </span><br><span class="line">            augment=augment,  <span class="comment"># augmentation  </span></span><br><span class="line">            hyp=hyp,  <span class="comment"># hyperparameters  </span></span><br><span class="line">            rect=rect,  <span class="comment"># rectangular batches  </span></span><br><span class="line">            cache_images=cache,  </span><br><span class="line">            single_cls=single_cls,  </span><br><span class="line">            stride=<span class="built_in">int</span>(stride),  </span><br><span class="line">            pad=pad,  </span><br><span class="line">            image_weights=image_weights,  </span><br><span class="line">            prefix=prefix,  </span><br><span class="line">            rank=rank,  </span><br><span class="line">        )  </span><br><span class="line">  </span><br><span class="line">    batch_size = <span class="built_in">min</span>(batch_size, <span class="built_in">len</span>(dataset))  </span><br><span class="line">    nd = torch.cuda.device_count()  <span class="comment"># number of CUDA devices  </span></span><br><span class="line">    <span class="comment"># 计算实际使用的子进程数nw，考虑 CPU 核心数、GPU 数量和批次大小</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count() // <span class="built_in">max</span>(nd, <span class="number">1</span>), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, workers])</span><br><span class="line">    <span class="comment"># ​配置分布式采样器，分布式训练支持​，如果rank != -1（分布式训练），使用 SmartDistributedSampler 分配数据到各进程；否则不使用采样器</span></span><br><span class="line">    sampler = <span class="literal">None</span> <span class="keyword">if</span> rank == -<span class="number">1</span> <span class="keyword">else</span> SmartDistributedSampler(dataset, shuffle=shuffle)  </span><br><span class="line">    <span class="comment"># 选择DataLoader类型，使用标准DataLoader（支持动态权重更新）；否则使用InfiniteDataLoader（无限循环迭代数据）</span></span><br><span class="line">    loader = DataLoader <span class="keyword">if</span> image_weights <span class="keyword">else</span> InfiniteDataLoader</span><br><span class="line">    <span class="comment"># 通过generator控制数据加载的随机性，确保实验可复现</span></span><br><span class="line">    generator = torch.Generator()  </span><br><span class="line">    generator.manual_seed(<span class="number">6148914691236517205</span> + seed + RANK)  </span><br><span class="line">    <span class="keyword">return</span> loader(  </span><br><span class="line">        dataset,  </span><br><span class="line">        batch_size=batch_size,  </span><br><span class="line">        shuffle=shuffle <span class="keyword">and</span> sampler <span class="keyword">is</span> <span class="literal">None</span>,  </span><br><span class="line">        num_workers=nw,  </span><br><span class="line">        sampler=sampler,  </span><br><span class="line">        <span class="comment"># 是否丢弃不完整的批次（quad时启用）</span></span><br><span class="line">        drop_last=quad,  </span><br><span class="line">        <span class="comment"># 是否将数据固定到内存（加速 GPU 传输）</span></span><br><span class="line">        pin_memory=PIN_MEMORY,  </span><br><span class="line">        <span class="comment"># 处理批次数据的函数（quad时使用四合一拼接的collate_fn4）</span></span><br><span class="line">        collate_fn=LoadImagesAndLabels.collate_fn4 <span class="keyword">if</span> quad <span class="keyword">else</span> LoadImagesAndLabels.collate_fn,</span><br><span class="line">        <span class="comment"># 进程的初始化函数（seed_worker 设置子进程的随机种子）</span></span><br><span class="line">        worker_init_fn=seed_worker,  </span><br><span class="line">        generator=generator,  </span><br><span class="line">    ), dataset</span><br></pre></td></tr></table></figure>

<p>返回值：</p>
<ol>
<li><strong>loader</strong>:  配置好的 DataLoader 实例，用于迭代训练数据</li>
<li>​<strong>dataset</strong>:  数据集对象，可用于获取样本数、类别数等元信息</li>
</ol>
<h3 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2.数据增强"></a>2.数据增强</h3><p>数据和标签已经准备好了接下来要读取每一个样本并进行处理（如数据增强）<br>整体流程如下：</p>
<ol>
<li>调用 <code>__getitem__</code> 加载图像</li>
<li>判断是否启用 Mosaic 增强</li>
<li>随机设定 Mosaic 中心点</li>
<li>拼接 4 张图像（1 当前索引 + 3 随机图）</li>
<li>将图像和标签重新组合，作为一个新的训练样本返回</li>
</ol>
<h4 id="1-getitem"><a href="#1-getitem" class="headerlink" title="1.__getitem__"></a>1.<code>__getitem__</code></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Fetches the dataset item at the given index, considering linear, shuffled, or weighted sampling.&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="comment"># 采样策略适配,根据预设的采样策略（线性/随机/加权）转换索引，支持多种数据加载模式</span></span><br><span class="line">    index = <span class="variable language_">self</span>.indices[index]  <span class="comment"># linear, shuffled, or image_weights  </span></span><br><span class="line">  </span><br><span class="line">    hyp = <span class="variable language_">self</span>.hyp  </span><br><span class="line">    <span class="comment"># Mosaic增强，概率性启用Mosaic</span></span><br><span class="line">    <span class="keyword">if</span> mosaic := <span class="variable language_">self</span>.mosaic <span class="keyword">and</span> random.random() &lt; hyp[<span class="string">&quot;mosaic&quot;</span>]:  </span><br><span class="line">        <span class="comment"># 加载4图拼接的大图及标签</span></span><br><span class="line">        img, labels = <span class="variable language_">self</span>.load_mosaic(index)  </span><br><span class="line">        shapes = <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 以hyp[&quot;mixup&quot;]概率叠加另一张Mosaic图，增强目标混合效果</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;mixup&quot;</span>]:  </span><br><span class="line">            img, labels = mixup(img, labels, *<span class="variable language_">self</span>.load_mosaic(random.choice(<span class="variable language_">self</span>.indices)))  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        <span class="comment"># Load image  </span></span><br><span class="line">        img, (h0, w0), (h, w) = <span class="variable language_">self</span>.load_image(index)  </span><br><span class="line">        <span class="comment"># Letterbox 调整 </span></span><br><span class="line">        shape = <span class="variable language_">self</span>.batch_shapes[<span class="variable language_">self</span>.batch[index]] <span class="keyword">if</span> <span class="variable language_">self</span>.rect <span class="keyword">else</span> <span class="variable language_">self</span>.img_size  <span class="comment"># final letterboxed shape  </span></span><br><span class="line">        img, ratio, pad = letterbox(img, shape, auto=<span class="literal">False</span>, scaleup=<span class="variable language_">self</span>.augment)  </span><br><span class="line">        shapes = (h0, w0), ((h / h0, w / w0), pad)  <span class="comment"># for COCO mAP rescaling  </span></span><br><span class="line">  </span><br><span class="line">        labels = <span class="variable language_">self</span>.labels[index].copy()  </span><br><span class="line">        <span class="comment"># 标签坐标转换</span></span><br><span class="line">        <span class="keyword">if</span> labels.size:  <span class="comment"># normalized xywh to pixel xyxy format  </span></span><br><span class="line">            labels[:, <span class="number">1</span>:] = xywhn2xyxy(labels[:, <span class="number">1</span>:], ratio[<span class="number">0</span>] * w, ratio[<span class="number">1</span>] * h, padw=pad[<span class="number">0</span>], padh=pad[<span class="number">1</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.augment:  </span><br><span class="line">            <span class="comment"># 数据增强：随机透视变换（旋转/缩放/平移/剪切/透视）（opencv实现）</span></span><br><span class="line">            img, labels = random_perspective(  </span><br><span class="line">                img,  </span><br><span class="line">                labels,  </span><br><span class="line">                degrees=hyp[<span class="string">&quot;degrees&quot;</span>],  </span><br><span class="line">                translate=hyp[<span class="string">&quot;translate&quot;</span>],  </span><br><span class="line">                scale=hyp[<span class="string">&quot;scale&quot;</span>],  </span><br><span class="line">                shear=hyp[<span class="string">&quot;shear&quot;</span>],  </span><br><span class="line">                perspective=hyp[<span class="string">&quot;perspective&quot;</span>],  </span><br><span class="line">            )  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标签归一化处理</span></span><br><span class="line">    nl = <span class="built_in">len</span>(labels)  <span class="comment"># number of labels  </span></span><br><span class="line">    <span class="keyword">if</span> nl:  </span><br><span class="line">        labels[:, <span class="number">1</span>:<span class="number">5</span>] = xyxy2xywhn(labels[:, <span class="number">1</span>:<span class="number">5</span>], w=img.shape[<span class="number">1</span>], h=img.shape[<span class="number">0</span>], clip=<span class="literal">True</span>, eps=<span class="number">1e-3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.augment:  </span><br><span class="line">        <span class="comment"># 调用第三方库实现多样化增强（如模糊、噪声、仿射变换等）  </span></span><br><span class="line">        img, labels = <span class="variable language_">self</span>.albumentations(img, labels)  </span><br><span class="line">        nl = <span class="built_in">len</span>(labels)  <span class="comment"># update after albumentations  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 随机调整HSV通道，模拟光照、饱和度变化  </span></span><br><span class="line">        augment_hsv(img, hgain=hyp[<span class="string">&quot;hsv_h&quot;</span>], sgain=hyp[<span class="string">&quot;hsv_s&quot;</span>], vgain=hyp[<span class="string">&quot;hsv_v&quot;</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 上下随机翻转</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;flipud&quot;</span>]:  </span><br><span class="line">            img = np.flipud(img)  </span><br><span class="line">            <span class="keyword">if</span> nl:  </span><br><span class="line">                labels[:, <span class="number">2</span>] = <span class="number">1</span> - labels[:, <span class="number">2</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 左右随机翻转</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;fliplr&quot;</span>]:  </span><br><span class="line">            img = np.fliplr(img)  </span><br><span class="line">            <span class="keyword">if</span> nl:  </span><br><span class="line">                labels[:, <span class="number">1</span>] = <span class="number">1</span> - labels[:, <span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 随机遮挡区域增强鲁棒性  </span></span><br><span class="line">        <span class="comment"># labels = cutout(img, labels, p=0.5)       </span></span><br><span class="line">	    <span class="comment"># nl = len(labels)  # update after cutout  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据格式标准化​</span></span><br><span class="line">    labels_out = torch.zeros((nl, <span class="number">6</span>))  </span><br><span class="line">    <span class="keyword">if</span> nl:  </span><br><span class="line">        <span class="comment"># 标签张量化</span></span><br><span class="line">        labels_out[:, <span class="number">1</span>:] = torch.from_numpy(labels)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># ​图像通道处理  </span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))[::-<span class="number">1</span>]  <span class="comment"># HWC to CHW, BGR to RGB  </span></span><br><span class="line">    img = np.ascontiguousarray(img)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># (图像张量， 标签张量， 图像路径， 原始与调整后的尺寸信息)</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(img), labels_out, <span class="variable language_">self</span>.im_files[index], shapes</span><br></pre></td></tr></table></figure>

<p><code>__getitem__</code>核心作用：</p>
<ol>
<li>​<strong>动态数据增强</strong>​：通过Mosaic、MixUp、空间&#x2F;颜色变换等提升模型泛化能力</li>
<li>​<strong>多策略采样</strong>​：支持多种索引分配方式，适配不同训练需求</li>
<li>​<strong>坐标系统一</strong>​：确保标签在不同增强步骤后仍保持归一化格式</li>
<li>​<strong>格式标准化</strong>​：输出直接适配模型训练的Tensor格式</li>
</ol>
<h4 id="2-Mosaic-增强"><a href="#2-Mosaic-增强" class="headerlink" title="2.Mosaic 增强"></a>2.Mosaic 增强</h4><p><code>load_mosaic</code>是用于实现Mosaic数据增强的核心函数，其主要作用是将四张图像拼接成一张大图，并调整对应的标注信息，以提升模型训练时的数据多样性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_mosaic</span>(<span class="params">self, index</span>):  <span class="comment"># index（当前样本的索引）</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Loads a 4-image mosaic for YOLOv5, combining 1 selected and 3 random images, with labels and segments.&quot;&quot;&quot;</span>  </span><br><span class="line">    labels4, segments4 = [], []  <span class="comment"># 存储四张图像的标注和分割信息</span></span><br><span class="line">    s = <span class="variable language_">self</span>.img_size  <span class="comment"># 输入图像的尺寸（如640x640）</span></span><br><span class="line">    yc, xc = (<span class="built_in">int</span>(random.uniform(-x, <span class="number">2</span> * s + x)) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.mosaic_border)  <span class="comment"># 随机生成在[-border, 2*s + border]范围内的马赛克中心点坐标</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成4张图的索引：1张当前索引 + 3张随机索引</span></span><br><span class="line">    indices = [index] + random.choices(<span class="variable language_">self</span>.indices, k=<span class="number">3</span>)</span><br><span class="line">    random.shuffle(indices)  <span class="comment"># 打乱顺序，位置随机</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历处理每张图</span></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> <span class="built_in">enumerate</span>(indices):  </span><br><span class="line">        <span class="comment"># 加载图像和尺寸 (h,w) </span></span><br><span class="line">        img, _, (h, w) = <span class="variable language_">self</span>.load_image(index)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># === 计算当前图像在大图中的放置位置 ===</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:  <span class="comment"># 左上角  </span></span><br><span class="line">            <span class="comment"># 创建2s x 2s的基图，初始填充为114（灰色）</span></span><br><span class="line">            img4 = np.full((s * <span class="number">2</span>, s * <span class="number">2</span>, img.shape[<span class="number">2</span>]), <span class="number">114</span>, dtype=np.uint8)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 大图中的坐标范围（可能被裁剪）xmin, ymin, xmax, ymax (large image)  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = <span class="built_in">max</span>(xc - w, <span class="number">0</span>), <span class="built_in">max</span>(yc - h, <span class="number">0</span>), xc, yc</span><br><span class="line">            <span class="comment"># 原图中的对应裁剪区域 xmin, ymin, xmax, ymax (small image)  </span></span><br><span class="line">            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h</span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">1</span>:  <span class="comment"># 右上角  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = xc, <span class="built_in">max</span>(yc - h, <span class="number">0</span>), <span class="built_in">min</span>(xc + w, s * <span class="number">2</span>), yc  </span><br><span class="line">            x1b, y1b, x2b, y2b = <span class="number">0</span>, h - (y2a - y1a), <span class="built_in">min</span>(w, x2a - x1a), h  </span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">2</span>:  <span class="comment"># 左下角</span></span><br><span class="line">            x1a, y1a, x2a, y2a = <span class="built_in">max</span>(xc - w, <span class="number">0</span>), yc, xc, <span class="built_in">min</span>(s * <span class="number">2</span>, yc + h)  </span><br><span class="line">            x1b, y1b, x2b, y2b = w - (x2a - x1a), <span class="number">0</span>, w, <span class="built_in">min</span>(y2a - y1a, h)  </span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">3</span>:  <span class="comment"># 右下角  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = xc, yc, <span class="built_in">min</span>(xc + w, s * <span class="number">2</span>), <span class="built_in">min</span>(s * <span class="number">2</span>, yc + h)  </span><br><span class="line">            x1b, y1b, x2b, y2b = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">min</span>(w, x2a - x1a), <span class="built_in">min</span>(y2a - y1a, h)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将原图区域img[y1b:y2b, x1b:x2b] 粘贴到大图img4[y1a:y2a, x1a:x2a]</span></span><br><span class="line">        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算坐标偏移量（用于调整标注框）</span></span><br><span class="line">        padw = x1a - x1b  <span class="comment"># x方向偏移</span></span><br><span class="line">        padh = y1a - y1b  <span class="comment"># y方向偏移</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># === 处理标注信息 ===  </span></span><br><span class="line">        labels, segments = <span class="variable language_">self</span>.labels[index].copy(), <span class="variable language_">self</span>.segments[index].copy()  </span><br><span class="line">        <span class="keyword">if</span> labels.size:  </span><br><span class="line">            <span class="comment"># 将归一化的xywh转换为大图中的绝对坐标xyxy</span></span><br><span class="line">            labels[:, <span class="number">1</span>:] = xywhn2xyxy(labels[:, <span class="number">1</span>:], w, h, padw, padh)</span><br><span class="line">            <span class="comment"># 调整分割点坐标 </span></span><br><span class="line">            segments = [xyn2xy(x, w, h, padw, padh) <span class="keyword">for</span> x <span class="keyword">in</span> segments]  </span><br><span class="line">            </span><br><span class="line">        labels4.append(labels)  <span class="comment"># 收集标签</span></span><br><span class="line">        segments4.extend(segments)  <span class="comment"># 收集分割点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># === 后处理 ===</span></span><br><span class="line">    <span class="comment"># 合并所有标签 (shape=[N, 5]) </span></span><br><span class="line">    labels4 = np.concatenate(labels4, <span class="number">0</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 裁剪坐标到[0, 2s]范围内，防止越界</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> (labels4[:, <span class="number">1</span>:], *segments4):  </span><br><span class="line">        np.clip(x, <span class="number">0</span>, <span class="number">2</span> * s, out=x)  <span class="comment"># clip when using random_perspective()  </span></span><br><span class="line">    <span class="comment"># img4, labels4 = replicate(img4, labels4)  # replicate  </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数据增强：随机复制粘贴目标（根据概率）   </span></span><br><span class="line">    img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=<span class="variable language_">self</span>.hyp[<span class="string">&quot;copy_paste&quot;</span>])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据增强：随机透视变换（旋转/缩放/平移/剪切/透视）（opencv实现）</span></span><br><span class="line">    img4, labels4 = random_perspective(  </span><br><span class="line">        img4,  </span><br><span class="line">        labels4,  </span><br><span class="line">        segments4,  </span><br><span class="line">        degrees=<span class="variable language_">self</span>.hyp[<span class="string">&quot;degrees&quot;</span>],  </span><br><span class="line">        translate=<span class="variable language_">self</span>.hyp[<span class="string">&quot;translate&quot;</span>],  </span><br><span class="line">        scale=<span class="variable language_">self</span>.hyp[<span class="string">&quot;scale&quot;</span>],  </span><br><span class="line">        shear=<span class="variable language_">self</span>.hyp[<span class="string">&quot;shear&quot;</span>],  </span><br><span class="line">        perspective=<span class="variable language_">self</span>.hyp[<span class="string">&quot;perspective&quot;</span>],  </span><br><span class="line">        border=<span class="variable language_">self</span>.mosaic_border,  </span><br><span class="line">    )  <span class="comment"># border to remove  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接后的图像img4和对应的标注labels4</span></span><br><span class="line">    <span class="keyword">return</span> img4, labels4</span><br></pre></td></tr></table></figure>

<h2 id="3-网络结构"><a href="#3-网络结构" class="headerlink" title="3.网络结构"></a>3.网络结构</h2><p>从输入层到输出层，讲解网络各层及结构的逻辑 会用清晰的“主线逻辑”串联复杂结构</p>
<h3 id="1-网络结构可视化"><a href="#1-网络结构可视化" class="headerlink" title="1.网络结构可视化"></a>1.网络结构可视化</h3><p>如果想要更直观的查看模型结构，可以使用模型可视化工具，比如<a href="https://github.com/lutzroeder/netron?tab=readme-ov-file">Netron</a>，但如果直接导入<code>yolov5s.pt</code> 模型时，展示的结构会不完整，只显示模块名称，看不出实际的数据流动细节，这时需要将<code>pt</code>格式转化为<code>onnx</code>格式。</p>
<blockquote>
<p><strong>ONNX（Open Neural Network Exchange）​</strong>​ 是一种开放格式，用于表示和交换深度学习模型。它的核心作用是让不同框架（如PyTorch、TensorFlow）训练的模型能够互相转换和运行。</p>
</blockquote>
<h4 id="1-ONNX模型导出"><a href="#1-ONNX模型导出" class="headerlink" title="1.ONNX模型导出"></a>1.ONNX模型导出</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先安装</span></span><br><span class="line">pip install onnx</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">转换成onnx文件</span></span><br><span class="line">python export.py --weights yolov5s.pt --include onnx</span><br></pre></td></tr></table></figure>
<h4 id="2-ONNX模型可视化"><a href="#2-ONNX模型可视化" class="headerlink" title="2.ONNX模型可视化"></a>2.ONNX模型可视化</h4><p>Netron支持多种方式可视化，我们可以通过浏览器地址<a href="https://netron.app/">Netron</a>加载<code>.onnx</code>模型：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/yolov5s.onnx.png"></p>
<h3 id="2-网络结构配置解读"><a href="#2-网络结构配置解读" class="headerlink" title="2.网络结构配置解读"></a>2.网络结构配置解读</h3><h4 id="1-核心模块"><a href="#1-核心模块" class="headerlink" title="1.核心模块"></a>1.核心模块</h4><h5 id="1-Conv模块（标准卷积模块）"><a href="#1-Conv模块（标准卷积模块）" class="headerlink" title="1.Conv模块（标准卷积模块）"></a>1.Conv模块（标准卷积模块）</h5><p>结构：Conv → BatchNorm → SiLU（激活函数）<br>作用：</p>
<ul>
<li>提取局部特征（边缘、纹理、角点等）</li>
<li>下采样（如果步长 &gt; 1）</li>
<li>控制通道数量，压缩或扩展特征图维度</li>
</ul>
<h5 id="2-C3模块（残差模块）"><a href="#2-C3模块（残差模块）" class="headerlink" title="2.C3模块（残差模块）"></a>2.C3模块（残差模块）</h5><p>结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">       ┌────────────┐</span><br><span class="line">input──┴─┐        ┌─┴─────┐</span><br><span class="line">         └─&gt; Bottleneck ──┤</span><br><span class="line">               × N次      └──&gt; Concat + Conv → output</span><br></pre></td></tr></table></figure>
<ul>
<li>输入被<strong>一分为二</strong></li>
<li>一部分走多个 Bottleneck 残差单元（默认含卷积 + 残差连接）</li>
<li>一部分不变</li>
<li>最后两者 Concatenate → 再接个卷积融合<br>作用：</li>
<li>提高特征提取能力</li>
<li>控制模型计算量（参数量比 ResNet 少）</li>
<li>保留不同路径的特征信息（浅+深）</li>
</ul>
<h5 id="3-SPPF模块（Spatial-Pyramid-Pooling-Fast）"><a href="#3-SPPF模块（Spatial-Pyramid-Pooling-Fast）" class="headerlink" title="3.SPPF模块（Spatial Pyramid Pooling - Fast）"></a>3.SPPF模块（Spatial Pyramid Pooling - Fast）</h5><p>结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input ──────────────┐</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                ↓</span><br><span class="line">   └─────Concat────→ Conv → output</span><br></pre></td></tr></table></figure>
<ul>
<li>连续做 <strong>3 次相同核大小的最大池化</strong></li>
<li>所得多个特征图拼接</li>
<li>最后再通过卷积融合<br>作用：</li>
<li><strong>扩展感受野</strong>：融合不同尺度空间上下文信息</li>
<li><strong>增强特征表达</strong>：尤其适合大目标或上下文强依赖的情况</li>
</ul>
<h5 id="4-Concat（特征拼接）"><a href="#4-Concat（特征拼接）" class="headerlink" title="4.Concat（特征拼接）"></a>4.Concat（特征拼接）</h5><p>结构：<br>Concat 模块没有卷积，它只是<strong>把来自不同层的特征图在通道维度拼接在一起</strong><br>作用：</p>
<ul>
<li>融合上采样后的特征图和 backbone 中较浅层（如 P3&#x2F;P4）的特征</li>
<li>提高模型对不同尺度目标的检测能力</li>
</ul>
<h5 id="5-上采样模块（nn-Upsample）"><a href="#5-上采样模块（nn-Upsample）" class="headerlink" title="5.上采样模块（nn.Upsample）"></a>5.上采样模块（nn.Upsample）</h5><p>结构：<br>PyTorch 内置上采样模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>作用：<br><strong>将特征图放大（恢复空间分辨率）</strong>，常用于：</p>
<ul>
<li>将深层（小尺寸）特征图上采样，和浅层（大尺寸）特征图进行拼接</li>
<li>类似 U-Net 中的上采样路径</li>
</ul>
<h5 id="5-Detect"><a href="#5-Detect" class="headerlink" title="5.Detect"></a>5.Detect</h5><p>为每个网格（每个 anchor）预测：    </p>
<ul>
<li>边界框坐标（x, y, w, h）</li>
<li>置信度（objectness）</li>
<li>类别概率（cls）</li>
</ul>
<h4 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2.网络结构"></a>2.网络结构</h4><p>YOLOv5s（small 版本）网络结构，包括超参数、骨干网络（backbone）和检测头（head）：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">models/yolov5s.yaml/</span></span><br><span class="line"><span class="comment"># 1. 超参数配置Parameters  </span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">80</span> <span class="comment"># 分类数量（COCO数据集中为80类） </span></span><br><span class="line"><span class="attr">depth_multiple:</span> <span class="number">0.33</span> <span class="comment"># 模块深度缩放因子（用于控制网络深度）</span></span><br><span class="line"><span class="attr">width_multiple:</span> <span class="number">0.50</span> <span class="comment"># 通道宽度缩放因子（用于控制网络宽度）</span></span><br><span class="line"><span class="attr">anchors:</span>  <span class="comment"># 不同特征层的锚框设置</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>] <span class="comment"># P3/8  </span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>] <span class="comment"># P4/16  </span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>] <span class="comment"># P5/32  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># depth_multiple和width_multiple控制模型轻量化，S版用的是最小的系数，表示较浅且窄的网络结构</span></span><br><span class="line"><span class="comment"># anchors是先验框的大小列表，每行表示一个输出尺度（3个）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOLOv5 v6.0 backbone（主干网络）</span></span><br><span class="line"><span class="comment"># 主干网络负责提取特征，基本上是由卷积层（Conv）、C3模块、SPPF模块组成</span></span><br><span class="line"><span class="attr">backbone:</span>  </span><br><span class="line">  <span class="comment"># [from, number, module, args]  </span></span><br><span class="line">  <span class="comment"># from: 当前层的输入来自哪一层（-1 表示上一层）</span></span><br><span class="line">  <span class="comment"># number: 当前模块重复几次（比如 C3 模块可重复多次）</span></span><br><span class="line">  <span class="comment"># module: 模块名称，比如 Conv, C3, SPPF</span></span><br><span class="line">  <span class="comment"># args: 模块的参数，具体由模块类型决定</span></span><br><span class="line">  [  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]], <span class="comment"># 通道64 卷积6*6 步长2 padding2 </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 通道128 卷积3*3 步长2</span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">128</span>]],  <span class="comment"># 通道128</span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 3-P3/8  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">6</span>, <span class="string">C3</span>, [<span class="number">256</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 5-P4/16  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">9</span>, <span class="string">C3</span>, [<span class="number">512</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 7-P5/32  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">1024</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">SPPF</span>, [<span class="number">1024</span>, <span class="number">5</span>]], <span class="comment"># 通道1024 池化核 5</span></span><br><span class="line">  ]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># YOLOv5 v6.0 head  </span></span><br><span class="line"><span class="comment"># head作用：将主干网络（backbone）提取到的特征图转化为目标检测的最终结果：即边界框、置信度、以及每个类别的概率</span></span><br><span class="line"><span class="attr">head:</span> [  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">nn.Upsample</span>, [<span class="string">None</span>, <span class="number">2</span>, <span class="string">&quot;nearest&quot;</span>]],  <span class="comment"># 使用最近邻插值方法特征图尺寸扩大2倍</span></span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">6</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat backbone P4  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">512</span>, <span class="literal">False</span>]], <span class="comment"># 输出通道数512  不使用残差连接</span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">nn.Upsample</span>, [<span class="string">None</span>, <span class="number">2</span>, <span class="string">&quot;nearest&quot;</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">4</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat backbone P3  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">256</span>, <span class="literal">False</span>]], <span class="comment"># 17 (P3/8-small)  </span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">14</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat head P4  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">512</span>, <span class="literal">False</span>]], <span class="comment"># 20 (P4/16-medium)  </span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">10</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat head P5  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">1024</span>, <span class="literal">False</span>]], <span class="comment"># 23 (P5/32-large)  </span></span><br><span class="line">  </span><br><span class="line">    [[<span class="number">17</span>, <span class="number">20</span>, <span class="number">23</span>], <span class="number">1</span>, <span class="string">Detect</span>, [<span class="string">nc</span>, <span class="string">anchors</span>]], <span class="comment"># nc分类数量  anchors锚框</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>
<h4 id="3-模型解析"><a href="#3-模型解析" class="headerlink" title="3.模型解析"></a>3.模型解析</h4><h5 id="1-模型构建"><a href="#1-模型构建" class="headerlink" title="1.模型构建"></a>1.模型构建</h5><p><code>DetectionModel.__init__</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg=<span class="string">&quot;yolov5s.yaml&quot;</span>, ch=<span class="number">3</span>, nc=<span class="literal">None</span>, anchors=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>加载并解析 YAML 配置文件，构建模型字典 self.yaml</li>
<li>如果传入 nc 或 anchors 会覆盖配置文件中的默认值</li>
<li>调用 parse_model(…) 来解析模型结构（构建 backbone、neck、head 等）</li>
<li>设置类别名 self.names，默认是 [0, 1, …, nc-1]</li>
<li>若最后一层是 Detect 或 Segment，还会：<ul>
<li>构建 stride（下采样倍数）</li>
<li>调整 anchors（除以 stride）</li>
<li>初始化偏置项 self._initialize_biases()</li>
</ul>
</li>
<li>初始化网络权重：initialize_weights(self)</li>
<li>打印模型信息：self.info()</li>
</ul>
<h5 id="2-前向传播阶段"><a href="#2-前向传播阶段" class="headerlink" title="2.前向传播阶段"></a>2.前向传播阶段</h5><p>调用 model(x) 会触发：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, augment=<span class="literal">False</span>, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>默认进入 _forward_once(x)</li>
<li>如果 augment&#x3D;True，则走增强推理 _forward_augment(x) 分支（多尺度+翻转）</li>
<li>profile 和 visualize 是可选功能：性能分析、特征可视化</li>
</ul>
<h5 id="3-forward-once"><a href="#3-forward-once" class="headerlink" title="3.forward_once"></a>3.forward_once</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_once</span>(<span class="params">self, x, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>遍历 self.model 中的每一层模块</li>
<li>如果 m.f !&#x3D; -1，说明当前模块依赖前面某一层的输出</li>
<li>执行前向传播：x &#x3D; m(x)</li>
<li>如果 m.i in self.save，就将输出 x 保存到 y 中</li>
<li>如果 visualize&#x3D;True，还会进行特征可视化<br>最终返回最后一层输出 x，对于 Detect&#x2F;Segment 模块，输出格式如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Detect:</span></span><br><span class="line"><span class="keyword">return</span> (batch, num_predictions, <span class="number">85</span>) -&gt; (x, y, w, h, obj_conf, class_probs)</span><br><span class="line"><span class="comment"># Segment:</span></span><br><span class="line"><span class="keyword">return</span> (x, proto) <span class="keyword">or</span> (x0, proto, x1) depending on mode</span><br></pre></td></tr></table></figure>
<p>最终返回最后一层输出 x，对于 Detect&#x2F;Segment 模块，输出格式如下：</p>
<h5 id="4-Detect-Segment-模块解析"><a href="#4-Detect-Segment-模块解析" class="headerlink" title="4.Detect&#x2F;Segment 模块解析"></a>4.Detect&#x2F;Segment 模块解析</h5><p>Detect 是检测 head，会根据 anchor&#x2F;grid 解码预测框：</p>
<ul>
<li>分类数 nc，每个输出通道为 no &#x3D; nc + 5（中心、宽高、置信度、分类概率）</li>
<li>anchor&#x2F;grid 是在首次前向推理中动态计算的</li>
<li>推理时输出 (batch, anchors × grid_x × grid_y, no)</li>
</ul>
<p>Segment 继承自 Detect，额外处理 mask 信息：    </p>
<ul>
<li>输出通道为 no &#x3D; 5 + nc + nm，其中 nm 是 mask 数量</li>
<li>使用 Proto 结构生成原型掩膜</li>
</ul>
<h5 id="5-增强推理（-forward-augment）"><a href="#5-增强推理（-forward-augment）" class="headerlink" title="5.增强推理（_forward_augment）"></a>5.增强推理（_forward_augment）</h5><p>通过缩放和翻转图像进行多尺度推理增强:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_augment</span>(<span class="params">self, x</span>):</span><br></pre></td></tr></table></figure>
<ul>
<li>对每个缩放比例和翻转方向进行推理</li>
<li>对输出结果反向还原：_descale_pred()</li>
<li>拼接所有预测结果：torch.cat(…)</li>
<li>修剪增强推理中的冗余部分：_clip_augmented(…)</li>
</ul>
<h2 id="4-训练流程与策略"><a href="#4-训练流程与策略" class="headerlink" title="4.训练流程与策略"></a>4.训练流程与策略</h2><h3 id="1-训练流程"><a href="#1-训练流程" class="headerlink" title="1.训练流程"></a>1.训练流程</h3><h4 id="1-日志记录与文件保存​"><a href="#1-日志记录与文件保存​" class="headerlink" title="1.日志记录与文件保存​"></a>1.日志记录与文件保存​</h4><p>YOLOv5 在训练过程中，不仅会在控制台输出训练信息，还会将大量有价值的训练信息保存到日志中。每次训练都会在runs&#x2F;train下生成一个exp文件夹:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">runs/train/exp4/</span><br><span class="line">├── F1_curve.png # F1 分数随阈值变化的曲线</span><br><span class="line">├── PR_curve.png # Precision-Recall 曲线，用于衡量模型在不同阈值下的性能</span><br><span class="line">├── P_curve.png # Precision（查准率）随置信度阈值的变化曲线</span><br><span class="line">├── R_curve.png # Recall（查全率）曲线</span><br><span class="line">├── confusion_matrix.png # 混淆矩阵图，用于展示不同类别的预测混淆情况（分类任务中常用）</span><br><span class="line">├── events.out.tfevents.xxx.xx # TensorBoard 记录文件</span><br><span class="line">├── hyp.yaml # 训练超参数（如学习率、IoU 阈值、损失权重等）</span><br><span class="line">├── labels.jpg # 展示训练集中标注框的分布情况</span><br><span class="line">├── labels_correlogram.jpg # 类别之间的相关性热力图（适合多标签任务）</span><br><span class="line">├── opt.yaml # 训练过程中的各种配置参数（命令行参数的备份）</span><br><span class="line">├── results.csv # 每个epoch的指标记录表格</span><br><span class="line">├── results.png # 包含loss、mAP、Precision、Recall等关键训练指标随epoch变化的曲线图</span><br><span class="line">├── train_batch0.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── train_batch1.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── train_batch2.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── val_batch0_labels.jpg # 验证集图像及其真实标签框</span><br><span class="line">├── val_batch0_pred.jpg # 验证集图像的模型预测结果</span><br><span class="line">└── weights # 用于保存模型权重文件</span><br><span class="line">    ├── best.pt # 验证集上效果最好的模型权重（val_loss 最低的）</span><br><span class="line">    └── last.pt # 训练过程中最后一次保存的模型权重（最后一个 epoch）</span><br></pre></td></tr></table></figure>
<h4 id="2-模型加载与初始化​"><a href="#2-模型加载与初始化​" class="headerlink" title="2. 模型加载与初始化​"></a>2. 模型加载与初始化​</h4><p>训练开始前，YOLOv5 会进行一系列初始化设置：</p>
<ul>
<li><strong>设置随机种子</strong>，保证结果可复现</li>
<li><strong>读取数据配置文件</strong>（如 data.yaml），确定类别数和路径</li>
<li><strong>检查数据集路径和配置是否正确</strong>，防止路径错误导致训练失败</li>
</ul>
<h4 id="3-模型构建与加载权重"><a href="#3-模型构建与加载权重" class="headerlink" title="3.模型构建与加载权重"></a>3.模型构建与加载权重</h4><p>模型的构建依赖配置文件（如 yolov5s.yaml），源码会根据结构定义逐层构建模型。<br>如果本地已经存在预训练模型（如 yolov5s.pt），则会优先加载本地模型；否则，会从 YOLOv5 的官方仓库自动下载。建议提前下载，以避免自动下载速度较慢。</p>
<h4 id="4-迁移学习与冻结层设置"><a href="#4-迁移学习与冻结层设置" class="headerlink" title="4.迁移学习与冻结层设置"></a>4.迁移学习与冻结层设置</h4><p>YOLOv5 支持迁移学习，即在预训练模型基础上进行微调。你可以选择是否“冻结”部分网络层（通常是 backbone 部分）来保留其预训练特征。<br>实践中发现：<strong>即便只用几十张图片，在不冻结层的情况下也能获得不错的检测效果</strong>。因此除非数据量特别小或训练不稳定，通常不需要特意冻结层。</p>
<h4 id="5-梯度累积机制：nbs-参数的作用"><a href="#5-梯度累积机制：nbs-参数的作用" class="headerlink" title="5.梯度累积机制：nbs 参数的作用"></a>5.梯度累积机制：nbs 参数的作用</h4><p>YOLOv5 中引入了 <strong>梯度累积（Gradient Accumulation）</strong> 机制，主要通过 nbs 参数控制。<br>举个例子：</p>
<ul>
<li>如果 batch size 为 16，nbs 为 64，那么模型会累积 4 个 batch 的梯度再进行一次反向传播更新。</li>
<li><strong>优点</strong>：在显存受限的设备上模拟更大的 batch size，提高训练稳定性和效果。<br>这个机制通过代码实现了变相扩大 batch size，有助于更稳定地更新模型权重。</li>
</ul>
<h4 id="6-优化器与学习率调度"><a href="#6-优化器与学习率调度" class="headerlink" title="6.优化器与学习率调度"></a>6.优化器与学习率调度</h4><p>优化器方面，YOLOv5 将模型参数分组处理（如偏置项、权重项分别优化），并支持如下优化策略：</p>
<ul>
<li>初始学习率、动量、权重衰减等参数可配置</li>
<li>支持多种 <strong>学习率衰减策略</strong>（如余弦衰减 CosineLR）</li>
<li>提供完整的学习率调度函数，借鉴了多个经典文献<br>虽然这部分源码涉及的数学细节较多，但理解其核心目的即可——<strong>随着训练迭代，逐步降低学习率，提高模型稳定性与精度</strong>。</li>
</ul>
<h3 id="2-训练策略"><a href="#2-训练策略" class="headerlink" title="2.训练策略"></a>2.训练策略</h3><h4 id="1-断点续训逻辑"><a href="#1-断点续训逻辑" class="headerlink" title="1.断点续训逻辑"></a>1.断点续训逻辑</h4><p>YOLOv5 支持断点续训，便于训练中断后的恢复。其机制如下：</p>
<ol>
<li><strong>加载断点模型</strong><ul>
<li>当我们指定了一个断点模型（如 –weights&#x3D;weights&#x2F;last.pt），YOLOv5 会自动加载上次训练时保存的所有状态（模型参数、优化器状态、学习率调度器状态、EMA等）。</li>
</ul>
</li>
<li><strong>自动判断是否继续训练</strong><ul>
<li>假设我们上次训练了 150 个 epoch，现在使用 –epochs 100 启动新的训练。</li>
<li>YOLOv5 会检查当前模型的已训练轮数。如果已经超过 100（如已训练 150），则不会再训练；如果未达到（如当前为 80），则会 <strong>继续训练剩余的轮数</strong>（此例中为 20）。</li>
</ul>
</li>
<li><strong>额外保存模型（双重保险）</strong><ul>
<li>加载断点模型后，YOLOv5 会额外保存一次模型权重。这一操作的初衷似乎是为了保险——防止覆盖原有模型。</li>
<li>实测表明：加载模型并不会覆盖原始权重文件。这个多保存一次的逻辑目前看起来意义不大，反而增加了存储负担，不过可以理解为一种“冗余备份机制”。</li>
</ul>
</li>
</ol>
<h4 id="2-图像尺寸校验逻辑（gs-检查）"><a href="#2-图像尺寸校验逻辑（gs-检查）" class="headerlink" title="2.图像尺寸校验逻辑（gs 检查）"></a>2.图像尺寸校验逻辑（gs 检查）</h4><p>在训练前，YOLOv5 会校验输入图像的尺寸是否符合网络结构要求。主要逻辑如下：</p>
<ul>
<li>YOLOv5 的 backbone 下采样倍数为 32，因此输入图像尺寸必须能被 32 整除（如 640×640）。</li>
<li>gs（grid size） 就是该下采样因子。如果尺寸不满足要求，会报错或自动调整图像尺寸。<br>这一检查确保了网络中卷积和特征图尺寸的兼容性，是非常基础但关键的一步。</li>
</ul>
<h4 id="3-EMA（滑动平均）机制的作用"><a href="#3-EMA（滑动平均）机制的作用" class="headerlink" title="3.EMA（滑动平均）机制的作用"></a>3.EMA（滑动平均）机制的作用</h4><p>YOLOv5 默认启用了 <strong>EMA（Exponential Moving Average）</strong>：</p>
<ul>
<li>通过对模型参数的历史状态进行滑动平均，生成一个更稳定的权重；</li>
<li>EMA 权重会用于最终评估和保存（best.pt），因为其结果通常更平滑、鲁棒性更强。</li>
</ul>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>YOLOv5是一个高度工程优化的目标检测框架，核心特点包括：</p>
<ol>
<li>​<strong>工程友好</strong>​：模块化代码结构清晰，支持快速训练自定义数据集（只需规范数据格式并修改YAML配置）</li>
<li>​<strong>高效训练</strong>​：集成Mosaic&#x2F;MixUp数据增强、梯度累积（nbs参数）、EMA权重平均等技术，提升模型泛化能力</li>
<li>​<strong>灵活部署</strong>​：提供Nano到XLarge多规格预训练模型，适配从嵌入式设备到服务器的不同场景</li>
<li>​<strong>全流程支持</strong>​：训练中自动记录日志、可视化指标（如PR曲线）、保存最佳模型（best.pt），便于调试和部署</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割与U-Net系列模型解析</title>
    <url>/2025/05/19/016-image-segmentation-u-net/</url>
    <content><![CDATA[<h2 id="1-图像分割"><a href="#1-图像分割" class="headerlink" title="1.图像分割"></a>1.图像分割</h2><p>虽然图像分割（Image Segmentation）与目标检测（Object Detection）都属于计算机视觉中的视觉识别任务，但它们的目标、输出形式和应用场景各不相同：</p>
<ul>
<li><strong>目标检测（Object Detection）</strong>：找出图像中有哪些物体，并框出每个物体的位置，比如说检测行人、车辆，以边界框 + 类别标签为输出形式。</li>
<li><strong>图像分割（Image Segmentation）</strong>：精确地标出图像中每个像素属于哪个类别，以每个像素的类别标签为输出形式。</li>
</ul>
<span id="more"></span>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250514143841.png"></p>
<p>举个例子：</p>
<ul>
<li>左图是目标检测任务，把人框出来。</li>
<li>右图是图像分割任务，每个像素都需要判断是属于“人”还是背景，类似于 Photoshop 中的“抠图”。</li>
</ul>
<p>图像分割任务可以分为：</p>
<h3 id="1-语义分割（Semantic-Segmentation）"><a href="#1-语义分割（Semantic-Segmentation）" class="headerlink" title="1.语义分割（Semantic Segmentation）"></a>1.语义分割（Semantic Segmentation）</h3><p> 把图像中的像素分为不同类别，同类的像素标注为相同颜色，<strong>不用区分个体</strong>。例如，如下图中5个人都被标注为“人类”类别，不需要区分谁是谁。</p>
<h3 id="2-实例分割（Instance-Segmentation）"><a href="#2-实例分割（Instance-Segmentation）" class="headerlink" title="2.实例分割（Instance Segmentation）"></a>2.实例分割（Instance Segmentation）</h3><p>不仅区分类别，还要<strong>区分每个实例</strong>。例如下图中5个人都属于“人类”类别，但每个人都需要被单独标记出来。</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250519132413.png"></p>
<p>目标检测中我们需要预测的是几个坐标点（回归问题），而图像分割中我们需要对<strong>每一个像素点</strong>做分类，最基础的图像分割是<strong>前景 vs 背景（二分类）</strong>，更高级一点的是<strong>多类别语义分割</strong>或<strong>实例分割</strong>。<br>换句话说，图像分割就是一个<strong>逐像素的分类任务（per-pixel classification）</strong></p>
<h2 id="2-分割任务损失函数"><a href="#2-分割任务损失函数" class="headerlink" title="2.分割任务损失函数"></a>2.分割任务损失函数</h2><p>在图像分割任务中，我们的目标是对图像中的每一个像素点进行分类——判断它是属于前景（如人、车、树等）还是背景。那我们该如何衡量模型预测的效果好坏呢？和其他深度学习任务一样，我们也需要一个<strong>损失函数</strong>。而图像分割中最常用的损失函数有两个<strong>加权交叉熵损失（Weighted Cross Entropy Loss）以及Focal Loss</strong>。</p>
<h3 id="1-加权交叉熵损失（Weighted-Cross-Entropy-Loss）"><a href="#1-加权交叉熵损失（Weighted-Cross-Entropy-Loss）" class="headerlink" title="1.加权交叉熵损失（Weighted Cross Entropy Loss）"></a>1.加权交叉熵损失（Weighted Cross Entropy Loss）</h3><h4 id="1-逐像素的交叉熵损失"><a href="#1-逐像素的交叉熵损失" class="headerlink" title="1. 逐像素的交叉熵损失"></a>1. 逐像素的交叉熵损失</h4><p>在最基础的语义分割任务中，我们对每个像素点预测其类别，并与真实标签进行比较，这和图像分类任务是一样的，只不过粒度从“整张图”变成了“每个像素”，这就是<strong>交叉熵损失函数</strong>（Cross Entropy Loss），公式如下：<br>$$\mathcal{L}{CE} &#x3D; - \sum{i} y_i \log(p_i)$$<br>其中：</p>
<ul>
<li>$i$ 类别索引，表示当前样本可能属于的各个类别</li>
<li>$y_i$ 是真实标签（通常是one-hot编码）</li>
<li>$p_i$ 是模型对该像素属于类别 $i$ 的预测概率</li>
</ul>
<h4 id="2-加入前景-背景的不平衡权重（加权交叉熵）"><a href="#2-加入前景-背景的不平衡权重（加权交叉熵）" class="headerlink" title="2. 加入前景&#x2F;背景的不平衡权重（加权交叉熵）"></a>2. 加入前景&#x2F;背景的不平衡权重（加权交叉熵）</h4><p>而在图像中，前景往往只占很小一部分，绝大多数像素都是背景。如果我们直接用普通交叉熵损失，那模型可能更倾向于“全部预测成背景”，这会导致训练不收敛或结果不理想。</p>
<p>因此，我们可以<strong>引入一个权重项</strong>，对前景像素赋予更高的权重，从而让模型更关注“稀有”的前景目标。这个权重可以根据前景和背景的像素数比例自动计算，也可以手动指定。<br>$$\mathcal{L}_{WCE} &#x3D; - \alpha \cdot y \log(p) - (1 - \alpha) \cdot (1 - y) \log(1 - p)$$<br>其中：</p>
<ul>
<li>$\alpha$ 是正样本（前景）的权重，值越大，模型对前景越敏感</li>
</ul>
<h3 id="2-Focal-Loss"><a href="#2-Focal-Loss" class="headerlink" title="2.Focal Loss"></a>2.Focal Loss</h3><p>除了数量上的不平衡，其实还有一个更细致的问题——有些像素点<strong>很好判断</strong>（比如大片背景或目标内部），而有些像素点<strong>非常难判断</strong>（比如目标边缘、遮挡处）。我们希望模型<strong>更加关注这些难判断的像素点</strong>。</p>
<p>这时候就要引入著名的<strong>Focal Loss</strong>：<br>$$\mathcal{L}_{focal} &#x3D; -\alpha (1 - p_t)^{\gamma} \log(p_t)$$<br>其中：</p>
<ul>
<li>$p_t$ 表示模型对真实类别的预测概率</li>
<li>$\gamma$ 是调节因子，一般设为 2</li>
<li>$\alpha$ 是样本类别的权重（和上面公式一样）</li>
</ul>
<p>这个公式的核心思想是：</p>
<ul>
<li>对于预测非常准确（$p_t \approx 1$）的样本，损失值被显著缩小</li>
<li>对于预测错误的样本（$p_t$ 小），损失值被放大<br>也就是说，Focal Loss <strong>会自动弱化容易分类的像素点、增强难分类像素点的权重</strong>，从而引导模型重点学习更有价值的信息。</li>
</ul>
<h3 id="3-加权交叉熵-Focal-Loss"><a href="#3-加权交叉熵-Focal-Loss" class="headerlink" title="3.加权交叉熵+Focal Loss"></a>3.加权交叉熵+Focal Loss</h3><p>加权交叉熵的关注点在于<strong>类别样本不均衡</strong>，而Focal Loss的关注点在于<strong>像素点难易程度不同</strong>。</p>
<p>在实际任务中，我们可以将这两者结合起来使用，例如使用带权重的Focal Loss：<br>$$\mathcal{L} &#x3D; - \alpha (1 - p_t)^\gamma \log(p_t)$$<br>其中：</p>
<ul>
<li><strong>权重 α：物以稀为贵。</strong> 前景像素少，就要给它更高的权重，像打游戏爆稀有装备一样，越少越珍贵</li>
<li><strong>调节因子 γ：难者多得分。</strong> 越是难分类的像素（比如目标边缘），对训练越有价值，就像我们抄错题、练习难题一样，要多加关注</li>
</ul>
<h2 id="3-语义分割中的评估指标"><a href="#3-语义分割中的评估指标" class="headerlink" title="3.语义分割中的评估指标"></a>3.语义分割中的评估指标</h2><p>训练完模型后，我们还需要评估模型的效果，<strong>IoU（Intersection over Union）</strong> 是语义分割中最常用的评估指标。</p>
<h3 id="1-IoU（Intersection-over-Union）"><a href="#1-IoU（Intersection-over-Union）" class="headerlink" title="1.IoU（Intersection over Union）"></a>1.IoU（Intersection over Union）</h3><p>IoU 表示的是预测区域与真实区域的交集与并集之比，公式如下：<br>$$\text{IoU} &#x3D; \frac{\text{Intersection}}{\text{Union}}$$</p>
<ul>
<li><strong>Intersection（交集）</strong>：预测为某类且真实也为该类的像素数量</li>
<li><strong>Union（并集）</strong>：预测为该类的像素数量 + 真实为该类的像素数量 − Intersection<br>在<strong>混淆矩阵</strong>中，IoU 的计算方式可以看作：<br>$$\text{IoU}_\text{class} &#x3D; \frac{TP}{TP + FP + FN}$$<br>其中：</li>
<li>TP（True Positive）：预测正确的正类</li>
<li>FP（False Positive）：误判为该类的像素</li>
<li>FN（False Negative）：漏判为其他类的像素</li>
</ul>
<h3 id="2-平均-IoU（mIoU）"><a href="#2-平均-IoU（mIoU）" class="headerlink" title="2.平均 IoU（mIoU）"></a>2.平均 IoU（mIoU）</h3><p>由于语义分割通常包含多个类别，我们通常会计算<strong>所有类别的 IoU</strong>，然后取平均，得到 <strong>mean IoU (mIoU)</strong>：<br>$$\text{mIoU} &#x3D; \frac{1}{C} \sum_{c&#x3D;1}^{C} \text{IoU}_c$$<br>这就像是多个类别下的 IoU 的加权平均，是衡量模型整体性能的核心指标。</p>
<h2 id="4-U-Net-网络结构"><a href="#4-U-Net-网络结构" class="headerlink" title="4.U-Net 网络结构"></a>4.U-Net 网络结构</h2><p>U-Net 是一种非常经典的语义分割网络，最初发表于 2015-2016 年，专为<strong>医学图像分割</strong>设计，因为其结构简单后来被广泛应用于各种像素级任务。因为整体结构：像字母U的形状，所以叫<strong>U-Net</strong>。</p>
<p>如下图，U-Net 是一个<strong>对称结构</strong>，左边下采样提取语义，右边上采样还原细节，跳跃连接帮助拼接高精度特征，最终生成和输入尺寸接近的像素级预测图。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250514150209.png"></p>
<h3 id="1-结构设计"><a href="#1-结构设计" class="headerlink" title="1.结构设计"></a>1.结构设计</h3><p> 可以类比为“编码-解码”的思想（像 Sequence-to-Sequence）</p>
<table>
<thead>
<tr>
<th><strong>模块</strong></th>
<th><strong>功能</strong></th>
<th><strong>类比</strong></th>
</tr>
</thead>
<tbody><tr>
<td>编码器（左边）</td>
<td>下采样，提取语义特征</td>
<td>像人眼看整体轮廓，从模糊到清晰</td>
</tr>
<tr>
<td>解码器（右边）</td>
<td>上采样，恢复空间分辨率，生成 mask</td>
<td>像放大镜一点点拼出目标的精细形状</td>
</tr>
<tr>
<td>跳跃连接（中间横线）</td>
<td>保留细节，连接浅层特征到深层输出</td>
<td>就像复习时要结合课本基础和考试重点一起理解</td>
</tr>
</tbody></table>
<h4 id="1-编码器（Contracting-Path）"><a href="#1-编码器（Contracting-Path）" class="headerlink" title="1.编码器（Contracting Path）"></a>1.编码器（Contracting Path）</h4><p>编码器的主要作用是，<strong>提取抽象语义特征 + 下采样</strong>。采用多个卷积 + ReLU + MaxPooling 层，逐步下采样（比如 256→128→64…），每个阶段是两个3 $\times$ 3卷积（蓝色箭头）+ ReLU，后跟一个2 $\times$ 2 max pooling（红色箭头）。随着层数加深，<strong>空间分辨率变小</strong>（572 → 284 → … → 28），<strong>通道数增多</strong>（64 → 128 → … → 1024），特征越粗，语义越强。<br>示例：</p>
<ul>
<li>第一层输入大小为 <strong>572×572×1</strong>（单通道图像）</li>
<li>卷积后输出：<strong>568×568×64</strong>（因为 3×3 卷积没有 padding）</li>
<li>然后 max pooling：下采样为 <strong>284×284×64</strong></li>
</ul>
<p>下采样（编码器）的作用：逐层抽象全局轮廓**​</p>
<ul>
<li>​<strong>感受野扩大</strong>​：通过池化&#x2F;卷积步长降低分辨率，每个神经元能覆盖更大图像区域，捕获整体结构（如器官形状、物体位置）</li>
<li>​<strong>高级语义提取</strong>​：深层网络识别抽象特征（如”这是肺部CT”而非像素级纹理），类似人类先看”大致轮廓”</li>
<li>​<strong>抗噪声干扰</strong>​：压缩空间信息后，对小位移和噪声更鲁棒</li>
</ul>
<h4 id="2-解码器（Expansive-Path）"><a href="#2-解码器（Expansive-Path）" class="headerlink" title="2.解码器（Expansive Path）"></a>2.解码器（Expansive Path）</h4><p>解码器的主要作用是<strong>上采样恢复原图尺寸 + 分割掩码生成</strong>。每个阶段是一次<strong>转置卷积</strong>（绿色箭头）进行上采样，然后将对应分辨率的特征图拼接（灰色箭头），再做两个 3 $\times$ 3 卷积（蓝色箭头）。<br>使用转置卷积（或上采样）逐步还原分辨率，每次上采样后，都把<strong>对应的编码器特征“跳跃连接”过来</strong>，拼接后再卷积。这样能<strong>结合深层的语义信息</strong>和<strong>浅层的位置信息</strong>。<br>示例：</p>
<ul>
<li>中间最底部是 <strong>28×28×1024</strong></li>
<li>上采样为 <strong>56×56×512</strong>，拼接编码器的 <strong>64×64×512</strong></li>
<li>然后卷积、ReLU 处理，输出通道逐渐减小</li>
</ul>
<p>上采样（解码器）的作用：逐步恢复空间细节​</p>
<ul>
<li>​<strong>定位精细化</strong>​：通过转置卷积&#x2F;插值逐步放大特征图，结合跳跃连接（skip connection）注入编码器的底层细节（如边缘、纹理）</li>
<li>​<strong>多尺度特征融合</strong>​：跳跃连接将高层语义（”这是什么”）与底层细节（”边界在哪”）拼接，实现”轮廓指导细节”的分割</li>
<li>​<strong>分辨率恢复</strong>​：最终输出与输入同分辨率，实现像素级预测</li>
</ul>
<h4 id="3-跳跃连接（Skip-Connection）"><a href="#3-跳跃连接（Skip-Connection）" class="headerlink" title="3.跳跃连接（Skip Connection）"></a>3.跳跃连接（Skip Connection）</h4><p>每下采样一次，保留当前的特征图，解码时，把<strong>对应分辨率的编码特征图复制并拼接</strong>到解码器中。这一步也叫：<strong>copy and crop</strong>。目的是防止上采样过程丢失空间信息，补充原始的细节和边缘特征。比如编码器在 128x128 层的特征，会跳到解码器的同尺寸上一起用。防止丢失空间细节，<strong>补回精细轮廓和边缘信息</strong>。</p>
<h4 id="4-最后一层输出（右上角）"><a href="#4-最后一层输出（右上角）" class="headerlink" title="4.最后一层输出（右上角）"></a>4.最后一层输出（右上角）</h4><p>使用一个 <strong>1×1 卷积（青色箭头）</strong> 将通道数变为类别数（图中为 2 类）。最终输出尺寸为：<strong>388×388×2</strong>（每个像素对应两个类别的概率）。</p>
<p>为啥尺寸变小了？（572→388）<br>因为卷积操作没有使用 padding，每次 3×3 卷积会减少 2 个像素，两次卷积减少 4 个像素，每层下采样都会累计空间损失，所以最终输出图比输入图小（用 crop 来对齐）。</p>
<h2 id="5-U-Net-的特征融合"><a href="#5-U-Net-的特征融合" class="headerlink" title="5.U-Net 的特征融合"></a>5.U-Net 的特征融合</h2><h3 id="1-为什么要做特征融合？"><a href="#1-为什么要做特征融合？" class="headerlink" title="1. 为什么要做特征融合？"></a>1. 为什么要做特征融合？</h3><p>在深度学习做视觉任务时，总会强调“<strong>特征融合</strong>”。什么是特征融合？就是把不同层级（深浅不同）的特征信息整合起来，既有<strong>局部细节</strong>，也有<strong>全局语义</strong>。在 U-Net 结构中，典型的融合方式就是从左侧编码器（下采样路径）拿出浅层特征，传到右侧解码器（上采样路径）对应位置进行融合。如下图。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250516135607.png"></p>
<h4 id="1-基本结构说明"><a href="#1-基本结构说明" class="headerlink" title="1.基本结构说明"></a>1.基本结构说明</h4><p>每个节点 $X^{i,j}$ 表示一个特征图，来自某一层的卷积输出<br>    $i$：表示网络的<strong>深度层级</strong>（从上到下）<br>    $j$：表示在同一分辨率下的<strong>第几个操作阶段</strong>（从左到右）<br>图中三种箭头说明不同的信息流路径：</p>
<ul>
<li>下黑实箭头：<strong>下采样</strong>（Down-sampling）</li>
<li>上黑实箭头：<strong>上采样</strong>（Up-sampling）</li>
<li>虚线箭头：<strong>跳跃连接</strong>（Skip Connection）</li>
<li>所有连接都是基于 <strong>卷积操作</strong>（节点本身）</li>
</ul>
<p>U-Net 之所以分割效果好，关键就在于它把“<strong>高分辨率细节特征</strong>”和“<strong>低分辨率语义特征</strong>”融合在了一起。</p>
<h4 id="2-跳跃连接（Skip-Connections）"><a href="#2-跳跃连接（Skip-Connections）" class="headerlink" title="2.跳跃连接（Skip Connections）"></a>2.跳跃连接（Skip Connections）</h4><p>每次下采样后保留的特征（如 $X^{0,0}, X^{1,0}, X^{2,0}$…），会在解码阶段通过虚线<strong>跳跃连接</strong>到对应分辨率的上采样阶段（如 $X^{0,4}, X^{1,3}$…）。</p>
<blockquote>
<p>深层特征语义强但空间信息模糊，浅层特征保留边缘细节但语义弱。跳跃连接能<strong>组合两者优点</strong>，形成精准分割。</p>
</blockquote>
<h4 id="3-拼接-卷积融合（Concat-Conv）"><a href="#3-拼接-卷积融合（Concat-Conv）" class="headerlink" title="3.拼接 + 卷积融合（Concat + Conv）"></a>3.拼接 + 卷积融合（Concat + Conv）</h4><p>在执行上采样操作后，U-Net 会把，当前上采样结果，对应的跳跃特征图，进行 <strong>通道维度的拼接（concatenate）</strong>，再通过卷积融合，生成新的特征图。<br>$$X^{2,2} &#x3D; Conv([Up(X^{3,1}) ⊕ X^{2,0}])$$<br>把解码路径中的上采样结果和编码路径中的浅层特征拼接，<strong>再交给卷积融合</strong>，这一步实现了真正的“融合”。</p>
<h4 id="4-多尺度融合（层层递进）"><a href="#4-多尺度融合（层层递进）" class="headerlink" title="4. 多尺度融合（层层递进）"></a>4. 多尺度融合（层层递进）</h4><p>从图中可见，最终输出 $X^{0,4}$ 是逐层融合浅层和深层特征得到的。每一级都融合了不同语义层级的特征，最终形成一个<strong>丰富多尺度信息的特征图</strong>。</p>
<p>类比理解：</p>
<blockquote>
<p>就像人做图像理解时，既需要看到整体（全局语义），也需要看细节（边界线条）。U-Net 就是“全景 + 放大镜”一起看。</p>
</blockquote>
<h2 id="6-U-Net-核心结构"><a href="#6-U-Net-核心结构" class="headerlink" title="6.U-Net++ 核心结构"></a>6.U-Net++ 核心结构</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250516135710.png"></p>
<h3 id="1-整体框架设计：升级版的-U-Net"><a href="#1-整体框架设计：升级版的-U-Net" class="headerlink" title="1.整体框架设计：升级版的 U-Net"></a>1.整体框架设计：升级版的 U-Net</h3><h4 id="1-基础结构"><a href="#1-基础结构" class="headerlink" title="1.基础结构"></a>1.基础结构</h4><ul>
<li>下采样（Down-sampling）：通过卷积步长为2的方式，将特征图尺寸逐步减半（例如：96 → 48 → 24 → 12 → 6）</li>
<li>上采样（Up-sampling）：使用插值（如最近邻或双线性）将特征图尺寸恢复（例如：6 → 12 → 24 → 48 → 96）</li>
</ul>
<h4 id="2-跳跃连接与特征融合"><a href="#2-跳跃连接与特征融合" class="headerlink" title="2. 跳跃连接与特征融合"></a>2. 跳跃连接与特征融合</h4><p>不仅连接当前层与对应的对称上采样层（如传统U-Net），还连接同一层级的多个历史特征图。每一层的输出可能融合了来自多个深度和广度的特征——<strong>类似 DenseNet 的密集连接思想</strong>，表现形式上是：<br>“当前节点 &#x3D; 上采样特征 + 所有前层同级别节点的融合”。</p>
<h3 id="2-网络结构核心思想：深度特征融合"><a href="#2-网络结构核心思想：深度特征融合" class="headerlink" title="2.网络结构核心思想：深度特征融合"></a>2.网络结构核心思想：深度特征融合</h3><h4 id="1-融合机制"><a href="#1-融合机制" class="headerlink" title="1.融合机制"></a>1.融合机制</h4><p>所有能拼接的特征图都尽可能进行融合，提高特征表达的丰富性，增强网络学习能力。类似 2017 CVPR Best Paper 中提出的 DenseNet 结构。</p>
<h4 id="2-U-Net-的特征融合方式"><a href="#2-U-Net-的特征融合方式" class="headerlink" title="2. U-Net++ 的特征融合方式"></a>2. U-Net++ 的特征融合方式</h4><p>类似于“多个路径、跨层连接、分支拼接”的机制，多层次、多尺度的特征信息被汇聚到一起。</p>
<h3 id="3-辅助监督机制：多层损失引导训练"><a href="#3-辅助监督机制：多层损失引导训练" class="headerlink" title="3.辅助监督机制：多层损失引导训练"></a>3.辅助监督机制：多层损失引导训练</h3><h4 id="1-中间监督（Deep-Supervision）"><a href="#1-中间监督（Deep-Supervision）" class="headerlink" title="1.中间监督（Deep Supervision）"></a>1.中间监督（Deep Supervision）</h4><p>网络训练时，不只在最后输出层加损失函数，而是所有输出尺寸一致的位置都可以加损失函数（例如多个 96x96 大小的节点）。并且每个阶段都加以监督，因为这样有利于梯度传播、加速收敛、提升中间层质量。</p>
<p>就像看人不是只看最终是否考上大学，而是每一个阶段（小学、初中、高中）都要尽力做到最好，才能最终成功。同理，网络中每一个中间输出都应该被优化，才能提升整体性能。</p>
<p>U-Net++ 作为 U-Net 的增强版本，在分割、检测等 CV 任务中应用广泛，结构通用、效果优秀，主要改进在于：</p>
<ul>
<li><strong>多级跳跃连接和特征融合机制</strong>，强化了跨层信息的整合</li>
<li><strong>多损失辅助监督机制</strong>，提高了模型的训练效率与精度</li>
</ul>
<h2 id="7-U-Net3-改进"><a href="#7-U-Net3-改进" class="headerlink" title="7.U-Net3+改进"></a>7.U-Net3+改进</h2><p>U-Net 3+统一解码器、全尺度特征融合，结构简洁、效果更强、计算更高效。</p>
<table>
<thead>
<tr>
<th><strong>模型</strong></th>
<th><strong>特征融合策略</strong></th>
<th><strong>改进点</strong></th>
<th><strong>存在问题（相对）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>U-Net++</strong></td>
<td>深度跳跃连接 + 密集嵌套结构（Nested skip）</td>
<td>强调<strong>语义一致性</strong>，引入了<strong>密集连接路径</strong>，减缓语义鸿沟</td>
<td>路径结构复杂、融合不彻底、解码器分支多、计算开销大</td>
</tr>
<tr>
<td><strong>U-Net 3+</strong></td>
<td>全尺度融合（Full-scale skip connection）</td>
<td>引入<strong>统一解码器结构</strong>，将浅层细节和深层语义<strong>全融合</strong>，提升效果且结构简洁</td>
<td>跳跃路径更多，特征对齐成本更高</td>
</tr>
</tbody></table>
<h3 id="1-从密集嵌套连接-➜-全尺度融合"><a href="#1-从密集嵌套连接-➜-全尺度融合" class="headerlink" title="1.从密集嵌套连接 ➜ 全尺度融合"></a>1.从密集嵌套连接 ➜ 全尺度融合</h3><ul>
<li><strong>U-Net++</strong> 通过构建密集的嵌套路径（Nested decoder），增强特征流动，但每一层的解码器是独立的</li>
<li><strong>U-Net 3+</strong> 则提出：<strong>每一层解码器只保留一个</strong>，将所有尺度的编码特征、解码特征<strong>全部统一融合</strong>，更高效、结构更简单<br>本质：从“多路径拼接” ➜ “一次性大融合”</li>
</ul>
<h3 id="2-统一解码器设计（One-Decoder-to-Rule-Them-All）"><a href="#2-统一解码器设计（One-Decoder-to-Rule-Them-All）" class="headerlink" title="2.统一解码器设计（One Decoder to Rule Them All）"></a>2.统一解码器设计（One Decoder to Rule Them All）</h3><ul>
<li><strong>U-Net++</strong>：每个输出都对应一个不同的子解码器结构（解码器嵌套）</li>
<li><strong>U-Net 3+</strong>：整个网络只保留<strong>一套统一的解码器路径</strong>，避免冗余计算，减少参数</li>
</ul>
<h3 id="3-多尺度上下文建模能力更强"><a href="#3-多尺度上下文建模能力更强" class="headerlink" title="3.多尺度上下文建模能力更强"></a>3.多尺度上下文建模能力更强</h3><p>在 U-Net 3+ 中，所有<strong>编码器特征</strong>通过上采样&#x2F;下采样对齐后统一拼接，同时利用<strong>解码器中间特征</strong>，提供更深层次语义信息。这样做的结果是：在每一层融合中，模型能够同时看到：浅层，边界细节，中层：语义和上下文，深层：全局理解。</p>
<h3 id="4-更轻量，训练和推理速度更快"><a href="#4-更轻量，训练和推理速度更快" class="headerlink" title="4.更轻量，训练和推理速度更快"></a>4.更轻量，训练和推理速度更快</h3><p>虽然跳跃连接更多，但结构统一，避免了解码器重复设计，在保持准确率的前提下，整体计算量低于 U-Net++。</p>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><p>本文主要讲了：</p>
<ul>
<li>图像分割任务，对比了目标检测差异</li>
<li>语义&#x2F;实例分割区别</li>
<li>解析加权交叉熵与Focal Loss，解决样本不均衡问题</li>
<li>IoU&#x2F;mIoU评估指标。</li>
</ul>
<p>还重点剖析了U-Net系列：</p>
<ul>
<li>U-Net如何通过编码-解码结构与跳跃连接实现特征融合的</li>
<li>U-Net++引入密集嵌套连接和中间监督增强语义一致性</li>
<li>U-Net3+创新全尺度融合与统一解码器，兼顾多尺度特征与计算效率，形成从基础到高阶的模型演进路径。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
        <tag>U-Net</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Transformer的detr目标检测算法思路分析</title>
    <url>/2025/05/13/015-transformer-to-detr/</url>
    <content><![CDATA[<h2 id="1-Transformer"><a href="#1-Transformer" class="headerlink" title="1. Transformer"></a>1. Transformer</h2><p>我们可以尝试用一个例子来理解 Transformer 的各个概念。学生在课堂上进行小组讨论写作文：一个班级里有一群学生，每个学生负责贡献一句话来完成一篇作文。他们必须交流彼此的观点（信息），形成一篇通顺的文章。这就像 Transformer 处理一个序列（比如一句话）时的过程。</p>
<h3 id="1-输入嵌入（Input-Embedding）"><a href="#1-输入嵌入（Input-Embedding）" class="headerlink" title="1. 输入嵌入（Input Embedding）"></a>1. 输入嵌入（Input Embedding）</h3><p>将原始的输入（如词、图像特征等）映射到一个高维向量空间中，便于 Transformer 网络进行后续处理。</p>
<p>就像每个学生都先写好一句话的草稿，用于后续讨论。每句话被转成一个有意义的表达——每个词转成向量。</p>
<span id="more"></span>
<h3 id="2-位置编码（Positional-Encoding）"><a href="#2-位置编码（Positional-Encoding）" class="headerlink" title="2.位置编码（Positional Encoding）"></a>2.位置编码（Positional Encoding）</h3><p>Transformer 的核心​<strong>自注意力机制（Self-Attention）​</strong>，它可以捕捉序列中任意两个元素之间的关系。但自注意力本身是 ​<strong>位置无关的</strong>​：无论词在序列中的位置如何，其计算方式完全相同。例如：句子 <code>猫 坐 在 垫子 上</code> 和 <code>垫子 坐 在 猫 上</code> 对自注意力来说，仅通过词嵌入无法区分两者的位置差异。因此，必须显式注入位置信息，否则模型无法理解顺序（如时间、空间顺序）。</p>
<p>就像学生按顺序坐在座位上，这样大家知道谁先说谁后说。否则你只看学生内容（词向量）是看不出顺序的。</p>
<h3 id="3-自注意力机制（Self-Attention）"><a href="#3-自注意力机制（Self-Attention）" class="headerlink" title="3.自注意力机制（Self-Attention）"></a>3.自注意力机制（Self-Attention）</h3><p>自注意力机制（Self-Attention）是 Transformer 模型的核心组件，它通过动态计算序列中每个元素与其他元素的关联权重，捕捉全局依赖关系。这样可以有效解决长距离依赖问题，替代 RNN 的串行计算和 CNN 的局部感受野限制。<br>核心思想：每个位置的表示可以参考序列中所有其他位置的信息。输入向量被分别线性映射为： <strong>Query（Q）</strong>、<strong>Key（K）</strong>、<strong>Value（V）</strong></p>
<p>每位学生（Query）在发言前，都会环顾四周，看看别人写了什么（Key），判断谁的信息最值得参考（注意力分数），然后重点参考这些同学的原始观点（Value），用来丰富自己这次的发言。</p>
<h3 id="4-多头注意力（Multi-Head-Attention）"><a href="#4-多头注意力（Multi-Head-Attention）" class="headerlink" title="4.多头注意力（Multi-Head Attention）"></a>4.多头注意力（Multi-Head Attention）</h3><p><strong>单一注意力头</strong>​ 只能捕捉一种语义模式（如语法结构或词义关系），而 ​<strong>多个头</strong>​ 允许模型从不同维度理解上下文。可以这么类比：人类观察物体时，通过多个感官（视觉、听觉、触觉）综合理解信息。<br>将 Q、K、V 划分成多个头（head），在不同子空间中并行计算注意力。让模型从不同的表示子空间中学习信息，最终结果是多个头的输出拼接后线性变换。</p>
<p>学生不仅从一个角度看别人说了什么，而是从多个角度来看（语法角度、情感角度、逻辑结构等），综合判断。</p>
<h3 id="5-前馈神经网络（FFN）"><a href="#5-前馈神经网络（FFN）" class="headerlink" title="5.前馈神经网络（FFN）"></a>5.前馈神经网络（FFN）</h3><p><strong>前馈神经网络（Feed-Forward Network, FFN）​</strong>​ 是每个编码器和解码器层的核心组件之一，负责对自注意力或交叉注意力的输出进行非线性变换，增强模型的表达能力。</p>
<p>每位学生在吸收别人的意见后，会自己再加工一下：加些修饰、润色语句，让发言更通顺。</p>
<h3 id="6-残差连接-LayerNorm"><a href="#6-残差连接-LayerNorm" class="headerlink" title="6.残差连接 + LayerNorm"></a>6.残差连接 + LayerNorm</h3><p>每个子层（如多头注意力、FFN）后都有残差连接和 LayerNorm：LayerNorm(x + Sublayer(x))。<br>主要作用是训练深层模型，避免梯度消失，促进信息直接传递。</p>
<p>学生在参考别人的意见后，还保留了自己最初的观点（残差），并统一风格、语气（归一化），让整体更协调。</p>
<h3 id="7-编码器（Encoder）"><a href="#7-编码器（Encoder）" class="headerlink" title="7.编码器（Encoder）"></a>7.编码器（Encoder）</h3><p>编码器负责将输入序列（如文本、图像块）转换为富含上下文信息的隐藏表示。其核心任务包括：</p>
<ul>
<li>​<strong>捕捉全局依赖</strong>​：通过自注意力机制建立序列内任意位置的关联</li>
<li>​<strong>特征抽象</strong>​：逐层提取高层次语义信息</li>
<li>​<strong>位置感知</strong>​：显式注入位置编码，弥补无卷积&#x2F;循环结构的不足</li>
</ul>
<p>在这个类比中，就像老师帮助每个小组整理他们的想法（编码），形成一套清晰的观点集。</p>
<h3 id="8-解码器（Decoder）"><a href="#8-解码器（Decoder）" class="headerlink" title="8.解码器（Decoder）"></a>8.解码器（Decoder）</h3><p>解码器负责将编码器生成的上下文信息转换为目标序列（如翻译结果、生成文本），核心作用有：</p>
<ul>
<li>​<strong>自回归生成</strong>​：逐个生成目标序列元素（如逐词生成翻译结果）</li>
<li>​<strong>上下文融合</strong>​：通过交叉注意力关联源序列与目标序列</li>
<li>​<strong>位置感知</strong>​：防止解码时“偷看”未来信息（通过掩码机制）​</li>
</ul>
<p>学生们根据讨论成果（Encoder 输出），开始一段一段地写作文。每写一句，就回顾前面的句子，看看是否连贯。</p>
<h3 id="9-掩码机制（Masking）"><a href="#9-掩码机制（Masking）" class="headerlink" title="9.掩码机制（Masking）"></a>9.掩码机制（Masking）</h3><p>掩码机制（Masking）是控制模型信息流动的核心设计，其主要作用</p>
<ul>
<li><strong>防止信息泄漏</strong>​（解码器）：确保自回归生成时，模型无法“偷看”未来信息</li>
<li><strong>处理填充符（Padding）​</strong>​（编码器&#x2F;解码器）：忽略无效位置（如填充符<code>&lt;PAD&gt;</code>）的影响</li>
<li><strong>动态注意力控制</strong>​：根据任务需求屏蔽特定区域（如局部注意力、稀疏注意力）</li>
</ul>
<p>防止某些学生提前偷看别人的后一句发言，只能参考已发言内容，保证作文是一步一步写出来的。</p>
<h3 id="10-最终输出"><a href="#10-最终输出" class="headerlink" title="10.最终输出"></a>10.最终输出</h3><p>最终所有学生的发言被串联起来，组成一篇内容连贯、参考了各自观点、逻辑清晰的作文——这就是 Transformer 输出的序列。</p>
<h2 id="2-DETR目标检测基本思想"><a href="#2-DETR目标检测基本思想" class="headerlink" title="2.DETR目标检测基本思想"></a>2.DETR目标检测基本思想</h2><p>DETR 证明了 Transformer 不仅可以做特征提取（Encoder），也可以直接参与下游任务的预测（Decoder），而且，它是第一个真正做到端到端目标检测的 Transformer 模型，很具有代表性。</p>
<h3 id="1-传统的目标检测"><a href="#1-传统的目标检测" class="headerlink" title="1.传统的目标检测"></a>1.传统的目标检测</h3><p>说到目标检测，大家可能脑海里已经浮现出几个关键词，比如 R-CNN 系列、YOLO 系列等等。</p>
<ul>
<li><strong>Fast R-CNN</strong>：在 2015 年非常火，它是 R-CNN 系列的代表之一，使用了 Region Proposal（候选区域）的方法去做目标检测。</li>
<li><strong>YOLO</strong>：2016 年崛起的代表，它的优势是把整个流程做得更简单、更统一。但它和 R-CNN 一样，仍然依赖一种叫做“anchor”（锚框）的机制。</li>
</ul>
<p>不管是 Fast R-CNN 还是 YOLO，它们大多都是基于锚框（anchor-based）机制来做目标检测的，然后再用 <strong>非极大值抑制（NMS）</strong> 去过滤掉重叠的框。</p>
<blockquote>
<p>NMS（Non-Maximum Suppression）是目标检测中的一种后处理算法，用于<strong>从多个重叠的预测框中选择最靠谱的一个</strong>，去掉冗余和低质量的框。</p>
</blockquote>
<h3 id="2-NMS-的弊端"><a href="#2-NMS-的弊端" class="headerlink" title="2.NMS 的弊端"></a>2.NMS 的弊端</h3><p>比如一张图像中只有一个人，但模型可能预测出多个框（蓝色、绿色、黑色），都在那个位置附近。为了只保留一个，我们就需要 NMS。但 NMS 效率不高，处理过程也繁琐，而且并不是端到端可学习的。<br>所以我们想：有没有可能不依赖 anchor，也不使用 NMS，就能完成目标检测任务？</p>
<h3 id="3-DETR-的思路"><a href="#3-DETR-的思路" class="headerlink" title="3.DETR 的思路"></a>3.DETR 的思路</h3><p>这时，DETR 出现了。DETR 是一个 <strong>完全基于 Transformer 架构</strong> 的目标检测方法，不依赖锚框、不用 NMS，甚至不需要传统意义上的候选框生成模块。<br>它的思路很新颖：</p>
<ol>
<li><strong>图像编码</strong>：输入图像首先被切分为 patch 或通过 CNN 编码成特征图</li>
<li><strong>Transformer 编码器（Encoder）</strong>：对这些特征进行全局建模，提取高级语义</li>
<li><strong>Transformer 解码器（Decoder）</strong>：引入一组 <strong>固定数量的查询向量（object queries）</strong>，每个向量学习预测一个物体</li>
</ol>
<h3 id="4-固定数量的预测框"><a href="#4-固定数量的预测框" class="headerlink" title="4.固定数量的预测框"></a>4.固定数量的预测框</h3><p>一个关键点是：<strong>无论图像中有几个目标，DETR 都输出固定数量（比如 100 个）框的预测结果。</strong></p>
<ul>
<li>如果图中实际有 2 个物体，那另外的 98 个框就代表“背景”或“无物体”。 </li>
<li>最终通过和 Ground Truth（真值、真实标签）的匹配 Hungarian Algorithm（匈牙利匹配）来对齐这 100 个框中哪些是真正的目标，哪些是背景。</li>
</ul>
<p>这个思路让 DETR 可以实现 <strong>端到端的训练和推理流程</strong>，不需要像 YOLO 那样做预定义 anchor，也不需要 Fast R-CNN 的 Region Proposal 模块。</p>
<blockquote>
<p>Ground Truth（真值、真实标签） 是监督学习中用于训练的“正确答案”。<br>在目标检测任务中，Ground Truth 通常包括：</p>
<ol>
<li><strong>目标类别（class label）</strong>：例如“人”、“猫”、“车”</li>
<li><strong>边界框（bounding box）</strong>：表示物体的位置 [x, y, w, h] 或 [x1, y1, x2, y2]</li>
<li><strong>（可选）分割掩码、关键点等其他信息</strong><br>它是 <strong>我们希望模型最终预测出的结果</strong>，训练的目标就是让模型的输出尽量接近 Ground Truth</li>
</ol>
</blockquote>
<blockquote>
<p>Hungarian Algorithm（匈牙利匹配），一种经典的 <strong>最小代价二分图匹配算法</strong>，用来在“两组对象”之间寻找最优一对一匹配方案。<br>在目标检测中，一边是 N 个 <strong>模型预测的框</strong>（如 100 个）；一边是 M 个 <strong>Ground Truth 真实框</strong>（如 7 个）；我们要找到一组 <strong>最优的</strong>一一匹配，使得每个真实框都分配一个预测框；没被分配的预测框，视为背景；然后匹配的总代价还要最小。</p>
</blockquote>
<h2 id="3-网络架构"><a href="#3-网络架构" class="headerlink" title="3.网络架构"></a>3.网络架构</h2><p>先回顾一下ViT（Vision Transformer），它是 Google 在 2020 年提出的视觉领域首个纯 Transformer 架构，核心思想是把图片当作「句子」，把图像块当作「单词」，用 NLP 里成功的 Transformer 模型来处理视觉任务。它主要分为两个部分：</p>
<ul>
<li><strong>Encoder</strong>：对图像进行 patch 分割 + 编码，通过Transformer结构提取全局特征</li>
<li><strong>Decoder</strong>：在ViT中没有用 decoder，因为我们只做分类。但在DETR中，这个 decoder 就是目标检测的关键<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250512154553.png"></li>
</ul>
<h3 id="1-DETR-的编码器（Encoder）"><a href="#1-DETR-的编码器（Encoder）" class="headerlink" title="1.DETR 的编码器（Encoder）"></a>1.DETR 的编码器（Encoder）</h3><p><strong>作用</strong>：提取图像的全局特征。</p>
<ul>
<li>输入图像先通过 CNN（如ResNet）编码，转化为 patch 特征</li>
<li>每个 patch 会加上 <strong>位置编码</strong>（2D位置编码，用于保留空间位置信息），得到加了位置编码的图像特征</li>
<li>通过自注意力机制建模图像内不同区域之间的全局依赖关系，输出仍是一组图像特征表示（包含上下文关系的表示）</li>
</ul>
<blockquote>
<p>为何需要添加位置编码（positional encoding）？<br>因为 Transformer 自身不具备空间结构感知能力，位置编码用于保留图像中“哪里”的信息</p>
</blockquote>
<h3 id="2-DETR-的解码器（Decoder）"><a href="#2-DETR-的解码器（Decoder）" class="headerlink" title="2.DETR 的解码器（Decoder）"></a>2.DETR 的解码器（Decoder）</h3><p>与 NLP 不同，不生成词语，而是直接生成目标框（bounding boxes）和类别</p>
<ul>
<li>我们不再按 NLP 那种方式“一个词一个词”串行预测，而是<strong>一次性并行预测100个目标框</strong></li>
<li>这些框不是 anchor-based 的，而是来自一组 <strong>初始化的 Learnable Queries（可学习向量）</strong></li>
</ul>
<h3 id="3-Prediction-Heads（预测头）"><a href="#3-Prediction-Heads（预测头）" class="headerlink" title="3.Prediction Heads（预测头）"></a>3.Prediction Heads（预测头）</h3><p>每个解码器输出都送入一个小的 <strong>前馈网络（FFN）</strong>：</p>
<ul>
<li>输出类别概率（包含“no object”类）</li>
<li>输出边界框坐标（通常是中心点 + 宽高）</li>
</ul>
<p>图中右边框显示：红色与黄色框成功预测了两只海鸥，绿色与蓝色框预测为“no object”</p>
<h3 id="4-主流程"><a href="#4-主流程" class="headerlink" title="4.主流程"></a>4.主流程</h3><ol>
<li><strong>初始化100个query向量</strong>：<ul>
<li>每一个向量的任务就是预测一个目标框 + 一个类别</li>
<li>可以把它们想象成“探测器”，去图像中找自己感兴趣的目标</li>
</ul>
</li>
<li><strong>每个query去encoder输出中“敲门”</strong>：<ul>
<li>每个 query 是一个 <strong>Q</strong>（Query）</li>
<li>它去 encoder 提供的所有 patch 特征中查找关联区域（K 和 V）</li>
<li>本质就是一个 attention 过程 —— “我该关注图像的哪一块？”</li>
</ul>
</li>
<li><strong>多个query并行执行</strong>：<ul>
<li>不是像机器翻译那样，先有第一个词再预测第二个词，而是100个query <strong>同时查图</strong></li>
<li>所以是并行的，不是串行的</li>
</ul>
</li>
<li><strong>每个query接一个全连接层</strong>：<ul>
<li>输出一个预测框（4个值）+ 一个类别分布（比如80个类别的softmax）。</li>
<li>某些query可能对应的是背景或者没有目标，训练时会自动学习到。</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th><strong>模块</strong></th>
<th><strong>功能</strong></th>
<th><strong>关键点</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Encoder</td>
<td>提取图像全局特征</td>
<td>CNN + Pos Encoding → K&#x2F;V</td>
</tr>
<tr>
<td>Decoder</td>
<td>预测目标框和分类</td>
<td>100个 learnable query 并行预测</td>
</tr>
</tbody></table>
<p>DETR的核心创新在于通过使用 Transformer 直接检测，而不依赖 anchor、不使用NMS、直接回归框。</p>
<h2 id="4-位置信息初始化"><a href="#4-位置信息初始化" class="headerlink" title="4.位置信息初始化"></a>4.位置信息初始化</h2><h3 id="为什么不能直接用-CNN-做特征提取？"><a href="#为什么不能直接用-CNN-做特征提取？" class="headerlink" title="为什么不能直接用 CNN 做特征提取？"></a><strong>为什么不能直接用 CNN 做特征提取？</strong></h3><p>我们可以思考一个问题：如果目标检测只需要输出几个 bbox，那直接用 CNN 抽特征，然后做分类和回归就行了，为什么还要用 transformer encoder？</p>
<p>从论文里可以知道答案：<strong>encoder 是通过 self-attention 把图像中“重要的区域”表示出来，尤其在存在遮挡时，它能更好地“指引 decoder 去关注哪里”。</strong><br>简单来说，<strong>encoder 是告诉 decoder：“嘿，这块儿有个目标，你重点看这儿。”</strong><br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250512134715.png"><br>比如图中有两头牛，虽然有遮挡，self-attention 能把一头牛的注意力集中在图像上半部分，另一头集中在下半部分。这说明即使目标被遮挡，encoder 也能有效定位注意区域。</p>
<h3 id="decoder-是怎么起作用的？"><a href="#decoder-是怎么起作用的？" class="headerlink" title="decoder 是怎么起作用的？"></a><strong>decoder 是怎么起作用的？</strong></h3><p>论文设置了 100 个 decoder 的查询向量（queries），这些向量的任务是从 encoder 输出中“选出目标”。就像一个选秀节目：100 个选手来选目标，选出来的几个是“最终预测的目标”，剩下的是陪跑的。<br>这些 decoder queries 一开始是 <strong>怎么初始化的？</strong></p>
<ul>
<li>一开始是 <strong>全 0 向量</strong>（比如维度是 768 全为 0）；</li>
<li>然后加上 <strong>位置编码</strong>：这相当于告诉每个 query：你去“关注”一个特定的位置区域。</li>
</ul>
<p>这种设计的用意是：<strong>一开始我先给每个 decoder query 一个不同的位置感知能力</strong>，让它们关注图像的不同区域，避免都聚焦在一块，提升模型的多样性和泛化能力。</p>
<h3 id="为什么要这么做？"><a href="#为什么要这么做？" class="headerlink" title="为什么要这么做？"></a><strong>为什么要这么做？</strong></h3><p>目标检测跟“位置”密切相关。直接用随机向量初始化 decoder queries 可能无法传递出“我要关注图像哪个区域”的这种信息。<br>而使用“全零 + 位置编码”的方式初始化，就相当于让 decoder queries 一开始就有“自己负责哪块区域”的暗示。这是为了：</p>
<ul>
<li>增强模型的空间感知能力</li>
<li>避免多个 queries 都关注到相同区域，导致预测冗余</li>
<li>提升遮挡、密集目标下的检测效果</li>
</ul>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h3><p>DETR用 transformer encoder 来精准提取注意区域，即使有遮挡也不怕；再用 decoder 通过“全零 + 位置编码”初始化的查询向量，像选秀一样挑出目标，从而实现 end-to-end 的目标检测。</p>
<h2 id="5-注意力机制"><a href="#5-注意力机制" class="headerlink" title="5.注意力机制"></a>5.注意力机制</h2><h3 id="1-Decoder-的工作机制（以-DETR-为例）"><a href="#1-Decoder-的工作机制（以-DETR-为例）" class="headerlink" title="1.Decoder 的工作机制（以 DETR 为例）"></a>1.Decoder 的工作机制（以 DETR 为例）</h3><p>DETR 的 decoder 本质上由多个 <strong>Transformer Decoder Block</strong> 叠加组成，每一个 Block 分两步：</p>
<ol>
<li>Self-Attention（自己和自己交流）</li>
<li>Cross-Attention（和 encoder 的输出交互）</li>
</ol>
<h4 id="1-Self-Attention（自我交流）"><a href="#1-Self-Attention（自我交流）" class="headerlink" title="1.Self-Attention（自我交流）"></a>1.Self-Attention（自我交流）</h4><p>目的：分工明确，别重复劳动<br>100 个初始化的向量（称作 object queries）一开始是全零 + 各自的 <strong>位置编码</strong>。自注意力让这 100 个向量“开个会”，互相说清楚：谁关注哪个区域、谁负责啥任务（比如这个管车，那个管人）。<br>本质上是：让这些向量的 Query 形成一定的多样性，避免后续都盯着同一块区域看。</p>
<h4 id="3-Cross-Attention（关注图像特征）"><a href="#3-Cross-Attention（关注图像特征）" class="headerlink" title="3.Cross-Attention（关注图像特征）"></a>3.Cross-Attention（关注图像特征）</h4><p>目的：去图像里“找对象”<br>Decoder 每个向量带着自己的 Query，去 encoder 的输出（图像特征）中，查找哪些地方值得注意。Encoder 提供 Key 和 Value，Decoder 提供 Query，通过 attention 找到图像上相关区域，把信息拿回来“强化自己”。</p>
<h3 id="2-核心流程"><a href="#2-核心流程" class="headerlink" title="2.核心流程"></a>2.核心流程</h3><ul>
<li>Decoder 的每个 Query（向量）就像一个侦察兵，它想抓一个目标（如一个物体），但它不知道目标在哪</li>
<li>所以它通过 Cross-Attention 去 encoder 提供的图像特征里“探查”</li>
<li>多层 decoder 的堆叠，就是不断 refine 这个 Query，让它越来越“懂得自己要找什么”</li>
</ul>
<h3 id="3-关于-Mask-的处理"><a href="#3-关于-Mask-的处理" class="headerlink" title="3.关于 Mask 的处理"></a>3.关于 Mask 的处理</h3><ul>
<li>传统 NLP 的 Decoder（如 GPT）中使用 mask 是因为语言是顺序性的，预测下一个词时不能看后面的词（防止“透题”）</li>
<li>但在 DETR 这种目标检测里，Decoder 的输入是 100 个 object queries，它们是并列的、没有顺序的</li>
<li>所以这里 <strong>不需要 mask</strong>，大家可以并行计算、互不干扰</li>
</ul>
<h3 id="4-多层-Decoder-Block"><a href="#4-多层-Decoder-Block" class="headerlink" title="4.多层 Decoder Block"></a>4.多层 Decoder Block</h3><ul>
<li><strong>只有第一层用 self-attention</strong> 来“分配任务”。</li>
<li>后续层不再重复 self-attention，而是持续用 cross-attention 来强化 query 表示。</li>
<li>每个 Block 后都有 FFN（全连接）进一步提取特征。</li>
</ul>
<p>这个机制体现出 DETR 最大的创新之一：<strong>用 set-based 的 query + cross attention 来直接回归目标，而不是用 anchor 或 dense head。</strong></p>
<h2 id="6-训练过程"><a href="#6-训练过程" class="headerlink" title="6.训练过程"></a>6.训练过程</h2><h3 id="1-Decoder-的结构与流程（以-DETR-为例）"><a href="#1-Decoder-的结构与流程（以-DETR-为例）" class="headerlink" title="1.Decoder 的结构与流程（以 DETR 为例）"></a>1.Decoder 的结构与流程（以 DETR 为例）</h3><h4 id="1-Self-Attention-自注意力机制"><a href="#1-Self-Attention-自注意力机制" class="headerlink" title="1.Self-Attention 自注意力机制"></a>1.Self-Attention 自注意力机制</h4><p>在 decoder 的第一层，每一个 query 向量自己和自己“开会”，彼此之间进行信息交互，但<strong>不涉及 encoder 的输出</strong>。<br>像是 100 个当家聚会，各自说清楚“自己要干什么”，比如谁管吃喝，谁管武器，谁管杂务，提前定好各自负责区域。<br>为每一个 query 向量初始化做准备，<strong>先做一个合理的任务划分（也就是“分地盘”）</strong>。</p>
<h4 id="2-Cross-Attention-与-Encoder-交互"><a href="#2-Cross-Attention-与-Encoder-交互" class="headerlink" title="2.Cross-Attention 与 Encoder 交互"></a>2.Cross-Attention 与 Encoder 交互</h4><p>从第二步起，不再使用 self-attention，decoder 的每个 query 只用自身向量作为 q，然后从 encoder 的输出中取 k 和 v。<br>decoder 的 query 向量拿着自己的身份去 encoder 里“查”，看看有哪些特征对自己是重要的，然后基于 q-k-v attention 机制，重新构造 query 特征。<br>核心任务：</p>
<ul>
<li>query 是整个生命周期的核心</li>
<li>最终每一个 query 会输出一个检测结果（bounding box + class）</li>
</ul>
<h4 id="3-损失计算中的匈牙利匹配（Hungarian-Matching）"><a href="#3-损失计算中的匈牙利匹配（Hungarian-Matching）" class="headerlink" title="3.损失计算中的匈牙利匹配（Hungarian Matching）"></a>3.损失计算中的匈牙利匹配（Hungarian Matching）</h4><p>decoder 输出的是一组固定数量的预测（如100个），但真实目标只有若干（如2个）。可以采用匈牙利算法将预测与真实标注进行<strong>最优匹配</strong>（最小化 loss）。<br>匈牙利匹配标准：</p>
<ul>
<li>可能包括多个损失项，例如分类损失、边框损失（如L1、GIoU）。</li>
<li>找出最适合匹配的两个 query，其余当作背景处理。</li>
</ul>
<h4 id="4-注意力可视化"><a href="#4-注意力可视化" class="headerlink" title="4.注意力可视化"></a>4.注意力可视化</h4><p>实验现象：即使目标之间存在<strong>严重遮挡或重叠</strong>，不同 query 的注意力区域仍能<strong>清晰分辨物体局部</strong>（如象腿、斑马蹄子）。<br>Transformer 的注意力机制对遮挡非常鲁棒，能分清复杂结构中哪些区域属于哪个目标。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250512154621.png"></p>
<h4 id="5-多层监督（Intermediate-Supervision）"><a href="#5-多层监督（Intermediate-Supervision）" class="headerlink" title="5.多层监督（Intermediate Supervision）"></a>5.多层监督（Intermediate Supervision）</h4><p>只在 decoder 最后一层加 loss，无法监督中间层的学习质量，若中间某层“出错”，后面层也会受影响。<br><strong>解决思路</strong>：每一层 decoder 都加 loss（即每层 query 都参与分类+回归的训练）。<br><strong>好处</strong>：促进逐层学习质量提升，类似“每个阶段都考试”，而不是等到最后一锤定音。</p>
<h2 id="7-关键对比"><a href="#7-关键对比" class="headerlink" title="7.关键对比"></a>7.关键对比</h2><table>
<thead>
<tr>
<th><strong>特性</strong>​</th>
<th>​<strong>传统方法（如YOLO、Faster R-CNN）​</strong>​</th>
<th>​<strong>DETR</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>依赖锚框</strong>​</td>
<td>是，需预设锚框调整预测</td>
<td>否，直接回归边界框</td>
</tr>
<tr>
<td>​<strong>后处理NMS</strong>​</td>
<td>是，过滤重叠框</td>
<td>否，匈牙利匹配解决冗余</td>
</tr>
<tr>
<td>​<strong>端到端</strong>​</td>
<td>否，分阶段训练（候选区域+分类回归）</td>
<td>是，编码器-解码器联合训练</td>
</tr>
<tr>
<td>​<strong>全局建模能力</strong>​</td>
<td>有限，依赖CNN局部感受野</td>
<td>强，自注意力捕捉长程依赖</td>
</tr>
<tr>
<td>​<strong>处理遮挡目标</strong>​</td>
<td>易漏检或重复预测</td>
<td>鲁棒，注意力区分物体局部</td>
</tr>
</tbody></table>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><ul>
<li>​<strong>Transformer</strong>​ 通过自注意力和位置编码处理序列，解决了长距离依赖和位置感知问题。</li>
<li>​<strong>DETR</strong>​ 创新性地将Transformer应用于目标检测，摒弃传统锚框和NMS，通过可学习查询向量和匈牙利匹配实现端到端检测，在复杂场景（如遮挡、密集目标）中表现优异。其核心在于全局特征建模与并行预测机制的统一。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>目标检测</tag>
        <tag>detr</tag>
      </tags>
  </entry>
  <entry>
    <title>U²-Net显著性目标检测</title>
    <url>/2025/06/04/018-u2net-saliency-detection/</url>
    <content><![CDATA[<h2 id="1-U²-Net介绍与应用"><a href="#1-U²-Net介绍与应用" class="headerlink" title="1.U²-Net介绍与应用"></a>1.U²-Net介绍与应用</h2><p>在 <a href="https://keychankc.github.io/2025/05/19/016-image-segmentation-u-net/">图像分割与U-Net系列模型解析</a> 和 <a href="https://keychankc.github.io/2025/05/27/017-unet-cell-segmentation/">基于U-Net++的细胞分割代码实现</a> 中提到了U-Net系列网络模型，而 <a href="https://github.com/xuebinqin/U-2-Net">U²-Net</a> 虽然是一个U-Net的变体版本，原本用于显著性检测任务，但由于其优异的前景提取能力，逐渐被广泛用于抠图、图像编辑、人像分割等任务中。</p>
<h3 id="1-U²-Net-概述"><a href="#1-U²-Net-概述" class="headerlink" title="1.U²-Net 概述"></a>1.U²-Net 概述</h3><p>U²-Net 属于“显著性检测”任务中的网络结构，其核心目标是从图像中识别出前景区域，即显著目标（Salient Object Detection, SOD）。从任务定义来看，它本质上和语义分割非常接近，将图像划分为前景和背景，只是语义标签通常只有两类。</p>
<span id="more"></span>
<blockquote>
<p>显著性检测（Salient Object Detection）指的是从一幅图像中识别出“最引人注意的”区域，通常即为前景区域。模型的输入是一张图像，输出是一张二值或灰度图，其中白色表示前景（显著区域），黑色表示背景。<br>例如：一只狗在草地上跑动，狗即为显著对象；一群人站在海滩上，人是前景，海滩是背景。</p>
</blockquote>
<h3 id="2-应用"><a href="#2-应用" class="headerlink" title="2.应用"></a>2.应用</h3><p>如下图，在肖像素描任务生成中，输入是一张彩色人像图像，输出则像是一幅素描画，纹理和细节都能够得到很好的保留，效果相比很多图像生成或风格转换方法更为自然一些，甚至比一些 GAN 模型生成的还要好，特别是人脸细节部分，U²-Net 在轮廓、皱纹、发丝等区域的提取的也非常准确。</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103139.png"></p>
<p>除此之外，U²-Net 在抠图（前景分离）任务中也有不错的效果，无论背景复杂与否，它都能较好地将人物主体从图像中分离出来，这在直播、虚拟背景替换、美颜等应用场景中有着非常广泛的应用价值。例如在某些直播中，主播本来需要一张绿幕才能实现实时背景替换，而利用U²-Net这一类模型就可以做到“无绿幕”抠图，显著提升了便捷性和效果稳定性。</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103241.png"></p>
<p>U²-Net 的模型结构不仅能够提取精确的前景，还能为后续处理任务提供干净的语义掩码（mask），这为实时视频处理、特效添加、风格迁移等任务打下了基础，要具备这些能力并非仅仅依赖于“更深的U结构”，而是得益于其独特的设计思想。</p>
<h2 id="2-U²-Net网络架构"><a href="#2-U²-Net网络架构" class="headerlink" title="2. U²-Net网络架构"></a>2. U²-Net网络架构</h2><p>U²-Net 的整体结构采用了 <strong>Encoder-Decoder（编码器-解码器）</strong> 框架，但不同于传统 U-Net，它在每个阶段都使用了一个更复杂的模块——<strong>RSU（Residual U-block）</strong>，也就是<strong>双层嵌套U型结构（U-in-U）</strong>。<br>整个网络由：</p>
<ul>
<li><strong>6 个编码模块（En_1 到 En_6）</strong></li>
<li><strong>5 个解码模块（De_1 到 De_5）</strong></li>
<li><strong>多个深监督输出（Sup1 ~ Sup6）</strong></li>
<li><strong>一个最终融合输出（S_fuse）</strong></li>
</ul>
<p>最终组成一个对称且层层嵌套的 U² 结构。如下图所示</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250530150316.png"></p>
<h3 id="1-RSU-模块"><a href="#1-RSU-模块" class="headerlink" title="1.RSU 模块"></a>1.RSU 模块</h3><p>RSU 模块是 U²-Net 的核心模块，全称为 <em>Residual U-shaped block</em>，如上图每个 En_x 和 De_x 模块其实并不是单纯的卷积块，而是一个 RSU 模块，其内部包含一个编码-解码结构（小型 U-Net），然后使用多个空洞卷积扩展感受野，同时保持输出尺寸不变，最终将输入与输出进行残差连接，强化特征传递与复用。</p>
<p>这样做的好处是能有效平衡模型深度与参数量，在保证性能的同时提高了效率，从而增强局部特征提取与上下文信息聚合的能力。</p>
<h4 id="1-基础组件：REBNCONV"><a href="#1-基础组件：REBNCONV" class="headerlink" title="1.基础组件：REBNCONV"></a>1.基础组件：REBNCONV</h4><p>RSU 模块的基础单元是 REBNCONV，它由以下部分组成：</p>
<ol>
<li>卷积层：3×3 卷积，支持空洞卷积（dilation）</li>
<li>批归一化：<code>BatchNorm2d</code>，用于稳定训练</li>
<li>ReLU激活：<code>ReLU(inplace=True)</code>，用于非线性变换</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">REBNCONV</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_ch=<span class="number">3</span>,out_ch=<span class="number">3</span>,dirate=<span class="number">1</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(REBNCONV,<span class="variable language_">self</span>).__init__()  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv_s1 = nn.Conv2d(in_ch,out_ch,<span class="number">3</span>,padding=<span class="number">1</span>*dirate,dilation=<span class="number">1</span>*dirate)  </span><br><span class="line">        <span class="variable language_">self</span>.bn_s1 = nn.BatchNorm2d(out_ch)  </span><br><span class="line">        <span class="variable language_">self</span>.relu_s1 = nn.ReLU(inplace=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):  </span><br><span class="line">        hx = x  </span><br><span class="line">        xout = <span class="variable language_">self</span>.relu_s1(<span class="variable language_">self</span>.bn_s1(<span class="variable language_">self</span>.conv_s1(hx)))  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> xout</span><br></pre></td></tr></table></figure>
<h4 id="2-RSU-模块结构"><a href="#2-RSU-模块结构" class="headerlink" title="2.RSU 模块结构"></a>2.RSU 模块结构</h4><p>以 RSU7 为例，RSU 模块包含以下部分：</p>
<h5 id="1-编码器路径（Encoder-Path）"><a href="#1-编码器路径（Encoder-Path）" class="headerlink" title="1.编码器路径（Encoder Path）"></a>1.编码器路径（Encoder Path）</h5><p>输入首先通过一个 REBNCONV 层（rebnconvin），然后依次通过多个 REBNCONV 层和最大池化层（MaxPool2d），逐步降低特征图的空间分辨率，同时增加通道数，最后通过一个空洞卷积（dirate&#x3D;2）进一步提取特征。</p>
<h5 id="2-解码器路径（Decoder-Path）"><a href="#2-解码器路径（Decoder-Path）" class="headerlink" title="2 解码器路径（Decoder Path）"></a>2 解码器路径（Decoder Path）</h5><p>从最深层开始，通过上采样 <code>_upsample_like</code> 和 REBNCONV 层逐步恢复空间分辨率，每一步都会将当前特征与编码器对应层的特征拼接（torch.cat），形成跳跃连接（skip connection）。</p>
<h5 id="3-残差连接"><a href="#3-残差连接" class="headerlink" title="3.残差连接"></a>3.残差连接</h5><p>最终输出是解码器路径的最后一层与输入特征（hxin）的残差和（hx1d + hxin），这有助于梯度流动和特征保留。</p>
<h5 id="4-具体实现（以-RSU7-为例）"><a href="#4-具体实现（以-RSU7-为例）" class="headerlink" title="4.具体实现（以 RSU7 为例）"></a>4.具体实现（以 RSU7 为例）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RSU7</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_ch=<span class="number">3</span>, mid_ch=<span class="number">12</span>, out_ch=<span class="number">3</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(RSU7,<span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="comment"># 输入层</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconvin = REBNCONV(in_ch,out_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 编码器路径</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool1 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool2 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool3 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool4 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool5 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">2</span>)  </span><br><span class="line">        <span class="comment"># 解码器路径</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconv6d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv5d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv4d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv3d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv2d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv1d = REBNCONV(mid_ch*<span class="number">2</span>,out_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):  </span><br><span class="line">        hx = x  </span><br><span class="line">        hxin = <span class="variable language_">self</span>.rebnconvin(hx) </span><br><span class="line">        <span class="comment"># 编码器路径 </span></span><br><span class="line">        hx1 = <span class="variable language_">self</span>.rebnconv1(hxin)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool1(hx1)  </span><br><span class="line">        hx2 = <span class="variable language_">self</span>.rebnconv2(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool2(hx2)  </span><br><span class="line">        hx3 = <span class="variable language_">self</span>.rebnconv3(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool3(hx3)  </span><br><span class="line">        hx4 = <span class="variable language_">self</span>.rebnconv4(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool4(hx4)  </span><br><span class="line">        hx5 = <span class="variable language_">self</span>.rebnconv5(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool5(hx5)  </span><br><span class="line">        hx6 = <span class="variable language_">self</span>.rebnconv6(hx)  </span><br><span class="line">        hx7 = <span class="variable language_">self</span>.rebnconv7(hx6)  </span><br><span class="line">        <span class="comment"># 解码器路径</span></span><br><span class="line">        hx6d =  <span class="variable language_">self</span>.rebnconv6d(torch.cat((hx7,hx6),<span class="number">1</span>))  </span><br><span class="line">        hx6dup = _upsample_like(hx6d,hx5)  </span><br><span class="line">        hx5d =  <span class="variable language_">self</span>.rebnconv5d(torch.cat((hx6dup,hx5),<span class="number">1</span>))  </span><br><span class="line">        hx5dup = _upsample_like(hx5d,hx4)  </span><br><span class="line">        hx4d = <span class="variable language_">self</span>.rebnconv4d(torch.cat((hx5dup,hx4),<span class="number">1</span>))  </span><br><span class="line">        hx4dup = _upsample_like(hx4d,hx3)  </span><br><span class="line">        hx3d = <span class="variable language_">self</span>.rebnconv3d(torch.cat((hx4dup,hx3),<span class="number">1</span>))  </span><br><span class="line">        hx3dup = _upsample_like(hx3d,hx2)  </span><br><span class="line">        hx2d = <span class="variable language_">self</span>.rebnconv2d(torch.cat((hx3dup,hx2),<span class="number">1</span>))  </span><br><span class="line">        hx2dup = _upsample_like(hx2d,hx1)  </span><br><span class="line">        hx1d = <span class="variable language_">self</span>.rebnconv1d(torch.cat((hx2dup,hx1),<span class="number">1</span>))  </span><br><span class="line">        <span class="comment"># 残差连接</span></span><br><span class="line">        <span class="keyword">return</span> hx1d + hxin</span><br></pre></td></tr></table></figure>
<h5 id="5-RSU-模块的变体"><a href="#5-RSU-模块的变体" class="headerlink" title="5. RSU 模块的变体"></a>5. RSU 模块的变体</h5><p>U²-Net 中定义了多种 RSU 模块变体（如 RSU7、RSU6、RSU5、RSU4、RSU4F），它们的区别主要在于：</p>
<ul>
<li>深度：编码器路径的层数（如 RSU7 有7层，RSU6 有6层）</li>
<li>通道数：中间层（mid_ch）和输出层（out_ch）的通道数</li>
<li>空洞卷积：最深层是否使用空洞卷积（dirate&#x3D;2）</li>
</ul>
<h5 id="6-作用与优势"><a href="#6-作用与优势" class="headerlink" title="6. 作用与优势"></a>6. 作用与优势</h5><ul>
<li>多尺度特征提取：通过编码器-解码器结构和跳跃连接，RSU 模块能够同时捕获局部和全局特征</li>
<li>残差学习：残差连接有助于梯度流动，避免梯度消失问题</li>
<li>灵活性：不同深度的 RSU 模块可以适应不同复杂度的任务</li>
</ul>
<h3 id="2-深度监督"><a href="#2-深度监督" class="headerlink" title="2.深度监督"></a>2.深度监督</h3><p>深度监督（Deep Supervision）指的是在网络训练时，<strong>不仅对最终输出计算损失</strong>，而是<strong>在中间多个层也加入监督信号</strong>，引导模型在多个尺度和层级上学习有意义的特征。</p>
<p>U²-Net 的深度监督（Deep Supervision）机制通过以下步骤实现：</p>
<h4 id="1-多输出设计"><a href="#1-多输出设计" class="headerlink" title="1. 多输出设计"></a>1. 多输出设计</h4><p>U²-Net 在解码器的每个阶段（stage）都输出一个显著性预测图（side output），这些输出分别对应不同尺度的特征图。模型的前向传播返回了7个输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># d0 是最终输出（主输出）</span></span><br><span class="line"><span class="comment"># d1 到 d6 是中间层的输出（side outputs）</span></span><br><span class="line">d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)</span><br></pre></td></tr></table></figure>
<h4 id="2-损失函数定义"><a href="#2-损失函数定义" class="headerlink" title="2. 损失函数定义"></a>2. 损失函数定义</h4><p>用于计算每个输出的二值交叉熵损失（BCE Loss）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">muti_bce_loss_fusion</span>(<span class="params">d0, d1, d2, d3, d4, d5, d6, labels_v</span>):  </span><br><span class="line">    loss0 = bce_loss(d0,labels_v)  </span><br><span class="line">    loss1 = bce_loss(d1,labels_v)  </span><br><span class="line">    loss2 = bce_loss(d2,labels_v)  </span><br><span class="line">    loss3 = bce_loss(d3,labels_v)  </span><br><span class="line">    loss4 = bce_loss(d4,labels_v)  </span><br><span class="line">    loss5 = bce_loss(d5,labels_v)  </span><br><span class="line">    loss6 = bce_loss(d6,labels_v)  </span><br><span class="line">  </span><br><span class="line">    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6   </span><br><span class="line">    <span class="keyword">return</span> loss0, loss</span><br></pre></td></tr></table></figure>

<p>每个输出（d0 到 d6）都与 ground truth（labels_v）计算 BCE 损失，最终的总损失是所有损失的简单相加（权重相等）。</p>
<h4 id="3-训练流程中的深度监督"><a href="#3-训练流程中的深度监督" class="headerlink" title="3. 训练流程中的深度监督"></a>3. 训练流程中的深度监督</h4><p>在训练循环中，模型的前向传播返回多个输出，然后通过 <code>muti_bce_loss_fusion</code> 计算损失：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)</span><br><span class="line"><span class="comment"># loss2 是主输出（d0）的损失，用于监控训练效果</span></span><br><span class="line"><span class="comment"># loss 是所有输出的总损失，用于反向传播和参数更新</span></span><br><span class="line">loss2, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<h4 id="4-作用与优势"><a href="#4-作用与优势" class="headerlink" title="4. 作用与优势"></a>4. 作用与优势</h4><ul>
<li>梯度流动：中间层的输出直接参与损失计算，有助于梯度更好地传递到网络深层，缓解梯度消失问题</li>
<li>多尺度监督：不同尺度的输出能够捕获不同层次的特征，提升模型的泛化能力</li>
<li>加速收敛：多输出的监督信号能够加速模型收敛</li>
</ul>
<h3 id="3-多尺度融合"><a href="#3-多尺度融合" class="headerlink" title="3.多尺度融合"></a>3.多尺度融合</h3><p>显著性目标可能大小不一、形态复杂。单一尺度难以同时兼顾，所以需要关注边缘、纹理、细节的<strong>低层特征</strong>和 关注语义、上下文、全局结构的<strong>高层特征</strong>。</p>
<p>U²-Net 的多尺度融合（Multi-scale Fusion）主要通过以下步骤实现：</p>
<h4 id="1-多尺度特征提取"><a href="#1-多尺度特征提取" class="headerlink" title="1. 多尺度特征提取"></a>1. 多尺度特征提取</h4><p>U²-Net 的编码器路径（Encoder Path）通过多个 RSU 模块（如 RSU7、RSU6、RSU5 等）逐步提取不同尺度的特征。每个 RSU 模块的输出特征图尺寸逐渐减小，但通道数逐渐增加，从而捕获不同层次的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage1 = RSU7(in_ch, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 输入 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage2 = RSU6(<span class="number">64</span>, <span class="number">32</span>, <span class="number">128</span>) <span class="comment"># 64通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage3 = RSU5(<span class="number">128</span>, <span class="number">64</span>, <span class="number">256</span>) <span class="comment"># 128通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage4 = RSU4(<span class="number">256</span>, <span class="number">128</span>, <span class="number">512</span>) <span class="comment"># 256通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage5 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage6 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br></pre></td></tr></table></figure>
<h4 id="2-解码器路径与跳跃连接"><a href="#2-解码器路径与跳跃连接" class="headerlink" title="2. 解码器路径与跳跃连接"></a>2. 解码器路径与跳跃连接</h4><p>解码器路径（Decoder Path）通过上采样<code>_upsample_like</code>和跳跃连接（skip connection）逐步恢复空间分辨率，同时融合不同尺度的特征：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解码器路径</span></span><br><span class="line">hx5d = <span class="variable language_">self</span>.stage5d(torch.cat((hx6up, hx5), <span class="number">1</span>)) <span class="comment"># 融合 hx6up 和 hx5</span></span><br><span class="line">hx5dup = _upsample_like(hx5d, hx4)</span><br><span class="line">hx4d = <span class="variable language_">self</span>.stage4d(torch.cat((hx5dup, hx4), <span class="number">1</span>)) <span class="comment"># 融合 hx5dup 和 hx4</span></span><br><span class="line">hx4dup = _upsample_like(hx4d, hx3)</span><br><span class="line">hx3d = <span class="variable language_">self</span>.stage3d(torch.cat((hx4dup, hx3), <span class="number">1</span>)) <span class="comment"># 融合 hx4dup 和 hx3</span></span><br><span class="line">hx3dup = _upsample_like(hx3d, hx2)</span><br><span class="line">hx2d = <span class="variable language_">self</span>.stage2d(torch.cat((hx3dup, hx2), <span class="number">1</span>)) <span class="comment"># 融合 hx3dup 和 hx2</span></span><br><span class="line">hx2dup = _upsample_like(hx2d, hx1)</span><br><span class="line">hx1d = <span class="variable language_">self</span>.stage1d(torch.cat((hx2dup, hx1), <span class="number">1</span>)) <span class="comment"># 融合 hx2dup 和 hx1</span></span><br></pre></td></tr></table></figure>
<p><code>torch.cat((hx6up, hx5), 1)</code> 将上采样后的特征与编码器对应层的特征拼接，形成跳跃连接<br>每个解码器阶段（stage5d、stage4d 等）进一步处理融合后的特征。</p>
<h4 id="3-多输出与最终融合"><a href="#3-多输出与最终融合" class="headerlink" title="3. 多输出与最终融合"></a>3. 多输出与最终融合</h4><p>U²-Net 在解码器的每个阶段都输出一个显著性预测图（side output），这些输出通过上采样调整到相同分辨率，然后拼接并融合为最终输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多输出</span></span><br><span class="line">d1 = <span class="variable language_">self</span>.side1(hx1d)</span><br><span class="line">d2 = <span class="variable language_">self</span>.side2(hx2d)</span><br><span class="line">d2 = _upsample_like(d2, d1)</span><br><span class="line">d3 = <span class="variable language_">self</span>.side3(hx3d)</span><br><span class="line">d3 = _upsample_like(d3, d1)</span><br><span class="line">d4 = <span class="variable language_">self</span>.side4(hx4d)</span><br><span class="line">d4 = _upsample_like(d4, d1)</span><br><span class="line">d5 = <span class="variable language_">self</span>.side5(hx5d)</span><br><span class="line">d5 = _upsample_like(d5, d1)</span><br><span class="line">d6 = <span class="variable language_">self</span>.side6(hx6)</span><br><span class="line">d6 = _upsample_like(d6, d1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终融合</span></span><br><span class="line">d0 = <span class="variable language_">self</span>.outconv(torch.cat((d1, d2, d3, d4, d5, d6), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>self.side1 到 self.side6 是 1×1 卷积层，用于将每个阶段的特征转换为显著性预测图。<br>self.outconv 是一个 1×1 卷积层，用于将拼接后的多尺度预测图融合为最终输。</p>
<h4 id="4-作用与优势-1"><a href="#4-作用与优势-1" class="headerlink" title="4. 作用与优势"></a>4. 作用与优势</h4><ul>
<li>多尺度特征捕获：通过不同深度的 RSU 模块，模型能够同时捕获局部细节和全局上下文信息</li>
<li>特征复用：跳跃连接允许低层特征（如边缘、纹理）与高层特征（如语义信息）直接融合，提升分割精度</li>
<li>灵活性：多输出设计不仅用于深度监督，还能在推理时提供多尺度的预测结果</li>
</ul>
<h2 id="3-编码器"><a href="#3-编码器" class="headerlink" title="3.编码器"></a>3.编码器</h2><p><strong>Encoder 编码器（En_1 到 En_6）</strong>：逐步提取特征，降低分辨率，增加语义信息。</p>
<h3 id="1-编码器结构"><a href="#1-编码器结构" class="headerlink" title="1. 编码器结构"></a>1. 编码器结构</h3><p>U²-Net 的编码器由多个 RSU（Residual U-block）模块组成，每个模块负责提取不同尺度的特征。编码器的设计遵循以下原则：</p>
<ul>
<li>逐步降采样：通过最大池化（MaxPool2d）逐步降低特征图的空间分辨率</li>
<li>逐步增加通道数：每个 RSU 模块的输出通道数逐渐增加，以捕获更丰富的特征</li>
</ul>
<h3 id="2-具体实现"><a href="#2-具体实现" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h3><h4 id="1-初始化编码器模块"><a href="#1-初始化编码器模块" class="headerlink" title="1.初始化编码器模块"></a>1.初始化编码器模块</h4><p>在 U2NET 类的 <strong>init</strong> 方法中，定义了编码器的各个阶段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage1 = RSU7(in_ch, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 输入 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool12 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage2 = RSU6(<span class="number">64</span>, <span class="number">32</span>, <span class="number">128</span>) <span class="comment"># 64通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool23 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage3 = RSU5(<span class="number">128</span>, <span class="number">64</span>, <span class="number">256</span>) <span class="comment"># 128通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool34 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage4 = RSU4(<span class="number">256</span>, <span class="number">128</span>, <span class="number">512</span>) <span class="comment"># 256通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool45 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage5 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool56 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage6 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br></pre></td></tr></table></figure>
<p>RSU7、RSU6、RSU5、RSU4、RSU4F 是不同深度的 RSU 模块，MaxPool2d 用于降采样，stride&#x3D;2 表示每次将特征图尺寸减半。</p>
<h4 id="2-前向传播过程"><a href="#2-前向传播过程" class="headerlink" title="2.前向传播过程"></a>2.前向传播过程</h4><p>在 forward 方法中，编码器的前向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hx = x</span><br><span class="line"></span><br><span class="line"><span class="comment"># stage 1</span></span><br><span class="line">hx1 = <span class="variable language_">self</span>.stage1(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool12(hx1)</span><br><span class="line"><span class="comment"># stage 2</span></span><br><span class="line">hx2 = <span class="variable language_">self</span>.stage2(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool23(hx2)</span><br><span class="line"><span class="comment"># stage 3</span></span><br><span class="line">hx3 = <span class="variable language_">self</span>.stage3(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool34(hx3)</span><br><span class="line"><span class="comment"># stage 4</span></span><br><span class="line">hx4 = <span class="variable language_">self</span>.stage4(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool45(hx4)</span><br><span class="line"><span class="comment"># stage 5</span></span><br><span class="line">hx5 = <span class="variable language_">self</span>.stage5(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool56(hx5)</span><br><span class="line"><span class="comment"># stage 6</span></span><br><span class="line">hx6 = <span class="variable language_">self</span>.stage6(hx)</span><br></pre></td></tr></table></figure>
<p>输入 x 依次通过 stage1 到 stage6 的 RSU 模块，每个阶段后通过 MaxPool2d 降采样，逐步降低特征图的空间分辨率。</p>
<h4 id="3-作用与优势"><a href="#3-作用与优势" class="headerlink" title="3.作用与优势"></a>3.作用与优势</h4><ul>
<li>多尺度特征提取：编码器通过不同深度的 RSU 模块捕获不同尺度的特征</li>
<li>逐步降采样：通过池化层逐步降低空间分辨率，增加感受野</li>
<li>通道数增加：逐步增加通道数，捕获更丰富的特征信息</li>
</ul>
<h2 id="4-解码器"><a href="#4-解码器" class="headerlink" title="4.解码器"></a>4.解码器</h2><p><strong>Decoder 解码器（De_1 到 De_5）</strong>：逐步恢复分辨率，并融合低层细节与高层语义。</p>
<h3 id="1-解码器结构"><a href="#1-解码器结构" class="headerlink" title="1. 解码器结构"></a>1. 解码器结构</h3><p>解码器的设计遵循以下原则：</p>
<ul>
<li>逐步上采样：通过上采样<code>_upsample_like</code>逐步恢复特征图的空间分辨率</li>
<li>跳跃连接：将编码器对应层的特征与上采样后的特征拼接（torch.cat），形成跳跃连接</li>
<li>多输出：每个解码器阶段都输出一个显著性预测图（side output），用于深度监督</li>
</ul>
<h3 id="2-具体实现-1"><a href="#2-具体实现-1" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h3><h4 id="1-初始化解码器模块"><a href="#1-初始化解码器模块" class="headerlink" title="1.初始化解码器模块"></a>1.初始化解码器模块</h4><p>在 U2NET 类的 <strong>init</strong> 方法中，定义了解码器的各个阶段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage5d = RSU4F(<span class="number">1024</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 1024通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage4d = RSU4(<span class="number">1024</span>, <span class="number">128</span>, <span class="number">256</span>) <span class="comment"># 1024通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage3d = RSU5(<span class="number">512</span>, <span class="number">64</span>, <span class="number">128</span>) <span class="comment"># 512通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage2d = RSU6(<span class="number">256</span>, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 256通道 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage1d = RSU7(<span class="number">128</span>, <span class="number">16</span>, <span class="number">64</span>) <span class="comment"># 128通道 -&gt; 64通道</span></span><br></pre></td></tr></table></figure>
<p>RSU4F、RSU4、RSU5、RSU6、RSU7 是不同深度的 RSU 模块，输入通道数是编码器对应层通道数的两倍（因为跳跃连接会拼接特征）。</p>
<h4 id="2-前向传播过程-1"><a href="#2-前向传播过程-1" class="headerlink" title="2.前向传播过程"></a>2.前向传播过程</h4><p>在 forward 方法中，解码器的前向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从最深层开始上采样</span></span><br><span class="line">hx6up = _upsample_like(hx6, hx5)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码器路径</span></span><br><span class="line">hx5d = <span class="variable language_">self</span>.stage5d(torch.cat((hx6up, hx5), <span class="number">1</span>)) <span class="comment"># 融合 hx6up 和 hx5</span></span><br><span class="line">hx5dup = _upsample_like(hx5d, hx4)</span><br><span class="line">hx4d = <span class="variable language_">self</span>.stage4d(torch.cat((hx5dup, hx4), <span class="number">1</span>)) <span class="comment"># 融合 hx5dup 和 hx4</span></span><br><span class="line">hx4dup = _upsample_like(hx4d, hx3)</span><br><span class="line">hx3d = <span class="variable language_">self</span>.stage3d(torch.cat((hx4dup, hx3), <span class="number">1</span>)) <span class="comment"># 融合 hx4dup 和 hx3</span></span><br><span class="line">hx3dup = _upsample_like(hx3d, hx2)</span><br><span class="line">hx2d = <span class="variable language_">self</span>.stage2d(torch.cat((hx3dup, hx2), <span class="number">1</span>)) <span class="comment"># 融合 hx3dup 和 hx2</span></span><br><span class="line">hx2dup = _upsample_like(hx2d, hx1)</span><br><span class="line">hx1d = <span class="variable language_">self</span>.stage1d(torch.cat((hx2dup, hx1), <span class="number">1</span>)) <span class="comment"># 融合 hx2dup 和 hx1</span></span><br></pre></td></tr></table></figure>
<p><code>_upsample_like</code>函数用于将特征图上采样到目标尺寸，torch.cat 将上采样后的特征与编码器对应层的特征拼接，形成跳跃连接。</p>
<h4 id="3-多输出与最终融合-1"><a href="#3-多输出与最终融合-1" class="headerlink" title="3.多输出与最终融合"></a>3.多输出与最终融合</h4><p>解码器的每个阶段都输出一个显著性预测图（side output），这些输出通过上采样调整到相同分辨率，然后拼接并融合为最终输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多输出</span></span><br><span class="line">d1 = <span class="variable language_">self</span>.side1(hx1d)</span><br><span class="line">d2 = <span class="variable language_">self</span>.side2(hx2d)</span><br><span class="line">d2 = _upsample_like(d2, d1)</span><br><span class="line">d3 = <span class="variable language_">self</span>.side3(hx3d)</span><br><span class="line">d3 = _upsample_like(d3, d1)</span><br><span class="line">d4 = <span class="variable language_">self</span>.side4(hx4d)</span><br><span class="line">d4 = _upsample_like(d4, d1)</span><br><span class="line">d5 = <span class="variable language_">self</span>.side5(hx5d)</span><br><span class="line">d5 = _upsample_like(d5, d1)</span><br><span class="line">d6 = <span class="variable language_">self</span>.side6(hx6)</span><br><span class="line">d6 = _upsample_like(d6, d1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终融合</span></span><br><span class="line">d0 = <span class="variable language_">self</span>.outconv(torch.cat((d1, d2, d3, d4, d5, d6), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><code>self.side1</code>到<code>self.side6</code>是 1×1 卷积层，用于将每个阶段的特征转换为显著性预测图。<code>self.outconv</code> 是一个 1×1 卷积层，用于将拼接后的多尺度预测图融合为最终输出。</p>
<h4 id="4-作用与优势-2"><a href="#4-作用与优势-2" class="headerlink" title="4.作用与优势"></a>4.作用与优势</h4><ul>
<li>逐步恢复空间分辨率：通过上采样逐步恢复特征图的空间分辨率</li>
<li>特征复用：跳跃连接允许低层特征（如边缘、纹理）与高层特征（如语义信息）直接融合，提升分割精度</li>
<li>多输出设计：每个解码器阶段都输出一个显著性预测图，用于深度监督</li>
</ul>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>U²-Net 是一种基于 U-Net 改进的显著性检测模型，通过独特的 ​<strong>双层嵌套U型结构（RSU模块）​</strong>​ 和 ​<strong>深度监督机制</strong>，在图像分割、抠图、人像素描生成等任务中表现出色。以下是核心内容总结：</p>
<h3 id="1-核心特点​"><a href="#1-核心特点​" class="headerlink" title="1.核心特点​"></a>1.核心特点​</h3><ul>
<li>​<strong>RSU模块</strong>​：每个模块内部嵌套小型U-Net，结合残差连接，实现多尺度特征提取与高效参数利用</li>
<li>​<strong>深度监督</strong>​：训练时对6个中间层输出和最终融合结果同时计算损失，增强梯度流动与多尺度学习能力</li>
<li>​<strong>多尺度融合</strong>​：通过跳跃连接和上采样整合不同层级的特征，兼顾局部细节与全局语义</li>
</ul>
<h3 id="​2-网络架构​"><a href="#​2-网络架构​" class="headerlink" title="​2.网络架构​"></a>​2.网络架构​</h3><ul>
<li>​<strong>编码器（En_1~En_6）​</strong>​：逐级降采样，使用不同深度的RSU模块（如RSU7、RSU4F）提取特征</li>
<li>​<strong>解码器（De_1~De_5）​</strong>​：逐级上采样并融合编码器特征，通过跳跃连接保留细节</li>
<li>​<strong>输出层</strong>​：生成6个中间预测图和1个融合结果，用于深度监督与最终预测</li>
</ul>
<h3 id="​3-关键应用​"><a href="#​3-关键应用​" class="headerlink" title="​3.关键应用​"></a>​3.关键应用​</h3><ul>
<li>​<strong>人像素描生成</strong>​：精准保留面部轮廓、发丝等细节，效果优于部分GAN模型</li>
<li>​<strong>无绿幕抠图</strong>​：复杂背景下分离前景，适用于直播、虚拟背景替换</li>
<li>​<strong>显著性检测</strong>​：识别图像中的突出物体（如人、动物），输出二值掩码</li>
</ul>
<h3 id="​4-优势​"><a href="#​4-优势​" class="headerlink" title="​4.优势​"></a>​4.优势​</h3><ul>
<li>​<strong>高精度</strong>​：RSU模块嵌套设计增强特征复用，显著提升边缘和细节处理能力</li>
<li>​<strong>轻量化</strong>​：通过残差连接和模块化设计平衡性能与参数量</li>
<li>​<strong>灵活性</strong>​：支持多任务扩展（如医学图像分割、视频处理）</li>
</ul>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><p>论文地址：<a href="https://arxiv.org/pdf/2005.09007">https://arxiv.org/pdf/2005.09007</a><br>开源代码地址：<a href="https://github.com/xuebinqin/U-2-Net">https://github.com/xuebinqin/U-2-Net</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
        <tag>U2Net</tag>
        <tag>显著性检测</tag>
      </tags>
  </entry>
  <entry>
    <title>基于U-Net++的细胞分割代码实现</title>
    <url>/2025/05/27/017-unet-cell-segmentation/</url>
    <content><![CDATA[<p>下面我们以一个医学图像实例分割任务为例，来介绍在 PyTorch 框架下如何使用 U-Net++ 网络。U-Net++ 是在经典 U-Net 基础上进行改进的语义分割网络，它通过引入密集跳跃连接和深层监督机制，增强了特征融合能力与梯度传播效果，特别适用于医学图像中边界模糊、结构复杂的分割任务。</p>
<h2 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1.数据预处理"></a>1.数据预处理</h2><h3 id="1-数据集介绍"><a href="#1-数据集介绍" class="headerlink" title="1.数据集介绍"></a>1.数据集介绍</h3><p>这个数据集是一些细胞图像，我们的目标是做前景背景分离，对每一个细胞做实例分割。数据集有以下特点：</p>
<span id="more"></span>
<ol>
<li>每个样本有图像（image）和标签（mask），如下图所示</li>
<li>标签（mask），是二值图（0&#x2F;1），表示像素点是否属于细胞</li>
<li>数据集总样本量为 670，样本数量比较少</li>
<li>图像（image）尺寸相对也是偏小的</li>
</ol>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173505.png"></p>
<h3 id="2-数据整合"><a href="#2-数据整合" class="headerlink" title="2.数据整合"></a>2.数据整合</h3><p>如上图所示，原始标签是每个细胞都被划分成一个独立 mask，不适合拿来直接做训练。需要将所有单个 mask 合并成一个统一的 mask 图（前景&#x3D;1，背景&#x3D;0）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 设置输出图像大小为 96×96    </span></span><br><span class="line">    img_size = <span class="number">96</span>  </span><br><span class="line">    <span class="comment"># 读取所有子文件夹，每个子文件夹对应一个图像样本（包含 images 和 masks 子目录）  </span></span><br><span class="line">    paths = glob(<span class="string">&#x27;inputs/stage1_train/*&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 用于存放缩放后的图像（image）</span></span><br><span class="line">    os.makedirs(<span class="string">&#x27;inputs/dsb2018_%d/images&#x27;</span> % img_size, exist_ok=<span class="literal">True</span>)  </span><br><span class="line">    <span class="comment"># 用于存放合并后的掩码图像（mask）</span></span><br><span class="line">    os.makedirs(<span class="string">&#x27;inputs/dsb2018_%d/masks/0&#x27;</span> % img_size, exist_ok=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(paths))): <span class="comment"># 用tqdm可在控制台显示处理进度  </span></span><br><span class="line">        path = paths[i]  </span><br><span class="line">        <span class="comment"># 读取图片  </span></span><br><span class="line">        img = cv2.imread(os.path.join(path, <span class="string">&#x27;images&#x27;</span>, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 合并掩码  </span></span><br><span class="line">        mask = np.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]))  </span><br><span class="line">        <span class="keyword">for</span> mask_path <span class="keyword">in</span> glob(os.path.join(path, <span class="string">&#x27;masks&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)):  </span><br><span class="line">            mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) &gt; <span class="number">127</span>  </span><br><span class="line">            mask[mask_] = <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 图像通道处理  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(img.shape) == <span class="number">2</span>: <span class="comment"># 灰度图（2D），复制为3通道图像  </span></span><br><span class="line">            img = np.tile(img[..., <span class="literal">None</span>], (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))  </span><br><span class="line">        <span class="keyword">if</span> img.shape[<span class="number">2</span>] == <span class="number">4</span>: <span class="comment"># RGBA（4通道），去掉透明度通道，只保留RGB  </span></span><br><span class="line">            img = img[..., :<span class="number">3</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 将图像和掩码都缩放为 96×96        </span></span><br><span class="line">        img = cv2.resize(img, (img_size, img_size))  </span><br><span class="line">        mask = cv2.resize(mask, (img_size, img_size))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 保存缩放后的图像和掩码  </span></span><br><span class="line">        cv2.imwrite(os.path.join(<span class="string">&#x27;inputs/dsb2018_%d/images&#x27;</span> % img_size, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>), img)  </span><br><span class="line">        cv2.imwrite(os.path.join(<span class="string">&#x27;inputs/dsb2018_%d/masks/0&#x27;</span> % img_size, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>), (mask * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="1-合并掩码"><a href="#1-合并掩码" class="headerlink" title="1.合并掩码"></a>1.合并掩码</h4><p>重点讲一下如何合并掩码，如何将某一张图像对应的多个单独掩码文件（每个掩码标注一个目标区域）合并为一个总掩码？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化一个与原始图像 img 大小相同的二维数组 mask，初始值全为 0</span></span><br><span class="line"><span class="comment"># mask 用于存放所有分割区域的合并结果（即所有目标的整体掩码）</span></span><br><span class="line">mask = np.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历路径 path/masks/ 目录下的所有掩码文件（每个文件对应一个实例或目标区域）</span></span><br><span class="line"><span class="comment"># glob 返回所有匹配的文件路径</span></span><br><span class="line"><span class="keyword">for</span> mask_path <span class="keyword">in</span> glob(os.path.join(path, <span class="string">&#x27;masks&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)):</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 读取当前掩码图像 mask_path，以灰度模式读取</span></span><br><span class="line">	<span class="comment"># &gt; 127 将图像二值化，转换为布尔数组，表示掩码中前景（目标）的位置</span></span><br><span class="line">	mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) &gt; <span class="number">127</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将所有当前掩码图中为 True（即目标区域）的位置，在总的 mask 中赋值为 1</span></span><br><span class="line">	<span class="comment"># 最终 mask 中为 1 的地方表示所有目标区域的合集</span></span><br><span class="line">	mask[mask_] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>合并后如下，图像（image）和标签（mask）：</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173609.png"></p>
<h3 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3.数据增强"></a>3.数据增强</h3><p>数据增强我们使用<a href="https://github.com/albumentations-team/albumentations">Albumentations</a>，它特别适合用于图像分类、分割、检测等深度学习任务。具有高性能（C++后端加速），高度可配置（支持组合增强），易于与 PyTorch、TensorFlow 等深度学习框架集成等特点。并且支持多种增强操作，包括但不限于：</p>
<ul>
<li><strong>几何变换</strong>：旋转、裁剪、缩放、仿射变换、透视变换等</li>
<li><strong>颜色变换</strong>：亮度、对比度、色调、饱和度、CLAHE、自适应直方图均衡</li>
<li><strong>噪声添加</strong>：高斯噪声、椒盐噪声、模糊、压缩失真</li>
<li><strong>分割&#x2F;检测支持</strong>：自动处理 mask、bboxes 等</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对训练数据进行增强</span></span><br><span class="line">train_transform = Compose([  </span><br><span class="line">    A.RandomRotate90(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率将图像随机旋转90、180或270度</span></span><br><span class="line">    A.HorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率进行水平翻转</span></span><br><span class="line">    A.VerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率进行垂直翻转</span></span><br><span class="line">    OneOf([</span><br><span class="line">        A.HueSaturationValue(p=<span class="number">1</span>),  <span class="comment"># 对图像的色调、饱和度和亮度进行随机扰动</span></span><br><span class="line">        A.RandomBrightnessContrast(brightness_limit=<span class="number">0.2</span>, contrast_limit=<span class="number">0.2</span>, p=<span class="number">1</span>),  <span class="comment"># 随机调整亮度和对比度</span></span><br><span class="line">    ], p=<span class="number">1</span>),  <span class="comment"># 二选一，只选择其中一个图像增强方式（概率为1，必须执行其一）</span></span><br><span class="line">    A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  <span class="comment"># 将图像缩放到模型输入所需的高度和宽度</span></span><br><span class="line">    A.Normalize(),  <span class="comment"># 将图像像素归一化到标准分布</span></span><br><span class="line">])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 对验证数据仅做必要的预处理</span></span><br><span class="line">val_transform = Compose([  </span><br><span class="line">    A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  <span class="comment"># 尺寸调整 96 * 96</span></span><br><span class="line">    A.Normalize(),  <span class="comment"># 归一化</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h3 id="4-加载数据集"><a href="#4-加载数据集" class="headerlink" title="4.加载数据集"></a>4.加载数据集</h3><p>config具体配置参数见3-1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># test_size=0.2 20%的图像将作为验证集，剩下 80% 作为训练集</span></span><br><span class="line"><span class="comment"># random_state=41 设置随机种子，确保每次运行划分结果一致（可复现）</span></span><br><span class="line">train_img_ids, val_img_ids = train_test_split(img_ids, test_size=<span class="number">0.2</span>, random_state=<span class="number">41</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载训练数据集  </span></span><br><span class="line">train_dataset = Dataset(  </span><br><span class="line">    img_ids=train_img_ids,  <span class="comment"># 用于定位每张图像</span></span><br><span class="line">    img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  <span class="comment"># 图像所在目录</span></span><br><span class="line">    mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  <span class="comment"># 掩码文件所在目录</span></span><br><span class="line">    img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  <span class="comment"># 图像扩展名</span></span><br><span class="line">    mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  <span class="comment"># 掩码扩展名</span></span><br><span class="line">    num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  <span class="comment"># 类别数量（用于多分类掩码，通常为1表示二分类）</span></span><br><span class="line">    transform=train_transform)  <span class="comment"># 图像与掩码的增强变换</span></span><br><span class="line"><span class="comment"># 加载验证数据集  </span></span><br><span class="line">val_dataset = Dataset(  </span><br><span class="line">    img_ids=val_img_ids,  </span><br><span class="line">    img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  </span><br><span class="line">    mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  </span><br><span class="line">    img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  </span><br><span class="line">    mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  </span><br><span class="line">    num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">    transform=val_transform)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据加载器</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(  </span><br><span class="line">    train_dataset,  </span><br><span class="line">    batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  <span class="comment"># 每次训练所取的样本数量</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,  <span class="comment"># 是否打乱数据顺序</span></span><br><span class="line">    num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  <span class="comment"># 读取数据时的线程数</span></span><br><span class="line">    drop_last=<span class="literal">True</span>)  <span class="comment"># 如果最后一个batch不足batch_size，是否丢弃它</span></span><br><span class="line"><span class="comment"># 验证数据加载器</span></span><br><span class="line">val_loader = torch.utils.data.DataLoader(  </span><br><span class="line">    val_dataset,  </span><br><span class="line">    batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  </span><br><span class="line">    shuffle=<span class="literal">False</span>,  </span><br><span class="line">    num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  </span><br><span class="line">    drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2-U-Net-网络结构"><a href="#2-U-Net-网络结构" class="headerlink" title="2.U-Net++网络结构"></a>2.U-Net++网络结构</h2><h3 id="1-VGGBlock"><a href="#1-VGGBlock" class="headerlink" title="1.VGGBlock"></a>1.VGGBlock</h3><p>VGG-style 卷积模块，也是图像分割网络（如 U-Net++）中常用的基础构建块，包含了两个连续的卷积层 + BN + ReLU激活，用于提取图像的局部特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGGBlock</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># in_channels: 输入特征图的通道数</span></span><br><span class="line">    <span class="comment"># middle_channels: 第一个卷积的输出通道数</span></span><br><span class="line">    <span class="comment"># out_channels: 第二个卷积的输出通道数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, middle_channels, out_channels</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># ReLU 激活函数，inplace=True 节省内存</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)  </span><br><span class="line">        <span class="comment"># Conv2d 3×3 卷积层，padding=1 保证输入输出尺寸一致</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels, middle_channels, <span class="number">3</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># BatchNorm2d 批标准化，加快训练速度、稳定收敛</span></span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(middle_channels)  </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(middle_channels, out_channels, <span class="number">3</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channels)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        out = <span class="variable language_">self</span>.conv1(x)  <span class="comment"># 第一次卷积</span></span><br><span class="line">        out = <span class="variable language_">self</span>.bn1(out)  <span class="comment"># 批标准化</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)  <span class="comment"># 激活</span></span><br><span class="line">  </span><br><span class="line">        out = <span class="variable language_">self</span>.conv2(out)  <span class="comment"># 第二次卷积</span></span><br><span class="line">        out = <span class="variable language_">self</span>.bn2(out)  <span class="comment"># 批标准化</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)  <span class="comment"># 激活</span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h3 id="2-UNet"><a href="#2-UNet" class="headerlink" title="2.UNet"></a>2.UNet</h3><p>一个基于 <strong>U-Net++ 架构的语义分割模型（简化版）</strong>，用于将输入图像逐像素分类成 num_classes 个类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># num_classes: 最终输出类别数（语义分割中每个像素属于哪个类）</span></span><br><span class="line">    <span class="comment"># input_channels: 输入图像的通道数（RGB=3，灰度=1）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, input_channels=<span class="number">3</span>, **kwargs</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># 每一层的通道数配置</span></span><br><span class="line">        nb_filter = [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器部分（下采样路径）</span></span><br><span class="line">        <span class="comment"># 图像尺寸逐步减小，通道数逐步增大，用于提取深层语义特征</span></span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)  <span class="comment"># 下采样操作</span></span><br><span class="line">        <span class="variable language_">self</span>.conv0_0 = VGGBlock(input_channels, nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_0 = VGGBlock(nb_filter[<span class="number">0</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_0 = VGGBlock(nb_filter[<span class="number">1</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_0 = VGGBlock(nb_filter[<span class="number">2</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv4_0 = VGGBlock(nb_filter[<span class="number">3</span>], nb_filter[<span class="number">4</span>], nb_filter[<span class="number">4</span>])  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器部分（上采样路径）</span></span><br><span class="line">        <span class="comment"># 包含多个上采样 + 特征融合（concat）+ 卷积</span></span><br><span class="line">        <span class="variable language_">self</span>.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)  <span class="comment"># 上采样</span></span><br><span class="line">        <span class="variable language_">self</span>.conv3_1 = VGGBlock(nb_filter[<span class="number">3</span>]+nb_filter[<span class="number">4</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_2 = VGGBlock(nb_filter[<span class="number">2</span>]+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_3 = VGGBlock(nb_filter[<span class="number">1</span>]+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_4 = VGGBlock(nb_filter[<span class="number">0</span>]+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 最终输出层</span></span><br><span class="line">        <span class="variable language_">self</span>.final = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        <span class="comment"># 编码阶段（下采样）：图像尺寸每次减半，特征逐步变深</span></span><br><span class="line">        x0_0 = <span class="variable language_">self</span>.conv0_0(<span class="built_in">input</span>)  </span><br><span class="line">        x1_0 = <span class="variable language_">self</span>.conv1_0(<span class="variable language_">self</span>.pool(x0_0))  </span><br><span class="line">        x2_0 = <span class="variable language_">self</span>.conv2_0(<span class="variable language_">self</span>.pool(x1_0))  </span><br><span class="line">        x3_0 = <span class="variable language_">self</span>.conv3_0(<span class="variable language_">self</span>.pool(x2_0))  </span><br><span class="line">        x4_0 = <span class="variable language_">self</span>.conv4_0(<span class="variable language_">self</span>.pool(x3_0))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码阶段（U-Net++风格）</span></span><br><span class="line">        <span class="comment"># 每一层的输出不仅使用其下层的上采样结果，还结合了它本身的特征图，形成一个更密集的 skip-connection 网络结构</span></span><br><span class="line">        x3_1 = <span class="variable language_">self</span>.conv3_1(torch.cat([x3_0, <span class="variable language_">self</span>.up(x4_0)], <span class="number">1</span>))  </span><br><span class="line">        x2_2 = <span class="variable language_">self</span>.conv2_2(torch.cat([x2_0, <span class="variable language_">self</span>.up(x3_1)], <span class="number">1</span>))  </span><br><span class="line">        x1_3 = <span class="variable language_">self</span>.conv1_3(torch.cat([x1_0, <span class="variable language_">self</span>.up(x2_2)], <span class="number">1</span>))  </span><br><span class="line">        x0_4 = <span class="variable language_">self</span>.conv0_4(torch.cat([x0_0, <span class="variable language_">self</span>.up(x1_3)], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出预测图</span></span><br><span class="line">        <span class="comment"># output是一个张量，形状为 (B, num_classes, H, W)，表示每个像素的类别预测</span></span><br><span class="line">        output = <span class="variable language_">self</span>.final(x0_4)  </span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="3-NestedUNet"><a href="#3-NestedUNet" class="headerlink" title="3.NestedUNet"></a>3.NestedUNet</h3><p><strong>U-Net++（Nested U-Net）</strong> 网络，通过<strong>更密集的 skip connections（跳跃连接）</strong>，实现更好的特征融合。</p>
<h4 id="1-命名规则"><a href="#1-命名规则" class="headerlink" title="1.命名规则"></a>1.命名规则</h4><p>convX_Y 表示第 X 层、第 Y 次更新，如：</p>
<ul>
<li>conv1_0: 第 1 层的初始特征提取</li>
<li>conv1_1: 第 1 层的第 1 次上采样拼接更新</li>
<li>conv0_3: 第 0 层的第 3 次融合更新<br>这些是 U-Net++ 的嵌套跳跃连接结构，越来越密集。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NestedUNet</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># num_classes: 分割类别数</span></span><br><span class="line">    <span class="comment"># input_channels: 输入图像通道数，默认为 3（RGB 图像）</span></span><br><span class="line">    <span class="comment"># deep_supervision: 是否启用多层输出作为监督信号（训练时更有效，测试时只用最后一层输出）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, input_channels=<span class="number">3</span>, deep_supervision=<span class="literal">False</span>, **kwargs</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">        nb_filter = [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.deep_supervision = deep_supervision  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_0 = VGGBlock(input_channels, nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_0 = VGGBlock(nb_filter[<span class="number">0</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_0 = VGGBlock(nb_filter[<span class="number">1</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_0 = VGGBlock(nb_filter[<span class="number">2</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv4_0 = VGGBlock(nb_filter[<span class="number">3</span>], nb_filter[<span class="number">4</span>], nb_filter[<span class="number">4</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_1 = VGGBlock(nb_filter[<span class="number">0</span>]+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_1 = VGGBlock(nb_filter[<span class="number">1</span>]+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_1 = VGGBlock(nb_filter[<span class="number">2</span>]+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_1 = VGGBlock(nb_filter[<span class="number">3</span>]+nb_filter[<span class="number">4</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_2 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">2</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_2 = VGGBlock(nb_filter[<span class="number">1</span>]*<span class="number">2</span>+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_2 = VGGBlock(nb_filter[<span class="number">2</span>]*<span class="number">2</span>+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_3 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">3</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_3 = VGGBlock(nb_filter[<span class="number">1</span>]*<span class="number">3</span>+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_4 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">4</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.deep_supervision:  </span><br><span class="line">            <span class="variable language_">self</span>.final1 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final2 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final3 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final4 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.final = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  </span><br><span class="line">        x0_0 = <span class="variable language_">self</span>.conv0_0(<span class="built_in">input</span>)  </span><br><span class="line">        x1_0 = <span class="variable language_">self</span>.conv1_0(<span class="variable language_">self</span>.pool(x0_0))  </span><br><span class="line">        x0_1 = <span class="variable language_">self</span>.conv0_1(torch.cat([x0_0, <span class="variable language_">self</span>.up(x1_0)], <span class="number">1</span>))  </span><br><span class="line">  </span><br><span class="line">        x2_0 = <span class="variable language_">self</span>.conv2_0(<span class="variable language_">self</span>.pool(x1_0))  </span><br><span class="line">        x1_1 = <span class="variable language_">self</span>.conv1_1(torch.cat([x1_0, <span class="variable language_">self</span>.up(x2_0)], <span class="number">1</span>))  </span><br><span class="line">        x0_2 = <span class="variable language_">self</span>.conv0_2(torch.cat([x0_0, x0_1, <span class="variable language_">self</span>.up(x1_1)], <span class="number">1</span>))  </span><br><span class="line">  </span><br><span class="line">        x3_0 = <span class="variable language_">self</span>.conv3_0(<span class="variable language_">self</span>.pool(x2_0))  </span><br><span class="line">        x2_1 = <span class="variable language_">self</span>.conv2_1(torch.cat([x2_0, <span class="variable language_">self</span>.up(x3_0)], <span class="number">1</span>))  </span><br><span class="line">        x1_2 = <span class="variable language_">self</span>.conv1_2(torch.cat([x1_0, x1_1, <span class="variable language_">self</span>.up(x2_1)], <span class="number">1</span>))  </span><br><span class="line">        x0_3 = <span class="variable language_">self</span>.conv0_3(torch.cat([x0_0, x0_1, x0_2, <span class="variable language_">self</span>.up(x1_2)], <span class="number">1</span>))  </span><br><span class="line">        </span><br><span class="line">        x4_0 = <span class="variable language_">self</span>.conv4_0(<span class="variable language_">self</span>.pool(x3_0))  </span><br><span class="line">        x3_1 = <span class="variable language_">self</span>.conv3_1(torch.cat([x3_0, <span class="variable language_">self</span>.up(x4_0)], <span class="number">1</span>))  </span><br><span class="line">        x2_2 = <span class="variable language_">self</span>.conv2_2(torch.cat([x2_0, x2_1, <span class="variable language_">self</span>.up(x3_1)], <span class="number">1</span>))  </span><br><span class="line">        x1_3 = <span class="variable language_">self</span>.conv1_3(torch.cat([x1_0, x1_1, x1_2, <span class="variable language_">self</span>.up(x2_2)], <span class="number">1</span>))  </span><br><span class="line">        x0_4 = <span class="variable language_">self</span>.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, <span class="variable language_">self</span>.up(x1_3)], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出层（支持深监督）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.deep_supervision:  </span><br><span class="line">            output1 = <span class="variable language_">self</span>.final1(x0_1)  </span><br><span class="line">            output2 = <span class="variable language_">self</span>.final2(x0_2)  </span><br><span class="line">            output3 = <span class="variable language_">self</span>.final3(x0_3)  </span><br><span class="line">            output4 = <span class="variable language_">self</span>.final4(x0_4)  </span><br><span class="line">            <span class="comment"># 输出多个不同深度的预测，常用于训练阶段融合损失</span></span><br><span class="line">            <span class="keyword">return</span> [output1, output2, output3, output4]  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            output = <span class="variable language_">self</span>.final(x0_4)  <span class="comment"># 卷积，输出最终预测</span></span><br><span class="line">            <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h4 id="2-深度监督"><a href="#2-深度监督" class="headerlink" title="2.深度监督"></a>2.深度监督</h4><p>深度监督是一种训练策略：在模型的中间层添加辅助输出，并在这些中间输出上也施加监督信号（即计算损失函数），帮助模型更早地获得梯度反馈，从而 <strong>加速收敛</strong>、<strong>提升性能</strong>。<br>其核心思想是，不仅在最终输出处监督模型，还要在中间层也加入监督，防止深层网络训练时梯度消失或收敛缓慢。</p>
<h4 id="3-图示"><a href="#3-图示" class="headerlink" title="3.图示"></a>3.图示</h4><p>下图是 <strong>U-Net++（Nested U-Net）</strong> 网络结构图，展示了它相较于原始 U-Net 所引入的“密集跳跃连接”和“深监督输出”机制。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250516135710.png"></p>
<h5 id="1-图中每个节点的含义"><a href="#1-图中每个节点的含义" class="headerlink" title="1.图中每个节点的含义"></a>1.图中每个节点的含义</h5><p>图中的每个节点用 $X^{i,j}$ 表示，含义如下：</p>
<ul>
<li>$i$：代表网络的深度层（下采样层数）</li>
<li>$j$：代表当前路径上该节点在嵌套结构中的层数（横向扩展层数）<br>例如：</li>
<li>$X^{0,0}$：最浅层（原图分辨率）第一次卷积输出</li>
<li>$X^{3,0}$：经过三次下采样后的卷积输出</li>
<li>$X^{0,3}$：第0层经过3次横向跳跃融合后的特征</li>
</ul>
<h5 id="2-图中箭头表示含义"><a href="#2-图中箭头表示含义" class="headerlink" title="2.图中箭头表示含义"></a>2.图中箭头表示含义</h5><p>右下角图例解释了箭头含义：</p>
<ul>
<li><strong>Down-sampling</strong>（下采样）：粗实线向下箭头<ul>
<li>如：从 $X^{0,0} → X^{1,0}$，通过 MaxPool 实现</li>
</ul>
</li>
<li><strong>Up-sampling</strong>（上采样）：粗实线向上箭头<ul>
<li>如：从 $X^{1,0} → X^{0,1}$，通过插值上采样（如 bilinear）</li>
</ul>
</li>
<li><strong>Skip connection</strong>（跳跃连接）：虚线箭头<ul>
<li>表示来自不同路径的特征拼接（cat）</li>
</ul>
</li>
</ul>
<h5 id="3-结构核心：嵌套密集跳跃连接"><a href="#3-结构核心：嵌套密集跳跃连接" class="headerlink" title="3.结构核心：嵌套密集跳跃连接"></a>3.结构核心：嵌套密集跳跃连接</h5><p>与原始 U-Net 不同，U-Net++ 每一个横向的节点（$X^{i,j}，j&gt;0$）不仅融合来自下一级的上采样特征，还融合同级之前所有横向特征（如 $X^{i,0}, X^{i,1}, …$）。这实现了<strong>更细致的特征聚合</strong>，提升了模型表现力。</p>
<h5 id="4-深监督输出（deep-supervision）"><a href="#4-深监督输出（deep-supervision）" class="headerlink" title="4.深监督输出（deep supervision）"></a>4.深监督输出（deep supervision）</h5><p>如上图中黄色框标注了 4 个输出点：$X^{0,1}、X^{0,2}、X^{0,3}、X^{0,4}$，每个点后面接一个 1×1 卷积层进行通道压缩得到预测，所有输出参与 loss 计算，提升训练稳定性和梯度传播效率。</p>
<h5 id="5-代码与结构图节点对应关系"><a href="#5-代码与结构图节点对应关系" class="headerlink" title="5.代码与结构图节点对应关系"></a>5.代码与结构图节点对应关系</h5><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">图结构节点：             对应代码：</span><br><span class="line">X^0,0  →             self.conv0_0</span><br><span class="line">X^1,0  →             self.conv1_0</span><br><span class="line">X^2,0  →             self.conv2_0</span><br><span class="line">X^3,0  →             self.conv3_0</span><br><span class="line">X^4,0  →             self.conv4_0</span><br><span class="line"></span><br><span class="line">X^0,1  →             self.conv0_1</span><br><span class="line">X^1,1  →             self.conv1_1</span><br><span class="line">X^2,1  →             self.conv2_1</span><br><span class="line">X^3,1  →             self.conv3_1</span><br><span class="line"></span><br><span class="line">X^0,2  →             self.conv0_2</span><br><span class="line">X^1,2  →             self.conv1_2</span><br><span class="line">X^2,2  →             self.conv2_2</span><br><span class="line"></span><br><span class="line">X^0,3  →             self.conv0_3</span><br><span class="line">X^1,3  →             self.conv1_3</span><br><span class="line"></span><br><span class="line">X^0,4  →             self.conv0_4</span><br></pre></td></tr></table></figure>
<p>所有 convX_Y 都是 VGGBlock（即 2 个 3×3 卷积 + BN + ReLU），节点间的数据流动方式严格对应图中的方向和跳跃连接，上采样统一用的是 <code>nn.Upsample(scale_factor=2, mode=&#39;bilinear&#39;)</code>。</p>
<h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3.训练"></a>3.训练</h2><h3 id="1-训练参数配置"><a href="#1-训练参数配置" class="headerlink" title="1.训练参数配置"></a>1.训练参数配置</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():  </span><br><span class="line">    parser = argparse.ArgumentParser()  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型名称  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="literal">None</span>, <span class="built_in">help</span>=<span class="string">&#x27;model name: (default: arch+timestamp)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 训练轮数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, default=<span class="number">10</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of total epochs to run&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 每个batch的数据量  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-b&#x27;</span>, <span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">8</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;mini-batch size (default: 16)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># model，控制模型结构、是否使用深度监督、输入图像尺寸  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--arch&#x27;</span>, <span class="string">&#x27;-a&#x27;</span>, metavar=<span class="string">&#x27;ARCH&#x27;</span>, default=<span class="string">&#x27;NestedUNet&#x27;</span>,  </span><br><span class="line">                        choices=ARCH_NAMES,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;model architecture: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join(ARCH_NAMES) + <span class="string">&#x27; (default: NestedUNet)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 是否使用深度监督（U-Net++ 特性），false，只用最后一层输出  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--deep_supervision&#x27;</span>, default=<span class="literal">False</span>, <span class="built_in">type</span>=str2bool)  </span><br><span class="line">    <span class="comment"># 输入图像通道数 3表示彩色图像（RGB）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_channels&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input channels&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 类别数量1 表示二分类（前景 vs 背景）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of classes&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 输入图像宽  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_w&#x27;</span>, default=<span class="number">96</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;image width&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 输入图像高  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_h&#x27;</span>, default=<span class="number">96</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;image height&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 损失函数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--loss&#x27;</span>, default=<span class="string">&#x27;BCEDiceLoss&#x27;</span>, choices=LOSS_NAMES,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;loss: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join(LOSS_NAMES) + <span class="string">&#x27; (default: BCEDiceLoss)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数据集  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, default=<span class="string">&#x27;dsb2018_96&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;dataset name&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 图像文件后缀  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--img_ext&#x27;</span>, default=<span class="string">&#x27;.png&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;image file extension&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 掩码的文件后缀  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mask_ext&#x27;</span>, default=<span class="string">&#x27;.png&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;mask file extension&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 优化器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--optimizer&#x27;</span>, default=<span class="string">&#x27;SGD&#x27;</span>,  </span><br><span class="line">                        choices=[<span class="string">&#x27;Adam&#x27;</span>, <span class="string">&#x27;SGD&#x27;</span>],  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;loss: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join([<span class="string">&#x27;Adam&#x27;</span>, <span class="string">&#x27;SGD&#x27;</span>]) + <span class="string">&#x27; (default: Adam)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 初始学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="string">&#x27;--learning_rate&#x27;</span>, default=<span class="number">1e-3</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, metavar=<span class="string">&#x27;LR&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;initial learning rate&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 动量项（SGD 特有）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--momentum&#x27;</span>, default=<span class="number">0.9</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;momentum&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 权重衰减（正则化）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weight_decay&#x27;</span>, default=<span class="number">1e-4</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;weight decay&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 是否使用 Nesterov 动量  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nesterov&#x27;</span>, default=<span class="literal">False</span>, <span class="built_in">type</span>=str2bool, <span class="built_in">help</span>=<span class="string">&#x27;nesterov&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 学习率调度器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scheduler&#x27;</span>, default=<span class="string">&#x27;CosineAnnealingLR&#x27;</span>,  </span><br><span class="line">                        choices=[<span class="string">&#x27;CosineAnnealingLR&#x27;</span>, <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>, <span class="string">&#x27;MultiStepLR&#x27;</span>, <span class="string">&#x27;ConstantLR&#x27;</span>])  </span><br><span class="line">    <span class="comment"># 最小学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_lr&#x27;</span>, default=<span class="number">1e-5</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;minimum learning rate&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 每次降低的倍数，用于某些调度器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--factor&#x27;</span>, default=<span class="number">0.1</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)  </span><br><span class="line">    <span class="comment"># scheduler 的耐心（多少次不提升再调整学习率）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--patience&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)  </span><br><span class="line">    <span class="comment"># 在哪些 epoch 降低学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--milestones&#x27;</span>, default=<span class="string">&#x27;1,2&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>)  </span><br><span class="line">    <span class="comment"># 学习率衰减系数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gamma&#x27;</span>, default=<span class="number">2</span> / <span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)  </span><br><span class="line">    <span class="comment"># 早停 -1 表示不启用  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--early_stopping&#x27;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;early stopping (default: -1)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 数据加载线程数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)  </span><br><span class="line">  </span><br><span class="line">    config = parser.parse_args()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure>
<h3 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2.损失函数"></a>2.损失函数</h3><h4 id="1-BCEDiceLoss"><a href="#1-BCEDiceLoss" class="headerlink" title="1.BCEDiceLoss"></a>1.BCEDiceLoss</h4><p>BCEDiceLoss结合了两种损失函数:</p>
<ul>
<li><strong>BCE（Binary Cross Entropy）</strong>：像素级分类准确性</li>
<li><strong>Dice Loss</strong>：评估预测区域与真实区域的重叠程度，适合前景-背景不平衡问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BCEDiceLoss</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, target</span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">        :param input: 模型输出 logits        </span></span><br><span class="line"><span class="string">        :param target: ground truth 掩码（0/1）  </span></span><br><span class="line"><span class="string">        :return:  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>        </span><br><span class="line">        <span class="comment"># 1.BCE Loss  </span></span><br><span class="line">        <span class="comment"># 直接使用带logits的BCE，内部自动做了sigmoid  </span></span><br><span class="line">        bce = F.binary_cross_entropy_with_logits(<span class="built_in">input</span>, target)  </span><br><span class="line">        smooth = <span class="number">1e-5</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.Dice Loss  </span></span><br><span class="line">        <span class="built_in">input</span> = torch.sigmoid(<span class="built_in">input</span>) <span class="comment"># 激活sigmoid，转换为概率  </span></span><br><span class="line">        <span class="comment"># reshape 展平  </span></span><br><span class="line">        num = target.size(<span class="number">0</span>)  </span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.view(num, -<span class="number">1</span>)  </span><br><span class="line">        target = target.view(num, -<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 计算Dice系数，Dice系数表示预测和目标之间的重叠程度，越大越好  </span></span><br><span class="line">        intersection = (<span class="built_in">input</span> * target)  </span><br><span class="line">        dice = (<span class="number">2.</span> * intersection.<span class="built_in">sum</span>(<span class="number">1</span>) + smooth) / (<span class="built_in">input</span>.<span class="built_in">sum</span>(<span class="number">1</span>) + target.<span class="built_in">sum</span>(<span class="number">1</span>) + smooth)  </span><br><span class="line">        dice = <span class="number">1</span> - dice.<span class="built_in">sum</span>() / num  </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * bce + dice</span><br></pre></td></tr></table></figure>
<p>前景像素非常少（比如肿瘤检测、医学分割、道路提取），Dice 可增强区域预测能力，BCE 保证细节与边界预测精度。</p>
<h4 id="2-LovaszHingeLoss"><a href="#2-LovaszHingeLoss" class="headerlink" title="2.LovaszHingeLoss"></a>2.LovaszHingeLoss</h4><p>结构感知的分割损失函数，基于 <strong>Lovász Hinge Loss</strong> 的结构性优化目标：</p>
<ul>
<li>与 IoU（交并比）相关，专门为 <strong>非凸、不可微的 mIoU 目标</strong> 设计的近似优化方法</li>
<li>强调 <strong>结构</strong> 的正确性（不是单个像素）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LovaszHingeLoss</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, target</span>):  </span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.squeeze(<span class="number">1</span>)  </span><br><span class="line">        target = target.squeeze(<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 计算每张图的结构性错误  </span></span><br><span class="line">        loss = lovasz_hinge(<span class="built_in">input</span>, target, per_image=<span class="literal">True</span>)  </span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>优势</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>结构感知</td>
<td>优化 IoU 相关指标而非逐像素损失</td>
</tr>
<tr>
<td>非凸优化</td>
<td>用次梯度方法优化非连续目标（如 mIoU）</td>
</tr>
<tr>
<td>表现优秀</td>
<td>在结构敏感型分割（如边缘、孔洞等）表现更佳</td>
</tr>
</tbody></table>
<h4 id="3-对比"><a href="#3-对比" class="headerlink" title="3.对比"></a>3.对比</h4><table>
<thead>
<tr>
<th><strong>损失函数</strong></th>
<th><strong>优点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td>BCEDiceLoss</td>
<td>简单有效，能兼顾像素准确与区域重叠</td>
<td>医学图像、前景稀疏场景</td>
</tr>
<tr>
<td>LovaszHingeLoss</td>
<td>更贴近 IoU 优化目标，更关注结构完整性</td>
<td>对结构敏感的任务，如道路提取、器官边界分割等</td>
</tr>
</tbody></table>
<h3 id="3-优化器"><a href="#3-优化器" class="headerlink" title="3.优化器"></a>3.优化器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.筛选需要优化的参数</span></span><br><span class="line"><span class="comment"># 只把可训练的参数传给优化器（忽略被冻结的参数）</span></span><br><span class="line">params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: p.requires_grad, model.parameters())  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.根据配置创建优化器</span></span><br><span class="line"><span class="comment"># 读取config字典，按配置创建对应的优化器实例</span></span><br><span class="line"><span class="keyword">if</span> config[<span class="string">&#x27;optimizer&#x27;</span>] == <span class="string">&#x27;Adam&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 自适应学习率的 Adam 优化器</span></span><br><span class="line">    optimizer = optim.Adam(  </span><br><span class="line">        params, lr=config[<span class="string">&#x27;lr&#x27;</span>], weight_decay=config[<span class="string">&#x27;weight_decay&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;optimizer&#x27;</span>] == <span class="string">&#x27;SGD&#x27;</span>: </span><br><span class="line">    <span class="comment"># 经典的随机梯度下降优化器</span></span><br><span class="line">    <span class="comment"># momentum：动量参数</span></span><br><span class="line">    <span class="comment"># nesterov：是否使用 Nesterov 动量加速（提前看一步梯度）</span></span><br><span class="line">    <span class="comment"># weight_decay：L2 正则项</span></span><br><span class="line">    optimizer = optim.SGD(params, </span><br><span class="line">		    lr=config[<span class="string">&#x27;lr&#x27;</span>], </span><br><span class="line">		    momentum=config[<span class="string">&#x27;momentum&#x27;</span>],  </span><br><span class="line">            nesterov=config[<span class="string">&#x27;nesterov&#x27;</span>], </span><br><span class="line">            weight_decay=config[<span class="string">&#x27;weight_decay&#x27;</span>])  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p> Adam 优化器适用：训练不稳定或梯度稀疏（如 Transformer、U-Net）。<br> SGD 优化器适用：训练稳定、想控制收敛过程精细（如 ResNet、分类任务）。</p>
<h3 id="4-学习率"><a href="#4-学习率" class="headerlink" title="4.学习率"></a>4.学习率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;CosineAnnealingLR&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 余弦下降：学习率在训练过程中像余弦曲线一样先慢慢下降，接近最后阶段时趋于 min_lr</span></span><br><span class="line">    scheduler = lr_scheduler.CosineAnnealingLR(  </span><br><span class="line">        optimizer, T_max=config[<span class="string">&#x27;epochs&#x27;</span>], eta_min=config[<span class="string">&#x27;min_lr&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 当模型某个评价指标（如验证 loss）在若干轮内不再下降时，就减小学习率</span></span><br><span class="line">    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=config[<span class="string">&#x27;factor&#x27;</span>], patience=config[<span class="string">&#x27;patience&#x27;</span>],  verbose=<span class="literal">True</span>, min_lr=config[<span class="string">&#x27;min_lr&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;MultiStepLR&#x27;</span>:  </span><br><span class="line">    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="built_in">int</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> config[<span class="string">&#x27;milestones&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)], gamma=config[<span class="string">&#x27;gamma&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ConstantLR&#x27;</span>:  </span><br><span class="line">    scheduler = <span class="literal">None</span>  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<h4 id="1-CosineAnnealingLR"><a href="#1-CosineAnnealingLR" class="headerlink" title="1.CosineAnnealingLR"></a>1.CosineAnnealingLR</h4><p>余弦退火，适合训练后期希望缓慢收敛，防止震荡，比如分类、分割、目标检测等任务</p>
<h4 id="2-ReduceLROnPlateau"><a href="#2-ReduceLROnPlateau" class="headerlink" title="2.ReduceLROnPlateau"></a>2.ReduceLROnPlateau</h4><p>性能不提升时降低学习率，适合模型容易早停，需要动态响应性能变化，比如医学图像、少样本任务等</p>
<h4 id="3-MultiStepLR"><a href="#3-MultiStepLR" class="headerlink" title="3.MultiStepLR"></a>3.MultiStepLR</h4><p>多阶段下降，训练有明显阶段性（如 ImageNet 训练常见策略）</p>
<h4 id="4-ConstantLR"><a href="#4-ConstantLR" class="headerlink" title="4.ConstantLR"></a>4.ConstantLR</h4><p>不使用调度器，适合做实验对照，或已知固定学习率效果不错</p>
<h3 id="5-训练流程"><a href="#5-训练流程" class="headerlink" title="5.训练流程"></a>5.训练流程</h3><h4 id="1-训练"><a href="#1-训练" class="headerlink" title="1.训练"></a>1.训练</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">config, train_loader, model, criterion, optimizer</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化状态</span></span><br><span class="line">    <span class="comment"># 记录每轮的平均 loss 和 IOU    </span></span><br><span class="line">    avg_meters = &#123;<span class="string">&#x27;loss&#x27;</span>: AverageMeter(), <span class="string">&#x27;iou&#x27;</span>: AverageMeter()&#125;  </span><br><span class="line">    model.train()  <span class="comment"># 设置为训练模式</span></span><br><span class="line">    pbar = tqdm(total=<span class="built_in">len</span>(train_loader))  <span class="comment"># 进度条，显示训练过程</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.遍历训练数据</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target, _ <span class="keyword">in</span> train_loader:  <span class="comment"># 每次读取一个批次（image mask）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.处理设备</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">            target = target.cuda()  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">            target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 4. 正向传播 &amp; 计算损失 + IoU</span></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">            outputs = model(<span class="built_in">input</span>) <span class="comment"># 多输出用于深度监督  </span></span><br><span class="line">            loss = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">for</span> output <span class="keyword">in</span> outputs:  </span><br><span class="line">                loss += criterion(output, target)  </span><br><span class="line">            loss /= <span class="built_in">len</span>(outputs)  </span><br><span class="line">            iou = iou_score(outputs[-<span class="number">1</span>], target)  </span><br><span class="line">            <span class="comment"># model(input) 返回多个输出（如 x0_1, x0_2, …, x0_4）</span></span><br><span class="line">            <span class="comment"># 每个输出都参与损失计算，然后平均</span></span><br><span class="line">            <span class="comment"># 只用最后一个输出计算 IoU（最深层最准确）</span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            output = model(<span class="built_in">input</span>)  </span><br><span class="line">            loss = criterion(output, target)  </span><br><span class="line">            iou = iou_score(output, target)  </span><br><span class="line">            <span class="comment"># 正常的单输出模型，直接计算损失和IoU</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 5. 梯度更新</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清空旧梯度</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 执行一次优化器更新</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 6.更新统计 &amp; 展示进度</span></span><br><span class="line">        avg_meters[<span class="string">&#x27;loss&#x27;</span>].update(loss.item(), <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">        avg_meters[<span class="string">&#x27;iou&#x27;</span>].update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">        <span class="comment"># 每个 batch 结束后更新累计 loss 与 iou 的加权平均</span></span><br><span class="line">        postfix = OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg),])  </span><br><span class="line">        pbar.set_postfix(postfix)  </span><br><span class="line">        pbar.update(<span class="number">1</span>)  </span><br><span class="line">    pbar.close()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7. 返回训练结果</span></span><br><span class="line">    <span class="comment"># 平均 loss 和 IoU，用于日志记录、调度器调整、验证等</span></span><br><span class="line">    <span class="keyword">return</span> OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg)])</span><br></pre></td></tr></table></figure>
<h4 id="2-验证"><a href="#2-验证" class="headerlink" title="2.验证"></a>2.验证</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">validate</span>(<span class="params">config, val_loader, model, criterion</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化两个累加器：分别记录本轮平均损失 与 IoU</span></span><br><span class="line">    avg_meters = &#123;<span class="string">&#x27;loss&#x27;</span>: AverageMeter(),  </span><br><span class="line">                  <span class="string">&#x27;iou&#x27;</span>: AverageMeter()&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2.把模型切到评估模式：BatchNorm使用全局均值/方差 Dropout关闭随机丢弃</span></span><br><span class="line">    model.<span class="built_in">eval</span>()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.不计算梯度，节省显存  </span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">        pbar = tqdm(total=<span class="built_in">len</span>(val_loader))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.每次读取一个批次（image mask）</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">input</span>, target, _ <span class="keyword">in</span> val_loader:  </span><br><span class="line">            <span class="comment"># 5.处理设备</span></span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">                target = target.cuda()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">                target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 6.前向推理与损失 / IoU 计算</span></span><br><span class="line">            <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">                outputs = model(<span class="built_in">input</span>)  </span><br><span class="line">                loss = <span class="number">0</span>  </span><br><span class="line">                <span class="keyword">for</span> output <span class="keyword">in</span> outputs:  </span><br><span class="line">                    <span class="comment"># 对每个输出单独计算损失，再求平均</span></span><br><span class="line">                    loss += criterion(output, target)  </span><br><span class="line">                loss /= <span class="built_in">len</span>(outputs)  </span><br><span class="line">                <span class="comment"># 只用最后一级 outputs[-1] 计算 IoU（最精细）</span></span><br><span class="line">                iou = iou_score(outputs[-<span class="number">1</span>], target)  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)  </span><br><span class="line">                loss = criterion(output, target)  </span><br><span class="line">                iou = iou_score(output, target)  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 7.指标累积</span></span><br><span class="line">            avg_meters[<span class="string">&#x27;loss&#x27;</span>].update(loss.item(), <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">            avg_meters[<span class="string">&#x27;iou&#x27;</span>].update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">  </span><br><span class="line">            postfix = OrderedDict([  </span><br><span class="line">                (<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg),  </span><br><span class="line">                (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg),  </span><br><span class="line">            ])  </span><br><span class="line">            pbar.set_postfix(postfix)  </span><br><span class="line">            pbar.update(<span class="number">1</span>)  </span><br><span class="line">        pbar.close()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以OrderedDict形式返回本epoch的 验证损失 与 验证 IoU</span></span><br><span class="line">    <span class="keyword">return</span> OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg)])</span><br></pre></td></tr></table></figure>
<h4 id="3-主流程"><a href="#3-主流程" class="headerlink" title="3.主流程"></a>3.主流程</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 获取参数字典  </span></span><br><span class="line">    config = <span class="built_in">vars</span>(parse_args())  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 自动生成模型名  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 保存配置文件  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 初始化损失函数  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建模型  </span></span><br><span class="line">    ... </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 选择优化器  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 配置学习率调度器  </span></span><br><span class="line">    ... </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载图像ID，并划分训练/验证集  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数据增强策略  </span></span><br><span class="line">    ...  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载数据集  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 日志记录结构  </span></span><br><span class="line">    log = OrderedDict([  </span><br><span class="line">        (<span class="string">&#x27;epoch&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;lr&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;loss&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;iou&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;val_loss&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;val_iou&#x27;</span>, []),  </span><br><span class="line">    ])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化参数</span></span><br><span class="line">    best_iou = <span class="number">0</span>  <span class="comment"># 记录迄今为止验证集上的最佳 IoU，用于模型保存判断</span></span><br><span class="line">    trigger = <span class="number">0</span>  <span class="comment"># - 记录连续验证集没有提升的 epoch 数，用于早停</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2.主训练循环 </span></span><br><span class="line">    <span class="comment"># 循环执行多个 epoch，每轮执行完整的训练-验证流程</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;epochs&#x27;</span>]):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch [%d/%d]&#x27;</span> % (epoch, config[<span class="string">&#x27;epochs&#x27;</span>]))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 每轮训练 &amp; 验证</span></span><br><span class="line">        train_log = train(config, train_loader, model, criterion, optimizer)  </span><br><span class="line">        val_log = validate(config, val_loader, model, criterion)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.学习率调度器更新  </span></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;CosineAnnealingLR&#x27;</span>: <span class="comment"># 基于 epoch 数变化</span></span><br><span class="line">            scheduler.step()  </span><br><span class="line">        <span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>: <span class="comment"># 根据 val loss 变化调整</span></span><br><span class="line">            scheduler.step(val_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 打印指标</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f&#x27;</span>  </span><br><span class="line">              % (train_log[<span class="string">&#x27;loss&#x27;</span>], train_log[<span class="string">&#x27;iou&#x27;</span>], val_log[<span class="string">&#x27;loss&#x27;</span>], val_log[<span class="string">&#x27;iou&#x27;</span>])) </span><br><span class="line">               </span><br><span class="line">        <span class="comment"># 6.日志记录  </span></span><br><span class="line">        log[<span class="string">&#x27;epoch&#x27;</span>].append(epoch)  </span><br><span class="line">        log[<span class="string">&#x27;lr&#x27;</span>].append(config[<span class="string">&#x27;lr&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;loss&#x27;</span>].append(train_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;iou&#x27;</span>].append(train_log[<span class="string">&#x27;iou&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;val_loss&#x27;</span>].append(val_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;val_iou&#x27;</span>].append(val_log[<span class="string">&#x27;iou&#x27;</span>])  </span><br><span class="line">        pd.DataFrame(log).to_csv(<span class="string">&#x27;models/%s/log.csv&#x27;</span> % config[<span class="string">&#x27;name&#x27;</span>], index=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">        trigger += <span class="number">1</span>  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 7.保存最佳模型  </span></span><br><span class="line">        <span class="keyword">if</span> val_log[<span class="string">&#x27;iou&#x27;</span>] &gt; best_iou:  </span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&#x27;models/%s/model.pth&#x27;</span> %  </span><br><span class="line">                       config[<span class="string">&#x27;name&#x27;</span>])  </span><br><span class="line">            best_iou = val_log[<span class="string">&#x27;iou&#x27;</span>]  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;=&gt; saved best model&quot;</span>)  </span><br><span class="line">            trigger = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 8.早停判断  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= config[<span class="string">&#x27;early_stopping&#x27;</span>] &lt;= trigger:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;=&gt; early stopping&quot;</span>)  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 9. 清理缓存</span></span><br><span class="line">        torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h2 id="4-验证"><a href="#4-验证" class="headerlink" title="4.验证"></a>4.验证</h2><h3 id="1-可视化结果"><a href="#1-可视化结果" class="headerlink" title="1.可视化结果"></a>1.可视化结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_examples</span>(<span class="params">datax, datay, model, num_examples=<span class="number">6</span></span>):  </span><br><span class="line">    <span class="comment"># 创建画布，准备绘制num_examples行、每行3列的图像（原图、预测、真值）</span></span><br><span class="line">    fig, ax = plt.subplots(nrows=num_examples, ncols=<span class="number">3</span>, figsize=(<span class="number">18</span>, <span class="number">4</span> * num_examples))  </span><br><span class="line">    m = datax.shape[<span class="number">0</span>]  <span class="comment"># 数据集样本总数（datax 是一个 batch 或完整验证集）</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> row_num <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):  </span><br><span class="line">        <span class="comment"># 随机选取一个图像索引</span></span><br><span class="line">        image_indx = np.random.randint(m)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取模型预测结果：输入的是一个图像 batch（1 张），</span></span><br><span class="line">        <span class="comment"># 输出后 squeeze 成单张，再转为 NumPy</span></span><br><span class="line">        image_arr = model(datax[image_indx:image_indx + <span class="number">1</span>]).squeeze(<span class="number">0</span>).detach().cpu().numpy()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 原始图像  </span></span><br><span class="line">        ax[row_num][<span class="number">0</span>].imshow(np.transpose(datax[image_indx].cpu().numpy(), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))[:, :, <span class="number">0</span>])  </span><br><span class="line">        ax[row_num][<span class="number">0</span>].set_title(<span class="string">&quot;Orignal Image&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 模型预测图像  </span></span><br><span class="line">        ax[row_num][<span class="number">1</span>].imshow(np.squeeze((image_arr &gt; <span class="number">0.40</span>)[<span class="number">0</span>, :, :].astype(<span class="built_in">int</span>)))  </span><br><span class="line">        ax[row_num][<span class="number">1</span>].set_title(<span class="string">&quot;Segmented Image localization&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># Ground Truth 掩码图像  </span></span><br><span class="line">        ax[row_num][<span class="number">2</span>].imshow(np.transpose(datay[image_indx].cpu().numpy(), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))[:, :, <span class="number">0</span>])  </span><br><span class="line">        ax[row_num][<span class="number">2</span>].set_title(<span class="string">&quot;Target image&quot;</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="2-验证-1"><a href="#2-验证-1" class="headerlink" title="2.验证"></a>2.验证</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    args = parse_args()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 1. 加载配置文件  </span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;models/%s/config.yml&#x27;</span> % args.name, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        config = yaml.load(f, Loader=yaml.FullLoader)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 打印配置信息，便于调试查看</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)  </span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> config.keys():  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (key, <span class="built_in">str</span>(config[key])))  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2. 初始化环境，启用 cuDNN 自动优化  </span></span><br><span class="line">    cudnn.benchmark = <span class="literal">True</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3. 创建模型  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; creating model %s&quot;</span> % config[<span class="string">&#x27;arch&#x27;</span>])  </span><br><span class="line">    model = archs.__dict__[config[<span class="string">&#x27;arch&#x27;</span>]](config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">                                           config[<span class="string">&#x27;input_channels&#x27;</span>],  </span><br><span class="line">                                           config[<span class="string">&#x27;deep_supervision&#x27;</span>])  </span><br><span class="line">    <span class="comment"># 加载到 CUDA（如可用）  </span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">        model = model.cuda()  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">        model.to(device)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4.加载数据集，读取所有图像ID（去掉扩展名）  </span></span><br><span class="line">    img_ids = glob(os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>, <span class="string">&#x27;*&#x27;</span> + config[<span class="string">&#x27;img_ext&#x27;</span>]))  </span><br><span class="line">    img_ids = [os.path.splitext(os.path.basename(p))[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> img_ids]  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 拆分验证集，随机划分出 20% 的验证集</span></span><br><span class="line">    _, val_img_ids = train_test_split(img_ids, test_size=<span class="number">0.2</span>, random_state=<span class="number">41</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 5.加载模型参数</span></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;models/%s/model.pth&#x27;</span> % config[<span class="string">&#x27;name&#x27;</span>]))  </span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># 设置为评估模式  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 6. 定义验证集增强，定义验证集图像增强（大小缩放 + 归一化）  </span></span><br><span class="line">    val_transform = Compose([  </span><br><span class="line">        A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  </span><br><span class="line">        A.Normalize(),  </span><br><span class="line">    ])  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载验证集数据集  </span></span><br><span class="line">    val_dataset = Dataset(  </span><br><span class="line">        img_ids=val_img_ids,  </span><br><span class="line">        img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  </span><br><span class="line">        mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  </span><br><span class="line">        img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  </span><br><span class="line">        mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  </span><br><span class="line">        num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">        transform=val_transform)  </span><br><span class="line">    <span class="comment"># 构建数据加载器  </span></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(  </span><br><span class="line">        val_dataset,  </span><br><span class="line">        batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  </span><br><span class="line">        shuffle=<span class="literal">False</span>,  </span><br><span class="line">        num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  </span><br><span class="line">        drop_last=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 7. 评估模型 初始化 IoU 评估器  </span></span><br><span class="line">    avg_meter = AverageMeter()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建输出目录  </span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;num_classes&#x27;</span>]):  </span><br><span class="line">        os.makedirs(os.path.join(<span class="string">&#x27;outputs&#x27;</span>, config[<span class="string">&#x27;name&#x27;</span>], <span class="built_in">str</span>(c)), exist_ok=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 8. 模型推理</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 验证阶段不计算梯度，节省显存 </span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">input</span>, target, meta <span class="keyword">in</span> tqdm(val_loader, total=<span class="built_in">len</span>(val_loader)):  </span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">                target = target.cuda()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">                target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 模型前向传播  </span></span><br><span class="line">            <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)[-<span class="number">1</span>] <span class="comment"># 深度监督则使用最后一个输出  </span></span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 计算 IoU 得分并更新平均器  </span></span><br><span class="line">            iou = iou_score(output, target)  </span><br><span class="line">            avg_meter.update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 输出后处理（Sigmoid + 转为 numpy）  </span></span><br><span class="line">            output = torch.sigmoid(output).cpu().numpy()  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 将预测结果保存为图像  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output)):  </span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;num_classes&#x27;</span>]):  </span><br><span class="line">                    cv2.imwrite(os.path.join(<span class="string">&#x27;outputs&#x27;</span>, config[<span class="string">&#x27;name&#x27;</span>], <span class="built_in">str</span>(c), meta[<span class="string">&#x27;img_id&#x27;</span>][i] + <span class="string">&#x27;.jpg&#x27;</span>), (output[i, c] * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>))  </span><br><span class="line">    <span class="comment"># 9. 打印验证结果 平均 IoU    </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;IoU: %.4f&#x27;</span> % avg_meter.avg)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 10.可视化样例  </span></span><br><span class="line">    plot_examples(<span class="built_in">input</span>, target, model, num_examples=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 11.释放显存  </span></span><br><span class="line">    torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<p>可视化样例如下图：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526155728.png"></p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>本文主要介绍了在PyTorch框架下使用U-Net++网络进行医学图像实例分割的代码实现：</p>
<ol>
<li>​<strong>数据预处理</strong>​<ul>
<li>数据集特点：670张细胞图像，二值掩码标签（0背景&#x2F;1细胞），图像尺寸较小</li>
<li>关键操作：合并多个独立细胞掩码为统一mask，使用OpenCV进行图像缩放和通道处理</li>
<li>数据增强：采用Albumentations库实现旋转&#x2F;翻转&#x2F;色彩扰动等增强策略</li>
</ul>
</li>
<li>​<strong>U-Net++网络结构</strong>​<ul>
<li>改进点：相比经典U-Net增加密集跳跃连接和深度监督机制</li>
<li>核心组件：<ul>
<li>VGGBlock：基础卷积模块（3x3卷积+BN+ReLU×2）</li>
<li>嵌套解码结构：convX_Y命名规则表示第X层第Y次特征融合</li>
</ul>
</li>
<li>深度监督：中间层输出辅助损失，缓解梯度消失</li>
</ul>
</li>
<li>​<strong>模型训练</strong>​<ul>
<li>损失函数：BCEDiceLoss（兼顾像素精度和区域重叠）和LovaszHingeLoss（优化IoU指标）</li>
<li>训练策略：余弦退火学习率、早停机制、模型保存最佳检查点</li>
<li>评估指标：IoU（交并比）作为主要评估标准</li>
</ul>
</li>
<li>​<strong>结果验证</strong>​<ul>
<li>可视化对比：并列显示原图、预测结果和真实标注</li>
<li>性能评估：批量计算验证集平均IoU，保存预测结果图像</li>
</ul>
</li>
</ol>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
<li>albumentations: 2.0.6</li>
</ul>
<h3 id="资源和代码"><a href="#资源和代码" class="headerlink" title="资源和代码"></a>资源和代码</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/011_U-net%2B%2B
</code></pre>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
        <tag>U-Net</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割DeepLab系列算法思路分析</title>
    <url>/2025/06/10/019-deeplab-series/</url>
    <content><![CDATA[<h2 id="1-DeepLab概述"><a href="#1-DeepLab概述" class="headerlink" title="1.DeepLab概述"></a>1.DeepLab概述</h2><p>DeepLab是由谷歌提出的专用于<strong>语义分割</strong>任务的系列模型，核心目标是为图像中的<strong>每个像素分配一个语义类别标签</strong>​。它在图像分割领域有很不错效果，曾在PASCAL VOC-2012数据集上达到当时最高水平（mIOU 79.7%） ，并在Cityscapes、PASCAL-Context等数据集上广泛使用。DeepLab的优势在于能够在保持高精度的同时还能结合上下文信息，对物体边界进行精确定位。</p>
<h3 id="1-U-Net-与-DeepLab"><a href="#1-U-Net-与-DeepLab" class="headerlink" title="1.U-Net 与 DeepLab"></a>1.U-Net 与 DeepLab</h3><p>同样是做分割任务<strong>U-Net</strong>和<strong>DeepLab</strong>有啥区别呢？<br><strong>U-Net</strong>更适合在生物医学图像分割（细胞、器官、病变区域等）、小目标分割、需要精确边界轮廓的应用，其优势边界分割极其精细、在<strong>小样本数据集</strong>​（尤其是医学影像）上表现卓越、架构相对也简单清晰、易于实现和改进。</p>
<span id="more"></span>
<p><strong>DeepLab (V3+)​</strong>适合对自动驾驶场景理解（Cityscapes 等）、可以用在通用场景分割（PASCAL VOC, ADE20K）、街景分割、实时分割等，它对<strong>多尺度物体识别鲁棒性强</strong>、擅长处理<strong>复杂场景和背景</strong>、在利用强大的骨干网络预训练时优势明显、并且在<strong>大规模自然场景数据集</strong>上能有不错的精度（尤其对大型物体）、推理速度（尤其使用轻量骨干时）也有优势。</p>
<p><strong>U-Net</strong>适用的任务有个显著特点是目标较小，我们可以将这些小目标看作是在整张图像中的局部区域，在此类任务中，仅依赖图像的局部特征往往就足以完成分割任务。而<strong>DeepLab</strong> 所面向的多为真实世界中的语义分割任务，在这些任务中，目标往往尺寸较大（如整个人体、一辆汽车），同时，这些目标还可能存在复杂的背景干扰、遮挡关系等，因此，仅凭局部特征已难以获得准确的分割结果，而这其中的实现原理不得不提一个概念<strong>感受野（Receptive Field）</strong>。</p>
<h3 id="2-感受野（Receptive-Field）"><a href="#2-感受野（Receptive-Field）" class="headerlink" title="2.感受野（Receptive Field）"></a>2.感受野（Receptive Field）</h3><p><strong>感受野（Receptive Field，RF）</strong> 描述的是网络中某一层某个特征图上的一个点所“看到”或“感受”到的输入图像上的区域大小。简单来说就是特征图上的一个点，是由输入图像上多大范围的像素计算出来的？这个输入图像上的范围就是感受野。</p>
<p>为什么感受野重要？<br>因为感受野决定了神经元能够捕获信息的<strong>空间范围</strong>，小的感受野关注局部细节（如边缘、纹理），大的感受野能理解更广阔的区域甚至全局结构（如物体、场景）。通过堆叠卷积层（或池化层），网络可以在较深的层获得更大的感受野，从而整合更大范围内的信息，但深度越深计算开销也会越大。</p>
<h3 id="3-深层网络的局限性"><a href="#3-深层网络的局限性" class="headerlink" title="3.深层网络的局限性"></a>3.深层网络的局限性</h3><p>增大感受野，常见的做法是加深网络结构，堆叠更多的卷积层，同时再辅以池化（Pooling）操作。然而这种方式虽然扩大了感受野，却还会带来其它副作用：<strong>特征图的空间分辨率逐渐降低</strong>，导致部分精细信息的丢失，这在语义分割等任务中是一个非常需要关注的问题，因为准确的像素级定位对于分割质量至关重要。</p>
<p>以 U-Net 为例，其采用<strong>下采样—上采样</strong>结构，试图在恢复高分辨率的同时保留上下文语义信息，但这种方法在处理大目标、复杂结构时仍有不足，尤其是在更深层次的特征图中，细节信息容易丢失。为了解决这个问题，DeepLab 系列算法引入了一个关键技术：空洞卷积（Dilated Convolution）。</p>
<h2 id="2-空洞卷积（Dilated-Convolution）"><a href="#2-空洞卷积（Dilated-Convolution）" class="headerlink" title="2.空洞卷积（Dilated Convolution）"></a>2.空洞卷积（Dilated Convolution）</h2><p>空洞卷积（Dilated Convolution），也称为<strong>膨胀卷积</strong>或<strong>扩张卷积</strong>，是卷积神经网络中一种在不增加参数量或计算量的前提下，显著扩大感受野（Receptive Field）的关键技术，它通过在标准卷积核的权重之间插入“空洞”（零值）来实现的。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609140911.png"></p>
<h3 id="1-标准卷积（Standard-Convolution）​​"><a href="#1-标准卷积（Standard-Convolution）​​" class="headerlink" title="1.标准卷积（Standard Convolution）​​"></a>1.标准卷积（Standard Convolution）​​</h3><p>标准卷积是最基础的卷积操作，其核心特点是卷积核在输入特征图上<strong>连续滑动</strong>进行计算。具体而言，每个输出像素是通过卷积核与输入特征图中对应的<strong>连续局部区域</strong>​（例如3×3的相邻像素块）进行逐元素相乘并求和得到的。</p>
<h4 id="​1-特点与适用场景​"><a href="#​1-特点与适用场景​" class="headerlink" title="​1.特点与适用场景​"></a>​1.特点与适用场景​</h4><ul>
<li>​<strong>连续采样</strong>​：卷积核的权重作用于相邻像素，能够有效捕捉局部细节特征</li>
<li>​<strong>有限感受野</strong>​：每个特征点仅能感知输入图像中的小范围区域（如3×3的局部窗口）</li>
<li>​<strong>适用场景</strong>​：在需要精细局部特征的任务中有不错的表现，例如<strong>小目标检测</strong>​（如医学图像中的细胞、显微结构）或<strong>局部特征提取</strong></li>
<li>​<strong>局限性</strong>​：由于感受野较小，在处理<strong>大尺度目标</strong>或<strong>复杂场景</strong>时，难以捕获足够的上下文信息，这会限制模型的全局建模能力</li>
</ul>
<h4 id="2-小卷积核VS大卷积核"><a href="#2-小卷积核VS大卷积核" class="headerlink" title="2.小卷积核VS大卷积核"></a>2.小卷积核VS大卷积核</h4><p>既然3×3的感受野偏小，为什么我们倾向于堆叠多个小卷积核而非使用大卷积核？</p>
<p>主要原因有：<br>​1.<strong>参数效率更高​</strong>：三层3×3卷积(27C²参数)相比单个7×7卷积(49C²参数)，在实现同样7×7感受野的情况下，参数量减少45%，可以显著降低模型复杂度，有效控制过拟合风险。</p>
<p>​2.<strong>表达能力更强</strong>：每个小卷积层后都包含BN和ReLU等非线性操作，三层3×3卷积提供三次非线性变换，而单个7×7卷积仅有一次，这样可以使模型具备更强的特征抽象能力。<br>	​<br>3.<strong>训练更稳定</strong>：​小卷积核更容易初始化，梯度传播更稳定，收敛过程更平滑，当然这种设计也更灵活，便于集成到残差连接、注意力机制等各种模块中。</p>
<p>​4.<strong>计算更高效</strong>​：虽然总计算量相近，但小卷积核更利于并行计算，更适合现代GPU架构，在实际部署中往往具有更优的推理速度。</p>
<p>这种设计理念已在VGGNet、ResNet等经典网络中得到验证，体现了”分解大问题为多个小问题”的核心思想。虽然在早期网络层或特殊任务中，大卷积核仍有一定优势，但小卷积核堆叠已成为大多数场景的更优选择。</p>
<h3 id="​2-空洞卷积（Dilated-Convolution）​​"><a href="#​2-空洞卷积（Dilated-Convolution）​​" class="headerlink" title="​2.空洞卷积（Dilated Convolution）​​"></a>​2.空洞卷积（Dilated Convolution）​​</h3><p>空洞卷积是对标准卷积的改进，通过引入<strong>膨胀率（dilation rate）​</strong>参数，在卷积核元素之间插入固定间隔的空洞，使得采样位置变为<strong>非连续</strong>。这一设计能够在<strong>不增加参数量</strong>的前提下，显著扩大感受野。</p>
<h4 id="​1-核心机制​"><a href="#​1-核心机制​" class="headerlink" title="​1.核心机制​"></a>​1.核心机制​</h4><ul>
<li>​<strong>感受野扩展</strong>​：例如，一个3×3的卷积核在设置<code>dilation rate=2</code>时，其等效感受野可扩大至5×5（相当于在核元素之间插入1个空洞）。若进一步增大<code>dilation rate=4</code>，感受野可扩展至9×9</li>
<li>​<strong>参数效率</strong>​：空洞卷积仍使用原始卷积核的权重（如3×3的9个参数），计算复杂度与标准卷积相同，仅通过调整采样间隔来扩大感受野</li>
<li>​<strong>稀疏采样</strong>​：随着<code>dilation rate</code>增大，实际参与计算的特征点数量减少，但覆盖的物理范围可以更广</li>
</ul>
<h4 id="​2-优势​"><a href="#​2-优势​" class="headerlink" title="​2.优势​"></a>​2.优势​</h4><ol>
<li>​<strong>大感受野与低计算开销</strong>​：无需通过堆叠更多卷积层或下采样操作（如池化）来扩大感受野，从而避免了信息损失和分辨率下降的问题。这一特性使其特别适合以下场景：<ul>
<li>​<strong>大尺度目标识别</strong>​（如建筑物、自然场景中的大型物体）</li>
<li>​<strong>复杂结构分割</strong>​（如场景解析、医学图像中的器官分割）</li>
<li>​<strong>存在遮挡时的特征判别</strong>​</li>
</ul>
</li>
<li>​<strong>分辨率保持</strong>​：空洞卷积能够在不降低特征图分辨率的情况下捕获全局上下文信息，这对密集预测任务（如语义分割）至关重要</li>
<li>​<strong>实现简单</strong>​：仅需在标准卷积中设置<code>dilation_rate</code>参数即可（例如PyTorch的<code>nn.Conv2d(dilation=2)</code>），因此被广泛应用于图像分类、目标检测、人体姿态估计等任务。</li>
</ol>
<h4 id="​3-局限性​"><a href="#​3-局限性​" class="headerlink" title="​3.局限性​"></a>​3.局限性​</h4><ul>
<li>​<strong>特征稀疏性</strong>​：过大的<code>dilation rate</code>会导致卷积核采样点过于稀疏，可能无法充分捕捉局部细节信息</li>
<li>​<strong>语义连续性假设</strong>​：空洞卷积依赖于输入特征的局部相关性，若目标区域的细节密集（如高频纹理），稀疏采样可能导致关键信息丢失</li>
</ul>
<h2 id="3-SPP层：空间金字塔池化"><a href="#3-SPP层：空间金字塔池化" class="headerlink" title="3.SPP层：空间金字塔池化"></a>3.SPP层：空间金字塔池化</h2><p>在 DeepLab 的 Home 版本中，模型引入了一个关键结构——<strong>SPP（Spatial Pyramid Pooling）层</strong>，用来增强模型对不同输入尺寸和多尺度信息的处理能力。要理解它的设计初衷，我们先从一个经典概念说起：<strong>图像金字塔（Image Pyramid）</strong>。</p>
<h3 id="1-图像金字塔"><a href="#1-图像金字塔" class="headerlink" title="1.图像金字塔"></a>1.图像金字塔</h3><p>图像金字塔是一种模拟人类多尺度视觉观察的方法。举个例子，当你看一幅画时，凑近能看到画笔细节，站远些能看到整体构图。图像金字塔正是通过生成同一图像的多个不同分辨率版本（从清晰的原图到逐渐模糊的小图），构建一个类似金字塔的多层结构，从而帮助算法同时理解细节与全局。</p>
<h4 id="1-核心原理​"><a href="#1-核心原理​" class="headerlink" title="1.核心原理​"></a>1.核心原理​</h4><p>从原始图像开始，每进行一步，都做<strong>高斯模糊</strong>，轻微模糊图像（抑制噪声和细节），再<strong>降采样</strong>​：缩小图像尺寸（如长宽各减半），重复这一过程，得到一系列越来越小的图像（原始图：1000×1000 → 第1层：500×500 → 第2层：250×250 → 第3层：125×125…）。在这个过程中还需要记录相邻层之间的差异信息（高分辨率图像减去低分辨率图像上采样后的结果），用于后续重建图像细节。</p>
<h4 id="2-优势"><a href="#2-优势" class="headerlink" title="2.优势"></a>2.优势</h4><p>可以解决目标尺度变化问题，对于​<strong>小目标</strong>​（如蚂蚁）在高分辨率层（底层）清晰可见，对于​<strong>大目标</strong>​（如建筑）在低分辨率层（高层）更易识别整体结构。</p>
<h4 id="3-问题点"><a href="#3-问题点" class="headerlink" title="3.问题点"></a>3.问题点</h4><p>然而，在实际中，我们往往受限于网络结构，尤其是<strong>全连接层</strong>。这类层通常要求输入尺寸固定，否则会导致参数无法匹配。而卷积层虽然本身支持任意输入大小，但在需要将特征图汇聚成固定维度表示（如用于分类）时，仍然会受到限制。</p>
<h3 id="2-SPP-层（Spatial-Pyramid-Pooling）"><a href="#2-SPP-层（Spatial-Pyramid-Pooling）" class="headerlink" title="2.SPP 层（Spatial Pyramid Pooling）"></a>2.SPP 层（Spatial Pyramid Pooling）</h3><p>SPP 层的设计目标有两个：让模型支持<strong>任意尺寸的输入图像</strong>和强化<strong>多尺度特征的表达能力</strong>。<br>其核心思想是：<strong>将特征图划分为多个尺度的网格区域，分别进行池化（如最大池化），然后将所有池化结果拼接起来，形成一个固定维度的向量。</strong></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150154.png"></p>
<p>如上图是SPP 层嵌入在 CNN 模型中的位置和处理流程，核心包含以下几个步骤：</p>
<h4 id="1-输入图像-→-卷积层提取特征"><a href="#1-输入图像-→-卷积层提取特征" class="headerlink" title="1. 输入图像 → 卷积层提取特征"></a>1. 输入图像 → 卷积层提取特征</h4><p>图的底部是输入图像，经过一系列卷积层（如图中的 conv₅）之后，得到一组大小为任意尺寸的特征图，这组特征图的尺寸可能因输入图像的大小不同而不同。而<strong>SPP 层的设计正是为了适应这种“尺寸不固定”的特征图输入</strong>。</p>
<h4 id="2-SPP-层：空间金字塔划分-池化"><a href="#2-SPP-层：空间金字塔划分-池化" class="headerlink" title="2. SPP 层：空间金字塔划分 + 池化"></a>2. SPP 层：空间金字塔划分 + 池化</h4><p>在“spatial pyramid pooling layer”部分，特征图被按照不同粒度划分为多个子区域，分别进行池化（通常是最大池化 Max Pooling），每层划分如下：</p>
<ul>
<li><strong>第一层（蓝色）</strong>：将特征图划分为 <strong>4×4 网格</strong> → 16 个子区域，每个区域进行池化，得到 <code>16 × 256-d</code> 的特征向量</li>
<li><strong>第二层（绿色）</strong>：划分为 <strong>2×2 网格</strong> → 4 个区域，输出 <code>4 × 256-d</code></li>
<li><strong>第三层（灰色）</strong>：全局池化（即 1×1） → 输出 <code>1 × 256-d</code><br>注意：每个子区域输出的都是 256-d（即 256 维）特征向量，因为池化操作只作用在空间维度，不改变通道数。</li>
</ul>
<h4 id="3-特征拼接成固定长度表示"><a href="#3-特征拼接成固定长度表示" class="headerlink" title="3. 特征拼接成固定长度表示"></a>3. 特征拼接成固定长度表示</h4><p>将三层输出的所有特征拼接在一起，得到一个长度为：<br>$(16 + 4 + 1) \times 256 &#x3D; 21 \times 256$<br>这个向量作为<strong>固定长度的特征表示（fixed-length representation）</strong>，传递给后续的全连接层（如 fc₆, fc₇）进行分类等任务。这样就可以不依赖于输入图像的原始尺寸，因此具备良好的通用性</p>
<h4 id="4-多尺度特征融合的优势"><a href="#4-多尺度特征融合的优势" class="headerlink" title="4. 多尺度特征融合的优势"></a>4. 多尺度特征融合的优势</h4><p>通过以上操作，SPP 层不仅实现了输入尺寸无关的特征表达，还融合了不同尺度的上下文信息：</p>
<ul>
<li>局部细节（4×4 子区域）</li>
<li>中等尺度结构（2×2）</li>
<li>全局语义（1×1 全局池化）<br>这种方式不仅显著提升了模型在复杂场景下的表现能力，而且还被后续许多模型广泛借鉴和作为改进的基础结构。</li>
</ul>
<h2 id="4-ASPP特征融合策略"><a href="#4-ASPP特征融合策略" class="headerlink" title="4.ASPP特征融合策略"></a>4.ASPP特征融合策略</h2><p>在 DeepLab 系列的发展过程中，第二代模型（DeepLab v2）又引入了一项重要改进：<strong>ASPP（Atrous Spatial Pyramid Pooling）结构</strong>。</p>
<h3 id="1-传统的多尺度特征提取策略"><a href="#1-传统的多尺度特征提取策略" class="headerlink" title="1. 传统的多尺度特征提取策略"></a>1. 传统的多尺度特征提取策略</h3><p>为了更好地理解 ASPP 的动机和结构，我们先回顾论文中所展示的一张对比图，该图总结了几种不同的多尺度特征提取方法：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150405.png"></p>
<h4 id="图像金字塔（Image-Pyramid-）"><a href="#图像金字塔（Image-Pyramid-）" class="headerlink" title="图像金字塔（Image Pyramid ）"></a>图像金字塔（Image Pyramid ）</h4><p>如上面讲的，图像金字塔是将原始图像缩放成多个尺度（比如原图、小一半、再小一半），然后分别送入同一个模型进行特征提取。其核心思想是用多种分辨率的输入图像，让模型在多个尺度上提取特征，最后再将这些特征合并。</p>
<ul>
<li><strong>优点</strong>：显式地建模不同物体尺度</li>
<li><strong>缺点</strong>：计算成本高，因为每个尺度都要跑一遍模型</li>
</ul>
<h4 id="编码器–解码器结构（Encoder–Decoder-）"><a href="#编码器–解码器结构（Encoder–Decoder-）" class="headerlink" title="编码器–解码器结构（Encoder–Decoder ）"></a>编码器–解码器结构（Encoder–Decoder ）</h4><p>编码器–解码器结构是先下采样图像提取深层特征，再通过上采样逐步恢复空间信息。其核心思想是在编码阶段提取抽象语义信息，再在解码阶段恢复空间细节。</p>
<ul>
<li><strong>优点</strong>：结构灵活，适用于需要空间分辨率输出的任务，如语义分割</li>
<li><strong>缺点</strong>：可能导致细节丢失，需注意特征融合方式</li>
</ul>
<h4 id="空洞卷积加深网络（Atrous-Convolution-）"><a href="#空洞卷积加深网络（Atrous-Convolution-）" class="headerlink" title="空洞卷积加深网络（Atrous Convolution ）"></a>空洞卷积加深网络（Atrous Convolution ）</h4><p> 空洞卷积是在不增加参数和计算量的前提下，通过引入“空洞”（即膨胀）卷积扩大感受野。其核心思想是通过设置不同的膨胀率，让卷积核在多个尺度上捕捉上下文信息。</p>
<ul>
<li><strong>优点</strong>：提升感受野、保持特征图大小，这是 DeepLab 系列的核心技术之一</li>
<li><strong>缺点</strong>：空洞卷积在小目标上效果可能不如标准卷积</li>
</ul>
<h4 id="空间金字塔池化（Spatial-Pyramid-Pooling-）"><a href="#空间金字塔池化（Spatial-Pyramid-Pooling-）" class="headerlink" title="空间金字塔池化（Spatial Pyramid Pooling ）"></a>空间金字塔池化（Spatial Pyramid Pooling ）</h4><p>空间金字塔池化是对同一张特征图，采用不同尺度的池化窗口提取信息（如 1×1、2×2、4×4），然后拼接结果。其核心思想是通过多尺度的池化操作融合局部和全局特征，获得多尺度上下文。</p>
<ul>
<li><strong>优点</strong>：输入尺寸灵活，能够高效建模多尺度语义信息</li>
<li><strong>缺点</strong>：不像空洞卷积那样直接在卷积层扩展感受野</li>
</ul>
<h3 id="2-ASPP：融合空洞卷积与-SPP-的改进结构"><a href="#2-ASPP：融合空洞卷积与-SPP-的改进结构" class="headerlink" title="2.ASPP：融合空洞卷积与 SPP 的改进结构"></a>2.ASPP：融合空洞卷积与 SPP 的改进结构</h3><p>基于上述方法，DeepLab v2 提出了一种更高效的方案——<strong>ASPP（Atrous Spatial Pyramid Pooling）</strong>。该结构结合了空洞卷积和 SPP 的思想，其核心目标是：<strong>在保持计算效率的同时，进一步提升模型的多尺度感知能力</strong>。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150455.png"></p>
<h4 id="1-输入图像（左侧猫咪图）"><a href="#1-输入图像（左侧猫咪图）" class="headerlink" title="1.输入图像（左侧猫咪图）"></a>1.输入图像（左侧猫咪图）</h4><p>首先进入一系列卷积和池化操作，逐步提取特征并降低分辨率。图中标注了输出特征图的空间步幅（output stride），先后为 4、8、16，表示图像被缩小的倍数。</p>
<h4 id="2-主干网络"><a href="#2-主干网络" class="headerlink" title="2. 主干网络"></a>2. 主干网络</h4><p>由多个 block 组成（如 Block1、Block2 等），每个 block 提取越来越抽象的语义特征。在 Block3 之后，使用了一个 <strong>空洞率为 2 的卷积</strong>，扩大感受野，同时保持分辨率不变。</p>
<h4 id="3-ASPP-模块（右侧黄色框）"><a href="#3-ASPP-模块（右侧黄色框）" class="headerlink" title="3. ASPP 模块（右侧黄色框）"></a>3. ASPP 模块（右侧黄色框）</h4><p>这是图中的重点部分，也就是所谓的<strong>空洞空间金字塔池化结构</strong>，它包含多个分支，每个分支采用不同的卷积感受野。<br>ASPP 用多个不同扩张率（dilation rate）的卷积并行处理同一张特征图，从而获取不同尺度的上下文信息：<br>a. Atrous Convolution 分支：</p>
<ul>
<li><strong>1x1 卷积</strong>：相当于不考虑邻域，仅用于压缩通道或增加非线性</li>
<li><strong>3x3 空洞卷积 rate&#x3D;6</strong>：感受野较小，适合提取中等区域信息</li>
<li><strong>3x3 空洞卷积 rate&#x3D;12</strong>：感受野更大，可以看到更远的上下文</li>
<li><strong>3x3 空洞卷积 rate&#x3D;18</strong>：感受野最大，有利于理解全局语义<br>b. Image Pooling 分支：</li>
<li>对整张特征图做<strong>全局平均池化</strong>，提取全局语义，再通过上采样还原回特征图大小，这样主要是为了引入<strong>图像整体场景的信息</strong></li>
</ul>
<h4 id="4-融合输出："><a href="#4-融合输出：" class="headerlink" title="4.融合输出："></a>4.融合输出：</h4><p>将上述五个分支的输出进行<strong>拼接</strong>（Concat），然后接一个 <strong>1x1 卷积</strong> 用于融合特征。得到的是融合了多个尺度信息的统一特征图，其空间尺寸不变（仍是 output stride 16 对应的大小）。</p>
<p>这种结构的优势在于：</p>
<ul>
<li>可同时具备局部精细信息与全局上下文信息</li>
<li>利用空洞卷积实现更大感受野，避免了图像金字塔带来的重复计算</li>
<li>与 SPP 相比，ASPP 通过引入可调膨胀率的卷积操作，进一步增强了特征的多样性与表达力</li>
</ul>
<p>虽然 DeepLab 系列在不断演进，但每一代之间的改进幅度并不总是显著。例如，在 DeepLab v3 之后，作者并未直接发布 “v4”，而是采用了“DeepLab v3+”这样的命名。这种命名方式反映了在一定程度上，后续改进更侧重于细节优化，而非架构。<br>因此，对于DeepLab 系列模型，理解 <strong>空洞卷积</strong> 与 <strong>ASPP&#x2F;SPP 结构</strong> 的本质与用法是关键。这些组件在语义分割及其他下游任务中具有广泛的适用性和借鉴价值。</p>
<h2 id="5-DeepLab-v3-网络架构"><a href="#5-DeepLab-v3-网络架构" class="headerlink" title="5.DeepLab v3+网络架构"></a>5.DeepLab v3+网络架构</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150956.png"><br>通过如上网络结构图即可很好地理解其设计核心，DeepLab v3+ 的整体结构可以概括为两个主要部分， ​编码器（蓝色虚线框）​，负责特征提取和压缩，解码器（红色虚线框）​​，负责重建细节并输出结果。</p>
<h3 id="1-Encoder模块"><a href="#1-Encoder模块" class="headerlink" title="1.Encoder模块"></a>1.Encoder模块</h3><p>在输入图像进入主干网络（Backbone）进行初步特征提取之后，DeepLab v3+ 在编码器部分引入了 ASPP（Atrous Spatial Pyramid Pooling）模块，用于捕捉不同尺度的上下文信息。<br>ASPP 的设计核心包括以下几条并行路径：</p>
<ol>
<li><strong>1×1 卷积分支</strong>：获取局部精细特征</li>
<li><strong>三个不同空洞率（rate）的空洞卷积分支</strong>：空洞卷积可以在不增加参数量的前提下扩大感受野，捕捉更丰富的上下文信息，不同的空洞率表示不同的采样间距，从而实现多尺度感知</li>
<li><strong>全局平均池化分支</strong>：对整张特征图做平均池化，再通过 1×1 卷积和上采样恢复到原尺寸，作为全局语义信息的补充。<br>这五个分支的输出特征图在尺寸一致的前提下拼接在一起，随后通过 1×1 卷积进一步融合，形成更具语义表达力的特征表示。</li>
</ol>
<blockquote>
<p>注：不同空洞率下的空洞卷积通过适当的 padding 来保证输出特征图尺寸一致。</p>
</blockquote>
<h3 id="2-Decoder模块"><a href="#2-Decoder模块" class="headerlink" title="2.Decoder模块"></a>2.Decoder模块</h3><p>为了提升分割结果的边缘细节与空间定位精度，DeepLab v3+ 引入了 Decoder 结构，将编码器提取的高级语义特征与浅层的低级特征进行融合。</p>
<p>具体流程如下：</p>
<ol>
<li><strong>浅层特征提取</strong>：从主干网络中提取一个较浅层次（如第一个 Block）的输出，作为低级特征（Low-Level Features），用于补充边缘与细节信息</li>
<li><strong>上采样高层特征</strong>：将 ASPP 输出的高层语义特征上采样，使其尺寸与低层特征一致</li>
<li><strong>通道对齐与拼接</strong>：对低层特征先通过 1×1 卷积降维，减少通道数，以匹配高层特征。将两者在通道维度上拼接</li>
<li><strong>融合与预测</strong>：拼接后的特征再经过若干个 3×3 卷积进行融合，最后上采样至输入图像的大小，输出逐像素的语义预测结果</li>
</ol>
<h3 id="3-网络设计总结与扩展性"><a href="#3-网络设计总结与扩展性" class="headerlink" title="3.网络设计总结与扩展性"></a>3.网络设计总结与扩展性</h3><p>DeepLab v3+ 的设计虽然不复杂，但融合了多种关键思想：</p>
<ul>
<li><strong>编码器-解码器结构（Encoder-Decoder）</strong>：提取高语义与低空间分辨率的特征后，通过解码器恢复空间信息</li>
<li><strong>ASPP 模块</strong>：利用空洞卷积实现多尺度感受野的构建</li>
<li><strong>特征融合机制</strong>：结合浅层的局部细节与深层的全局语义，提高分割精度</li>
</ul>
<h2 id="6-DeepLab算法演进总结"><a href="#6-DeepLab算法演进总结" class="headerlink" title="6.DeepLab算法演进总结"></a>6.DeepLab算法演进总结</h2><h3 id="1-​核心问题定位​"><a href="#1-​核心问题定位​" class="headerlink" title="1. ​核心问题定位​"></a>1. ​核心问题定位​</h3><p>针对语义分割任务中<strong>大尺度目标识别</strong>与<strong>复杂场景理解</strong>的挑战，传统方案（如U-Net）依赖局部特征和逐步下采样，易丢失全局信息。DeepLab提出<strong>空洞卷积（Dilated Convolution）​</strong>​。</p>
<h3 id="2-​关键技术：空洞卷积​"><a href="#2-​关键技术：空洞卷积​" class="headerlink" title="2. ​关键技术：空洞卷积​"></a>2. ​关键技术：空洞卷积​</h3><p> ​在标准卷积核中插入”空洞”（零值间距），通过调整<strong>膨胀率（dilation rate）​</strong>​ 控制采样间隔。<br>​<strong>优势</strong>​：  </p>
<ul>
<li>同等参数量下<strong>显著扩大感受野</strong>​（如3×3卷积在dilation&#x3D;6时等效13×13感受野）  </li>
<li><strong>保持特征图分辨率</strong>，避免池化导致的信息损失  </li>
<li>支持<strong>多尺度语义捕获</strong>​（不同膨胀率对应不同感受野）</li>
</ul>
<h3 id="3-​多尺度特征融合机制"><a href="#3-​多尺度特征融合机制" class="headerlink" title="3. ​多尺度特征融合机制"></a>3. ​多尺度特征融合机制</h3><p>ASPP结构（Atrous Spatial Pyramid Pooling）​：并行多分支结构，1×1卷积 + 多个不同膨胀率的3×3空洞卷积（如rate&#x3D;6,12,18） + 全局平均池化。拼接各分支输出，通过1×1卷积融合多尺度特征<br><strong>效果</strong>​：  </p>
<ul>
<li>同时捕获局部细节（小膨胀率）与全局上下文（大膨胀率）  </li>
<li>提升模型对尺度变化和遮挡的鲁棒性</li>
</ul>
<h3 id="4-​DeepLab-v3-架构创新"><a href="#4-​DeepLab-v3-架构创新" class="headerlink" title="4. ​DeepLab v3+架构创新"></a>4. ​DeepLab v3+架构创新</h3><p><strong>编码器-解码器设计</strong>​：</p>
<ul>
<li>​<strong>编码器</strong>​：骨干网络（如ResNet）+ ASPP模块 → 提取<strong>高语义特征</strong>​</li>
<li>​<strong>解码器</strong>​：<ol>
<li>对深层特征上采样</li>
<li>与浅层高分辨率特征拼接（经1×1卷积对齐通道）</li>
<li>3×3卷积融合 → 恢复<strong>细节边界</strong>​<br>​<strong>技术融合</strong>​：<br>  空洞卷积（扩大感受野） + ASPP（多尺度融合） + 跳连（补充细节）</li>
</ol>
</li>
</ul>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><ol>
<li>DeepLab v1 论文地址：<a href="https://arxiv.org/pdf/1412.7062v4.pdf">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</a>》</li>
<li>DeepLab v2 论文地址：<a href="https://arxiv.org/abs/1606.00915">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a>》</li>
<li>DeepLab v3 论文地址：<a href="https://arxiv.org/pdf/1706.05587v3.pdf">Rethinking Atrous Convolution for Semantic Image Segmentation</a></li>
<li>DeepLab v3+ 论文地址：<a href="https://arxiv.org/pdf/1802.02611v3.pdf">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a>》</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
        <tag>DeepLab</tag>
      </tags>
  </entry>
  <entry>
    <title>​DeepLabv3+语义分割代码解析</title>
    <url>/2025/06/18/020-deepdab3-with-pascal-voc2012/</url>
    <content><![CDATA[<h2 id="1-Pascal-VOC-2012"><a href="#1-Pascal-VOC-2012" class="headerlink" title="1.Pascal VOC 2012"></a>1.Pascal VOC 2012</h2><p><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/">Pascal VOC (Visual Object Classes) 2012</a> 数据集是计算机视觉领域具有里程碑意义的公开基准数据集，以其全面性、高质量标注和在众多任务上的广泛应用而著称，被广泛用于模型训练、评估与比较研究，尤其作为图像分类、目标检测和语义分割等核心任务的经典基准。</p>
<h3 id="1-核心特性：多任务基准"><a href="#1-核心特性：多任务基准" class="headerlink" title="1. 核心特性：多任务基准"></a>1. 核心特性：多任务基准</h3><p>Pascal VOC 2012 的核心价值在于其<strong>多任务性</strong>。它并非针对单一任务设计，而是为多种计算机视觉任务提供了丰富且一致的标注：</p>
<span id="more"></span>
<ul>
<li>​<strong>图像分类 (Image Classification)：​</strong>​ 判断图像中存在的物体类别（20类）。</li>
<li>​<strong>目标检测 (Object Detection)：​</strong>​ 定位并识别图像中的目标物体，提供物体的<strong>边界框 (Bounding Boxes)​</strong>​ 和<strong>类别标签</strong>。</li>
<li>​<strong>语义分割 (Semantic Segmentation)：​</strong>​ 为图像中的<strong>每一个像素</strong>分配类别标签（包含20类物体和背景）。这也是本文聚焦的核心任务。​​</li>
<li>其他任务：如<strong>动作识别 (Action Recognition)​</strong>​ 等。<br>丰富的标注（类别标签、边界框、像素级分割掩码）使其成为评估模型在多种视觉理解能力上的通用性强基准。</li>
</ul>
<h3 id="2-数据组成与目录结构​"><a href="#2-数据组成与目录结构​" class="headerlink" title="2. 数据组成与目录结构​"></a>2. 数据组成与目录结构​</h3><p>数据集解压后几个文件夹分别作用：</p>
<ul>
<li>​<strong>JPEGImages&#x2F;</strong>：存储数据集所有原始 <code>.jpg</code> 格式图像文件，内容涵盖包含20类目标的多样化真实世界场景。</li>
<li>​<strong>Annotations&#x2F;​</strong>：​ 存储 ​<strong>XML格式</strong>​ 的目标检测标注文件。每个图像对应一个 <code>.xml</code> 文件，详细记录其包含物体的<strong>类别</strong>、<strong>边界框坐标 (如 xmin, ymin, xmax, ymax)​</strong>​ 以及其他属性（如是否截断、是否困难样本等）。</li>
<li>​<strong>SegmentationClass&#x2F;​</strong>：​ 存储标准的像素级语义分割标注图（伪彩色图，每个像素值对应预设类别）。</li>
<li>​<strong>SegmentationClassAug&#x2F;</strong> (关键)： 存储语义分割任务的<strong>增强版标签</strong>​（由第三方基于原始数据扩展）。本文将使用此目录下的标注进行训练，因为它提供了比原始<code>SegmentationClass</code>更多的标注图像。</li>
<li>​<strong>ImageSets&#x2F;</strong>：​ 包含划分不同任务的图像列表：<ul>
<li>​<strong>ImageSets&#x2F;Main&#x2F;​</strong>：​图像分类任务的训练&#x2F;验证集列表（按类别划分）。</li>
<li>​<strong>ImageSets&#x2F;Segmentation&#x2F;</strong>：​ (本文使用) 语义分割任务的 <code>train.txt</code>, <code>val.txt</code> 和 <code>trainval.txt</code> 文件，列出用于训练和验证的图像文件名（不含扩展名）。</li>
<li>其他任务对应目录：如 <code>Layout/</code>, <code>Action/</code> 等。</li>
</ul>
</li>
<li>其他目录：包含其他任务（非本文重点）的特定数据或标注。</li>
</ul>
<h3 id="3-数据集划分与使用-​"><a href="#3-数据集划分与使用-​" class="headerlink" title="3. 数据集划分与使用**​"></a>3. 数据集划分与使用**​</h3><ul>
<li>​<strong>标准划分：​</strong>​ 数据集一般会明确划分为<strong>训练集 (train)​</strong>、<strong>验证集 (val)​</strong>​ 和<strong>测试集 (test)​</strong>。</li>
<li>​<strong>本地训练与验证：​</strong>​ 在本地进行模型训练和调优时，仅可使用<strong>训练集 (<code>train</code>) 和验证集 (<code>val</code>) 或其合并集 (<code>trainval</code>) 以及对应标注 (<code>Annotations</code>, <code>SegmentationClassAug</code>)​</strong>。</li>
<li>​<strong>测试集评估 (重要限制):​</strong>​ Pascal VOC 2012 官方<strong>未公开测试集的真实标签 (Ground Truth)​</strong>。对最终模型在测试集上的性能评估，​<strong>必须将模型的预测结果提交至官方评测服务器</strong>，由其使用私有的测试标注进行计算并反馈评估指标（如语义分割的 mIoU）。</li>
</ul>
<h3 id="4-语义分割任务目标与示例"><a href="#4-语义分割任务目标与示例" class="headerlink" title="4.语义分割任务目标与示例"></a>4.语义分割任务目标与示例</h3><p>本文的核心任务是<strong>语义分割</strong>。目标是训练一个模型，使其能为输入图像的<strong>每一个像素</strong>预测正确的类别标签（如“飞机”、“鸟”、“背景”等）。好的语义分割模型能够精确识别图像中不同物体的轮廓，并将属于同一语义类别的区域（无论实例数量）分割出来。如下图所示，模型输出应清晰划分不同对象区域（如飞机、天空、地面），并生成高质量的分割掩码。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/city_6_overlay.png"></p>
<h2 id="2-参数解析与数据处理"><a href="#2-参数解析与数据处理" class="headerlink" title="2.参数解析与数据处理"></a>2.参数解析与数据处理</h2><h3 id="1-参数说明"><a href="#1-参数说明" class="headerlink" title="1.参数说明"></a>1.参数说明</h3><p><code>main.py/get_argparser</code>中的各个参数主要用于配置 DeepLabV3+ 模型的训练和测试过程，也顺便可以看看整个工程支持哪些功能：</p>
<h4 id="1-数据集相关参数-Dataset-Options"><a href="#1-数据集相关参数-Dataset-Options" class="headerlink" title="1.数据集相关参数 (Dataset Options)"></a>1.数据集相关参数 (Dataset Options)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--data_root&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./datasets/data&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;数据集根目录路径&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;voc&#x27;</span>,</span><br><span class="line">                    choices=[<span class="string">&#x27;voc&#x27;</span>, <span class="string">&#x27;cityscapes&#x27;</span>], </span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;选择数据集类型：VOC或Cityscapes&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--num_classes&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="literal">None</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;类别数量（默认：None，会根据数据集自动设置）&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-DeepLab模型相关参数-Deeplab-Options"><a href="#2-DeepLab模型相关参数-Deeplab-Options" class="headerlink" title="2.DeepLab模型相关参数 (Deeplab Options)"></a>2.DeepLab模型相关参数 (Deeplab Options)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--model&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;deeplabv3plus_mobilenet&#x27;</span>,</span><br><span class="line">                    choices=[<span class="string">&#x27;deeplabv3_resnet50&#x27;</span>, <span class="string">&#x27;deeplabv3plus_resnet50&#x27;</span>,</span><br><span class="line">                            <span class="string">&#x27;deeplabv3_resnet101&#x27;</span>, <span class="string">&#x27;deeplabv3plus_resnet101&#x27;</span>,</span><br><span class="line">                            <span class="string">&#x27;deeplabv3_mobilenet&#x27;</span>, <span class="string">&#x27;deeplabv3plus_mobilenet&#x27;</span>],</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;选择模型架构&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--separable_conv&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;是否在解码器和ASPP中使用可分离卷积&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--output_stride&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>, choices=[<span class="number">8</span>, <span class="number">16</span>],</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;输出步长，控制特征图大小&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="3-训练相关参数-Train-Options"><a href="#3-训练相关参数-Train-Options" class="headerlink" title="3.训练相关参数 (Train Options)"></a>3.训练相关参数 (Train Options)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--test_only&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;仅进行测试模式&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--save_val_results&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;是否保存验证结果到&#x27;./results&#x27;目录&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--total_itrs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">30e3</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;总迭代次数（默认：30k）&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lr&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;学习率（默认：0.01）&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lr_policy&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;poly&#x27;</span>, choices=[<span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;step&#x27;</span>],</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;学习率调度策略：多项式衰减或步进式衰减&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--step_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10000</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;学习率步进式衰减的步长&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--crop_val&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;是否对验证集进行裁剪&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;训练批次大小&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--val_batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;验证批次大小&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--crop_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">513</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;输入图像裁剪大小&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="4-检查点相关参数"><a href="#4-检查点相关参数" class="headerlink" title="4. 检查点相关参数"></a>4. 检查点相关参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--ckpt&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;从检查点恢复模型&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--continue_training&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;是否继续训练&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="5-损失函数和优化器参数"><a href="#5-损失函数和优化器参数" class="headerlink" title="5.损失函数和优化器参数"></a>5.损失函数和优化器参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--loss_type&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;cross_entropy&#x27;</span>,</span><br><span class="line">                    choices=[<span class="string">&#x27;cross_entropy&#x27;</span>, <span class="string">&#x27;focal_loss&#x27;</span>],</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;损失函数类型&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--weight_decay&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-4</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;权重衰减系数&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="6-硬件和随机种子参数"><a href="#6-硬件和随机种子参数" class="headerlink" title="6. 硬件和随机种子参数"></a>6. 硬件和随机种子参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--gpu_id&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;使用的GPU ID&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--random_seed&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;随机种子&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="7-日志和验证相关参数"><a href="#7-日志和验证相关参数" class="headerlink" title="7. 日志和验证相关参数"></a>7. 日志和验证相关参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--print_interval&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;损失打印间隔&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--val_interval&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;验证间隔&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="8-PASCAL-VOC特定参数"><a href="#8-PASCAL-VOC特定参数" class="headerlink" title="8. PASCAL VOC特定参数"></a>8. PASCAL VOC特定参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--year&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;2012&#x27;</span>,</span><br><span class="line">                    choices=[<span class="string">&#x27;2012_aug&#x27;</span>, <span class="string">&#x27;2012&#x27;</span>, <span class="string">&#x27;2011&#x27;</span>, <span class="string">&#x27;2009&#x27;</span>, <span class="string">&#x27;2008&#x27;</span>, <span class="string">&#x27;2007&#x27;</span>],</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;VOC数据集年份&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="9-可视化相关参数"><a href="#9-可视化相关参数" class="headerlink" title="9.可视化相关参数"></a>9.可视化相关参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--enable_vis&quot;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;是否使用visdom进行可视化&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--vis_port&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;13570&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;visdom服务器端口&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--vis_env&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;main&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;visdom环境名称&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--vis_num_samples&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;可视化样本数量&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h3><p>以 VOC 数据集为例，我们主要关注以下几个方法：</p>
<h4 id="1-数据读取"><a href="#1-数据读取" class="headerlink" title="1.数据读取"></a>1.数据读取</h4><h5 id="1-PASCAL-VOC数据集读取"><a href="#1-PASCAL-VOC数据集读取" class="headerlink" title="1.PASCAL VOC数据集读取"></a>1.PASCAL VOC数据集读取</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VOCSegmentation</span>(data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, year=<span class="string">&#x27;2012&#x27;</span>, image_set=<span class="string">&#x27;train&#x27;</span>, </span></span><br><span class="line"><span class="params">				download=<span class="literal">False</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 初始化数据集路径和参数</span></span><br><span class="line">        <span class="variable language_">self</span>.root = os.path.expanduser(root)</span><br><span class="line">        <span class="variable language_">self</span>.year = year</span><br><span class="line">        <span class="variable language_">self</span>.transform = transform</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 设置图像和掩码目录</span></span><br><span class="line">        image_dir = os.path.join(voc_root, <span class="string">&#x27;JPEGImages&#x27;</span>)</span><br><span class="line">        mask_dir = os.path.join(voc_root, <span class="string">&#x27;SegmentationClass&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 读取数据集分割文件</span></span><br><span class="line">        split_f = os.path.join(splits_dir, image_set + <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(split_f, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            file_names = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建图像和掩码路径列表</span></span><br><span class="line">        <span class="variable language_">self</span>.images = [os.path.join(image_dir, x + <span class="string">&quot;.jpg&quot;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> file_names]</span><br><span class="line">        <span class="variable language_">self</span>.masks = [os.path.join(mask_dir, x + <span class="string">&quot;.png&quot;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> file_names]</span><br></pre></td></tr></table></figure>
<h5 id="2-数据读取的核心方法"><a href="#2-数据读取的核心方法" class="headerlink" title="2.数据读取的核心方法"></a>2.数据读取的核心方法</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取单个样本&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 读取图像和标签</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(<span class="variable language_">self</span>.images[index]).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">    target = Image.<span class="built_in">open</span>(<span class="variable language_">self</span>.masks[index])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用数据增强</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        img, target = <span class="variable language_">self</span>.transform(img, target)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> img, target</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回数据集大小&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.images)</span><br></pre></td></tr></table></figure>

<h4 id="2-数据增强和预处理"><a href="#2-数据增强和预处理" class="headerlink" title="2.数据增强和预处理"></a>2.数据增强和预处理</h4><p>数据增强通过ExtCompose组合多个转换操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_transform = et.ExtCompose([</span><br><span class="line">    <span class="comment"># 随机缩放</span></span><br><span class="line">    et.ExtRandomScale((<span class="number">0.5</span>, <span class="number">2.0</span>)),</span><br><span class="line">    <span class="comment"># 随机裁剪</span></span><br><span class="line">    et.ExtRandomCrop(size=(opts.crop_size, opts.crop_size), pad_if_needed=<span class="literal">True</span>),</span><br><span class="line">    <span class="comment"># 随机水平翻转</span></span><br><span class="line">    et.ExtRandomHorizontalFlip(),</span><br><span class="line">    <span class="comment"># 转换为张量</span></span><br><span class="line">    et.ExtToTensor(),</span><br><span class="line">    <span class="comment"># 标准化</span></span><br><span class="line">    et.ExtNormalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                    std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="3-构建-DataLoader"><a href="#3-构建-DataLoader" class="headerlink" title="3.构建 DataLoader"></a>3.构建 DataLoader</h4><p>在main.py中，使用DataLoader来批量加载数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_loader = data.DataLoader(</span><br><span class="line">    train_dst, </span><br><span class="line">    batch_size=opts.batch_size, </span><br><span class="line">    shuffle=<span class="literal">True</span>, </span><br><span class="line">    num_workers=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">val_loader = data.DataLoader(</span><br><span class="line">    val_dst, </span><br><span class="line">    batch_size=opts.val_batch_size, </span><br><span class="line">    shuffle=<span class="literal">True</span>, </span><br><span class="line">    num_workers=<span class="number">0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="3-核心架构设计"><a href="#3-核心架构设计" class="headerlink" title="3.核心架构设计"></a>3.核心架构设计</h2><h3 id="1-模型构建"><a href="#1-模型构建" class="headerlink" title="1.模型构建"></a>1.模型构建</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Set up model  </span></span><br><span class="line"><span class="comment"># 模型映射表</span></span><br><span class="line">model_map = &#123;  </span><br><span class="line">    <span class="string">&#x27;deeplabv3_resnet50&#x27;</span>: network.deeplabv3_resnet50,  </span><br><span class="line">    <span class="string">&#x27;deeplabv3plus_resnet50&#x27;</span>: network.deeplabv3plus_resnet50,  </span><br><span class="line">    <span class="string">&#x27;deeplabv3_resnet101&#x27;</span>: network.deeplabv3_resnet101,  </span><br><span class="line">    <span class="string">&#x27;deeplabv3plus_resnet101&#x27;</span>: network.deeplabv3plus_resnet101,  </span><br><span class="line">    <span class="string">&#x27;deeplabv3_mobilenet&#x27;</span>: network.deeplabv3_mobilenet,  </span><br><span class="line">    <span class="string">&#x27;deeplabv3plus_mobilenet&#x27;</span>: network.deeplabv3plus_mobilenet  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = model_map[opts.model](num_classes=opts.num_classes, </span><br></pre></td></tr></table></figure>
<h3 id="2-模型定义"><a href="#2-模型定义" class="headerlink" title="2.模型定义"></a>2.模型定义</h3><h4 id="1-基础模型"><a href="#1-基础模型" class="headerlink" title="1.基础模型"></a>1.基础模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_SimpleSegmentationModel</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone, classifier</span>):  </span><br><span class="line">        <span class="built_in">super</span>(_SimpleSegmentationModel, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="variable language_">self</span>.backbone = backbone  <span class="comment"># 主干网络</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = classifier  <span class="comment"># 分类头</span></span><br><span class="line">          </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        input_shape = x.shape[-<span class="number">2</span>:]  <span class="comment"># 获取输入图像的高和宽（H, W）</span></span><br><span class="line">        features = <span class="variable language_">self</span>.backbone(x)  <span class="comment"># 提取特征（可能是字典或张量）</span></span><br><span class="line">        x = <span class="variable language_">self</span>.classifier(features)  <span class="comment"># 生成分割逻辑图（未上采样）</span></span><br><span class="line">        x = F.interpolate(x, size=input_shape, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)  </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>初始化模型的两个核心组件：</p>
<ul>
<li><code>backbone</code>：负责提取图像特征的主干网络（如 ResNet、MobileNet）</li>
<li><code>classifier</code>：负责将特征图转换为分割结果的分类头（如 DeepLab 的 ASPP 模块）</li>
</ul>
<p>前向传播 (forward)​步骤解析**​：</p>
<ol>
<li>​<strong>保存输入尺寸</strong>​：<ul>
<li><code>x.shape[-2:]</code> 获取输入张量的最后两个维度（即图像的高度 <code>H</code> 和宽度 <code>W</code>）。</li>
<li>例如，输入 <code>x</code> 的形状为 <code>(B, C, H, W)</code>，则 <code>input_shape = (H, W)</code>。</li>
</ul>
</li>
<li>​<strong>特征提取</strong>​：<ul>
<li><code>features = self.backbone(x)</code>：通过主干网络提取多级特征。<ul>
<li>对于 DeepLabv3+，<code>backbone</code> 可能返回一个字典，包含深层特征（<code>out</code>）和浅层特征（<code>low_level</code>）。</li>
<li>对于 DeepLabv3，可能直接返回最后一层的特征图。</li>
</ul>
</li>
</ul>
</li>
<li>​<strong>分类头处理</strong>​：<ul>
<li><code>x = self.classifier(features)</code>：将特征转换为分割逻辑图（logits）。<ul>
<li>输出形状通常为 <code>(B, num_classes, h, w)</code>，其中 <code>h</code> 和 <code>w</code> 是特征图的尺寸（小于输入尺寸）。</li>
</ul>
</li>
</ul>
</li>
<li>​<strong>上采样恢复分辨率</strong>​：<ul>
<li><code>F.interpolate</code>：使用双线性插值将分割图上采样到输入图像尺寸<ul>
<li><code>size=input_shape</code>：目标尺寸（原始图像的 H 和 W）</li>
<li><code>mode=&#39;bilinear&#39;</code>：插值方式（双线性插值适合分割任务）</li>
<li><code>align_corners=False</code>：保持与其他框架（如 TensorFlow）的兼容性</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="2-DeepLabV3-模型类"><a href="#2-DeepLabV3-模型类" class="headerlink" title="2.DeepLabV3+模型类"></a>2.DeepLabV3+模型类</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabV3</span>(<span class="title class_ inherited__">_SimpleSegmentationModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;DeepLabV3模型实现&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p><code>DeepLabV3</code>类继承自<code>_SimpleSegmentationModel</code>类，它通过继承获得了所有必要的功能，不需要额外添加新的方法或属性。</p>
<h3 id="3-模型组件"><a href="#3-模型组件" class="headerlink" title="3.模型组件"></a>3.模型组件</h3><h4 id="1-骨干网络"><a href="#1-骨干网络" class="headerlink" title="1.骨干网络"></a>1.骨干网络</h4><p>支持两种骨干网络：</p>
<h5 id="1-ResNet系列"><a href="#1-ResNet系列" class="headerlink" title="1.ResNet系列"></a>1.ResNet系列</h5><p>创建一个基于ResNet的语义分割模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_segm_resnet</span>(<span class="params">name, backbone_name, num_classes, output_stride, pretrained_backbone</span>):</span><br><span class="line">    <span class="comment">#   name: 模型类型，可以是 &#x27;deeplabv3plus&#x27; 或 &#x27;deeplabv3&#x27;</span></span><br><span class="line">    <span class="comment">#   backbone_name: ResNet主干网络名称（如 &#x27;resnet50&#x27;, &#x27;resnet101&#x27;）</span></span><br><span class="line">    <span class="comment">#   num_classes: 分割输出的类别数量</span></span><br><span class="line">    <span class="comment">#   output_stride: 输出特征图的步幅（8或16），控制特征图分辨率</span></span><br><span class="line">    <span class="comment">#   pretrained_backbone: 是否加载ImageNet预训练权重（布尔值）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> output_stride == <span class="number">8</span>:</span><br><span class="line">        <span class="comment"># 当output_stride=8时，配置高级特征提取参数</span></span><br><span class="line">        replace_stride_with_dilation = [<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>]</span><br><span class="line">        <span class="comment"># 指示在ResNet的哪个阶段使用空洞卷积代替步幅卷积：</span></span><br><span class="line">        <span class="comment">#   [layer2, layer3, layer4] -&gt; [False, True, True]</span></span><br><span class="line">        <span class="comment">#   表示在layer3和layer4中使用空洞卷积</span></span><br><span class="line"></span><br><span class="line">        aspp_dilate = [<span class="number">12</span>, <span class="number">24</span>, <span class="number">36</span>]</span><br><span class="line">        <span class="comment"># 为ASPP（空洞空间金字塔池化）模块设置扩张率（dilation rates）</span></span><br><span class="line">        <span class="comment"># 这些较大的扩张率适用于高分辨率输出（output_stride=8）</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 当output_stride=16时（默认配置）</span></span><br><span class="line">        replace_stride_with_dilation = [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>]</span><br><span class="line">        <span class="comment"># 仅在最后一个阶段（layer4）使用空洞卷积</span></span><br><span class="line">        <span class="comment"># 这会使layer4的特征图尺寸减半</span></span><br><span class="line"></span><br><span class="line">        aspp_dilate = [<span class="number">6</span>, <span class="number">12</span>, <span class="number">18</span>]</span><br><span class="line">        <span class="comment"># 使用较小的ASPP扩张率适用于标准分辨率输出</span></span><br><span class="line"></span><br><span class="line">    backbone = resnet.__dict__[backbone_name](</span><br><span class="line">        pretrained=pretrained_backbone,</span><br><span class="line">        replace_stride_with_dilation=replace_stride_with_dilation)</span><br><span class="line">    <span class="comment"># 创建ResNet主干网络：</span></span><br><span class="line">    <span class="comment">#   resnet.__dict__[backbone_name]：通过名称从resnet模块获取对应的模型类</span></span><br><span class="line">    <span class="comment">#   pretrained：是否加载预训练权重</span></span><br><span class="line">    <span class="comment">#   replace_stride_with_dilation：传递空洞卷积配置</span></span><br><span class="line">    </span><br><span class="line">    inplanes = <span class="number">2048</span></span><br><span class="line">    <span class="comment"># ResNet最后一层（layer4）的输出通道数</span></span><br><span class="line">    <span class="comment"># 对于标准ResNet50/101/152，该值为2048</span></span><br><span class="line">    </span><br><span class="line">    low_level_planes = <span class="number">256</span></span><br><span class="line">    <span class="comment"># 浅层特征（layer1输出）的通道数</span></span><br><span class="line">    <span class="comment"># ResNet中layer1的输出通道固定为256</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> name == <span class="string">&#x27;deeplabv3plus&#x27;</span>:</span><br><span class="line">        <span class="comment"># DeepLabv3+ 模型配置</span></span><br><span class="line">        return_layers = &#123;<span class="string">&#x27;layer4&#x27;</span>: <span class="string">&#x27;out&#x27;</span>, <span class="string">&#x27;layer1&#x27;</span>: <span class="string">&#x27;low_level&#x27;</span>&#125;</span><br><span class="line">        <span class="comment"># 指定要提取的中间层及其别名：</span></span><br><span class="line">        <span class="comment">#   &#x27;layer4&#x27;: 高级语义特征 -&gt; 别名为&#x27;out&#x27;</span></span><br><span class="line">        <span class="comment">#   &#x27;layer1&#x27;: 低级空间细节 -&gt; 别名为&#x27;low_level&#x27;</span></span><br><span class="line">        </span><br><span class="line">        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)</span><br><span class="line">        <span class="comment"># 创建DeepLabv3+解码器头部:</span></span><br><span class="line">        <span class="comment">#   输入：深层特征通道数(inplanes), 浅层特征通道数(low_level_planes)</span></span><br><span class="line">        <span class="comment">#   输出：分割类别数(num_classes)</span></span><br><span class="line">        <span class="comment">#   使用配置的ASPP扩张率(aspp_dilate)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> name == <span class="string">&#x27;deeplabv3&#x27;</span>:</span><br><span class="line">        <span class="comment"># DeepLabv3 模型配置</span></span><br><span class="line">        return_layers = &#123;<span class="string">&#x27;layer4&#x27;</span>: <span class="string">&#x27;out&#x27;</span>&#125;</span><br><span class="line">        <span class="comment"># 仅提取最后一层（layer4）的特征</span></span><br><span class="line">        </span><br><span class="line">        classifier = DeepLabHead(inplanes, num_classes, aspp_dilate)</span><br><span class="line">        <span class="comment"># 创建DeepLabv3解码器头部:</span></span><br><span class="line">        <span class="comment"># 仅使用深层特征，不包含浅层细节</span></span><br><span class="line">    </span><br><span class="line">    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)</span><br><span class="line">    <span class="comment"># 包装ResNet主干网络：</span></span><br><span class="line">    <span class="comment">#   IntermediateLayerGetter修改网络使其返回指定中间层的输出</span></span><br><span class="line">    <span class="comment">#   例如对于DeepLabv3+：返回包含&#x27;out&#x27;和&#x27;low_level&#x27;两个特征图的字典</span></span><br><span class="line">    </span><br><span class="line">    model = DeepLabV3(backbone, classifier)</span><br><span class="line">    <span class="comment"># 组合主干网络和分类器：</span></span><br><span class="line">    <span class="comment">#   DeepLabV3是一个将特征提取和分类解耦的容器类</span></span><br><span class="line">    <span class="comment">#   backbone输出特征图，classifier生成最终分割图</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h5 id="2-MobileNetV2"><a href="#2-MobileNetV2" class="headerlink" title="2.MobileNetV2"></a>2.MobileNetV2</h5><p>基于MobileNetV2构建DeepLabv3或DeepLabv3+模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_segm_mobilenet</span>(<span class="params">name, backbone_name, num_classes, output_stride, pretrained_backbone</span>):</span><br><span class="line">    <span class="comment"># name: 模型类型，&#x27;deeplabv3plus&#x27; 或 &#x27;deeplabv3&#x27;</span></span><br><span class="line">    <span class="comment"># backbone_name: 主干网络名称（本函数固定使用mobilenetv2）</span></span><br><span class="line">    <span class="comment"># num_classes: 分割类别数</span></span><br><span class="line">	<span class="comment"># output_stride: 输出步幅（8或16），控制特征图下采样率</span></span><br><span class="line">	<span class="comment"># pretrained_backbone: 是否加载预训练权重</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据输出步幅设置ASPP模块的空洞率(dilation rates)</span></span><br><span class="line">    <span class="keyword">if</span> output_stride == <span class="number">8</span>:</span><br><span class="line">        aspp_dilate = [<span class="number">12</span>, <span class="number">24</span>, <span class="number">36</span>]  <span class="comment"># 输出步幅8需要更大的空洞率保持感受野</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        aspp_dilate = [<span class="number">6</span>, <span class="number">12</span>, <span class="number">18</span>]   <span class="comment"># 默认输出步幅16的空洞率配置</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化MobileNetV2主干网络</span></span><br><span class="line">    backbone = mobilenetv2.mobilenet_v2(</span><br><span class="line">        pretrained=pretrained_backbone,  <span class="comment"># 是否加载预训练权重</span></span><br><span class="line">        output_stride=output_stride     <span class="comment"># 控制网络内部的下采样行为</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 重构MobileNetV2的特征提取层</span></span><br><span class="line">    <span class="comment"># 将原features模块拆分为低层特征和高层特征</span></span><br><span class="line">    backbone.low_level_features = backbone.features[<span class="number">0</span>:<span class="number">4</span>]  <span class="comment"># 前4层作为低层特征（保留更多空间细节）</span></span><br><span class="line">    backbone.high_level_features = backbone.features[<span class="number">4</span>:-<span class="number">1</span>] <span class="comment"># 第5层到最后倒数第二层作为高层特征（包含更多语义信息）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 释放不再需要的组件引用</span></span><br><span class="line">    backbone.features = <span class="literal">None</span>   <span class="comment"># 移除原特征提取器</span></span><br><span class="line">    backbone.classifier = <span class="literal">None</span> <span class="comment"># 移除原始分类头（因为我们要做分割任务）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置特征通道数</span></span><br><span class="line">    inplanes = <span class="number">320</span>       <span class="comment"># 高层特征的输出通道数（MobileNetV2最后一层的通道数）</span></span><br><span class="line">    low_level_planes = <span class="number">24</span> <span class="comment"># 低层特征的输出通道数（第4层的输出通道数）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据模型类型配置返回层和分类头</span></span><br><span class="line">    <span class="keyword">if</span> name == <span class="string">&#x27;deeplabv3plus&#x27;</span>:</span><br><span class="line">        <span class="comment"># DeepLabv3+需要同时返回高层和低层特征</span></span><br><span class="line">        return_layers = &#123;</span><br><span class="line">            <span class="string">&#x27;high_level_features&#x27;</span>: <span class="string">&#x27;out&#x27;</span>,      <span class="comment"># 高层特征别名为&#x27;out&#x27;</span></span><br><span class="line">            <span class="string">&#x27;low_level_features&#x27;</span>: <span class="string">&#x27;low_level&#x27;</span>  <span class="comment"># 低层特征别名为&#x27;low_level&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 使用DeepLabv3+特有的分类头（包含特征融合模块）</span></span><br><span class="line">        classifier = DeepLabHeadV3Plus(</span><br><span class="line">            inplanes,              <span class="comment"># 高层特征通道数</span></span><br><span class="line">            low_level_planes,       <span class="comment"># 低层特征通道数 </span></span><br><span class="line">            num_classes,            <span class="comment"># 分类数</span></span><br><span class="line">            aspp_dilate             <span class="comment"># ASPP模块的空洞率配置</span></span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> name == <span class="string">&#x27;deeplabv3&#x27;</span>:</span><br><span class="line">        <span class="comment"># DeepLabv3只需要返回高层特征</span></span><br><span class="line">        return_layers = &#123;<span class="string">&#x27;high_level_features&#x27;</span>: <span class="string">&#x27;out&#x27;</span>&#125;</span><br><span class="line">        <span class="comment"># 使用标准DeepLab分类头</span></span><br><span class="line">        classifier = DeepLabHead(</span><br><span class="line">            inplanes,              <span class="comment"># 高层特征通道数</span></span><br><span class="line">            num_classes,           <span class="comment"># 分类数</span></span><br><span class="line">            aspp_dilate            <span class="comment"># ASPP模块的空洞率配置</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用IntermediateLayerGetter包装主干网络</span></span><br><span class="line">    <span class="comment"># 使其能够返回指定的中间层结果</span></span><br><span class="line">    backbone = IntermediateLayerGetter(</span><br><span class="line">        backbone,                  <span class="comment"># 主干网络</span></span><br><span class="line">        return_layers=return_layers <span class="comment"># 指定需要返回的层及其别名</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 组合主干网络和分类头构建完整模型</span></span><br><span class="line">    model = DeepLabV3(</span><br><span class="line">        backbone,     <span class="comment"># 特征提取器</span></span><br><span class="line">        classifier    <span class="comment"># 分类解码器</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h4 id="2-解码器头（Decoder-Head）"><a href="#2-解码器头（Decoder-Head）" class="headerlink" title="2.解码器头（Decoder Head）"></a>2.解码器头（Decoder Head）</h4><p>DeepLabV3+的解码头模块，包含ASPP模块和多级特征融合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DeepLabHeadV3Plus</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># in_channels: 高层特征输入通道数(来自backbone的layer4)</span></span><br><span class="line">    <span class="comment"># low_level_channels: 低层特征输入通道数(来自backbone的layer1)</span></span><br><span class="line">    <span class="comment"># num_classes: 分类类别数</span></span><br><span class="line">    <span class="comment"># aspp_dilate: ASPP模块的空洞率配置(default=[12,24,36])</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, low_level_channels, num_classes, aspp_dilate=[<span class="number">12</span>, <span class="number">24</span>, <span class="number">36</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(DeepLabHeadV3Plus, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 低层特征投影层：将低层特征通道数降维到48</span></span><br><span class="line">        <span class="variable language_">self</span>.project = nn.Sequential( </span><br><span class="line">            nn.Conv2d(low_level_channels, <span class="number">48</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),  <span class="comment"># 1x1卷积降维</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">48</span>),                                <span class="comment"># 批归一化</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),                             <span class="comment"># ReLU激活</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ASPP模块：提取多尺度上下文信息</span></span><br><span class="line">        <span class="variable language_">self</span>.aspp = ASPP(in_channels, aspp_dilate)  <span class="comment"># 输入通道为高层特征维度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分类器：融合高低层特征后输出最终预测</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">304</span>, <span class="number">256</span>, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),  <span class="comment"># 304=256(ASPP输出)+48(低层)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),                            <span class="comment"># 批归一化</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),                           <span class="comment"># ReLU激活</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, num_classes, <span class="number">1</span>)                   <span class="comment"># 1x1卷积输出分类结果</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化权重</span></span><br><span class="line">        <span class="variable language_">self</span>._init_weight()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, feature</span>):</span><br><span class="line">        <span class="comment"># 前向传播流程: 1.处理低层特征 2.通过ASPP处理高层特征 3.特征融合后分类</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 低层特征处理 (shape: [B, 256, H/4, W/4] -&gt; [B, 48, H/4, W/4])</span></span><br><span class="line">        low_level_feature = <span class="variable language_">self</span>.project(feature[<span class="string">&#x27;low_level&#x27;</span>])  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 高层特征通过ASPP (shape: [B, 2048, H/16, W/16] -&gt; [B, 256, H/16, W/16])</span></span><br><span class="line">        output_feature = <span class="variable language_">self</span>.aspp(feature[<span class="string">&#x27;out&#x27;</span>])  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 上采样高层特征到低层特征尺寸 (H/16-&gt;H/4)</span></span><br><span class="line">        output_feature = F.interpolate(</span><br><span class="line">            output_feature, </span><br><span class="line">            size=low_level_feature.shape[<span class="number">2</span>:],  <span class="comment"># 匹配低层特征的空间尺寸</span></span><br><span class="line">            mode=<span class="string">&#x27;bilinear&#x27;</span>,                  <span class="comment"># 双线性插值</span></span><br><span class="line">            align_corners=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 沿通道维度拼接特征 (256+48=304)</span></span><br><span class="line">        fused_feature = torch.cat([low_level_feature, output_feature], dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过分类器得到最终输出 (shape: [B, num_classes, H/4, W/4])</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.classifier(fused_feature)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 权重初始化方法: 卷积层使用Kaiming初始化 归一化层权重初始化为1，偏置初始化为0</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight)  <span class="comment"># 卷积层He初始化</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm)):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)     <span class="comment"># 归一化层权重设为1</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)       <span class="comment"># 归一化层偏置设为0</span></span><br></pre></td></tr></table></figure>
<h4 id="3-ASPP模块"><a href="#3-ASPP模块" class="headerlink" title="3.ASPP模块"></a>3.ASPP模块</h4><p>ASPP模块通过并行多分支卷积捕获多尺度上下文信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ASPP</span>(nn.Module):</span><br><span class="line">	<span class="comment"># in_channels: 输入特征图的通道数</span></span><br><span class="line">	<span class="comment"># atrous_rates: 三个空洞卷积的空洞率列表(如[6,12,18])</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, atrous_rates</span>):</span><br><span class="line">        <span class="built_in">super</span>(ASPP, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        out_channels = <span class="number">256</span>  <span class="comment"># 所有分支的输出通道数</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分支模块列表</span></span><br><span class="line">        modules = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分支1: 1x1标准卷积 (空洞率=1)</span></span><br><span class="line">        modules.append(nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, <span class="number">1</span>, bias=<span class="literal">False</span>),  <span class="comment"># 1x1卷积</span></span><br><span class="line">            nn.BatchNorm2d(out_channels),                         <span class="comment"># 批归一化</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)))                               <span class="comment"># ReLU激活</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分支2-4: 3x3空洞卷积 (不同空洞率)</span></span><br><span class="line">        rate1, rate2, rate3 = <span class="built_in">tuple</span>(atrous_rates)  <span class="comment"># 解包空洞率参数</span></span><br><span class="line">        modules.append(ASPPConv(in_channels, out_channels, rate1))  <span class="comment"># 空洞率1</span></span><br><span class="line">        modules.append(ASPPConv(in_channels, out_channels, rate2))  <span class="comment"># 空洞率2  </span></span><br><span class="line">        modules.append(ASPPConv(in_channels, out_channels, rate3))  <span class="comment"># 空洞率3</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分支5: 全局平均池化 + 1x1卷积</span></span><br><span class="line">        modules.append(ASPPPooling(in_channels, out_channels))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将5个分支注册为ModuleList</span></span><br><span class="line">        <span class="variable language_">self</span>.convs = nn.ModuleList(modules)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 特征融合层: 拼接后降维</span></span><br><span class="line">        <span class="variable language_">self</span>.project = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">5</span> * out_channels, out_channels, <span class="number">1</span>, bias=<span class="literal">False</span>),  <span class="comment"># 5 * 256-&gt;256</span></span><br><span class="line">            nn.BatchNorm2d(out_channels),                              <span class="comment"># 批归一化</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),                                     <span class="comment"># ReLU激活</span></span><br><span class="line">            nn.Dropout(<span class="number">0.1</span>),)                                          <span class="comment"># 正则化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 前向传播流程: 各分支并行处理输入特征 -&gt; 沿通道维度拼接结果 -&gt; 融合降维后输出</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> conv <span class="keyword">in</span> <span class="variable language_">self</span>.convs:</span><br><span class="line">            res.append(conv(x))  <span class="comment"># 各分支分别处理</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 沿通道维度拼接 (5个256通道 -&gt; 1280通道)</span></span><br><span class="line">        res = torch.cat(res, dim=<span class="number">1</span>)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过融合层降维回256通道</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.project(res)</span><br></pre></td></tr></table></figure>
<h2 id="4-训练策略"><a href="#4-训练策略" class="headerlink" title="4.训练策略"></a>4.训练策略</h2><h3 id="1-学习率调整策略"><a href="#1-学习率调整策略" class="headerlink" title="1.学习率调整策略"></a>1.学习率调整策略</h3><p>在utils.py中实现了两种学习率调整策略：</p>
<h4 id="1-多项式衰减（Poly）"><a href="#1-多项式衰减（Poly）" class="headerlink" title="1.多项式衰减（Poly）"></a>1.多项式衰减（Poly）</h4><p>特点：</p>
<ul>
<li>控制平滑，学习率下降自然</li>
<li>对于复杂任务（如语义分割）训练更稳定</li>
<li>参数少（只需 max_iters 和 power），易于使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PolyLR</span>(<span class="title class_ inherited__">_LRScheduler</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, optimizer, max_iters, power=<span class="number">0.9</span>, last_epoch=-<span class="number">1</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_iters = max_iters</span><br><span class="line">        <span class="variable language_">self</span>.power = power</span><br><span class="line">        <span class="built_in">super</span>(PolyLR, <span class="variable language_">self</span>).__init__(optimizer, last_epoch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_lr</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [base_lr * (<span class="number">1</span> - <span class="variable language_">self</span>.last_epoch / <span class="variable language_">self</span>.max_iters) ** <span class="variable language_">self</span>.power</span><br><span class="line">                <span class="keyword">for</span> base_lr <span class="keyword">in</span> <span class="variable language_">self</span>.base_lrs]</span><br></pre></td></tr></table></figure>
<h4 id="2-步进式衰减（Step）"><a href="#2-步进式衰减（Step）" class="headerlink" title="2.步进式衰减（Step）"></a>2.步进式衰减（Step）</h4><p>StepLR 是一种“阶梯状”地调整学习率的方法，每隔固定的步数将学习率缩小（乘以 gamma），是一种简洁且有效的学习率下降策略。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StepLR</span>(<span class="title class_ inherited__">_LRScheduler</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, optimizer, step_size, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.step_size = step_size</span><br><span class="line">        <span class="variable language_">self</span>.gamma = gamma</span><br><span class="line">        <span class="built_in">super</span>(StepLR, <span class="variable language_">self</span>).__init__(optimizer, last_epoch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_lr</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [base_lr * <span class="variable language_">self</span>.gamma ** (<span class="variable language_">self</span>.last_epoch // <span class="variable language_">self</span>.step_size)</span><br><span class="line">                <span class="keyword">for</span> base_lr <span class="keyword">in</span> <span class="variable language_">self</span>.base_lrs]</span><br></pre></td></tr></table></figure>
<h3 id="2-优化器配置"><a href="#2-优化器配置" class="headerlink" title="2.优化器配置"></a>2.优化器配置</h3><p>在main.py中配置优化器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建优化器：按模块设置不同学习率（用于迁移学习/微调）</span></span><br><span class="line">optimizer = torch.optim.SGD(</span><br><span class="line">    params=[</span><br><span class="line">        &#123;<span class="string">&#x27;params&#x27;</span>: model.backbone.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span> * opts.lr&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;params&#x27;</span>: model.classifier.parameters(), <span class="string">&#x27;lr&#x27;</span>: opts.lr&#125;,</span><br><span class="line">    ],</span><br><span class="line">    momentum=opts.momentum,</span><br><span class="line">    weight_decay=opts.weight_decay</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建学习率调度器 # 根据配置选择 PolyLR 或 StepLR 学习率衰减策略</span></span><br><span class="line"><span class="keyword">if</span> opts.lr_policy == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">    scheduler = utils.PolyLR(optimizer, max_iters=opts.epochs * <span class="built_in">len</span>(train_loader), power=<span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.step_size, gamma=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-训练循环实现"><a href="#3-训练循环实现" class="headerlink" title="3.训练循环实现"></a>3.训练循环实现</h3><p>在main.py中的训练循环：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 训练循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opts.start_epoch, opts.epochs):</span><br><span class="line">        <span class="comment"># 训练一个epoch</span></span><br><span class="line">        train_epoch(model, train_loader, criterion, optimizer, device, epoch, opts)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 验证</span></span><br><span class="line">        <span class="keyword">if</span> opts.val_interval &gt; <span class="number">0</span> <span class="keyword">and</span> (epoch + <span class="number">1</span>) % opts.val_interval == <span class="number">0</span>:</span><br><span class="line">            val_epoch(model, val_loader, criterion, device, opts)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新学习率</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存检查点</span></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % opts.save_interval == <span class="number">0</span>:</span><br><span class="line">            save_checkpoint(model, optimizer, epoch, opts)</span><br></pre></td></tr></table></figure>
<h3 id="4-损失函数选择"><a href="#4-损失函数选择" class="headerlink" title="4. 损失函数选择"></a>4. 损失函数选择</h3><p>支持的损失函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 损失函数选择</span></span><br><span class="line"><span class="keyword">if</span> opts.loss_type == <span class="string">&#x27;focal&#x27;</span>:</span><br><span class="line">    criterion = utils.FocalLoss(ignore_index=<span class="number">255</span>, size_average=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">elif</span> opts.loss_type == <span class="string">&#x27;cross_entropy&#x27;</span>:</span><br><span class="line">    criterion = nn.CrossEntropyLoss(ignore_index=<span class="number">255</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="5-评估与可视化"><a href="#5-评估与可视化" class="headerlink" title="5.评估与可视化"></a>5.评估与可视化</h2><h3 id="1-评估函数"><a href="#1-评估函数" class="headerlink" title="1.评估函数"></a>1.评估函数</h3><p>评估函数实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">val_epoch</span>(<span class="params">model, loader, criterion, device, opts</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    ret_samples = []</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_pixels = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            </span><br><span class="line">            outputs = model(images)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算准确率</span></span><br><span class="line">            pred = outputs.argmax(dim=<span class="number">1</span>)</span><br><span class="line">            correct = (pred == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">            total_correct += correct</span><br><span class="line">            total_pixels += labels.numel()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 保存样本用于可视化</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; opts.vis_num_samples:</span><br><span class="line">                ret_samples.append((images[<span class="number">0</span>].detach().cpu().numpy(),</span><br><span class="line">                                 labels[<span class="number">0</span>].detach().cpu().numpy(),</span><br><span class="line">                                 pred[<span class="number">0</span>].detach().cpu().numpy()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算平均指标</span></span><br><span class="line">    avg_loss = total_loss / <span class="built_in">len</span>(loader)</span><br><span class="line">    avg_acc = total_correct / total_pixels</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> avg_loss, avg_acc, ret_samples</span><br></pre></td></tr></table></figure>
<h3 id="2-评估指标计算"><a href="#2-评估指标计算" class="headerlink" title="2.评估指标计算"></a>2.评估指标计算</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AverageMeter</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算并存储平均值和当前值&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.reset()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.val = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.avg = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.count = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, val, n=<span class="number">1</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.val = val</span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">sum</span> += val * n</span><br><span class="line">        <span class="variable language_">self</span>.count += n</span><br><span class="line">        <span class="variable language_">self</span>.avg = <span class="variable language_">self</span>.<span class="built_in">sum</span> / <span class="variable language_">self</span>.count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">pred, target, num_classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算各种评估指标&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 混淆矩阵</span></span><br><span class="line">    confusion_matrix = np.zeros((num_classes, num_classes))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            confusion_matrix[i, j] = np.<span class="built_in">sum</span>((pred == i) &amp; (target == j))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算IoU</span></span><br><span class="line">    intersection = np.diag(confusion_matrix)</span><br><span class="line">    union = np.<span class="built_in">sum</span>(confusion_matrix, axis=<span class="number">1</span>) + np.<span class="built_in">sum</span>(confusion_matrix, axis=<span class="number">0</span>) - intersection</span><br><span class="line">    iou = intersection / (union + <span class="number">1e-10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = np.<span class="built_in">sum</span>(intersection) / np.<span class="built_in">sum</span>(confusion_matrix)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;confusion_matrix&#x27;</span>: confusion_matrix,</span><br><span class="line">        <span class="string">&#x27;iou&#x27;</span>: iou,</span><br><span class="line">        <span class="string">&#x27;mean_iou&#x27;</span>: np.mean(iou),</span><br><span class="line">        <span class="string">&#x27;accuracy&#x27;</span>: accuracy</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-可视化"><a href="#3-可视化" class="headerlink" title="3.可视化"></a>3.可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Visualizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, opts</span>):</span><br><span class="line">        <span class="variable language_">self</span>.opts = opts</span><br><span class="line">        <span class="variable language_">self</span>.vis_dir = os.path.join(opts.vis_dir, opts.model)</span><br><span class="line">        os.makedirs(<span class="variable language_">self</span>.vis_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">vis_segmentation</span>(<span class="params">self, image, label, pred, epoch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;可视化分割结果&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 创建图像网格</span></span><br><span class="line">        fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示原始图像</span></span><br><span class="line">        axes[<span class="number">0</span>].imshow(image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">        axes[<span class="number">0</span>].set_title(<span class="string">&#x27;Input Image&#x27;</span>)</span><br><span class="line">        axes[<span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示真实标签</span></span><br><span class="line">        axes[<span class="number">1</span>].imshow(label, cmap=<span class="string">&#x27;tab20&#x27;</span>)</span><br><span class="line">        axes[<span class="number">1</span>].set_title(<span class="string">&#x27;Ground Truth&#x27;</span>)</span><br><span class="line">        axes[<span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示预测结果</span></span><br><span class="line">        axes[<span class="number">2</span>].imshow(pred, cmap=<span class="string">&#x27;tab20&#x27;</span>)</span><br><span class="line">        axes[<span class="number">2</span>].set_title(<span class="string">&#x27;Prediction&#x27;</span>)</span><br><span class="line">        axes[<span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存图像</span></span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.vis_dir, <span class="string">f&#x27;epoch_<span class="subst">&#123;epoch&#125;</span>.png&#x27;</span>))</span><br><span class="line">        plt.close()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">vis_metrics</span>(<span class="params">self, metrics, epoch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;可视化评估指标&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 创建图像网格</span></span><br><span class="line">        fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">15</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制混淆矩阵</span></span><br><span class="line">        sns.heatmap(metrics[<span class="string">&#x27;confusion_matrix&#x27;</span>], </span><br><span class="line">                   annot=<span class="literal">True</span>, </span><br><span class="line">                   fmt=<span class="string">&#x27;d&#x27;</span>, </span><br><span class="line">                   ax=axes[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">        axes[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;Confusion Matrix&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制IoU条形图</span></span><br><span class="line">        axes[<span class="number">0</span>, <span class="number">1</span>].bar(<span class="built_in">range</span>(<span class="built_in">len</span>(metrics[<span class="string">&#x27;iou&#x27;</span>])), metrics[<span class="string">&#x27;iou&#x27;</span>])</span><br><span class="line">        axes[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;IoU per Class&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制损失曲线</span></span><br><span class="line">        axes[<span class="number">1</span>, <span class="number">0</span>].plot(metrics[<span class="string">&#x27;loss_history&#x27;</span>])</span><br><span class="line">        axes[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;Loss History&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 绘制准确率曲线</span></span><br><span class="line">        axes[<span class="number">1</span>, <span class="number">1</span>].plot(metrics[<span class="string">&#x27;acc_history&#x27;</span>])</span><br><span class="line">        axes[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Accuracy History&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存图像</span></span><br><span class="line">        plt.savefig(os.path.join(<span class="variable language_">self</span>.vis_dir, <span class="string">f&#x27;metrics_<span class="subst">&#123;epoch&#125;</span>.png&#x27;</span>))</span><br><span class="line">        plt.close()</span><br></pre></td></tr></table></figure>
<h3 id="4-训练过程可视化"><a href="#4-训练过程可视化" class="headerlink" title="4.训练过程可视化"></a>4.训练过程可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">model, loader, criterion, optimizer, device, epoch, opts</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    vis = Visualizer(opts)</span><br><span class="line">    metrics = &#123;</span><br><span class="line">        <span class="string">&#x27;loss_history&#x27;</span>: [],</span><br><span class="line">        <span class="string">&#x27;acc_history&#x27;</span>: [],</span><br><span class="line">        <span class="string">&#x27;confusion_matrix&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line">        <span class="string">&#x27;iou&#x27;</span>: <span class="literal">None</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        <span class="comment"># 前向传播和损失计算</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算指标</span></span><br><span class="line">        pred = outputs.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        metrics[<span class="string">&#x27;loss_history&#x27;</span>].append(loss.item())</span><br><span class="line">        metrics[<span class="string">&#x27;acc_history&#x27;</span>].append((pred == labels).<span class="built_in">float</span>().mean().item())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定期可视化</span></span><br><span class="line">        <span class="keyword">if</span> i % opts.vis_interval == <span class="number">0</span>:</span><br><span class="line">            vis.vis_segmentation(</span><br><span class="line">                images[<span class="number">0</span>].detach().cpu().numpy(),</span><br><span class="line">                labels[<span class="number">0</span>].detach().cpu().numpy(),</span><br><span class="line">                pred[<span class="number">0</span>].detach().cpu().numpy(),</span><br><span class="line">                epoch</span><br><span class="line">            )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 每个epoch结束可视化指标</span></span><br><span class="line">    vis.vis_metrics(metrics, epoch)</span><br></pre></td></tr></table></figure>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><h3 id="1-Pascal-VOC-2012-数据集​"><a href="#1-Pascal-VOC-2012-数据集​" class="headerlink" title="1.Pascal VOC 2012 数据集​"></a>1.Pascal VOC 2012 数据集​</h3><ul>
<li>​<strong>多任务基准</strong>​：支持分类、检测、分割（像素级标注）</li>
<li>​<strong>数据组成</strong>​：JPEGImages（原始图像）、Annotations（边界框）、SegmentationClass（分割标签）</li>
<li>​<strong>评估限制</strong>​：测试集标签不公开，需提交官方服务器计算指标（如 mIoU）</li>
</ul>
<h3 id="2-DeepLabV3-模型设计"><a href="#2-DeepLabV3-模型设计" class="headerlink" title="2.DeepLabV3+ 模型设计"></a>2.DeepLabV3+ 模型设计</h3><ul>
<li>​<strong>骨干网络</strong>​：支持 ResNet 和 MobileNetV2，适应不同计算需求</li>
<li>​<strong>ASPP 模块</strong>​：多尺度空洞卷积，捕获上下文信息</li>
<li>​<strong>特征融合</strong>​：结合深层语义特征（高层）与浅层细节（低层）​</li>
</ul>
<h3 id="3-训练与优化"><a href="#3-训练与优化" class="headerlink" title="3.训练与优化"></a>3.训练与优化</h3><ul>
<li>​<strong>学习率策略</strong>​：多项式衰减（PolyLR）或步进衰减（StepLR）</li>
<li>​<strong>损失函数</strong>​：交叉熵或 Focal Loss（处理类别不平衡）</li>
<li>​<strong>优化器</strong>​：SGD，分层设置学习率（骨干网络更低）</li>
</ul>
<h3 id="4-评估与可视化​"><a href="#4-评估与可视化​" class="headerlink" title="4.评估与可视化​"></a>4.评估与可视化​</h3><ul>
<li>​<strong>指标计算</strong>​：mIoU、像素准确率、混淆矩阵</li>
<li>​<strong>可视化工具</strong>​：展示输入图像、真实标签、预测结果及训练曲线</li>
</ul>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><p>工程地址：<a href="https://github.com/VainF/DeepLabV3Plus-Pytorch">https://github.com/VainF/DeepLabV3Plus-Pytorch</a><br>Pascal VOC (Visual Object Classes) 2012数据集：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
        <tag>DeepLab</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer:多头注意力驱动的编码器-解码器架构</title>
    <url>/2025/06/25/021-transformer/</url>
    <content><![CDATA[<h2 id="1-循环神经网络"><a href="#1-循环神经网络" class="headerlink" title="1.循环神经网络"></a>1.循环神经网络</h2><p>前文有实现过一个<a href="https://keychankc.github.io/2025/03/14/005-rnn-classification-text/">基于循环神经网络的文本分类实践</a>任务，循环神经网络（<strong>Recurrent Neural Network, RNN</strong>）也叫递归神经网络，是专门处理<strong>序列数据</strong>的神经网络架构，其核心思想是通过<strong>循环连接</strong>使网络具备“记忆”能力，从而构建序列中时序之间的依赖关系。而处理具有<strong>时序或顺序关系</strong>的数据（如语言、语音、基因序列等）的核心挑战是<strong>理解序列中的上下文依赖关系</strong>，这就涉及到序列建模问题。</p>
<span id="more"></span>
<h3 id="1-序列建模问题"><a href="#1-序列建模问题" class="headerlink" title="1.序列建模问题"></a>1.序列建模问题</h3><p>与图像处理不同，序列建模关注的是<strong>输入数据的时序特性</strong>。例如：</p>
<ul>
<li>在时间序列预测中，我们可以根据前几天的指标（如身高、体重、年龄、饮食情况等）来预测未来的身体状态</li>
<li>在文本建模任务中，输入为一个个按顺序排列的单词或字符，模型需要捕捉语言的上下文关系</li>
</ul>
<p>这类任务的共同特点是：<strong>输入之间存在时间&#x2F;位置上的顺序关系</strong>，即当前状态往往依赖于过去的信息。</p>
<h3 id="2-RNN-的基本结构与前向传播机制"><a href="#2-RNN-的基本结构与前向传播机制" class="headerlink" title="2. RNN 的基本结构与前向传播机制"></a>2. RNN 的基本结构与前向传播机制</h3><p>为了解决这类时序相关问题，RNN 通过引入“记忆”机制，在每个时间步上对<strong>当前输入和上一个时间步的隐藏状态</strong>共同进行建模。</p>
<p>以时间序列为例，模型的输入如下：</p>
<ol>
<li>在第一个时间步$x_0$：通过线性变换（如 $h_0 &#x3D; f(Wx_0 + b)）$得到隐藏状态 $h_0$，可以输出一个中间预测值</li>
<li>在第二个时间步 $x_1$：模型不仅接收当前输入 $x_1$，还会接收前一时刻的隐藏状态 $h_0$，组合后作为输入生成 $h_1$，继续输出</li>
<li>以此类推，到第 t 个时间步 $x_t$，模型会基于当前输入和前一隐藏状态来生成 $h_t$<br>这一结构意味着，后续的每个隐藏状态都隐式包含了之前所有时间步的信息。例如：<br>$$h_3 &#x3D; f(x_3, h_2) \Rightarrow f(x_3, f(x_2, h_1)) \Rightarrow f(x_3, f(x_2, f(x_1, h_0)))$$</li>
</ol>
<p>最终可以使用最后一个时间步的隐藏状态 $h_t$ 来表示整段序列的语义，从而用于后续分类、回归等任务。</p>
<h3 id="3-RNN-的主要问题"><a href="#3-RNN-的主要问题" class="headerlink" title="3. RNN 的主要问题"></a>3. RNN 的主要问题</h3><p>尽管 RNN 在设计上适应了时序数据的建模需求，但在实际应用中却暴露出许多关键性问题：</p>
<h4 id="问题一：长期依赖难以捕捉"><a href="#问题一：长期依赖难以捕捉" class="headerlink" title="问题一：长期依赖难以捕捉"></a>问题一：长期依赖难以捕捉</h4><p>当输入序列较长时，早期的信息（如 $x_0$）需要通过多个非线性变换传递到后续节点。由于梯度在反向传播过程中会不断衰减（即梯度消失问题），模型往往难以有效记住较早时间步的信息。<br>这一现象会导致<strong>RNN 无法有效捕捉长期依赖关系</strong>，只能关注较近的上下文。</p>
<h4 id="问题二：计算过程为串行，难以并行化"><a href="#问题二：计算过程为串行，难以并行化" class="headerlink" title="问题二：计算过程为串行，难以并行化"></a>问题二：计算过程为串行，难以并行化</h4><p>RNN 的每个时间步必须依赖前一时间步的计算结果，因此其计算过程是<strong>串行</strong>的，不能像 CNN 那样并行处理所有输入。<br>这会显著限制模型的训练效率，尤其在处理长序列时，训练成本和时间开销变得极高。</p>
<h4 id="问题三：难以堆叠更深层结构"><a href="#问题三：难以堆叠更深层结构" class="headerlink" title="问题三：难以堆叠更深层结构"></a>问题三：难以堆叠更深层结构</h4><p>由于其串行依赖性，RNN 通常只能堆叠极少的层数（如 2~3 层），一旦层数过多，训练难度迅速上升，模型性能还会下降。因此，与 CNN 等深层结构相比，RNN 的建模能力受到限制。</p>
<h4 id="问题四：结构为单向，缺乏对未来信息的利用"><a href="#问题四：结构为单向，缺乏对未来信息的利用" class="headerlink" title="问题四：结构为单向，缺乏对未来信息的利用"></a>问题四：结构为单向，缺乏对未来信息的利用</h4><p>标准的 RNN 仅能从前向后建模（即从 $x_0$ 到 $x_t$），只能考虑历史信息，而无法利用“未来的信息”对当前施加影响。这在某些自然语言处理任务中尤为致命——因为当前词的含义往往依赖于后文。</p>
<h3 id="4-双向-RNN（Bidirectional-RNN）"><a href="#4-双向-RNN（Bidirectional-RNN）" class="headerlink" title="4. 双向 RNN（Bidirectional RNN）"></a>4. 双向 RNN（Bidirectional RNN）</h3><p>为解决上述单向性问题，提出了<strong>双向 RNN（BiRNN）结构</strong>：</p>
<ul>
<li>先构建一条前向 RNN 处理从 $x_0$ 到 $x_t$ 的顺序</li>
<li>再构建另外一条反向 RNN 处理从 $x_t$ 到 $x_0$ 的逆序</li>
<li>最后把两条路径的隐藏状态进行拼接（或加权融合），作为最终的表示<br>这样，模型在每个时间步都能同时获得<strong>前文与后文</strong>的信息，从而可以更全面地理解上下文。然而，这一结构确还是不能从根本上解决“长期依赖”和“串行计算”的问题。</li>
</ul>
<h3 id="5-信息获取机制的思考：局部-vs-全局影响"><a href="#5-信息获取机制的思考：局部-vs-全局影响" class="headerlink" title="5. 信息获取机制的思考：局部 vs 全局影响"></a>5. 信息获取机制的思考：局部 vs 全局影响</h3><p>在 BiRNN 中，模型认为<strong>当前位置的语义最主要受邻近位置的影响</strong>。比如对于时间步 $x_3$，它主要融合来自 $x_2$ 和 $x_4$ 的信息。但实际上，某些远距离信息可能对当前任务具有更重要的影响，例如“某个关键事件”可能发生在很早以前。因此我们应该思考的是：</p>
<blockquote>
<p>当前时刻的信息，应该由<strong>模型自主动态决定该关注谁</strong>，而不是依赖固定的结构性传播。</p>
</blockquote>
<p>这种需要“动态决定关注谁”的思想，为后续的注意力机制（Attention）与 Transformer 架构的出现奠定了基础。</p>
<h2 id="2-Transformer概述"><a href="#2-Transformer概述" class="headerlink" title="2.Transformer概述"></a>2.Transformer概述</h2><p>这篇发表于 2017 年的论文<a href="https://arxiv.org/pdf/1706.03762">《Attention is All You Need》</a>是一篇里程碑之作，它不仅提出了 Transformer 这一全新的架构，更彻底改变了自然语言处理乃至整个人工智能的发展方向。</p>
<h3 id="1-Transformer-的提出：从“注意力”到“结构性突破”"><a href="#1-Transformer-的提出：从“注意力”到“结构性突破”" class="headerlink" title="1. Transformer 的提出：从“注意力”到“结构性突破”"></a>1. Transformer 的提出：从“注意力”到“结构性突破”</h3><p>2017 年，Google 团队在论文《Attention is All You Need》中提出了一种全新的模型架构——<strong>Transformer</strong>。这项工作最初的灵感源于“注意力机制”的有效性，而后作者们又进一步发展出了一种完全基于注意力机制、摒弃传统递归（RNN）和卷积结构的深度学习架构。</p>
<p>Transformer 的核心创新在于：</p>
<ul>
<li><strong>去除序列间的依赖结构</strong>（如 RNN 的串行处理），转而依赖自注意力机制进行信息交互</li>
<li><strong>提高了并行处理能力</strong>，可以大幅加速训练</li>
<li><strong>有更强的上下文建模能力</strong>，使得模型能够灵活捕捉长距离依赖关系</li>
</ul>
<h3 id="2-BERT-的问世：从架构到预训练范式的统一"><a href="#2-BERT-的问世：从架构到预训练范式的统一" class="headerlink" title="2. BERT 的问世：从架构到预训练范式的统一"></a>2. BERT 的问世：从架构到预训练范式的统一</h3><p>虽然 Transformer 的结构十分先进，但真正让它走向工业应用、普及到主流研究的，是 2018 年 Google 提出的 <strong>BERT（Bidirectional Encoder Representations from Transformers）</strong> 模型。</p>
<p>BERT 的重要意义体现在两点：</p>
<ul>
<li><strong>采用了纯 Transformer 编码器架构</strong></li>
<li><strong>提出了通用的预训练 + 微调范式</strong>，通过大规模语料进行预训练，再针对下游任务进行微调，这样显著提升了各类自然语言处理任务的最终效果</li>
</ul>
<p>预训练的思想本质上解决了“从零开始训练”的困难。就像建筑施工如果完全从头开始搭建会耗时耗力，而如果提供一套成熟的“图纸”和“模板”，再在其基础上构建，就会高效许多。同样，预训练模型为下游任务提供了强大的“知识迁移”能力。</p>
<p>BERT 的发布引发了一波空前的研究热潮，大量学者基于 BERT 架构进行下游任务优化，刷新了几乎所有公开数据集的基准性能。可以说，BERT 将 Transformer 的潜力推向了一个新的高峰，也标志着 NLP 进入了“预训练语言模型”时代。</p>
<h3 id="3-GPT-系列的崛起：从边缘探索者到时代主角"><a href="#3-GPT-系列的崛起：从边缘探索者到时代主角" class="headerlink" title="3. GPT 系列的崛起：从边缘探索者到时代主角"></a>3. GPT 系列的崛起：从边缘探索者到时代主角</h3><p>与 BERT 同期诞生的还有 OpenAI 的 <strong>GPT（Generative Pre-trained Transformer）</strong>。不过，相较于 BERT 的“完形填空式”输入-输出结构，GPT 更专注于 <strong>语言生成任务</strong>，采用单向结构，通过自回归方式生成文本。起初，GPT 系列并未引起足够关注，市场和学界的重心几乎全部集中在 BERT 及其变体上。但 GPT 并未停止演进，反而持续扩大模型规模、优化训练方式，最终在 GPT-3、GPT-4 的阶段迎来爆发，成为今日大模型浪潮的中心。</p>
<p>这也反映出一个事实：在 2018 年，BERT 主导了 NLP 领域几乎 99% 的关注，而 GPT 系列在当时被广泛忽视。然而如今，GPT 已成为引领行业发展的旗帜，反观 BERT 架构已逐渐退居二线。由此可见，技术演进的路径并非线性，而是由架构、预训练方式、数据规模和应用场景共同推动的。</p>
<h3 id="4-Transformer-的本质任务：特征建模与表达重塑"><a href="#4-Transformer-的本质任务：特征建模与表达重塑" class="headerlink" title="4. Transformer 的本质任务：特征建模与表达重塑"></a>4. Transformer 的本质任务：特征建模与表达重塑</h3><p>在深入理解 Transformer 架构前，我们首先需要明确一个基本问题：Transformer 到底在做什么？<br>我们可以将 Transformer 看作一个<strong>特征重塑器</strong>。它的目标是接收一组原始输入特征，通过多层注意力机制进行全局信息建模与交互，最终输出一组更加<strong>棱角分明、语义丰富</strong>的表示。</p>
<p>举个类比：假设每个输入向量是一个平平无奇的人物，缺乏特点，模型很难分辨；而 Transformer 的作用就是通过“问一问周围的人怎么说”、“看看全局谁更重要”等机制，重新塑造每个人的性格标签，让他们在模型眼中变得鲜明可辨。这种机制极大提升了模型对上下文的理解能力，也为下游任务提供了更具判别力的输入表示。</p>
<p>因此，Transformer 的核心工作是：</p>
<ul>
<li>建立输入之间的全局关系</li>
<li>强化有意义的特征维度，抑制冗余信息</li>
<li>输出适用于分类、生成等任务的高质量表示</li>
</ul>
<h3 id="5-AI-的范式迁移与启示"><a href="#5-AI-的范式迁移与启示" class="headerlink" title="5. AI 的范式迁移与启示"></a>5. AI 的范式迁移与启示</h3><p>从 RNN 到 Transformer，不仅仅是结构的替换，更是计算范式的根本转变：</p>
<ul>
<li>从串行到并行</li>
<li>从局部依赖到全局建模</li>
<li>从“手工设计结构”到“数据驱动表示学习”</li>
</ul>
<p>2017 年的 Transformer 是一场变革的起点，2018 年的 BERT 是推广的催化剂，而今天的 GPT 系列与多模态模型则将这一技术带入了前所未有的高度。可以说，Transformer 不仅定义了 NLP，也逐渐在视觉、音频、强化学习等多个领域建立统治地位，成为真正的“通用架构”。</p>
<p>接下来，我们将深入分析 Transformer 的具体结构，包括多头注意力机制、位置编码方式、前馈神经网络与残差连接等模块，剖析其如何高效地实现上下文建模与语义表示学习。</p>
<h2 id="3-Transformer整体架构"><a href="#3-Transformer整体架构" class="headerlink" title="3.Transformer整体架构"></a>3.Transformer整体架构</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250624114203.png"></p>
<h3 id="1-核心结构"><a href="#1-核心结构" class="headerlink" title="1.核心结构"></a>1.核心结构</h3><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250624144755.png"></p>
<h4 id="编码器（左侧）​​"><a href="#编码器（左侧）​​" class="headerlink" title="编码器（左侧）​​"></a><strong>编码器（左侧）​</strong>​</h4><ul>
<li>包含 ​<strong>N个相同层</strong>​（图中<code>ENCODER #1</code>, <code>ENCODER #2</code>）</li>
<li>每层含：​<strong>自注意力层 + 残差连接 &amp; 层归一化 + 前馈网络</strong>​</li>
</ul>
<h4 id="解码器（右侧）​​"><a href="#解码器（右侧）​​" class="headerlink" title="解码器（右侧）​​"></a><strong>解码器（右侧）​</strong>​</h4><ul>
<li>包含 ​<strong>N个相同层</strong>​（图中<code>DECODER #1</code>, <code>DECODER #2</code>）</li>
<li>每层比编码器多一层：​<strong>编码器-解码器注意力层</strong>​</li>
<li>结构顺序 : <code>掩码自注意力 → 残差&amp;归一化 → 编码器-解码器注意力 → 残差&amp;归一化 → 前馈网络</code></li>
</ul>
<p><strong>堆叠设计</strong>​：  </p>
<blockquote>
<p>多个编码器&#x2F;解码器层堆叠（图中为2层）是为了构建深层网络，这样就可以学习更复杂的特征表示。</p>
</blockquote>
<h3 id="​2-输入如何编码？​​"><a href="#​2-输入如何编码？​​" class="headerlink" title="​2.输入如何编码？​​"></a>​2.输入如何编码？​​</h3><h4 id="​1-输入预处理流程​"><a href="#​1-输入预处理流程​" class="headerlink" title="​1. 输入预处理流程​"></a>​1. 输入预处理流程​</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入序列 = [<span class="string">&quot;Thinking&quot;</span>, <span class="string">&quot;Machines&quot;</span>]</span><br></pre></td></tr></table></figure>
<ol>
<li>​<strong>词嵌入（Word Embedding）​</strong>​：每个单词映射为<strong>稠密向量</strong>​（如512维向量 <code>[0.3, -0.8, ..., 0.1]</code>）</li>
<li>​<strong>位置编码（Positional Encoding）​</strong>​：再为每个位置生成<strong>位置向量</strong>​（正弦&#x2F;余弦函数）<ul>
<li>例：</li>
</ul>
 <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&quot;Thinking&quot; (位置0) → [sin(0), cos(0), sin(0.01), cos(0.01), ...]  </span><br><span class="line">&quot;Machines&quot; (位置1) → [sin(1), cos(1), sin(0.0001), cos(0.0001), ...]  </span><br></pre></td></tr></table></figure></li>
<li>​<strong>融合输入</strong>​： <br> $$最终输入向量&#x3D;词嵌入向量+位置编码向量$$<br>这样可以同时保留语义信息和顺序信息，供编码器处理。</li>
</ol>
<h3 id="​3-输出结果是什么？​"><a href="#​3-输出结果是什么？​" class="headerlink" title="​3.输出结果是什么？​"></a>​3.输出结果是什么？​</h3><h4 id="​1-输出生成逻辑​"><a href="#​1-输出生成逻辑​" class="headerlink" title="​1. 输出生成逻辑​"></a>​1. 输出生成逻辑​</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> 未生成结束符:</span><br><span class="line">   <span class="number">1.</span> 解码器接收：当前已生成序列（初始为&lt;start&gt;）</span><br><span class="line">   <span class="number">2.</span> 通过多层解码器生成隐状态</span><br><span class="line">   <span class="number">3.</span> 输出层预测下一个单词概率分布</span><br><span class="line">   <span class="number">4.</span> 采样一个单词（如贪心选择最高概率词）</span><br></pre></td></tr></table></figure>
<h4 id="​2-输出层结构​"><a href="#​2-输出层结构​" class="headerlink" title="​2. 输出层结构​"></a>​2. 输出层结构​</h4><ul>
<li>​<strong>线性层（Linear）​</strong>​：将解码器输出的高维向量映射到词汇表大小维度</li>
<li>​<strong>Softmax</strong>​：计算每个单词的生成概率 <br>$$ P(下一个单词&#x3D;wi​)&#x3D;∑j​exp(zj​)exp(zi​) $$​<br>📌 ​<strong>示例输出</strong>​：<blockquote>
<p>输入：”Thinking Machines”<br>输出可能是：”思考” → “机器” → <code>&lt;end&gt;</code>（机器翻译场景）</p>
</blockquote>
</li>
</ul>
<h3 id="​4-Attention的核心目的​"><a href="#​4-Attention的核心目的​" class="headerlink" title="​4.Attention的核心目的​"></a>​4.Attention的核心目的​</h3><h4 id="​1-三种注意力机制​"><a href="#​1-三种注意力机制​" class="headerlink" title="​1. 三种注意力机制​"></a>​1. 三种注意力机制​</h4><table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>目的</strong></th>
<th><strong>计算差异</strong></th>
</tr>
</thead>
<tbody><tr>
<td>自注意力（Self-Attention）</td>
<td>让每个词动态地看整个句子，从而捕捉上下文关系</td>
<td>Query、Key、Value 都来自同一个序列</td>
</tr>
<tr>
<td>掩码自注意力（Masked Self-Attention）</td>
<td>防止解码器“偷看”未来信息，只能关注当前位置及之前的词</td>
<td>在自注意力计算中对未来位置加掩码（mask）</td>
</tr>
<tr>
<td>编码器-解码器注意力（Encoder-Decoder Attention）</td>
<td>让解码器在生成每个词时去关注编码器输出，即源句子内容</td>
<td>Query 来自解码器，Key 和 Value 来自编码器</td>
</tr>
</tbody></table>
<h4 id="​2-核心价值​"><a href="#​2-核心价值​" class="headerlink" title="​2. 核心价值​"></a>​2. 核心价值​</h4><ul>
<li>​<strong>解决长距离依赖</strong>​：直接关联任意距离的两个词（无需RNN的逐步传递）</li>
<li>​<strong>可解释性</strong>​：注意力权重可视化（例：翻译”Machines”时关注”机器”）</li>
<li>​<strong>并行计算</strong>​：所有位置注意力同时计算（极大加速训练）</li>
</ul>
<h3 id="​5-组件如何协作？端到端流程​"><a href="#​5-组件如何协作？端到端流程​" class="headerlink" title="​5.组件如何协作？端到端流程​"></a>​5.组件如何协作？端到端流程​</h3><h4 id="​1-完整流程（以机器翻译为例）​​"><a href="#​1-完整流程（以机器翻译为例）​​" class="headerlink" title="​1. 完整流程（以机器翻译为例）​​"></a>​1. 完整流程（以机器翻译为例）​​</h4><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250624152338.png"></p>
<h4 id="​2-关键协作设计​"><a href="#​2-关键协作设计​" class="headerlink" title="​2. 关键协作设计​"></a>​2. 关键协作设计​</h4><ul>
<li>​<strong>残差连接（Add）​</strong>​：每层输出 &#x3D; 原始输入 + 本层变换 → 防止深层网络梯度消失</li>
<li>​<strong>层归一化（Normalize）​</strong>​：对每层输出归一化 → 稳定训练过程</li>
<li>​<strong>信息传递路径</strong>​：编码器输出 → 每个解码器的<strong>编码器-解码器注意力层</strong>​ → 对齐输入输出关键信息</li>
</ul>
<p><strong>以”Thinking Machines”英译中为例</strong>​： </p>
<blockquote>
<ol>
<li>编码器分析”Thinking”与”Machines”的语义关系</li>
<li>解码器生成”思考”时，通过编码器-解码器注意力聚焦”Thinking”</li>
<li>生成”机器”时，注意力同时聚焦”Machines”和已生成的”思考”</li>
</ol>
</blockquote>
<h3 id="​总结：Transformer如何突破传统？​​"><a href="#​总结：Transformer如何突破传统？​​" class="headerlink" title="​总结：Transformer如何突破传统？​​"></a>​总结：Transformer如何突破传统？​​</h3><table>
<thead>
<tr>
<th>​<strong>维度</strong>​</th>
<th>​<strong>传统模型（RNN）​</strong>​</th>
<th>​<strong>Transformer</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>顺序处理</strong>​</td>
<td>逐步计算（无法并行）</td>
<td>全序列并行计算</td>
</tr>
<tr>
<td>​<strong>长距离依赖</strong>​</td>
<td>需多次传递（易丢失信息）</td>
<td>注意力一步直达</td>
</tr>
<tr>
<td>​<strong>位置建模</strong>​</td>
<td>天然顺序（但慢）</td>
<td>显式位置编码（快且灵活）</td>
</tr>
<tr>
<td>​<strong>架构本质</strong>​</td>
<td>时间驱动</td>
<td>​<strong>空间关联驱动（注意力矩阵）​</strong>​</td>
</tr>
</tbody></table>
<h2 id="4-自注意力机制（处理序列内部关系）"><a href="#4-自注意力机制（处理序列内部关系）" class="headerlink" title="4.自注意力机制（处理序列内部关系）"></a>4.自注意力机制（处理序列内部关系）</h2><h3 id="​1-自注意力的目标​"><a href="#​1-自注意力的目标​" class="headerlink" title="​1.自注意力的目标​"></a>​1.自注意力的目标​</h3><p>解决序列的核心问题：<strong>如何让序列中的每个元素（如单词）理解自身与其他元素之间的关系？​</strong>​</p>
<p>例：在句 <em>“The cat did not catch the mouse because it was tired”</em> 中，<em>“it”</em> 需要知道它指代的是 “cat”（而非 “mouse”）这就需要​<strong>依赖上下文关联</strong>。</p>
<blockquote>
<p><strong>自注意力的本质</strong>​：​<strong>动态计算序列内任意两个元素的相关性权重</strong>。</p>
</blockquote>
<h3 id="​2-自注意力在架构中的位置​"><a href="#​2-自注意力在架构中的位置​" class="headerlink" title="​2.自注意力在架构中的位置​"></a>​2.自注意力在架构中的位置​</h3><ul>
<li>​<strong>编码器（ENCODER）​</strong>​：每个编码器层中的 ​<strong>Self-Attention 模块</strong>​</li>
<li>​<strong>解码器（DECODER）​</strong>​：每个解码器层中的 ​<strong>Masked Self-Attention 模块</strong>​</li>
</ul>
<p> 图中路径：  </p>
<blockquote>
<p><code>输入序列 → 位置编码 → 编码器 Self-Attention → 解码器 Masked Self-Attention</code></p>
</blockquote>
<h3 id="​3-自注意力运行机制（3步）​​"><a href="#​3-自注意力运行机制（3步）​​" class="headerlink" title="​3.自注意力运行机制（3步）​​"></a>​3.自注意力运行机制（3步）​​</h3><h4 id="​1-生成查询向量（Query）、键向量（Key）、值向量（Value）"><a href="#​1-生成查询向量（Query）、键向量（Key）、值向量（Value）" class="headerlink" title="​1.生成查询向量（Query）、键向量（Key）、值向量（Value）"></a>​1.生成查询向量（Query）、键向量（Key）、值向量（Value）</h4><p>对序列中 ​<strong>每个单词的嵌入向量​</strong>（如 “Thinking”）做线性变换： </p>
<ul>
<li>$Q &#x3D; W_q · x_i$    主动“询问”向量，表示当前词想“了解什么”</li>
<li>$K &#x3D; W_k · x_i$    被检索的“标识”向量，表示其他词“能提供什么”</li>
<li>$V &#x3D; W_v · x_i$    实际携带信息的向量，是最终被提取的语义信息</li>
</ul>
<h4 id="​2-计算注意力权重（序列元素间的关联强度）​​"><a href="#​2-计算注意力权重（序列元素间的关联强度）​​" class="headerlink" title="​2.计算注意力权重（序列元素间的关联强度）​​"></a>​2.计算注意力权重（序列元素间的关联强度）​​</h4><p>通过 ​<strong>点积（Dot-Product）​</strong>​ 计算词与词之间的相关性分数：</p>
<ul>
<li>$分数 &#x3D; Q_i · K_j &#x2F; √d_k$    &#x2F;&#x2F; $d_k$为K的维度（缩放避免梯度消失）<br>对分数做 ​<strong>Softmax 归一化</strong>​ → 得到概率分布</li>
<li>$权重 α_{ij} &#x3D; softmax(分数_ij)$   &#x2F;&#x2F; $α_{ij}$表示第j个词对第i个词的重要性<br>示例：  <blockquote>
<p>当处理 “it” 时，$α_{it,cat} ≈ 0.9, α_{it,mouse} ≈ 0.1$</p>
</blockquote>
</li>
</ul>
<h4 id="​3-加权聚合值向量（V）​​"><a href="#​3-加权聚合值向量（V）​​" class="headerlink" title="​3.加权聚合值向量（V）​​"></a>​3.加权聚合值向量（V）​​</h4><p>用权重 $α_{ij}$ 对 ​<strong>所有词的 V 向量加权求和</strong>，生成当前词的新表示：<br>$$z_i &#x3D; ∑<em>{j&#x3D;1}^n α</em>{ij} V_j$$<br>输出​：  </p>
<blockquote>
<p>$z_i$ 是融合了<strong>全局上下文信息</strong>的新向量（如“it”的向量中包含了“cat”的信息）</p>
</blockquote>
<h3 id="4-举例“今天晚上吃啥”"><a href="#4-举例“今天晚上吃啥”" class="headerlink" title="4.举例“今天晚上吃啥”"></a>4.举例“今天晚上吃啥”</h3><h4 id="1-每个词先被映射成三个向量：Query、Key、Value"><a href="#1-每个词先被映射成三个向量：Query、Key、Value" class="headerlink" title="1.每个词先被映射成三个向量：Query、Key、Value"></a>1.每个词先被映射成三个向量：Query、Key、Value</h4><p>对于序列 [“今天”, “晚上”, “吃”, “啥”]，每个词都会被分别映射成：Q（Query）、K（Key）、V（Value）<br>比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q_今天 = W_Q × Emb(&quot;今天&quot;)</span><br><span class="line">K_今天 = W_K × Emb(&quot;今天&quot;)</span><br><span class="line">V_今天 = W_V × Emb(&quot;今天&quot;)</span><br><span class="line"># 其它词同理</span><br></pre></td></tr></table></figure>
<h4 id="2-“今天”去和每个词计算相关性：点积-softmax"><a href="#2-“今天”去和每个词计算相关性：点积-softmax" class="headerlink" title="2.“今天”去和每个词计算相关性：点积 + softmax"></a>2.“今天”去和每个词计算相关性：点积 + softmax</h4><p>我们想更新“今天”这个词的信息表示，那么我们用它的 Query 去和所有词的 Key 做<strong>点积</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Score_今天-今天 = Q_今天 · K_今天</span><br><span class="line">Score_今天-晚上 = Q_今天 · K_晚上</span><br><span class="line">Score_今天-吃   = Q_今天 · K_吃</span><br><span class="line">Score_今天-啥   = Q_今天 · K_啥</span><br></pre></td></tr></table></figure>
<p>然后把这些分数做一个 softmax 归一化，生成一组<strong>权重</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Softmax([Score_今天-今天, Score_今天-晚上, Score_今天-吃, Score_今天-啥]) </span><br><span class="line">→ [0.5, 0.1, 0.3, 0.1]</span><br></pre></td></tr></table></figure>
<p>最终就得到了 <strong>“注意力百分比”</strong></p>
<h4 id="3-用这组权重去加权-Value-向量"><a href="#3-用这组权重去加权-Value-向量" class="headerlink" title="3.用这组权重去加权 Value 向量"></a>3.用这组权重去加权 Value 向量</h4><p>最后，“今天”这个词的最终表示就变成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">新的今天 = 0.5 × V_今天 + 0.1 × V_晚上 + 0.3 × V_吃 + 0.1 × V_啥</span><br></pre></td></tr></table></figure>
<p>这里的“今天”、“晚上”等等都是对应词的 <strong>Value 向量</strong>（而不是原始文字）。</p>
<h4 id="4-类比一下"><a href="#4-类比一下" class="headerlink" title="4.类比一下"></a>4.类比一下</h4><p>你可以把这个过程想成“今天”这个词要做一次信息融合，它在“问大家”：<br><strong>“我‘今天’想重新理解自己，我该参考谁多一点？”</strong></p>
<ul>
<li>它看自己（50%），因为“今天”对自身有最强的语义绑定</li>
<li>看“吃”（30%），因为“吃饭”时间通常和“今天”有时序关系</li>
<li>看“晚上”（10%），“今天晚上”是一个常见搭配</li>
<li>“啥”（10%）可能关系较弱<br>这个“参考比例”也就是 attention score。</li>
</ul>
<p>你看到的“0.5、0.1、0.3、0.1”的权重，是由：</p>
<blockquote>
<p>Query(今天) 和所有 Key 做点积 → 再经过 softmax → 得到的一组概率分布，这些概率就决定了“今天”这个词在自注意力中<strong>融合哪些词的内容、要融合多少</strong>。</p>
</blockquote>
<h4 id="5-注意点"><a href="#5-注意点" class="headerlink" title="5.注意点"></a>5.注意点</h4><p>在实际训练或使用预训练模型时，<strong>这些权重（比如注意力机制中的 $W_Q, W_K, W_V$）都不需要我们手动初始化</strong>。因为 <strong>预训练模型已经学好了这些参数</strong>，我们只需要加载并使用即可。</p>
<h3 id="​5-自注意力如何解决序列问题？（对比RNN）​​"><a href="#​5-自注意力如何解决序列问题？（对比RNN）​​" class="headerlink" title="​5.自注意力如何解决序列问题？（对比RNN）​​"></a>​5.自注意力如何解决序列问题？（对比RNN）​​</h3><table>
<thead>
<tr>
<th>​<strong>能力</strong>​</th>
<th>​<strong>RNN&#x2F;LSTM</strong>​</th>
<th>​<strong>自注意力</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>建模长距离依赖</strong>​</td>
<td>需逐步传递（信息易丢失&#x2F;稀释）</td>
<td>一步直达，直接计算任意距离关联（任意位置连线）</td>
</tr>
<tr>
<td>​<strong>并行计算</strong>​</td>
<td>严格时间序，不可并行</td>
<td>所有位置QKV同时计算（矩阵并行）</td>
</tr>
<tr>
<td>​<strong>语义关联可视化</strong>​</td>
<td>隐状态难以解释</td>
<td>注意力权重$α_{ij}$可直观解释</td>
</tr>
<tr>
<td>​<strong>计算复杂度</strong>​</td>
<td>$O(T·d)$</td>
<td>$O(T²·d)$（但GPU并行效率更高）</td>
</tr>
</tbody></table>
<p><strong>关键优势</strong>​：  <strong>上下文感知（Context-Aware）​</strong>​  </p>
<blockquote>
<p>每个词的输出向量（如 $z_i$）都融合了<strong>整个序列的信息</strong>​ → 动态理解多义词（如“bank”在“river bank” vs “bank account”中不同含义）</p>
</blockquote>
<h3 id="​6-自注意力的输入→输出"><a href="#​6-自注意力的输入→输出" class="headerlink" title="​6.自注意力的输入→输出"></a>​6.自注意力的输入→输出</h3><p>以编码器中的 Self-Attention为例：</p>
<ol>
<li>​<strong>输入</strong>​：词嵌入向量 + 位置编码（<code>Thinking</code>, <code>Machines</code> 的向量）</li>
<li>​<strong>过程</strong>​：自注意力计算 <code>Thinking</code> 与 <code>Machines</code> 的相互影响权重，生成新的上下文向量（包含两者关系）</li>
<li>​<strong>输出</strong>​：传入下一层（<code>Add &amp; Normalize → Feed Forward</code>）继续抽象</li>
</ol>
<h3 id="​7-自注意力的本质​"><a href="#​7-自注意力的本质​" class="headerlink" title="​7.自注意力的本质​"></a>​7.自注意力的本质​</h3><ul>
<li>​<strong>技术意义</strong>​：抛弃循环，用 ​<strong>Query-Key-Value 三明治机制</strong>​ 实现全局语义融合。</li>
<li>​<strong>架构地位</strong>​：图中 ​<strong>Self-Attention 模块是 Transformer 的CPU</strong>，承担核心计算任务。</li>
<li>​<strong>扩展影响</strong>​：后续大模型如 BERT（仅用自注意力编码器）、GPT（用掩码自注意力解码器），均以此为基础。</li>
</ul>
<h2 id="5-多头注意力（并行捕捉不同维度的关联）"><a href="#5-多头注意力（并行捕捉不同维度的关联）" class="headerlink" title="5.多头注意力（并行捕捉不同维度的关联）"></a>5.多头注意力（并行捕捉不同维度的关联）</h2><h3 id="1-多头注意力（Multi-Head-Attention）作用"><a href="#1-多头注意力（Multi-Head-Attention）作用" class="headerlink" title="1. 多头注意力（Multi-Head Attention）作用"></a>1. 多头注意力（Multi-Head Attention）作用</h3><p>就是<strong>让模型在多个子空间中并行地观察词与词之间的关系，捕捉不同角度的信息。</strong> 单头注意力只看一个“角度”或一种“相似度”，而多头注意力就像请了多个专家，各自用不同的标准分析句子中词之间的关系，<strong>并行、多元、综合</strong>。</p>
<h3 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h3><h4 id="1-单头-vs-多头"><a href="#1-单头-vs-多头" class="headerlink" title="1.单头 vs 多头"></a>1.单头 vs 多头</h4><h5 id="单头注意力："><a href="#单头注意力：" class="headerlink" title="单头注意力："></a>单头注意力：</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q = X @ W_Q     # X: 输入序列，W_Q: 权重矩阵</span><br><span class="line">K = X @ W_K</span><br><span class="line">V = X @ W_V</span><br><span class="line">Attention = softmax(Q @ K.T / √d) @ V</span><br></pre></td></tr></table></figure>
<h5 id="多头注意力（以-8-头为例）："><a href="#多头注意力（以-8-头为例）：" class="headerlink" title="多头注意力（以 8 头为例）："></a>多头注意力（以 8 头为例）：</h5><p>把 Q&#x2F;K&#x2F;V 分别用 <strong>8 套不同的投影矩阵</strong>做线性变换：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i in range(8):    # 8个头</span><br><span class="line">    Q_i = X @ W_Q_i   # 每个 W_Q_i 是不同的线性变换</span><br><span class="line">    K_i = X @ W_K_i</span><br><span class="line">    V_i = X @ W_V_i</span><br><span class="line">    Attention_i = softmax(Q_i @ K_i.T / √d_i) @ V_i</span><br></pre></td></tr></table></figure>

<p>然后把 8 个头的输出拼在一起：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Concat(Attention_1, ..., Attention_8) → 再通过一个线性层</span><br></pre></td></tr></table></figure>

<p>这个线性层就是 $W_O$，可以想象成“专家总结”。</p>
<h3 id="3-模型参数"><a href="#3-模型参数" class="headerlink" title="3.模型参数"></a>3.模型参数</h3><p>假设输入维度是 512</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">W_Q_i / W_K_i / W_V_i   // [512, 64]（每个头 64 维）</span><br><span class="line">8个头变换后               // [512, 8×64 = 512]</span><br><span class="line">W_O                     // [512, 512]（拼接后还原维度）</span><br></pre></td></tr></table></figure>
<h3 id="4-类比：小组讨论的直觉比喻"><a href="#4-类比：小组讨论的直觉比喻" class="headerlink" title="4. 类比：小组讨论的直觉比喻"></a>4. 类比：小组讨论的直觉比喻</h3><p>你有一个句子「今天晚上吃啥」，你想分析“今天”这个词该关注谁。<br>于是请来了 <strong>8 位专家</strong>，每位都从不同角度给建议：    </p>
<ul>
<li>第一个专注时间线（今天←→晚上）        </li>
<li>第二个关注动作（吃） </li>
<li>第三个关注主宾关系（吃←→啥）</li>
<li>……其余人从语法、句法、话题等维度看<br>每个人（注意力头）单独打分，再分别输出他们的建议，最后把这些拼在一起，再交给一个“综合裁判”整合信息。</li>
</ul>
<p>多头注意力可以从不同头关注不同信息，这样就不容易“信息冲突”或“遗漏关键线索”，提高了表达能力。即使某一头注意力失败，其他头可以弥补，实际更稳定&#x2F;灵活。</p>
<blockquote>
<p>多头注意力 &#x3D; 多个注意力专家并行工作，分别分析不同语义维度，最后综合出一个更全面的理解。</p>
</blockquote>
<h2 id="6-位置编码（注入序列顺序信息）"><a href="#6-位置编码（注入序列顺序信息）" class="headerlink" title="6.位置编码（注入序列顺序信息）"></a>6.位置编码（注入序列顺序信息）</h2><h3 id="1-为什么需要位置编码？"><a href="#1-为什么需要位置编码？" class="headerlink" title="1.为什么需要位置编码？"></a>1.为什么需要位置编码？</h3><p>Transformer 结构完全没有 RNN &#x2F; CNN 中的“顺序感”。原始的 Transformer 是基于 Attention 的，它不管输入词的前后顺序，全靠计算相互之间的注意力。</p>
<p>那么问题来了，我怎么知道“今天晚上吃啥”跟“吃啥今天晚上”是不同的？<br>位置编码就是给每个词<strong>加上“位置信息”</strong>，让模型知道哪个词在第几个位置。我们给每个词的 embedding 向量中 <strong>添加一段专门的“位置信息向量”</strong>，这样词的表示就和它的位置挂钩了。</p>
<h3 id="2-两种常见方法："><a href="#2-两种常见方法：" class="headerlink" title="2.两种常见方法："></a>2.两种常见方法：</h3><h4 id="1-Sinusoidal-Encoding（正余弦函数编码）——Transformer-原版"><a href="#1-Sinusoidal-Encoding（正余弦函数编码）——Transformer-原版" class="headerlink" title="1.Sinusoidal Encoding（正余弦函数编码）——Transformer 原版"></a>1.Sinusoidal Encoding（正余弦函数编码）——Transformer 原版</h4><blockquote>
<p>不依赖学习，使用公式构造，适合泛化到更长句子</p>
</blockquote>
<p>对于位置 $pos$ 和维度 $i$，定义：<br>$$PE_{(pos, 2i)} &#x3D; \sin\left(\frac{pos}{10000^{2i&#x2F;d}}\right)$$<br>$$PE_{(pos, 2i+1)} &#x3D; \cos\left(\frac{pos}{10000^{2i&#x2F;d}}\right)$$</p>
<ul>
<li>偶数维用 $sin$，奇数维用 $cos$</li>
<li>低维度捕捉短期关系，高维度捕捉长期位置关系</li>
<li>向量之间的差值有意义，便于模型学习“相对位置信息”</li>
</ul>
<p>每个位置会对应一个固定的向量，直接加到词向量上。</p>
<h4 id="2-Learnable-Position-Embedding（可学习的位置向量）"><a href="#2-Learnable-Position-Embedding（可学习的位置向量）" class="headerlink" title="2.Learnable Position Embedding（可学习的位置向量）"></a>2.Learnable Position Embedding（可学习的位置向量）</h4><p>直接把位置当作一个“词”一样来训练，比如说最多处理 512 个位置，就定义一个：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pos_embedding = nn.Embedding(512, d_model)</span><br></pre></td></tr></table></figure>
<p>每个位置 0~511 都有一个向量，随着训练自动学。</p>
<p>优点：灵活、能拟合训练语料的结构<br>缺点：泛化能力差，位置超过训练长度可能表现差</p>
<p>怎么加到词上？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = word_embedding + positional_encoding</span><br></pre></td></tr></table></figure>
<p>词的语义 + 位置信息 &#x3D; 带位置信息的输入表示</p>
<h3 id="3-类比：拼火车"><a href="#3-类比：拼火车" class="headerlink" title="3.类比：拼火车"></a>3.类比：拼火车</h3><p>假设句子是“今天 晚上 吃 啥”，每个词是一节火车车厢。<br>你给每节车厢都贴个编号（1、2、3、4），贴的标签就是位置编码。</p>
<p>没有标签 → 模型只知道“有这几节车厢”<br>加上标签 → 模型知道“车厢的顺序”</p>
<h2 id="7-编码器-解码器结构（核心框架）"><a href="#7-编码器-解码器结构（核心框架）" class="headerlink" title="7.编码器-解码器结构（核心框架）"></a>7.编码器-解码器结构（核心框架）</h2><p>编码器把输入句子变成信息浓缩的“理解结果”，解码器基于这个理解一步步“生成”目标句子。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入句子（源语言）  ─→  编码器（Encoder）  ─→  编码结果</span><br><span class="line">                                            ↓</span><br><span class="line">                                      解码器（Decoder）  ─→  输出句子（目标语言）</span><br></pre></td></tr></table></figure>

<p>比如输入：“今天晚上吃啥？”，生成：“What shall we eat tonight?”</p>
<h3 id="1-编码器（Encoder）"><a href="#1-编码器（Encoder）" class="headerlink" title="1.编码器（Encoder）"></a>1.编码器（Encoder）</h3><p>由多个 <strong>Encoder Layer</strong> 叠加组成，每层结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[输入词向量 + 位置编码]</span><br><span class="line">       ↓</span><br><span class="line">自注意力（Self-Attention）</span><br><span class="line">       ↓</span><br><span class="line">前馈神经网络（Feed Forward）</span><br><span class="line">       ↓</span><br><span class="line">输出表示（保留输入中每个词的信息，考虑了上下文）</span><br></pre></td></tr></table></figure>
<p>每个词在理解过程中不会只关注自己，而是会参考句子中其他词的信息，综合上下文后更新自己的表示，使得每个词的向量都包含了整句话的语义线索。<br>编码器的任务不是生成词语或句子，而是将输入句子转换为一组表达其含义的高维向量，用于后续生成阶段使用。</p>
<h3 id="2-解码器（Decoder）"><a href="#2-解码器（Decoder）" class="headerlink" title="2.解码器（Decoder）"></a>2.解码器（Decoder）</h3><p>由多个 <strong>Decoder Layer</strong> 叠加组成，每层结构会复杂一些：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[目标词向量 + 位置编码]</span><br><span class="line">       ↓</span><br><span class="line">掩码自注意力（Masked Self-Attention）</span><br><span class="line">       ↓</span><br><span class="line">编码器-解码器注意力（Encoder-Decoder Attention）</span><br><span class="line">       ↓</span><br><span class="line">前馈神经网络（Feed Forward）</span><br><span class="line">       ↓</span><br><span class="line">输出向量（用于预测下一个词）</span><br></pre></td></tr></table></figure>

<p>掩码自注意力的作用是在生成一个词的时候，只允许模型查看它前面已经生成的词，故意遮住后面的词，防止提前知道答案、出现“抄袭”现象。<br>编码器-解码器注意力是指当模型要生成一个词时，就会去“参考”输入句子中哪些词最相关，借此更好地决定该输出什么，从而提升翻译或生成的准确性。</p>
<h3 id="3-类比：翻译员结构"><a href="#3-类比：翻译员结构" class="headerlink" title="3.类比：翻译员结构"></a>3.类比：翻译员结构</h3><p>你可以把 Transformer 想象成一个翻译过程：</p>
<ul>
<li>编码器 &#x3D; 一个理解中文的人，他把“今天晚上吃啥”理解成一份压缩的语义笔记</li>
<li>解码器 &#x3D; 一个会英文的说话者，他一边看这份笔记一边逐字翻译出：“What shall we eat tonight?”</li>
</ul>
<p>其中解码器不能一次性生成所有单词，它是“边看边说”。每生成一个词（比如 “What”），它会重新计算注意力、生成下一个词（“shall”）</p>
<h3 id="4-编码器-vs-解码器-对比"><a href="#4-编码器-vs-解码器-对比" class="headerlink" title="4.编码器 vs 解码器 对比"></a>4.编码器 vs 解码器 对比</h3><table>
<thead>
<tr>
<th><strong>模块</strong></th>
<th><strong>输入</strong></th>
<th><strong>注意力类型</strong></th>
<th><strong>目的</strong></th>
</tr>
</thead>
<tbody><tr>
<td>编码器</td>
<td>源语言（比如中文）</td>
<td>自注意力</td>
<td>理解上下文</td>
</tr>
<tr>
<td>解码器</td>
<td>已生成的目标词（英文）+ 编码器输出</td>
<td>掩码自注意力 + 编码器-解码器注意力</td>
<td>生成新词、参考输入</td>
</tr>
</tbody></table>
<h2 id="8-层标准化（稳定训练过程）"><a href="#8-层标准化（稳定训练过程）" class="headerlink" title="8.层标准化（稳定训练过程）"></a>8.层标准化（稳定训练过程）</h2><p>在每一层网络中，可以把输出“调成标准状态”（均值为0，方差为1），这样可以让训练更平稳，减少震荡，更快收敛。</p>
<p>就像一群学生考试，有人考90分，有人考30分，差距太大，老师很难统一讲解。层标准化就像是先把分数都“标准化”，大家都围绕平均线波动，这样更容易统一训练策略，也能避免某些值太大或太小影响整个模型。</p>
<h2 id="9-残差连接（缓解梯度消失）"><a href="#9-残差连接（缓解梯度消失）" class="headerlink" title="9.残差连接（缓解梯度消失）"></a>9.残差连接（缓解梯度消失）</h2><p>给每一层加一条“捷径”，让原始信息绕过复杂计算，直接传给后面的层，帮助模型更容易训练，不容易梯度消失。</p>
<p>想象你在传话，一个人一句地传，很容易出错。残差连接就像是你偷偷把原话也发了条微信备份，最后的人可以同时听到“中间人转述的版本”和“原话”，即使中间转述有点偏，也不至于彻底误解。</p>
<h2 id="10-前馈神经网络（非线性特征变换）"><a href="#10-前馈神经网络（非线性特征变换）" class="headerlink" title="10.前馈神经网络（非线性特征变换）"></a>10.前馈神经网络（非线性特征变换）</h2><p>在注意力机制之后，加一层小型的神经网络，对每个词的表示再加工一次，让它学到更复杂的特征和语义关系。</p>
<p>你可以把前面的注意力比作“信息收集”，而前馈网络就像“深加工工厂”——收集到的信息还比较粗糙，前馈网络用非线性函数再精细处理，让每个词的表示更聪明、更有表现力。</p>
<h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11.总结"></a>11.总结</h2><p><strong>Transformer本质</strong>​：通过注意力机制重构序列建模，从“逐步传递”到“动态关联”，最终成为大模型时代的基础架构。</p>
<ol>
<li>​<strong>自注意力机制</strong>​：动态计算序列元素间关联（QKV矩阵），直接建模长距离依赖，替代RNN的串行传递</li>
<li>​<strong>编码器-解码器结构</strong>​<ul>
<li>​<strong>编码器</strong>​：自注意力+前馈网络，提取输入特征</li>
<li>​<strong>解码器</strong>​：掩码自注意力（防信息泄露）+ 编码器交互注意力（对齐输入）</li>
</ul>
</li>
<li>​<strong>关键技术点</strong>​<ul>
<li>​<strong>多头注意力</strong>​：并行多组注意力，捕捉不同维度关系</li>
<li>​<strong>位置编码</strong>​：注入位置信息，弥补注意力缺失的时序感知</li>
<li>​<strong>残差连接+层标准化</strong>​：稳定深层训练，缓解梯度消失</li>
</ul>
</li>
<li>​<strong>突破性优势</strong>​<ul>
<li>​<strong>全局建模</strong>​：任意位置直接关联，解决长距离依赖</li>
<li>​<strong>并行计算</strong>​：矩阵运算替代串行处理，大幅提升效率</li>
<li>​<strong>可解释性</strong>​：注意力权重可视化，揭示模型决策逻辑</li>
</ul>
</li>
</ol>
<h2 id="11-备注"><a href="#11-备注" class="headerlink" title="11.备注"></a>11.备注</h2><p>Attention is All You Need : <a href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>从像素到区域：MaskFormer 系列详解</title>
    <url>/2025/07/08/023-segmentation-mask2former/</url>
    <content><![CDATA[<h2 id="1-MaskFormer概述"><a href="#1-MaskFormer概述" class="headerlink" title="1.MaskFormer概述"></a>1.MaskFormer概述</h2><h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h3><p>在图像分割任务中，传统方法如 U-Net、DeepLab 系列通常采用“逐像素点分类”的策略：模型需要判断图像中每一个像素所属的类别。这种方式在语义分割中表现出色，但在实例分割场景下却存在明显的局限性。例如，同一类别的多个实例往往难以区分，因此仅靠逐像素分类很难准确完成实例级的区域划分。</p>
<span id="more"></span>
<p>针对这一问题，Facebook Research 团队提出了 MaskFormer，其核心思想是将图像分割任务从“逐像素点分类”转化为“mask 分类”，即：不是预测每一个像素的类别，而是直接预测整块区域（mask）的类别标签。</p>
<h3 id="2-核心思想"><a href="#2-核心思想" class="headerlink" title="2.核心思想"></a>2.核心思想</h3><p>传统的图像分割方法采用逐像素分类的方式，就像是在工厂里进行质检——每一颗螺丝钉、每一块电路板都要单独检查，每一个细节都不能放过。这种方式追求的是精细度，每一个像素都必须被准确判断属于哪个类别。<br>而 MaskFormer 提出的“mask 分类”方法，更像是仓库管理中的“整托管理”：不再一件一件地点数、检查，而是直接判断“这一整箱是什么货物”，例如“这托盘上是饮料”、“那一堆是书籍”。它关注的是区域的整体语义，而不是逐个像素的归属。<br>也就是说，传统方法在做“逐件清点”，而 MaskFormer 在做“批量识别”。  </p>
<h3 id="3-大致实现思路"><a href="#3-大致实现思路" class="headerlink" title="3.大致实现思路"></a>3.大致实现思路</h3><p>MaskFormer 的结构中存在多个查询（queries），可以将其理解为有多个“工人”，每一个工人负责“识别一类区域”。具体机制如下：</p>
<ul>
<li><strong>每个查询输出一个二分类 mask</strong>：例如某个查询预测“这是肝脏 vs 不是肝脏”，另一个查询预测“这是肺 vs 不是肺”，如此类推</li>
<li><strong>每个查询对应一个全局类别标签</strong>：也就是说，每个 mask 预测结果不仅是一个区域，还附带一个类别标签，用于告诉我们“这块区域是什么”</li>
<li><strong>竞争机制</strong>：多个查询可能会关注相似区域（比如两个都关注白菜），但最终只有得分最高的一个查询会被采纳为最终结果。其他无效或重复的查询则被归为“背景”</li>
<li><strong>多余查询的处理</strong>：例如在一个三类别的任务中，模型可能有 100 个查询，大多数查询关注的是背景。只有前几个最有信心的查询会被保留用于预测输出</li>
</ul>
<p>这种机制避免了像素级预测中复杂的后处理流程（如 NMS、聚类等），而是直接在 mask 层面做预测和分类，从而实现更简洁高效的分割流程。</p>
<h3 id="4-优势与适用场景"><a href="#4-优势与适用场景" class="headerlink" title="4.优势与适用场景"></a>4.优势与适用场景</h3><p>MaskFormer 的设计带来了几个明显优势：</p>
<ul>
<li><strong>统一的框架</strong>：语义分割、实例分割、全景分割都可在同一结构下完成</li>
<li><strong>模块兼容性强</strong>：可直接兼容以往网络中的编码器、损失函数、训练流程，无需大规模修改</li>
<li><strong>适用于复杂任务</strong>：尤其在类别数量较多（如超过 30 类、50 类等）时，mask 分类相较于逐像素分类更具优势</li>
<li><strong>易于扩展</strong>：为后续改进提供了清晰方向，例如更强的查询机制、更灵活的匹配策略等</li>
</ul>
<p>在面对众多分割模型时，如果优先选择具有代表性、通用性和先进性的模型，MaskFormer 无疑是值得深入研究和学习的对象。</p>
<h2 id="2-MaskFormer模型解析"><a href="#2-MaskFormer模型解析" class="headerlink" title="2.MaskFormer模型解析"></a>2.MaskFormer模型解析</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250702143815.png"><br>这张图正是 <strong>MaskFormer</strong> 的大致的模型结构图，它展示了从输入图像到最终语义分割结果的完整流程，模型可以分为三个主要模块：</p>
<h3 id="1-Pixel-Level-Module（像素级模块）"><a href="#1-Pixel-Level-Module（像素级模块）" class="headerlink" title="1.Pixel-Level Module（像素级模块）"></a>1.Pixel-Level Module（像素级模块）</h3><p>这一部分主要负责从图像中提取逐像素的语义表示，构建“图像的细节描述”。</p>
<h4 id="1-Backbone（主干网络）"><a href="#1-Backbone（主干网络）" class="headerlink" title="1.Backbone（主干网络）"></a>1.Backbone（主干网络）</h4><p>提取图像的多尺度特征，这是整个模型的信息“感知器”。</p>
<p>具体机制：<br>给定一张原始图像（比如 512×512 的 RGB 图像），Backbone（通常是 <strong>ResNet</strong>、<strong>Swin Transformer</strong> 等）会对图像进行多层次的卷积或注意力计算，提取出多个尺度的特征图，例如：</p>
<ul>
<li>第一级：分辨率较高但语义浅（比如 1&#x2F;4 尺寸）</li>
<li>第四级：分辨率低但语义强（比如 1&#x2F;32 尺寸）</li>
</ul>
<p>这些不同尺度的特征图分别编码了从<strong>边缘细节</strong>到<strong>语义概念</strong>的各种信息。</p>
<p>输出多组不同分辨率的特征图，记作：<br>$$ \mathcal{F}_1, \mathcal{F}_2, …, \mathcal{F}_n $$<br>它们是接下来 <strong>Pixel Decoder</strong> 的输入。</p>
<p>打个比方，Backbone 就像是一台照X光的扫描仪，它能从一张图片中“看出”不同层级的结构——既能看到轮廓边缘，也能识别出深层语义，比如“这里可能是猫脸”，“那边是草地”。</p>
<h4 id="2-Pixel-Decoder（像素解码器）"><a href="#2-Pixel-Decoder（像素解码器）" class="headerlink" title="2.Pixel Decoder（像素解码器）"></a>2.Pixel Decoder（像素解码器）</h4><p>目的是多尺度特征融合，恢复高分辨率空间，并为每个像素构建语义向量。</p>
<p>具体机制：<br>输入是刚才<strong>Backbone</strong>输出的多组特征图 $\mathcal{F}_i$，输出是一张大小为 $H \times W$、每个位置是一个 $C$ 维特征的图，这叫做 <strong>pixel embedding map</strong>。<br>这一步的主要逻辑包括：    </p>
<ol>
<li><strong>多尺度融合</strong>：将不同分辨率的特征图通过上采样、卷积等方式融合（类似 FPN 或 Transformer-FPN）</li>
<li><strong>空间还原</strong>：恢复到原图大小或接近原图大小</li>
<li><strong>语义压缩</strong>：将融合后的特征，压缩成每个像素点的语义向量（类似 per-pixel descriptor）</li>
</ol>
<p>打个比方，<strong>Pixel Decoder</strong> 就像一台“语义地图生成机”——它接收从 <strong>backbone</strong> 来的各种“粗略草图”，将它们拼接整合，最终生成一张每个像素都带有“身份描述”的地图。比如说，这个像素的 embedding 可能意味着“它很有可能属于猫耳朵区域”，另一个像素的embedding 表示“它看起来像是马路的一部分”。</p>
<h3 id="2-Transformer-Module（Transformer-模块）"><a href="#2-Transformer-Module（Transformer-模块）" class="headerlink" title="2.Transformer Module（Transformer 模块）"></a>2.Transformer Module（Transformer 模块）</h3><p>这一部分是模型的“理解引擎”，它尝试从图像中识别出语义区域（或称为 mask 对象），其中每个区域对应一个查询。</p>
<h4 id="1-Learnable-Queries（可学习查询）"><a href="#1-Learnable-Queries（可学习查询）" class="headerlink" title="1.Learnable Queries（可学习查询）"></a>1.Learnable Queries（可学习查询）</h4><p>作为“假设区域”的探针，每个 query 对应图中潜在的一个语义区域。</p>
<p>具体机制：<br>模型预设了 $N$ 个 learnable queries（通常是长度为 $d$ 的向量），可以理解为“区域建议器”。这些 queries 是参数向量，<strong>在训练中不断被优化</strong>，学习如何“提问”或“寻找”图像中的不同语义区域。</p>
<p>打个比方，想象图像是一幅地图，这些 learnable queries 就像是一群探险家，每人带着一个任务：“你去找猫”，“你去找人”，“你去找建筑”……虽然最开始大家是“盲猜”，但经过一轮轮训练后，他们会越来越擅长精准找到自己“负责的区域”。</p>
<h4 id="2-Transformer-Decoder"><a href="#2-Transformer-Decoder" class="headerlink" title="2.Transformer Decoder"></a>2.Transformer Decoder</h4><p>将每个 query 与图像特征交互，理解并捕捉对应的语义区域。</p>
<p>具体机制</p>
<ol>
<li><strong>输入</strong>：<br> 图像的语义特征图（来自 pixel decoder） $\mathcal{E}_{\text{pixel}} \in \mathbb{R}^{C \times H \times W}$ 以及 Learnable queries $\mathcal{Q} \in \mathbb{R}^{N \times d}$</li>
<li><strong>交互过程</strong>：<br> 每一层 decoder 都会进行：<ul>
<li>Self-Attention（query 之间互动，协调信息）</li>
<li>Cross-Attention（query 和图像像素特征互动，定位语义区域）</li>
<li>FeedForward（更新 query 表示）</li>
</ul>
</li>
<li><strong>输出</strong>：<br> 得到 $N$ 个 enriched query 表示，每个 query 现在“知道自己该关注哪里了”</li>
</ol>
<p>打个比方，decoder 是一个开会的过程，每个 query 是一个代表，会议中它不仅要和其他代表沟通（self-attention），还要去图像里取证、调研（cross-attention），最后形成报告（输出表示），告诉你它代表的是什么区域、区域是什么类别。</p>
<h4 id="3-输出两类向量（来自每个-Query）"><a href="#3-输出两类向量（来自每个-Query）" class="headerlink" title="3.输出两类向量（来自每个 Query）"></a>3.输出两类向量（来自每个 Query）</h4><p>Decoder 最终输出 $N$ 个 query 向量，模型会将它们分成两个不同用途的分支：</p>
<h5 id="1-类别预测向量（Classification-Head）"><a href="#1-类别预测向量（Classification-Head）" class="headerlink" title="1.类别预测向量（Classification Head）"></a>1.类别预测向量（Classification Head）</h5><p>每个 query 输出一个向量 $q_i$，送入一个小的 MLP → 输出维度为 $K+1$（$K$ 个类别 + 1 个“无效&#x2F;空”类），表示这个 query 所代表的区域是哪个语义类别。训练时通过 cross-entropy loss 与 ground truth 类别对齐。</p>
<h5 id="2-Mask-Embedding-向量（Mask-Head）"><a href="#2-Mask-Embedding-向量（Mask-Head）" class="headerlink" title="2.Mask Embedding 向量（Mask Head）"></a>2.Mask Embedding 向量（Mask Head）</h5><p>同一个 query 还会输出一个 embedding（或将 query 自身作为 embedding）→ 记为 $e_i$。这个 embedding 会去和 Pixel Decoder 输出的每个像素向量做<strong>点积匹配</strong>，生成该 query 对应的<strong>全图掩码</strong>。每个 query 相当于“用自己的形状模板”去和整张图进行匹配，得出一个 mask。</p>
<p>每个 query 其实就像一名记者：</p>
<ul>
<li>他写了一篇报道（query 向量），说明自己发现了什么（这个区域是猫还是人）</li>
<li>他还画了一张地图（mask embedding），标记出“这片区域就是我看到的对象”</li>
</ul>
<h3 id="3-Segmentation-Module（分割模块）"><a href="#3-Segmentation-Module（分割模块）" class="headerlink" title="3.Segmentation Module（分割模块）"></a>3.Segmentation Module（分割模块）</h3><p>这一部分负责根据 mask embedding 和逐像素特征之间的相似度，生成每个 query 对应的空间掩码，即哪些位置属于这个 query 表示的区域。</p>
<h4 id="1-掩码生成（Mask-Generation）"><a href="#1-掩码生成（Mask-Generation）" class="headerlink" title="1.掩码生成（Mask Generation）"></a>1.掩码生成（Mask Generation）</h4><p>根据每个 query 的语义“印象”，判断图中哪些像素属于这个区域。</p>
<p>具体机制</p>
<ul>
<li><strong>输入</strong>：<ul>
<li>每个 query 输出的 <strong>mask embedding 向量</strong>（记为 $e_i$）</li>
<li>来自 Pixel Decoder 的 <strong>每个像素的语义向量</strong>（记为 $\mathcal{E}_{\text{pixel}}(x, y)$）</li>
</ul>
</li>
<li><strong>操作</strong>：<br>  对每个 query $i$，通过点积方式得到一张大小为 $H \times W$ 的 mask heatmap，表示每个像素属于该区域的“相似度”。</li>
<li><strong>输出</strong>：<br>  共得到 $N$ 张掩码图，每张对应一个 query 的区域分布，通常这个 mask heatmap 会再过一个 sigmoid 函数，将其映射为 [0, 1] 区间，用作 <strong>概率图</strong> 或 <strong>soft mask</strong></li>
</ul>
<p>把 mask embedding 想象成“某个物体的特征模板”，然后它去整张图里“匹配相似的像素”。比如：一个 embedding 是“猫”的特征，那么当它与每个像素点比较时，猫脸、猫耳朵的区域点积值就会更高，从而生成对应的“猫 mask”。</p>
<h4 id="2-监督信号（训练阶段）"><a href="#2-监督信号（训练阶段）" class="headerlink" title="2.监督信号（训练阶段）"></a>2.监督信号（训练阶段）</h4><p>训练时，需要对分类和掩码两个部分分别进行监督。</p>
<h5 id="1-分类损失（Classification-Loss）"><a href="#1-分类损失（Classification-Loss）" class="headerlink" title="1. 分类损失（Classification Loss）"></a><strong>1. 分类损失（Classification Loss）</strong></h5><p>每个 query 会预测一个类别（$K+1$ 类，包括一个“空”类别）。使用 <strong>Cross-Entropy Loss</strong> 计算预测类别和 Ground Truth 类别之间的差距。如果一个 query 没有匹配任何真实目标，它应被分类为“空”类。</p>
<h5 id="2-掩码损失（Mask-Loss）"><a href="#2-掩码损失（Mask-Loss）" class="headerlink" title="2. 掩码损失（Mask Loss）"></a><strong>2. 掩码损失（Mask Loss）</strong></h5><p>每个 query 对应的 mask 会与 Ground Truth 的真实 mask 进行比较。<br>损失通常包括两部分：</p>
<ul>
<li><strong>Binary Cross Entropy (BCE) Loss</strong>：逐像素的概率误差。     </li>
<li><strong>Dice Loss</strong> 或 <strong>Focal Loss</strong>：用于处理不平衡或边界模糊的情况。<br>只有被匹配到的 query（非空）才会参与 mask loss 的计算。</li>
</ul>
<h5 id="3-Hungarian-Matching（匈牙利匹配）机制"><a href="#3-Hungarian-Matching（匈牙利匹配）机制" class="headerlink" title="3. Hungarian Matching（匈牙利匹配）机制"></a><strong>3. Hungarian Matching（匈牙利匹配）机制</strong></h5><p>为了让 query 与 Ground Truth 区域一一对应（而不是乱序配对），采用 <strong>匈牙利匹配算法</strong> 计算最佳一对一分配。依据分类损失 + 掩码损失的总和来找最优匹配方案。</p>
<p>就像在考试中，每个学生（query）要回答一个问题（类别），还要画一张图（mask）。<br>评分时：先通过“匈牙利匹配”来决定谁答哪道题，然后评分两部分：答对题（分类损失）+ 图画得准（掩码损失）。</p>
<h4 id="3-推理阶段（Inference-Only）"><a href="#3-推理阶段（Inference-Only）" class="headerlink" title="3.推理阶段（Inference Only）"></a>3.推理阶段（Inference Only）</h4><p>在测试或实际使用时，模型只进行前向传播，不再使用损失函数，而是基于预测结果生成最终分割图。</p>
<p>推理流程：</p>
<ol>
<li><strong>丢弃无效 query</strong>：<br> 分类结果为 “空类” 的 query 所生成的 mask 丢弃（这些 query 被认为没有匹配到任何真实区域）。</li>
<li><strong>有效 query 的融合</strong>：<br> 每个剩下的有效 query 会输出一个类别概率：表示它认为这个区域属于哪个类。soft mask（$H \times W$）：表示区域的空间分布。把每个 mask 乘上其对应类别的概率分数，得到加权掩码：<br>$$<br> \text{Mask}_i(x, y) &#x3D; p_i^{\text{class}} \cdot \sigma(\hat{M}_i(x, y))<br> $$</li>
<li><strong>最终语义图组合</strong>：<br> 所有有效 query 的掩码叠加，按每个像素的最大响应决定最终类别。得到一个语义分割图：<br> $$<br> \text{Segmentation map} \in \mathbb{R}^{K \times H \times W}<br> $$</li>
</ol>
<p>想象你组织一场采访活动，最终要做一张报道图：</p>
<ul>
<li>有些记者（query）啥也没采访到（被丢弃）</li>
<li>剩下的记者提交了采访对象（类别）和报道区域（mask）</li>
<li>你把他们的图和打分叠加起来，就能合成一张完整的语义地图</li>
</ul>
<h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>MaskFormer 把语义分割转换为一个“mask + 分类”的任务，而不是传统的“逐像素分类”。</p>
<p>每个 query 就像一个“候选语义区域”，模型只需判断它是什么类别，以及它的区域范围即可。这种做法统一了语义分割、实例分割和全景分割的形式，也为后来的 <strong>Mask2Former</strong> 奠定了基础。</p>
<h2 id="3-Mask2Former"><a href="#3-Mask2Former" class="headerlink" title="3.Mask2Former"></a>3.Mask2Former</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h3><p><strong>Mask2Former（CVPR 2022）</strong> 对 MaskFormer 做了全面升级，它不仅保留了“<strong>mask 分类</strong>”的核心思想，还引入了一系列结构性改进，使其能更好地适配 <strong>语义分割、实例分割、全景分割</strong> 三大任务。</p>
<p>Mask2Former是在 MaskFormer 基础上做了一些改进，它使用 query 自身预测出的 mask 来引导 attention 位置，既提升了效率，又提高了准确率，<strong>Masked Cross Attention &#x3D; Mask2Former 的精髓</strong>，如下图是 Mask2Former 的核心结构图：</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250702153232.png"></p>
<h3 id="2-左侧：Mask2Former-的整体流程图"><a href="#2-左侧：Mask2Former-的整体流程图" class="headerlink" title="2.左侧：Mask2Former 的整体流程图"></a>2.左侧：Mask2Former 的整体流程图</h3><h4 id="1-Backbone-Pixel-Decoder"><a href="#1-Backbone-Pixel-Decoder" class="headerlink" title="1.Backbone + Pixel Decoder"></a>1.Backbone + Pixel Decoder</h4><h5 id="1-Backbone"><a href="#1-Backbone" class="headerlink" title="1.Backbone"></a>1.Backbone</h5><p>从图像中提取出多层次的语义特征，常见结构：如 <strong>ResNet</strong>, <strong>Swin Transformer</strong> 等，输出：多个不同尺度的 feature maps，例如：</p>
<ul>
<li>P2（高分辨率，低语义）</li>
<li>P3、P4、P5（越来越低分辨率，但语义更强）</li>
</ul>
<p>打个比方，Backbone 就像一个分层的“观察塔”，从近处细节（P2）到远处全貌（P5），逐层提取不同抽象层次的特征。</p>
<h5 id="2-Pixel-Decoder"><a href="#2-Pixel-Decoder" class="headerlink" title="2.Pixel Decoder"></a>2.Pixel Decoder</h5><p>将多尺度的特征（P2 ~ P5）进行<strong>融合与还原</strong>，得到一张高分辨率、语义丰富的“统一特征图”。使用的机制：<strong>Multi-scale Deformable Attention</strong>：从不同层中灵活采样关键点，类似于升级版的 FPN，更智能、更灵活。<br>输出：一张尺寸为 $H \times W$ 的融合特征图，记作：<br>$$<br>\mathcal{E}_{\text{pixel}} \in \mathbb{R}^{C \times H \times W}<br>$$<br>Pixel Decoder 就像一台“图像语义压缩&#x2F;拼接机”，把从各层收集到的信息拼成一张“每个像素都有语义”的地图，供后续模块查询。</p>
<h4 id="2-Transformer-Decoder-1"><a href="#2-Transformer-Decoder-1" class="headerlink" title="2.Transformer Decoder"></a>2.Transformer Decoder</h4><p>这个部分是整个模型的“理解中心”，负责根据图像特征，<strong>挖掘图像中可能存在的语义区域（mask）</strong>，并识别出它们是什么类别。</p>
<p>相比 MaskFormer 做了如下改进：</p>
<table>
<thead>
<tr>
<th><strong>改进点</strong></th>
<th><strong>MaskFormer</strong></th>
<th><strong>Mask2Former</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>1. 注意力方式</strong></td>
<td>标准 Cross-Attention（无区域引导）</td>
<td><strong>掩码引导注意力（Mask Attention）</strong>：只在 mask 区域交互</td>
</tr>
<tr>
<td><strong>2. 掩码生成时机</strong></td>
<td>mask embedding 点积后独立生成</td>
<td>每层 decoder block 都生成 mask，引导下一轮交互</td>
</tr>
<tr>
<td><strong>3. 多层级特征交互</strong></td>
<td>单一分辨率特征（decoder 与 pixel decoder 输出交互）</td>
<td>使用 pixel decoder 输出的<strong>多尺度特征</strong> + deformable attention</td>
</tr>
<tr>
<td><strong>4. 解码方式</strong></td>
<td>decoder 后直接分类 &amp; mask 输出</td>
<td>decoder <strong>迭代 refinement</strong>，每轮都更新 mask、区域逐步清晰</td>
</tr>
<tr>
<td><strong>5. 计算效率优化</strong></td>
<td>全图 dense 运算，显存开销大</td>
<td>支持<strong>稀疏点采样</strong>，显存和训练效率提升显著</td>
</tr>
</tbody></table>
<p>Mask2Former 对 Transformer Decoder 做了结构和机制上的全面升级，核心是“区域感知 + 多尺度特征融合 + 高效监督”。它让每个 query 更专注、训练更高效、分割结果更准确，是真正从“dense 交互”迈向“精细区域建模”的一步飞跃。</p>
<h3 id="3-右侧：Decoder-Block-内部结构"><a href="#3-右侧：Decoder-Block-内部结构" class="headerlink" title="3.右侧：Decoder Block 内部结构"></a>3.右侧：Decoder Block 内部结构</h3><p>这部分展示的是 <strong>Transformer Decoder 的单个 Block</strong>，重点是它采用了 <strong>Masked Attention</strong>。</p>
<p>相比 MaskFormer 做了如下改进：</p>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>MaskFormer</strong></th>
<th><strong>Mask2Former</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Cross Attention</strong></td>
<td>标准 cross-attention（无引导）</td>
<td><strong>Masked Cross Attention（掩码引导交互）</strong></td>
</tr>
<tr>
<td><strong>Query 区域建模</strong></td>
<td>全图注意力：不知目标在哪</td>
<td>通过 mask（soft mask）控制 attention 区域：更聚焦、更高效</td>
</tr>
<tr>
<td><strong>信息更新频率</strong></td>
<td>只在最后一层 decoder 生成 mask</td>
<td><strong>每一层 decoder 都生成 mask，循环 refine</strong></td>
</tr>
<tr>
<td><strong>训练计算量</strong></td>
<td>Dense 全图交互，开销大</td>
<td>掩码调制 attention weights，显著减少冗余计算</td>
</tr>
</tbody></table>
<p>Mask2Former 的 Decoder Block 在结构形式上延续了 Transformer 架构（Self-Attn + Cross-Attn + FFN），但核心创新是：引入掩码引导机制（Masked Cross Attention），并将 mask 迭代融入每一层中，使得每个 query 更高效、专注地定位并 refine 自己的目标区域。</p>
<p>这使得它比 MaskFormer 更准确、更高效、更适配大图像和多目标场景。</p>
<h2 id="4-总结-1"><a href="#4-总结-1" class="headerlink" title="4.总结"></a>4.总结</h2><p>MaskFormer 系列从本质上<strong>重塑了我们对“分割任务”的理解</strong>：它不再执着于像素级判断，而是从“区域感知”角度出发，将分割任务提升到一个更结构化、更具扩展性的层次。</p>
<p>Mask 分类范式的提出不仅解决了过去的一些效率与精度问题，更为图像理解、交互式分割、跨模态建模等方向铺平了道路。未来，<strong>我们可以期待更多融合前景估计、跨模态 prompt、稀疏 attention 的分割模型，真正做到“高效、通用、可控”的视觉理解系统</strong>。</p>
<h2 id="5-备注"><a href="#5-备注" class="headerlink" title="5.备注"></a>5.备注</h2><ul>
<li>MaskFormer : <a href="https://arxiv.org/pdf/2107.06278">https://arxiv.org/pdf/2107.06278</a></li>
<li>Mask2Former:  <a href="https://arxiv.org/pdf/2112.01527">https://arxiv.org/pdf/2112.01527</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyTorch</tag>
        <tag>计算机视觉</tag>
        <tag>目标分割</tag>
      </tags>
  </entry>
  <entry>
    <title>ViT — Transformer在视觉领域应用代码解析</title>
    <url>/2025/07/02/022-vision-transformer/</url>
    <content><![CDATA[<h2 id="1-ViT概述"><a href="#1-ViT概述" class="headerlink" title="1.ViT概述"></a>1.ViT概述</h2><p>在上一篇文章中主要讲了 <a href="https://keychankc.github.io/2025/06/25/021-transformer/">Transformer 的基本原理</a>，尤其是在自然语言处理（NLP）任务中的应用，包括编码器和解码器的主要功能和注意力机制的具体实现。但这些内容大多基于 NLP 领域的示例，本篇我们看看在计算机视觉（CV）领域，Transformer 在图像任务中的使用方式。</p>
<h3 id="1-在视觉领域的发展背景"><a href="#1-在视觉领域的发展背景" class="headerlink" title="1.在视觉领域的发展背景"></a>1.在视觉领域的发展背景</h3><span id="more"></span>
<p>Transformer 模型自 2017 年在 NLP 领域大获成功之后，于 2020 年开始进入视觉领域。第一个具有里程碑意义的工作是 Google 提出的 <strong>Vision Transformer (ViT)</strong>，它首次在图像分类任务中展现出优异表现，随后 <strong>DETR</strong>（由 Facebook AI 提出）也将 Transformer 成功应用于目标检测任务。<br>这标志着 Transformer 模型正式进军 CV，并在分类、检测、分割等多个任务中取得突破性进展。随着模型结构的不断优化，特别是对计算量的压缩与架构的轻量化，Transformer 已逐步从“只能搞研究”的状态，走向实际应用的阶段。</p>
<h3 id="2-视觉任务中-Transformer-的基本思路"><a href="#2-视觉任务中-Transformer-的基本思路" class="headerlink" title="2.视觉任务中 Transformer 的基本思路"></a>2.视觉任务中 Transformer 的基本思路</h3><p>Transformer 模型在图像任务中的核心挑战是：<strong>如何将图像转换为序列化的输入形式</strong>，以适配 Transformer 的原始结构。</p>
<h4 id="1-图像如何转为序列？"><a href="#1-图像如何转为序列？" class="headerlink" title="1.图像如何转为序列？"></a>1.图像如何转为序列？</h4><p>Transformer 的输入是一个向量序列，在 NLP 中通过词嵌入（embedding）将词语转化为向量，而在视觉中，我们可以输入二维图像矩阵，而这需要一种方式将其转换为向量序列。通常的做法有以下两种：</p>
<ul>
<li><strong>直接切分图像块（Patch Embedding）</strong>：将图像均匀划分成小块，如 $16\times16$ 大小的 patch，每个 patch 被展平为一个向量，这就是 ViT 的实现逻辑。</li>
<li><strong>使用卷积提取 patch 特征</strong>：对每个 patch 通过多个卷积核提取特征（如使用 512 个卷积核），使每个图像块最终映射为一个高维向量（如 512 维），再组成序列。</li>
</ul>
<p>这一步的核心目标是：<strong>获得一个由向量组成的序列，每个向量代表图像中一个局部区域的特征</strong>。</p>
<h4 id="2-为什么使用-Transformer？"><a href="#2-为什么使用-Transformer？" class="headerlink" title="2.为什么使用 Transformer？"></a>2.为什么使用 Transformer？</h4><p>与卷积神经网络（CNN）相比，Transformer 的显著优势是<strong>全局建模能力强</strong>。在 CNN 中，信息传播是局部的、逐层扩散的；而 Transformer 通过 self-attention 机制，在每一层中就能捕捉到任意位置之间的关系，实现了更强的全局依赖建模。<br>例如：</p>
<blockquote>
<p>如果把网络比作公司，CNN 就像是新员工从基层逐步熟悉公司结构；而 Transformer 就像空降高管，上来就能和公司所有部门对接，迅速掌握全局。</p>
</blockquote>
<h3 id="3-Transformer-输出的用途"><a href="#3-Transformer-输出的用途" class="headerlink" title="3.Transformer 输出的用途"></a>3.Transformer 输出的用途</h3><p>Transformer 最终输出的是每个 patch 的全局上下文特征。根据任务的不同，处理方式也不同：</p>
<ul>
<li><strong>分类任务</strong>：通常使用一个特殊的 [CLS] token 来聚合所有 patch 信息，或对所有位置的向量进行池化，得到全图的表征向量，接分类头输出预测结果。</li>
<li><strong>目标检测、图像分割</strong>：输出的序列会进一步送入解码模块或其他结构中，用于生成 bounding box、mask 或语义标签。</li>
</ul>
<h2 id="2-ViT整体实现架构"><a href="#2-ViT整体实现架构" class="headerlink" title="2.ViT整体实现架构"></a>2.ViT整体实现架构</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250626163939.png"><br>这张图是 <strong>Vision Transformer (ViT)</strong> 的整体结构示意图，左边是 ViT 的整体流程，右边是每一个 <strong>Transformer Encoder</strong> 的内部结构。</p>
<h3 id="1-ViT-的整体流程"><a href="#1-ViT-的整体流程" class="headerlink" title="1.ViT 的整体流程"></a>1.ViT 的整体流程</h3><h4 id="1-输入图像切分成Patch"><a href="#1-输入图像切分成Patch" class="headerlink" title="1.输入图像切分成Patch"></a>1.输入图像切分成Patch</h4><p>原始图像会被均匀地切成多个固定大小的图像块（patches），比如 $16 \times 16$ 像素一块。图中最底下显示了将整幅图像切成了 9 个 patch。</p>
<h4 id="2-每个-patch-展平-线性投影"><a href="#2-每个-patch-展平-线性投影" class="headerlink" title="2.每个 patch 展平 + 线性投影"></a>2.每个 patch 展平 + 线性投影</h4><p>每个 patch 被展平成一个向量（Flatten），比如形状 [3, 16, 16]（RGB通道）展平成 3×16×16 &#x3D; 768 维。然后通过一个线性变换（Linear Projection）投影成固定维度，比如 D &#x3D; 768，作为 token 向量。</p>
<h4 id="3-加上位置编码Position-Embedding"><a href="#3-加上位置编码Position-Embedding" class="headerlink" title="3.加上位置编码Position Embedding"></a>3.加上位置编码Position Embedding</h4><p>因为 Transformer 本身不理解顺序，所以每个 patch 都要加上对应的 <strong>位置编码</strong>（可学习的向量），告诉模型“这是第几个 patch”。<br>同时，图中还有一个额外的 * patch —— <strong>可学习的 [class] token</strong>，用来代表整张图像的全局信息（类似 BERT 的 [CLS] token），最终用于分类。</p>
<h4 id="4-输入-Transformer-编码器"><a href="#4-输入-Transformer-编码器" class="headerlink" title="4.输入 Transformer 编码器"></a>4.输入 Transformer 编码器</h4><p>所有 patch 向量 + [class] token 一起作为 token 序列，送入 Transformer Encoder。<br>这个 Encoder 会做自注意力计算，进行信息融合。</p>
<h4 id="5-分类头（MLP-Head）"><a href="#5-分类头（MLP-Head）" class="headerlink" title="5.分类头（MLP Head）"></a>5.分类头（MLP Head）</h4><p>只取最前面的 [class] token 作为全图表达，送入一个简单的 <strong>MLP（多层感知机）</strong> 来输出分类结果（鸟、球、车等）。</p>
<h3 id="2-Transformer-Encoder-的结构细节"><a href="#2-Transformer-Encoder-的结构细节" class="headerlink" title="2.Transformer Encoder 的结构细节"></a>2.Transformer Encoder 的结构细节</h3><p>每个 Encoder Block 都是标准的 Transformer 结构，重复堆叠 $L$ 层。</p>
<h4 id="1-子结构"><a href="#1-子结构" class="headerlink" title="1.子结构"></a>1.子结构</h4><ol>
<li><strong>Multi-Head Self-Attention</strong>：让每个 patch token 能看到其它所有 patch 的信息。通过注意力机制动态决定“我关注谁”。</li>
<li><strong>Feed Forward（MLP）</strong>：每个 token 单独通过一个两层的前馈网络，增加非线性表达能力。</li>
</ol>
<h4 id="2-其它"><a href="#2-其它" class="headerlink" title="2.其它"></a>2.其它</h4><p>LayerNorm 层归一化（Norm）和 残差连接</p>
<h2 id="3-数据预处理"><a href="#3-数据预处理" class="headerlink" title="3.数据预处理"></a>3.数据预处理</h2><p>具体实现在<code>models/modeling.py</code> 文件的 Embeddings 类，Embeddings 类负责把图像切成小块（patch），每个小块变成一个向量，加上位置编码 + 特殊的 [CLS] token，最后输出一个 shape 为 [B, N+1, D] 的 token 序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Embeddings</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, img_size, in_channels=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Embeddings, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.hybrid = <span class="literal">None</span></span><br><span class="line">        img_size = _pair(img_size)</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        1️⃣.判断是否使用 hybrid 模型（是否用 CNN 提特征）</span></span><br><span class="line"><span class="string">            如果用了 grid，说明模型启用了 Hybrid ViT 模式，先用一个 CNN（比如 ResNet）</span></span><br><span class="line"><span class="string">            处理图片，再将 CNN 的输出特征图切成 patch。否则就是标准的 ViT（直接对原始图像</span></span><br><span class="line"><span class="string">            切 patch）。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> config.patches.get(<span class="string">&quot;grid&quot;</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            grid_size = config.patches[<span class="string">&quot;grid&quot;</span>]</span><br><span class="line">            patch_size = (img_size[<span class="number">0</span>] // <span class="number">16</span> // grid_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // <span class="number">16</span> // grid_size[<span class="number">1</span>])  <span class="comment"># 计算 patch 大小</span></span><br><span class="line">            n_patches = (img_size[<span class="number">0</span>] // <span class="number">16</span>) * (img_size[<span class="number">1</span>] // <span class="number">16</span>)  <span class="comment"># patch 总数量（H/16 × W/16）</span></span><br><span class="line">            <span class="variable language_">self</span>.hybrid = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            2️⃣.计算 patch 的尺寸和数量</span></span><br><span class="line"><span class="string">                将输入图像大小除以 patch 大小，得到总共切了多少个 patch</span></span><br><span class="line"><span class="string">                patch 大小和数量关系着位置编码 shape 和后续 patch embedding 的 shape</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            patch_size = _pair(config.patches[<span class="string">&quot;size&quot;</span>])  <span class="comment"># 直接使用指定的 patch 大小</span></span><br><span class="line">            n_patches = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>]) * (img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])  <span class="comment"># patch 总数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="variable language_">self</span>.hybrid = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果启用 hybrid 模式，就用 ResNetV2 先提特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.hybrid:</span><br><span class="line">            <span class="variable language_">self</span>.hybrid_model = ResNetV2(block_units=config.resnet.num_layers,</span><br><span class="line">                                         width_factor=config.resnet.width_factor)</span><br><span class="line">            <span class="comment"># 输出特征通道数：ResNet 的输出通道 * 16（因为是最后 stage 输出）</span></span><br><span class="line">            in_channels = <span class="variable language_">self</span>.hybrid_model.width * <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        3️⃣.构建 patch embedding 层（Conv2d 模拟 patch + linear）</span></span><br><span class="line"><span class="string">            直接用 Conv2d 进行切 patch + flatten + linear映射三合一操作</span></span><br><span class="line"><span class="string">            输入是原始图像或 CNN 特征图，输出是 shape 为 [B, D, H_patch, W_patch] 的特征</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.patch_embeddings = Conv2d(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=config.hidden_size,  <span class="comment"># 投影后的向量维度</span></span><br><span class="line">            kernel_size=patch_size,</span><br><span class="line">            stride=patch_size</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        4️⃣.构建位置编码与 [CLS] token</span></span><br><span class="line"><span class="string">            位置编码：可学习的位置向量，告诉模型每个 patch 的“位置信息”</span></span><br><span class="line"><span class="string">            CLS token：特殊 token，代表整张图的全局语义，最终用于分类</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.position_embeddings = nn.Parameter(torch.zeros(<span class="number">1</span>, n_patches + <span class="number">1</span>, config.hidden_size))</span><br><span class="line">        <span class="variable language_">self</span>.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, config.hidden_size))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># dropout 进行 regularization</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = Dropout(config.transformer[<span class="string">&quot;dropout_rate&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B = x.shape[<span class="number">0</span>]  <span class="comment"># 批量大小</span></span><br><span class="line">        <span class="comment"># 扩展 cls token，复制为 B 个样本，每个 shape 为 [1, 1, D] → [B, 1, D]</span></span><br><span class="line">        cls_tokens = <span class="variable language_">self</span>.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是 hybrid 模式，则先用 ResNet 提取特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.hybrid:</span><br><span class="line">            x = <span class="variable language_">self</span>.hybrid_model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        5️⃣.前向传播：将图像编码为序列 token</span></span><br><span class="line"><span class="string">            图像 → patch → patch embedding → 加 CLS → 加位置信息 → Dropout</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 用 Conv2d 切 patch 并做线性映射，输出 shape 为 [B, D, H_patch, W_patch]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.patch_embeddings(x)</span><br><span class="line">        <span class="comment"># 将空间维度展平：[B, D, H_patch, W_patch] → [B, D, N_patches]</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 调整维度顺序：[B, D, N] → [B, N, D]，符合 Transformer 输入格式</span></span><br><span class="line">        x = x.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 拼接 [CLS] token 在序列最前面，得到 [B, N+1, D]</span></span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 加上位置编码（Broadcast 自动匹配）</span></span><br><span class="line">        embeddings = x + <span class="variable language_">self</span>.position_embeddings</span><br><span class="line">        <span class="comment"># 加入 dropout 以防止过拟合</span></span><br><span class="line">        embeddings = <span class="variable language_">self</span>.dropout(embeddings)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> embeddings  <span class="comment"># 最终输出为 [B, N+1, D]，作为 Transformer 的输入</span></span><br></pre></td></tr></table></figure>
<p>供后续 Transformer encoder 处理的输出格式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shape: [B, N+<span class="number">1</span>, D]  </span><br><span class="line">B：batch_size  </span><br><span class="line">N：patch数量  </span><br><span class="line">+<span class="number">1</span>：CLS token  </span><br><span class="line">D：每个 token 的维度（hidden_size）</span><br></pre></td></tr></table></figure>
<p>Embeddings实现逻辑有一个很好的类比:</p>
<blockquote>
<p>“把图像裁成一堆小图片（patch），每块都贴上编号（位置编码），再加个代表全图的‘班长token’，然后把它们一起打包发到 transformer 班级里开会。”</p>
</blockquote>
<h2 id="4-构建Transformer输入"><a href="#4-构建Transformer输入" class="headerlink" title="4.构建Transformer输入"></a>4.构建Transformer输入</h2><p>具体实现在<code>models/modeling.py</code> 文件的 Embeddings 类的 forward 方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    B = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    1️⃣.拼接所有patch embedding和position embedding</span></span><br><span class="line"><span class="string">        这三步将所有patch的embedding拼接成一个序列，形状为 [batch, N_patches, hidden]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = <span class="variable language_">self</span>.patch_embeddings(x) <span class="comment"># [B, hidden, H_patch, W_patch]</span></span><br><span class="line">    x = x.flatten(<span class="number">2</span>) <span class="comment"># [B, hidden, N_patches]</span></span><br><span class="line">    x = x.transpose(-<span class="number">1</span>, -<span class="number">2</span>) <span class="comment"># [B, N_patches, hidden]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    2️⃣.添加CLS token:创建了一个可学习的CLS token，并在序列最前面拼接</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cls_tokens = <span class="variable language_">self</span>.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># [B, 1, hidden]</span></span><br><span class="line">    x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>) <span class="comment"># [B, N_patches+1, hidden]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    3️⃣.加上可学习的位置编码</span></span><br><span class="line"><span class="string">         位置编码和patch embedding逐元素相加，保留了位置信息</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    embeddings = x + <span class="variable language_">self</span>.position_embeddings <span class="comment"># [B, N_patches+1, hidden]</span></span><br><span class="line">    </span><br><span class="line">    embeddings = <span class="variable language_">self</span>.dropout(embeddings)</span><br><span class="line">    <span class="keyword">return</span> embeddings</span><br></pre></td></tr></table></figure>

<p><code>patch embedding</code>和<code>position embedding</code>的拼接、<code>CLS token</code>的添加都在Embeddings类的forward方法中实现，最终输出作为Transformer的输入。</p>
<h2 id="5-Transformer编码器"><a href="#5-Transformer编码器" class="headerlink" title="5.Transformer编码器"></a>5.Transformer编码器</h2><p>这是Transformer编码器的实现，负责将输入的patch序列（含CLS token）通过多层Transformer Block进行特征提取和全局信息交互。</p>
<h3 id="1-Transformer-Encoder"><a href="#1-Transformer-Encoder" class="headerlink" title="1.Transformer Encoder"></a>1.Transformer Encoder</h3><p>Encoder 类就是多个 Transformer 编码器 Block 的堆叠，并在最后加一个 LayerNorm，最后输出编码后的 token 和（可选）注意力权重。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, vis</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Encoder, <span class="variable language_">self</span>).__init__()  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1️⃣.初始化基础组件</span></span><br><span class="line">        <span class="variable language_">self</span>.vis = vis  <span class="comment"># 是否启用注意力可视化</span></span><br><span class="line">        <span class="variable language_">self</span>.layer = nn.ModuleList()  <span class="comment"># 一个装有多层 Transformer Block 的模块列表</span></span><br><span class="line">        <span class="comment"># 对最终输出做 LayerNorm</span></span><br><span class="line">        <span class="variable language_">self</span>.encoder_norm = LayerNorm(config.hidden_size, eps=<span class="number">1e-6</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2️⃣.构建多个 Transformer Block（循环添加）</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(config.transformer[<span class="string">&quot;num_layers&quot;</span>]):  </span><br><span class="line">            <span class="comment"># 每层是一个完整的 Transformer Block（带 attention 和 MLP）</span></span><br><span class="line">            layer = Block(config, vis) </span><br><span class="line">            <span class="comment"># 使用 deepcopy 确保每层独立，参数不共享 </span></span><br><span class="line">            <span class="variable language_">self</span>.layer.append(copy.deepcopy(layer))  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># hidden_states 是输入序列，一般 shape 是 [B, N, D]</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, hidden_states</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3️⃣.前向传播：依次通过每个 Transformer Block</span></span><br><span class="line">        attn_weights = []  <span class="comment"># 存储所有层的注意力矩阵（仅在 vis=True 时启用）</span></span><br><span class="line">        <span class="keyword">for</span> layer_block <span class="keyword">in</span> <span class="variable language_">self</span>.layer:  </span><br><span class="line">            <span class="comment"># 输入当前 hidden_states，输出更新后的状态和注意力权重</span></span><br><span class="line">            hidden_states, weights = layer_block(hidden_states)  </span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.vis:  <span class="comment"># 如果启用了 vis，则会收集每一层的注意力权重（用于可视化）</span></span><br><span class="line">                attn_weights.append(weights)  </span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 4️⃣.对最终的输出 hidden_states 做 LayerNorm，作为输出特征</span></span><br><span class="line">        encoded = <span class="variable language_">self</span>.encoder_norm(hidden_states)  <span class="comment"># [B, N+1, D] → 标准化处理</span></span><br><span class="line">        <span class="keyword">return</span> encoded, attn_weights</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以把这个 Encoder 类比成一个“专家委员会”，由多个“专家（Block）”组成，图像每个 patch 是一个“提案”，他们在每一轮里互相交换信息、总结观点，最终得出一份“共识文档（encoded）”。</p>
</blockquote>
<h3 id="2-Block结构"><a href="#2-Block结构" class="headerlink" title="2.Block结构"></a>2.Block结构</h3><p>这个 Block 类是 Vision Transformer 的一个标准 Transformer 编码器子层，包括：</p>
<ul>
<li>一个 <strong>多头自注意力（Multi-head Self-Attention）模块</strong></li>
<li>一个 <strong>前馈神经网络（MLP）</strong></li>
<li>两个 <strong>LayerNorm</strong></li>
<li>两个 <strong>残差连接（Residual Add）</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, vis</span>):  </span><br><span class="line">        <span class="built_in">super</span>(Block, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="comment"># 模型隐藏维度（通常是 768）</span></span><br><span class="line">        <span class="variable language_">self</span>.hidden_size = config.hidden_size  </span><br><span class="line">        <span class="comment"># Attention 前的 LayerNorm（用于稳定训练）</span></span><br><span class="line">        <span class="variable language_">self</span>.attention_norm = LayerNorm(config.hidden_size, eps=<span class="number">1e-6</span>)  </span><br><span class="line">        <span class="comment"># FFN 前的 LayerNorm</span></span><br><span class="line">        <span class="variable language_">self</span>.ffn_norm = LayerNorm(config.hidden_size, eps=<span class="number">1e-6</span>)  </span><br><span class="line">        <span class="comment"># MLP 模块（含两层全连接层 + GELU）</span></span><br><span class="line">        <span class="variable language_">self</span>.ffn = Mlp(config)  </span><br><span class="line">        <span class="comment"># 多头注意力模块（包含 query/key/value + heads 合并等）</span></span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(config, vis)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="built_in">print</span>(x.shape)  <span class="comment"># 输入 shape：[B, N, D]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1️⃣.自注意力</span></span><br><span class="line">        h = x  <span class="comment"># 保存输入，用于残差连接</span></span><br><span class="line">        x = <span class="variable language_">self</span>.attention_norm(x)  <span class="comment"># LayerNorm 正则化</span></span><br><span class="line">        x, weights = <span class="variable language_">self</span>.attn(x)  <span class="comment"># 多头自注意力计算，返回输出和注意力矩阵</span></span><br><span class="line">        x = x + h  <span class="comment"># 残差连接：加回原始输入</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2️⃣.前馈网络</span></span><br><span class="line">        h = x  <span class="comment"># 保存当前输入</span></span><br><span class="line">        x = <span class="variable language_">self</span>.ffn_norm(x)  <span class="comment"># LayerNorm</span></span><br><span class="line">        x = <span class="variable language_">self</span>.ffn(x)  <span class="comment"># 前馈神经网络：FC1 → GELU → Dropout → FC2 → Dropout</span></span><br><span class="line">        x = x + h  <span class="comment"># 再次残差连接</span></span><br><span class="line">        <span class="keyword">return</span> x, weights  <span class="comment"># 返回更新后的特征和注意力权重（用于可视化）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 权重加载部分: 从预训练模型中手动加载权重</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_from</span>(<span class="params">self, weights, n_block</span>):  </span><br><span class="line">        ROOT = <span class="string">f&quot;Transformer/encoderblock_<span class="subst">&#123;n_block&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 在权重加载过程中禁用梯度计算，加快速度并避免误更新</span></span><br><span class="line">            <span class="comment"># 1️⃣.Attention 权重加载</span></span><br><span class="line">            <span class="comment"># 从 .npz 权重中取出 Q/K/V/Out 的权重并转置适配 PyTorch 格式</span></span><br><span class="line">            query_weight = np2th(weights[ROOT + <span class="string">&quot;/&quot;</span> + ATTENTION_Q + <span class="string">&quot;/kernel&quot;</span>]).view(<span class="variable language_">self</span>.hidden_size, <span class="variable language_">self</span>.hidden_size).t()</span><br><span class="line">            key_weight = ...</span><br><span class="line">            value_weight = ...</span><br><span class="line">            out_weight = ...</span><br><span class="line">            <span class="comment"># 加载偏置</span></span><br><span class="line">            query_bias = ...</span><br><span class="line">            key_bias = ...</span><br><span class="line">            value_bias = ...</span><br><span class="line">            out_bias = ...</span><br><span class="line">            <span class="comment"># 将权重拷贝到 attention 模块的对应参数</span></span><br><span class="line">            <span class="variable language_">self</span>.attn.query.weight.copy_(query_weight)</span><br><span class="line">            <span class="variable language_">self</span>.attn.key.weight.copy_(key_weight)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2️⃣.MLP 权重加载</span></span><br><span class="line">            <span class="comment"># FC1 权重</span></span><br><span class="line">            mlp_weight_0 = np2th(weights[ROOT + <span class="string">&quot;/&quot;</span> + FC_0 + <span class="string">&quot;/kernel&quot;</span>]).t() </span><br><span class="line">            <span class="comment"># FC2 权重 </span></span><br><span class="line">            mlp_weight_1 = np2th(weights[ROOT + <span class="string">&quot;/&quot;</span> + FC_1 + <span class="string">&quot;/kernel&quot;</span>]).t()  </span><br><span class="line">            mlp_bias_0 = ...</span><br><span class="line">            mlp_bias_1 = ...</span><br><span class="line"></span><br><span class="line">            <span class="variable language_">self</span>.ffn.fc1.weight.copy_(mlp_weight_0)</span><br><span class="line">            <span class="variable language_">self</span>.ffn.fc2.weight.copy_(mlp_weight_1)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3️⃣.LayerNorm 权重加载</span></span><br><span class="line">            <span class="comment"># 加载 attention_norm 和 ffn_norm 的 gamma 和 beta（scale 和 bias）</span></span><br><span class="line">            <span class="variable language_">self</span>.attention_norm.weight.copy_(np2th(weights[ROOT + <span class="string">&quot;/&quot;</span> + ATTENTION_NORM + <span class="string">&quot;/scale&quot;</span>]))</span><br><span class="line">            <span class="variable language_">self</span>.attention_norm.bias.copy_(np2th(weights[ROOT + <span class="string">&quot;/&quot;</span> + ATTENTION_NORM + <span class="string">&quot;/bias&quot;</span>]))</span><br><span class="line">            <span class="variable language_">self</span>.ffn_norm.weight.copy_(...)</span><br></pre></td></tr></table></figure>

<p>Block结构图：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  输入 x (B, N, D)</span><br><span class="line">        ↓</span><br><span class="line">  LayerNorm（层归一化）</span><br><span class="line">        ↓</span><br><span class="line"> Residual Add（残差连接）</span><br><span class="line">        ↓</span><br><span class="line">  LayerNorm（层归一化）</span><br><span class="line">        ↓</span><br><span class="line">FFN（MLP）（前馈神经网络）</span><br><span class="line">        ↓</span><br><span class="line"> Residual Add（残差连接）</span><br><span class="line">        ↓</span><br><span class="line">      输出 x</span><br></pre></td></tr></table></figure>
<h2 id="6-VisionTransformer"><a href="#6-VisionTransformer" class="headerlink" title="6.VisionTransformer"></a>6.VisionTransformer</h2><p>这是整个ViT模型的顶层封装，负责将输入图片经过embedding、Transformer编码器、分类头等完整流程，输出最终的分类结果。主要包含</p>
<ul>
<li>完整的 Transformer 编码器结构</li>
<li>线性分类头 head</li>
<li>从预训练权重中加载参数的load_from() 方法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config, img_size=<span class="number">224</span>, num_classes=<span class="number">21843</span>, zero_head=<span class="literal">False</span>, vis=<span class="literal">False</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.num_classes = num_classes  <span class="comment"># 分类类别数（如 1000 或 21843）</span></span><br><span class="line">        <span class="variable language_">self</span>.zero_head = zero_head  <span class="comment"># 是否在初始化时将分类头置为 0</span></span><br><span class="line">        <span class="variable language_">self</span>.classifier = config.classifier  <span class="comment"># 分类策略（如 &quot;token&quot;）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建 Transformer 主体（包含 Embedding、Encoder）</span></span><br><span class="line">        <span class="variable language_">self</span>.transformer = Transformer(config, img_size, vis)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分类头：将 CLS token 映射为类别预测值</span></span><br><span class="line">        <span class="variable language_">self</span>.head = Linear(config.hidden_size, num_classes)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, labels=<span class="literal">None</span></span>):  </span><br><span class="line">        <span class="comment"># 输入图片 x，通过 Transformer 得到 token 特征（含 CLS token）</span></span><br><span class="line">        x, attn_weights = <span class="variable language_">self</span>.transformer(x)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取出 CLS token 向量（即 x 的第 0 个 token），做分类预测</span></span><br><span class="line">        logits = <span class="variable language_">self</span>.head(x[:, <span class="number">0</span>])  </span><br><span class="line">        <span class="built_in">print</span>(logits.shape)  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="comment"># 如果有标签，则计算 loss（训练模式）</span></span><br><span class="line">            loss_fct = CrossEntropyLoss()  </span><br><span class="line">            loss = loss_fct(logits.view(-<span class="number">1</span>, <span class="variable language_">self</span>.num_classes), labels.view(-<span class="number">1</span>))  </span><br><span class="line">            <span class="keyword">return</span> loss  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 推理模式：返回 logits 和注意力权重</span></span><br><span class="line">            <span class="keyword">return</span> logits, attn_weights  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 权重加载方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_from</span>(<span class="params">self, weights</span>):  </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁止梯度计算，直接加载权重</span></span><br><span class="line">            <span class="comment"># 1.加载分类头参数</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.zero_head:  </span><br><span class="line">                <span class="comment"># 若启用 zero_head，则将分类头初始化为全 0（不使用预训练分类头）</span></span><br><span class="line">                nn.init.zeros_(<span class="variable language_">self</span>.head.weight)  </span><br><span class="line">                nn.init.zeros_(<span class="variable language_">self</span>.head.bias)  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="comment"># 否则从预训练权重中加载分类头</span></span><br><span class="line">                <span class="variable language_">self</span>.head.weight.copy_(np2th(weights[<span class="string">&quot;head/kernel&quot;</span>]).t())  </span><br><span class="line">                <span class="variable language_">self</span>.head.bias.copy_(np2th(weights[<span class="string">&quot;head/bias&quot;</span>]).t())  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2.加载 patch embedding 模块参数（卷积 + 位置编码 + CLS token）</span></span><br><span class="line">            <span class="comment"># 加载 patch embedding 卷积核</span></span><br><span class="line">            <span class="variable language_">self</span>.transformer.embeddings.patch_embeddings.weight.</span><br><span class="line">            copy_(np2th(weights[<span class="string">&quot;embedding/kernel&quot;</span>], conv=<span class="literal">True</span>))  </span><br><span class="line">            <span class="variable language_">self</span>.transformer.embeddings.patch_embeddings.bias.</span><br><span class="line">            copy_(np2th(weights[<span class="string">&quot;embedding/bias&quot;</span>]))  </span><br><span class="line">            <span class="comment"># 加载 [CLS] token 向量</span></span><br><span class="line">            <span class="variable language_">self</span>.transformer.embeddings.cls_token.</span><br><span class="line">            copy_(np2th(weights[<span class="string">&quot;cls&quot;</span>]))  </span><br><span class="line">            <span class="comment"># 加载最后 encoder norm 层的参数</span></span><br><span class="line">            <span class="variable language_">self</span>.transformer.encoder.encoder_norm.weight.</span><br><span class="line">            copy_(np2th(weights[<span class="string">&quot;Transformer/encoder_norm/scale&quot;</span>]))  </span><br><span class="line">            <span class="variable language_">self</span>.transformer.encoder.encoder_norm.bias.</span><br><span class="line">            copy_(np2th(weights[<span class="string">&quot;Transformer/encoder_norm/bias&quot;</span>]))  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3.加载位置编码（含 resize 逻辑）</span></span><br><span class="line">            <span class="comment"># 加载位置编码</span></span><br><span class="line">            posemb = np2th(weights[<span class="string">&quot;Transformer/posembed_input/pos_embedding&quot;</span>])  </span><br><span class="line">            posemb_new = <span class="variable language_">self</span>.transformer.embeddings.position_embeddings  </span><br><span class="line">            <span class="keyword">if</span> posemb.size() == posemb_new.size():  </span><br><span class="line">                <span class="comment"># 尺寸一致，直接加载</span></span><br><span class="line">                <span class="variable language_">self</span>.transformer.embeddings.position_embeddings.copy_(posemb)  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="comment"># 若尺寸不一致，则插值 resize（一般因输入图片大小不同）</span></span><br><span class="line">                logger.info(<span class="string">&quot;load_pretrained: resized variant: %s to %s&quot;</span> % (posemb.size(), posemb_new.size()))  </span><br><span class="line">                ntok_new = posemb_new.size(<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.classifier == <span class="string">&quot;token&quot;</span>:  </span><br><span class="line">                    <span class="comment"># token 分类方式：分离 [CLS] 和 patch 部分</span></span><br><span class="line">                    posemb_tok, posemb_grid = posemb[:, :<span class="number">1</span>], posemb[<span class="number">0</span>, <span class="number">1</span>:]  </span><br><span class="line">                    ntok_new -= <span class="number">1</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    <span class="comment"># GAP 分类方式：不包含 token</span></span><br><span class="line">                    posemb_tok, posemb_grid = posemb[:, :<span class="number">0</span>], posemb[<span class="number">0</span>]  </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 原位置编码网格大小</span></span><br><span class="line">                gs_old = <span class="built_in">int</span>(np.sqrt(<span class="built_in">len</span>(posemb_grid)))  </span><br><span class="line">                gs_new = <span class="built_in">int</span>(np.sqrt(ntok_new))  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;load_pretrained: grid-size from %s to %s&#x27;</span> % (gs_old, gs_new))  </span><br><span class="line">                <span class="comment"># 将位置编码 reshape 成二维图像再缩放</span></span><br><span class="line">                posemb_grid = posemb_grid.reshape(gs_old, gs_old, -<span class="number">1</span>)  </span><br><span class="line">                zoom = (gs_new / gs_old, gs_new / gs_old, <span class="number">1</span>)  </span><br><span class="line">                posemb_grid = ndimage.zoom(posemb_grid, zoom, order=<span class="number">1</span>)  </span><br><span class="line">                posemb_grid = posemb_grid.reshape(<span class="number">1</span>, gs_new * gs_new, -<span class="number">1</span>) </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 合并 [CLS] token 和缩放后的位置编码</span></span><br><span class="line">                posemb = np.concatenate([posemb_tok, posemb_grid], axis=<span class="number">1</span>)		                 <span class="variable language_">self</span>.transformer.embeddings.position_embeddings.</span><br><span class="line">                copy_(np2th(posemb))  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4.加载 Transformer 中每一层 Block 的参数</span></span><br><span class="line">            <span class="keyword">for</span> bname, block <span class="keyword">in</span> <span class="variable language_">self</span>.transformer.encoder.named_children():  </span><br><span class="line">                <span class="keyword">for</span> uname, unit <span class="keyword">in</span> block.named_children():  </span><br><span class="line">                    unit.load_from(weights, n_block=uname)  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5.加载 hybrid CNN 模块的参数（若启用）</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.transformer.embeddings.hybrid:  </span><br><span class="line">                <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<p>结构图：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">VisionTransformer</span><br><span class="line">├── Transformer</span><br><span class="line">│   ├── Embeddings（Patch + Pos + CLS）</span><br><span class="line">│   ├── Encoder（多个 Block + LayerNorm）</span><br><span class="line">├── head（分类器）</span><br><span class="line">└── load_from（支持不同输入尺寸权重加载 + hybrid 模块加载）</span><br></pre></td></tr></table></figure>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>本文主要介绍了Vision Transformer (ViT) 的主要实现，包括：</p>
<ol>
<li>​<strong>ViT概述</strong>​：Transformer从NLP扩展到CV领域，ViT是首个在图像分类中表现优异的Transformer模型。核心思路：将图像切分为patch序列，通过Transformer处理，利用self-attention的全局建模能力替代CNN的局部感受野</li>
<li>​<strong>ViT架构</strong>​：<ul>
<li><strong>图像分块</strong>：将输入图像切分为固定大小的patch</li>
<li><strong>Patch Embedding</strong>：每个patch展平后通过线性投影得到向量表示</li>
<li><strong>位置编码</strong>：添加可学习的位置编码保留空间信息</li>
<li><strong>[CLS] Token</strong>：添加特殊token用于分类任务</li>
<li><strong>Transformer Encoder</strong>：多层自注意力机制和前馈网络堆叠</li>
</ul>
</li>
<li>​<strong>关键实现</strong>​：<ul>
<li><strong>Embedding层</strong>：处理图像分块、位置编码和CLS token</li>
<li><strong>Transformer Encoder</strong>：包含多头自注意力和MLP，使用LayerNorm和残差连接</li>
<li><strong>分类头</strong>：基于CLS token输出分类结果</li>
</ul>
</li>
</ol>
<h2 id="8-备注"><a href="#8-备注" class="headerlink" title="8.备注"></a>8.备注</h2><ul>
<li>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale : <a href="https://arxiv.org/pdf/2010.11929">https://arxiv.org/pdf/2010.11929</a></li>
<li>vision_transformer code:  <a href="https://github.com/google-research/vision_transformer">https://github.com/google-research/vision_transformer</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习 — 试错、策略与长期奖励</title>
    <url>/2025/07/14/024-reinforcement-learning-start/</url>
    <content><![CDATA[<h2 id="1-强化学习：从试错中学习策略"><a href="#1-强化学习：从试错中学习策略" class="headerlink" title="1.强化学习：从试错中学习策略"></a>1.强化学习：从试错中学习策略</h2><p>我们先从一个轻松的生活片段切入：某天夜里，小明肚子咕咕叫，他想去找点吃的，但房间漆黑一片，他不敢开灯，只能凭借记忆和感知，一步一步摸索前进，一开始他撞到了桌角，又不小心踩到了猫，猫的尖叫声还吓了他一跳（负反馈），他又调整方向，继续摸索。他记住了这个方向有桌子不能走，那个方向可能有猫，不断的修正自己的路线，最终摸到了冰箱，找到了食物（正反馈）。这就是强化学习（Reinforcement Learning, RL）核心思想的具象呈现：</p>
<blockquote>
<p>智能体在完全未知的环境中，靠“做出行为 → 接受反馈 → 调整策略”这一闭环，在不断试错中学习完成任务的最佳方式。</p>
</blockquote>
<span id="more"></span>
<p>强化学习与人的成长过程极为相似：从不懂规则的孩子，到逐步掌握做事规律的成年人，这个过程本质上就是一个持续与环境互动、在反馈中进步的过程。</p>
<h3 id="1-强化学习的四个关键特征"><a href="#1-强化学习的四个关键特征" class="headerlink" title="1.强化学习的四个关键特征"></a>1.强化学习的四个关键特征</h3><ol>
<li><strong>从“无知”到“掌握策略”</strong>：智能体起初对环境一无所知，只能通过反复尝试来摸索出完成任务</li>
<li><strong>依赖与环境的持续交互</strong>：强化学习不是“看图识字”或“记答案”，而是通过做出动作并观察环境反应来调整行为</li>
<li><strong>学习过程由试错驱动</strong>：每次尝试产生的反馈（奖励&#x2F;惩罚）构成了智能体积累经验、改进策略的基础</li>
<li><strong>学习目标导向明确，但过程探索自由</strong>：强化学习没有明确标签指引每一步行为是否正确，但整体方向是明确的：<strong>最大化长期奖励</strong></li>
</ol>
<h3 id="2-强化学习的认知类比"><a href="#2-强化学习的认知类比" class="headerlink" title="2.强化学习的认知类比"></a>2.强化学习的认知类比</h3><p>将强化学习比作孩子的成长过程，我们可以更直观地理解其学习机制。</p>
<h4 id="1-孩子的成长过程-强化学习的学习路径"><a href="#1-孩子的成长过程-强化学习的学习路径" class="headerlink" title="1. 孩子的成长过程 &#x3D; 强化学习的学习路径"></a>1. 孩子的成长过程 &#x3D; 强化学习的学习路径</h4><ul>
<li>起点：一无所知，只能试错</li>
<li>过程：与环境交互，接收反馈（如家长批评、奖励）</li>
<li>结果：总结经验、形成规则、学会做决策</li>
</ul>
<p>例如，因为考试没考好被家长批评，从中意识到“努力学习”能带来正向反馈，这种从“结果”中反推“行动价值”的学习方式，就类似强化学习。</p>
<h4 id="2-强化学习强调“先做，再评估”"><a href="#2-强化学习强调“先做，再评估”" class="headerlink" title="2. 强化学习强调“先做，再评估”"></a>2. 强化学习强调“先做，再评估”</h4><p>与监督学习中“先给出标签再预测”的范式不同，强化学习中的智能体<strong>必须先行动，才能知道结果好坏</strong>。这就导致：RL没有每步的明确标签（而是延迟奖励），就需要大量尝试来估计长期收益，这更接近真实世界中的学习方式。</p>
<h2 id="2-经典示例：飞船着陆任务"><a href="#2-经典示例：飞船着陆任务" class="headerlink" title="2.经典示例：飞船着陆任务"></a>2.经典示例：飞船着陆任务</h2><p>为了更清晰地展示强化学习的流程和目标，我们来看一个经典案例——<strong>让一艘小飞船安全着陆</strong>。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/PPO_LunarLander-v2.gif"></p>
<h3 id="1-初始阶段：行为随机、目标未知"><a href="#1-初始阶段：行为随机、目标未知" class="headerlink" title="1. 初始阶段：行为随机、目标未知"></a>1. 初始阶段：行为随机、目标未知</h3><p>飞船起初不知哪里适合降落，所有动作都是盲目的探索。</p>
<h3 id="2-设计奖励机制：用“结果”引导学习"><a href="#2-设计奖励机制：用“结果”引导学习" class="headerlink" title="2. 设计奖励机制：用“结果”引导学习"></a>2. 设计奖励机制：用“结果”引导学习</h3><p>我们为该任务设计如下奖励策略：</p>
<ul>
<li>成功着陆 → +100 分</li>
<li>偏离目标 → -50 分或 -100 分</li>
<li>每一步偏离方向 → -10 分</li>
<li>每一步朝目标靠近 → +5 或 +10 分</li>
</ul>
<p>这种既奖励结果，又鼓励过程表现的设计，有助于模型形成“通向成功的正确路径”，而不是仅仅“完成任务”即可。</p>
<h3 id="3-学习演进过程可视化"><a href="#3-学习演进过程可视化" class="headerlink" title="3. 学习演进过程可视化"></a>3. 学习演进过程可视化</h3><table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>行为特征</strong></th>
<th><strong>学习机制</strong></th>
</tr>
</thead>
<tbody><tr>
<td>初期探索</td>
<td>随机飞行，动作无规律</td>
<td>采集经验，构建基本认知</td>
</tr>
<tr>
<td>中期训练</td>
<td>初步形成策略，开始避开错误路径</td>
<td>估算每个状态下的动作价值</td>
</tr>
<tr>
<td>后期收敛</td>
<td>稳定实现目标，路径接近最优</td>
<td>策略优化完成，实现稳定任务完成</td>
</tr>
</tbody></table>
<blockquote>
<p>强化学习关注的是“长期回报”的最大化，而不是某一步骤的对错。</p>
</blockquote>
<h2 id="3-监督、无监督和强化学习"><a href="#3-监督、无监督和强化学习" class="headerlink" title="3.监督、无监督和强化学习"></a>3.监督、无监督和强化学习</h2><h3 id="1-监督学习与深度学习的关系"><a href="#1-监督学习与深度学习的关系" class="headerlink" title="1.监督学习与深度学习的关系"></a>1.监督学习与深度学习的关系</h3><p>深度学习是通过<strong>多层神经网络</strong>自动学习数据的层次化特征，而监督学习是通过<strong>已标注的数据</strong>​（输入-输出对）学习一个映射函数（模型），用于预测新数据的输出。深度学习是一种<strong>模型实现方式</strong>​（用深层神经网络），而监督学习是一个<strong>学习范式</strong>​（需要标注数据），两者属于不同维度。同样强化学习也是一种学习范式。</p>
<h3 id="2-基本定义与学习方式对比"><a href="#2-基本定义与学习方式对比" class="headerlink" title="2.基本定义与学习方式对比"></a>2.基本定义与学习方式对比</h3><table>
<thead>
<tr>
<th><strong>学习类型</strong></th>
<th><strong>定义</strong></th>
<th><strong>输入</strong></th>
<th><strong>输出</strong></th>
<th><strong>学习目标</strong></th>
<th><strong>是否需要标签</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>监督学习</strong></td>
<td>学习从输入到输出的映射关系</td>
<td>特征 + 正确标签</td>
<td>预测标签</td>
<td>拟合已知数据的输入输出映射，最小化误差</td>
<td>有标签</td>
</tr>
<tr>
<td><strong>无监督学习</strong></td>
<td>学习数据的内在结构或分布</td>
<td>仅有特征数据</td>
<td>聚类 &#x2F; 维度 &#x2F; 分布结构</td>
<td>发现数据的隐藏模式</td>
<td>无标签</td>
</tr>
<tr>
<td><strong>强化学习</strong></td>
<td>学习在环境中如何行动</td>
<td>状态（来自环境）</td>
<td>行为 &#x2F; 动作</td>
<td>最大化<strong>长期累积奖励</strong></td>
<td>无标签（但有奖励）</td>
</tr>
</tbody></table>
<h3 id="3-核心区别类比（类比为学习场景）"><a href="#3-核心区别类比（类比为学习场景）" class="headerlink" title="3.核心区别类比（类比为学习场景）"></a>3.核心区别类比（类比为学习场景）</h3><table>
<thead>
<tr>
<th><strong>学习类型</strong></th>
<th><strong>类比为人类学习方式</strong></th>
<th><strong>教学过程</strong></th>
<th><strong>是否立即得到反馈</strong></th>
<th><strong>反馈来源</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>监督学习</strong></td>
<td>老师讲题 + 提供标准答案</td>
<td>有“对错参考答案”</td>
<td>马上知道对错</td>
<td>明确标签</td>
</tr>
<tr>
<td><strong>无监督学习</strong></td>
<td>看书学习</td>
<td>没有参考答案</td>
<td>不知道对错</td>
<td>无标签，靠模式归纳</td>
</tr>
<tr>
<td><strong>强化学习</strong></td>
<td>玩游戏找通关方法</td>
<td>没人教你，只给你“通关奖励”</td>
<td>奖励可能延迟</td>
<td>环境反馈（奖励&#x2F;惩罚）</td>
</tr>
</tbody></table>
<h3 id="4-常见用途与代表任务"><a href="#4-常见用途与代表任务" class="headerlink" title="4.常见用途与代表任务"></a>4.常见用途与代表任务</h3><table>
<thead>
<tr>
<th><strong>学习类型</strong></th>
<th><strong>典型任务</strong></th>
<th><strong>常见应用</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>监督学习</strong></td>
<td>分类（图像识别）、回归（房价预测）</td>
<td>猫狗识别、人脸识别、情感分析、语音识别、自动驾驶感知模块</td>
</tr>
<tr>
<td><strong>无监督学习</strong></td>
<td>聚类（用户分群）、降维（PCA）、异常检测</td>
<td>客户画像、推荐系统、异常检测、文本建模</td>
</tr>
<tr>
<td><strong>强化学习</strong></td>
<td>决策规划、策略优化</td>
<td>游戏AI、自动驾驶控制、机器人路径规划、金融交易、智能推荐系统</td>
</tr>
</tbody></table>
<h3 id="5-训练方式与挑战差异"><a href="#5-训练方式与挑战差异" class="headerlink" title="5.训练方式与挑战差异"></a>5.训练方式与挑战差异</h3><table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>监督学习</strong></th>
<th><strong>无监督学习</strong></th>
<th><strong>强化学习</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据依赖</td>
<td>大量标注数据</td>
<td>原始数据即可</td>
<td>环境交互数据（+ 模拟器）</td>
</tr>
<tr>
<td>训练成本</td>
<td>标签标注贵</td>
<td>模型选择难</td>
<td>数据收集贵、训练不稳定</td>
</tr>
<tr>
<td>学习稳定性</td>
<td>高，能收敛</td>
<td>中，依赖算法</td>
<td>低，奖励稀疏难优化</td>
</tr>
<tr>
<td>收敛难度</td>
<td>相对较低</td>
<td>中等偏高</td>
<td>很高，尤其是在复杂环境中</td>
</tr>
<tr>
<td>反馈机制</td>
<td>有明确标签</td>
<td>无标签反馈</td>
<td>延迟奖励、靠累计经验</td>
</tr>
</tbody></table>
<h3 id="6-联系与融合趋势"><a href="#6-联系与融合趋势" class="headerlink" title="6.联系与融合趋势"></a>6.联系与融合趋势</h3><h4 id="1-联系"><a href="#1-联系" class="headerlink" title="1.联系"></a>1.联系</h4><p>三者都是“从数据中自动学习”，目标是形成<strong>泛化能力</strong>，都可以使用深度神经网络作为模型，也都可归类为<strong>机器学习范式</strong>的一种。</p>
<h4 id="2-融合趋势"><a href="#2-融合趋势" class="headerlink" title="2.融合趋势"></a>2.融合趋势</h4><ul>
<li><strong>自监督学习（Self-Supervised Learning）</strong>：介于无监督与监督之间，用数据本身生成伪标签，极大提升了大模型的训练效率（如 GPT、BERT）</li>
<li><strong>强化学习 + 监督学习</strong>：在策略学习中结合人类演示（如 AlphaGo 用专家棋谱进行初始监督学习）</li>
<li><strong>无监督预训练 + 强化学习微调</strong>：用于让智能体“先感知世界”，再进行试错学习（如视觉感知 + 决策控制）</li>
</ul>
<p>总结一下，监督学习是知道答案，目标是“学会模仿”；无监督学习是不知道答案，目标是“发现结构”；强化学习是不知道答案也没人告诉你，但你知道“通关有奖”，目标是“学会做决策”。</p>
<h2 id="4-强化学习的工作流程"><a href="#4-强化学习的工作流程" class="headerlink" title="4.强化学习的工作流程"></a>4.强化学习的工作流程</h2><h3 id="1-强化学习整体流程概览"><a href="#1-强化学习整体流程概览" class="headerlink" title="1.强化学习整体流程概览"></a>1.强化学习整体流程概览</h3><p>我们可以用一句话概括强化学习的基本框架：</p>
<blockquote>
<p><strong>Agent 在环境中观察状态，选择动作，接收奖励与下一个状态，通过不断试错学习最优策略。</strong></p>
</blockquote>
<p>其流程如下图所示：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250714114119.png"></p>
<h3 id="2-强化学习工作流程详细分解"><a href="#2-强化学习工作流程详细分解" class="headerlink" title="2.强化学习工作流程详细分解"></a>2.强化学习工作流程详细分解</h3><p>下面我们用一个标准的迭代过程来说明强化学习的完整循环过程。</p>
<h4 id="1-初始化"><a href="#1-初始化" class="headerlink" title="1. 初始化"></a>1. 初始化</h4><p>初始化智能体的策略、值函数或模型（取决于使用哪种算法），以及初始化环境，设置起始状态。</p>
<h4 id="2-循环进行交互"><a href="#2-循环进行交互" class="headerlink" title="2. 循环进行交互"></a>2. 循环进行交互</h4><h5 id="1-观察状态"><a href="#1-观察状态" class="headerlink" title="1.观察状态"></a>1.观察状态</h5><p>$s_t$: 智能体从环境中接收当前状态 $s_t$（例如游戏画面、机器人传感器读数等）。</p>
<h5 id="2-选择动作"><a href="#2-选择动作" class="headerlink" title="2.选择动作"></a>2.选择动作</h5><p>选择动作 $a_t$ 是强化学习中<strong>核心环节之一</strong>，它决定了智能体如何在当前状态 $s_t$ 下进行决策。这个决策过程由“策略（Policy）”控制，而策略可以是显式的，也可以是由神经网络隐式建模的。</p>
<h6 id="1-什么是策略-π-a-s-？"><a href="#1-什么是策略-π-a-s-？" class="headerlink" title="1.什么是策略 π(a|s)？"></a>1.什么是策略 π(a|s)？</h6><p>策略是一个函数，描述了在给定状态 $s$ 下，采取动作 $a$ 的概率：</p>
<ul>
<li><strong>确定性策略</strong>：总是选择固定动作，例如：$π(s) &#x3D; argmax Q(s, a)$</li>
<li><strong>随机性策略</strong>：为每个动作分配一个概率，例如：$π(a|s) &#x3D; 0.7$ 走左，0.3 走右</li>
</ul>
<p>策略的设计决定了<strong>智能体的“性格”</strong>：是喜欢冒险（探索），还是喜欢安稳地走老路（利用）。</p>
<h6 id="2-常见动作选择策略"><a href="#2-常见动作选择策略" class="headerlink" title="2.常见动作选择策略"></a>2.常见动作选择策略</h6><ol>
<li>ε-greedy 策略（最常见）：大部分时候选最优动作，但偶尔随机探索。</li>
</ol>
<table>
<thead>
<tr>
<th><strong>步骤</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>ε 的概率</td>
<td><strong>随机选一个动作</strong>（探索 Explore）</td>
</tr>
<tr>
<td>1 - ε 的概率</td>
<td><strong>选当前最优动作</strong>，如：$argmax Q(s, a)$</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if random() &lt; ε:</span><br><span class="line">    action = random.choice(all_actions)</span><br><span class="line">else:</span><br><span class="line">    action = argmax(Q[s])</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>优点</strong>：简单易实现，能保证探索</li>
<li><strong>缺点</strong>：探索是“盲目”的，随机选动作可能不合理</li>
<li><strong>适用场景</strong>：Q-learning、DQN 等值函数方法</li>
</ul>
<blockquote>
<p>类比：大部分时候你点最爱吃的外卖（炸鸡），但偶尔点点新菜试试（探索）</p>
</blockquote>
<ol start="2">
<li>Softmax 策略（带温度的概率选择）：将每个动作的“值”转换为概率，值越大概率越高。<br>公式如下：$P(a_i) &#x3D; \frac{\exp(Q(s, a_i)&#x2F;\tau)}{\sum_j \exp(Q(s, a_j)&#x2F;\tau)}$</li>
</ol>
<ul>
<li>$\tau$：温度参数，控制探索程度：<ul>
<li><strong>高温度</strong>（如 τ&#x3D;10）：接近均匀分布 → 更随机</li>
<li><strong>低温度</strong>（如 τ&#x3D;0.01）：接近贪婪策略 → 近似 argmax</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">probs = softmax(Q[s] / temperature)</span><br><span class="line">action = np.random.choice(actions, p=probs)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>优点</strong>：比 ε-greedy 更“智能”的探索</li>
<li><strong>缺点</strong>：参数敏感，调不好容易崩</li>
<li><strong>适用场景</strong>：策略梯度、Actor-Critic 也常用类似思想</li>
</ul>
<blockquote>
<p>类比：你喜欢炸鸡 90 分，烤肉 85 分，素食 70 分，softmax 会让你更偏向点炸鸡，但也可能点烤肉（而不是盲选素食）</p>
</blockquote>
<ol start="3">
<li>神经网络输出动作概率（策略网络&#x2F;Actor）<br>这种方式下，策略 $π(a|s)$ 由一个<strong>神经网络建模</strong>，直接输出每个动作的概率分布：</li>
</ol>
<ul>
<li>输入：状态 $s$</li>
<li>输出：动作的概率分布 $\pi(a|s; \theta)$</li>
<li>采样：根据这个概率进行抽样动作</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">probs = actor_network(state)  # 输出 [0.7, 0.2, 0.1]</span><br><span class="line">action = sample_from_distribution(probs)</span><br></pre></td></tr></table></figure>
<p>适用于策略梯度方法，如：    </p>
<ul>
<li><strong>REINFORCE</strong></li>
<li><strong>Actor-Critic</strong></li>
<li><strong>PPO（Proximal Policy Optimization）</strong></li>
</ul>
<p>优势：</p>
<ul>
<li>可以学习复杂策略（非线性映射）</li>
<li>输出连续动作时更自然（输出均值&#x2F;方差）</li>
<li>和环境反馈协同训练，端到端</li>
</ul>
<h6 id="3-三者对比总结"><a href="#3-三者对比总结" class="headerlink" title="3.三者对比总结"></a>3.三者对比总结</h6><table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>特点</strong></th>
<th><strong>适用算法</strong></th>
<th><strong>探索方式</strong></th>
</tr>
</thead>
<tbody><tr>
<td>ε-greedy</td>
<td>简单、高效</td>
<td>Q-learning、DQN</td>
<td>ε 概率随机</td>
</tr>
<tr>
<td>Softmax</td>
<td>更温和的探索方式</td>
<td>policy gradient、Dyna-Q</td>
<td>概率分布</td>
</tr>
<tr>
<td>策略网络输出</td>
<td>强表达能力，支持连续动作</td>
<td>Actor-Critic、PPO</td>
<td>神经网络建模的分布</td>
</tr>
</tbody></table>
<blockquote>
<p>动作选择策略的设计，是强化学习探索-利用权衡的核心。你是“保守派”，还是“冒险派”，看 π(a|s) 如何设定。</p>
</blockquote>
<h5 id="3-执行动作与环境交互"><a href="#3-执行动作与环境交互" class="headerlink" title="3.执行动作与环境交互"></a>3.执行动作与环境交互</h5><p>这一步就是智能体将选择好的动作 $a_t$ 真正“付诸实践”，环境也会据此作出“回应”——这正是<strong>强化学习“试错”的核心舞台</strong>。</p>
<p><strong>这一步的目的是什么?</strong><br>在时间步 $t$，智能体选定动作 $a_t$，然后将其作用于环境 $\mathcal{E}$，环境根据自己的内部状态与规则，给予智能体一个反馈：<strong>奖励</strong> $r_t$，同时更新自身并输出下一个状态：<strong>状态</strong> $s_{t+1}$。</p>
<p>用一句话概括就是：<strong>“你干了件事，环境告诉你这事干得好不好，并给你一个新的局面。”</strong></p>
<p><strong>环境做了什么事情？</strong><br>这个过程通常通过一个函数来建模：$(s_{t+1}, r_t) &#x3D; \mathcal{E}(s_t, a_t)$，也可以是概率形式：$P(s_{t+1}, r_t | s_t, a_t)$<br>说明：</p>
<ul>
<li>环境是 <strong>马尔可夫决策过程（MDP）</strong> 的一部分。</li>
<li>它根据当前状态 $s_t$ 和动作 $a_t$，<strong>决定下一个状态和奖励</strong>。</li>
<li>可以是<strong>确定的</strong>（固定结果）或<strong>随机的</strong>（环境有内在随机性）</li>
</ul>
<p><strong>奖励 $r_t$ 是什么？</strong></p>
<ol>
<li>奖励是强化学习的核心信号：它衡量动作的“好坏”，是学习的唯一指导。<ul>
<li><strong>正奖励（+）</strong>：鼓励行为，如机器人成功避开障碍</li>
<li><strong>负奖励（−）</strong>：惩罚行为，如撞墙、超时</li>
<li><strong>零奖励</strong>：无显著反馈，例如在迷宫中没走错也没走对</li>
</ul>
</li>
<li>奖励的设计极其重要（Reward Design）因为设计太“稀疏”：智能体很难学到，而奖励太“贪婪”：可能导致过拟合策略或作弊</li>
</ol>
<blockquote>
<p>类比：你玩游戏，每赢一局给你 100 分（正奖励），被打败扣你 50 分（负奖励），这就是你的激励机制。</p>
</blockquote>
<p><strong>状态 $s_{t+1}$是什么？</strong></p>
<ol>
<li>状态是描述“环境当前状况”的向量或图像，状态可以非常多样，具体取决于任务类型：</li>
</ol>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>状态例子</strong></th>
</tr>
</thead>
<tbody><tr>
<td>迷宫游戏</td>
<td>老鼠当前坐标</td>
</tr>
<tr>
<td>Atari 游戏</td>
<td>当前帧图像</td>
</tr>
<tr>
<td>棋类游戏</td>
<td>棋盘布局</td>
</tr>
<tr>
<td>自动驾驶</td>
<td>当前车速、路况、传感器信息</td>
</tr>
<tr>
<td>股票交易</td>
<td>当前价格、趋势图、技术指标</td>
</tr>
</tbody></table>
<ol start="2">
<li>状态更新反映环境的变化，动作导致环境进入新状态，智能体在下一步就要基于 $s_{t+1}$ 再次做决策，进入下一个循环。</li>
</ol>
<p><strong>具体例子演示</strong><br>游戏场景：Flappy Bird:</p>
<ol>
<li>当前状态 $s_t$：小鸟的位置、速度、管道距离</li>
<li>智能体选择动作 $a_t$：是否跳跃</li>
<li>执行动作，环境反馈：<ul>
<li>如果跳起来避过障碍，$r_t$ &#x3D; +1，新的 $s_{t+1}$ 是更新后的小鸟状态</li>
<li>如果撞墙了，$r_t &#x3D; -10$，游戏结束，done&#x3D;True</li>
</ul>
</li>
</ol>
<p><strong>这一步与训练的关系？</strong><br>这一步提供了强化学习中“经验回放”（Experience Replay）或“轨迹采样”的原始数据：<br>每一步采样一个四元组（transition）：$(s_t, a_t, r_t, s_{t+1})$<br>这些数据将存入经验池（replay buffer），供后续学习算法（如 Q-learning, DDPG, PPO）进行优化。</p>
<p><strong>常见坑：环境交互设计不合理会导致学习失败</strong></p>
<ul>
<li>奖励太稀疏：比如只在任务完成时才给分，导致训练难以进行</li>
<li>状态缺失信息：智能体感知不到重要变量</li>
<li>非马尔可夫环境：当前状态不包含未来决策所需信息（必须堆叠历史）</li>
</ul>
<blockquote>
<p>马尔可夫环境（Markov Environment）是指环境的状态转移和奖励生成过程满足马尔可夫性质（Markov Property）​，即：  <strong>​“未来只依赖于当前状态和动作，而与过去的历史无关。”​</strong>​</p>
</blockquote>
<p><strong>总结：执行动作与环境交互是 RL 的关键闭环</strong></p>
<table>
<thead>
<tr>
<th><strong>环节</strong></th>
<th><strong>解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td>执行动作 $a_t$</td>
<td>智能体“尝试”做决策</td>
</tr>
<tr>
<td>环境反馈 $r_t$</td>
<td>给智能体打分，引导方向</td>
</tr>
<tr>
<td>环境转移 $s_{t+1}$</td>
<td>带来新的局面，进入下一轮学习</td>
</tr>
</tbody></table>
<blockquote>
<p>这一步就像<strong>打怪升级的回合制游戏</strong>：你出招，世界反应，你总结经验，再迎下一轮，如此循环往复直至结束。</p>
</blockquote>
<h5 id="4-学习-更新策略"><a href="#4-学习-更新策略" class="headerlink" title="4.学习&#x2F;更新策略"></a>4.学习&#x2F;更新策略</h5><p>前面几步（观察状态、选择动作、执行动作、获取奖励）都是<strong>数据采集</strong>，而<strong>这一步是智能体真正“变聪明”的过程</strong>。它的目标是——让智能体不断改进策略 $π$，使得它未来能做出更好的动作，获得更多奖励。</p>
<h6 id="1-什么是“学习-更新策略”？"><a href="#1-什么是“学习-更新策略”？" class="headerlink" title="1.什么是“学习&#x2F;更新策略”？"></a>1.什么是“学习&#x2F;更新策略”？</h6><p>在强化学习中，智能体通过一系列经验：$(s_t, a_t, r_t, s_{t+1})$，来调整自己的内部结构（如 Q 表或神经网络权重），从而实现<strong>更准确地评估“哪个动作更好”</strong> 以及<strong>更有效地选择策略动作 π(a|s)</strong>。<br>根据不同的算法，学习目标略有不同，但都遵循一个核心理念： <strong>最大化未来累计奖励（即最大化预期回报）</strong></p>
<h6 id="2-三种常见更新方式详解"><a href="#2-三种常见更新方式详解" class="headerlink" title="2.三种常见更新方式详解"></a>2.三种常见更新方式详解</h6><ol>
<li><p>Q-Learning：基于表格的值函数方法（离策略），适用于<strong>小型离散状态空间的任务（如迷宫、简单棋盘游戏）</strong>，思路是：</p>
<ul>
<li>维护一个 Q 表，记录每个状态-动作对的预期累计奖励：<br> $Q(s, a) \approx \text{当前状态下采取该动作所获得的长期回报}$</li>
<li>通过贝尔曼方程进行更新：<br>$$Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha \cdot \left[r_t + \gamma \cdot \max_{a’} Q(s_{t+1}, a’) - Q(s_t, a_t) \right]$$<br>  其中：<ul>
<li>$\alpha$：学习率</li>
<li>$\gamma$：折扣因子，衡量未来奖励的价值</li>
<li>$r_t$：当前奖励</li>
<li>$\max Q(s_{t+1}, a’)$：估计从下一状态起最好的动作的价值</li>
</ul>
</li>
</ul>
<p> 示例代码：<br> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q[s][a] += lr * (r + gamma * max(Q[s_next]) - Q[s][a])</span><br></pre></td></tr></table></figure><br> 这种方式的优点，简单直观、好实现。缺点是不适合连续或大状态空间，Q 表会爆炸。</p>
</li>
<li><p>DQN（Deep Q-Network）：用神经网络逼近 Q 函数，适用于<strong>状态空间较大（如图像输入）、动作空间离散的任务（如 Atari 游戏）</strong>。思路是：</p>
<ul>
<li>不再用 Q 表，而用神经网络 $Q_\theta(s, a)$ 来近似 Q 函数</li>
<li>通过一批样本 ($s_t, a_t, r_t, s_{t+1}$) 构造损失函数：<br>$$\mathcal{L}(\theta) &#x3D; \left[r_t + \gamma \cdot \max_{a’} Q_{\theta^-}(s_{t+1}, a’) - Q_{\theta}(s_t, a_t)\right]^2$$<ul>
<li>通过<strong>梯度下降</strong>更新神经网络参数 $\theta$</li>
</ul>
</li>
</ul>
<p> 关键技术：</p>
<ul>
<li><strong>经验回放（Experience Replay）</strong>：打乱数据相关性，提升稳定性</li>
<li><strong>目标网络（Target Network）</strong>：使用固定参数的 Q_target 防止震荡<br> 这种方式的优点是可处理高维输入（如图像），强大，可适用于大型游戏，缺点是动作空间必须是离散的，学习不稳定，需精心设计</li>
</ul>
</li>
<li><p>PPO（Proximal Policy Optimization）：策略梯度方法（Actor-Critic）。适用于：连续动作空间、高维策略控制（如机器人控制、自然语言）。思路是：</p>
<ul>
<li>策略 $π(a|s; θ)$ 由一个神经网络建模，直接优化策略函数</li>
<li>使用优势函数（Advantage）来评估当前动作好坏：<br> $$A(s_t, a_t) &#x3D; Q(s_t, a_t) - V(s_t)$$</li>
<li>PPO 的目标函数如下（简化版）：<br>$$\mathcal{L}^{\text{PPO}} &#x3D; \mathbb{E}_t\left[\min\left(r_t(\theta) \cdot A_t, \text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon) \cdot A_t\right)\right]$$<br>  其中：<ul>
<li>$r_t(\theta) &#x3D; \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$</li>
<li>clip 是核心创新，限制更新幅度，防止策略崩坏<br> 这种方式的优点是非常稳定，适合大规模训练，支持连续动作、复用采样数据，但缺点是实现较复杂，需并行训练。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>三者总结对比：</p>
<table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>特点</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>适用任务</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Q-Learning</td>
<td>表格法</td>
<td>简单易懂</td>
<td>不适用于大状态空间</td>
<td>小型离散问题</td>
</tr>
<tr>
<td>DQN</td>
<td>深度值函数</td>
<td>处理图像等高维输入</td>
<td>动作必须离散、训练不稳定</td>
<td>Atari 游戏、图像输入任务</td>
</tr>
<tr>
<td>PPO</td>
<td>策略优化</td>
<td>稳定强大、支持连续动作</td>
<td>实现复杂、计算重</td>
<td>连续控制、机器人、NLP</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>策略更新 &#x3D; 智能体看了过去的表现（经验），然后调整自己未来的决策方式，让自己下次更聪明。</strong></p>
</blockquote>
<h4 id="3-重复步骤-2"><a href="#3-重复步骤-2" class="headerlink" title="3. 重复步骤 2"></a>3. 重复步骤 2</h4><p>重复上述过程多个回合（episode），直到收敛、训练结束或达到一定评估标准。</p>
<h4 id="4-最终输出"><a href="#4-最终输出" class="headerlink" title="4. 最终输出"></a>4. 最终输出</h4><p>得到一个训练好的策略 π*，可用于测试或部署。在实际任务中，策略可直接控制机器人、自动交易、游戏角色等。</p>
<h2 id="5-强化学习中的几个关键组件"><a href="#5-强化学习中的几个关键组件" class="headerlink" title="5.强化学习中的几个关键组件"></a>5.强化学习中的几个关键组件</h2><h3 id="1-环境（Environment）"><a href="#1-环境（Environment）" class="headerlink" title="1.环境（Environment）"></a>1.环境（Environment）</h3><p><strong>环境</strong>是智能体所“生活”的世界，它定义了任务规则、物理约束、奖励机制等。</p>
<h3 id="2-状态（State-s-）"><a href="#2-状态（State-s-）" class="headerlink" title="2.状态（State, $s$）"></a>2.状态（State, $s$）</h3><p><strong>状态</strong>是环境当前的描述，是智能体决策所依据的信息输入。状态要尽可能<strong>完整地描述当前局势</strong>，例如：</p>
<ul>
<li>图像（像素）：用于游戏或视觉任务</li>
<li>数值向量：机器人的位置、速度、传感器数值</li>
<li>离散符号：棋盘位置、标记标签等</li>
</ul>
<h3 id="3-动作（Action-a-）"><a href="#3-动作（Action-a-）" class="headerlink" title="3.动作（Action, $a$）"></a>3.动作（Action, $a$）</h3><p>智能体可采取的操作（如移动、跳跃）。</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>举例</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>离散动作</td>
<td>左、右、跳</td>
<td>用整数 ID 表示</td>
</tr>
<tr>
<td>连续动作</td>
<td>转向角、推进力</td>
<td>用向量表示，如 a &#x3D; [-0.2, 0.9]</td>
</tr>
</tbody></table>
<p>离散动作空间，用 softmax 输出概率分布。连续动作空间，用神经网络输出动作均值 + 方差，采样得到动作。</p>
<blockquote>
<p>类比：人在迷宫里选择“往东走”就是一个动作；机器人调整关节角度也是动作。</p>
</blockquote>
<h3 id="4-奖励（Reward-r-）"><a href="#4-奖励（Reward-r-）" class="headerlink" title="4.奖励（Reward, $r$）"></a>4.奖励（Reward, $r$）</h3><p><strong>奖励</strong>是环境给智能体的反馈信号，用于指示动作好坏，是强化学习学习的<strong>唯一目标信号</strong>。<br>奖励形式一般是<strong>标量数值</strong>（正数奖励，负数惩罚），通常只代表<strong>即时收益</strong>，不包含长期利益。<br>奖励设计陷阱如果太稀疏：模型学不到信息（例如：只有完成才得分），如果太容易作弊：智能体可能“投机取巧”来最大化奖励。</p>
<h3 id="5-策略（Policy-π）"><a href="#5-策略（Policy-π）" class="headerlink" title="5.策略（Policy, π）"></a>5.策略（Policy, π）</h3><p><strong>策略</strong>是智能体在给定状态下采取动作的方式，是学习的主要目标。</p>
<h4 id="1-实现方式"><a href="#1-实现方式" class="headerlink" title="1.实现方式"></a>1.实现方式</h4><ul>
<li>离散动作策略：神经网络输出 softmax 概率分布 </li>
<li>连续动作策略：输出均值 + 标准差，构建高斯分布</li>
</ul>
<h4 id="2-策略学习方法"><a href="#2-策略学习方法" class="headerlink" title="2.策略学习方法"></a>2.策略学习方法</h4><ul>
<li><strong>基于值函数</strong>：例如 ε-greedy from Q(s, a)</li>
<li><strong>直接优化策略</strong>：例如 REINFORCE、PPO</li>
</ul>
<h3 id="6-价值函数（Value-Function）"><a href="#6-价值函数（Value-Function）" class="headerlink" title="6. 价值函数（Value Function）"></a>6. 价值函数（Value Function）</h3><p><strong>价值函数</strong>衡量在某个状态（或状态-动作）下，未来可能获得的<strong>累计奖励的期望值</strong>。</p>
<h3 id="7-模型（Model）"><a href="#7-模型（Model）" class="headerlink" title="7.模型（Model）"></a>7.模型（Model）</h3><p><strong>模型</strong>是对环境动态的预测器，即预测状态转移和奖励函数。</p>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>定义与作用</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>环境 Environment</strong></td>
<td>任务运行的平台，提供状态与奖励，响应智能体行为</td>
</tr>
<tr>
<td><strong>状态 State</strong> $s$</td>
<td>当前环境的观测信息，是智能体做出决策的输入</td>
</tr>
<tr>
<td><strong>动作 Action</strong> $a$</td>
<td>智能体对环境的操作或决策，控制环境转移</td>
</tr>
<tr>
<td><strong>奖励 Reward</strong> $r$</td>
<td>表示行为好坏的反馈信号，引导学习目标</td>
</tr>
<tr>
<td><strong>策略 Policy</strong> $\pi$</td>
<td>从状态映射到动作，是智能体的“行为方式”</td>
</tr>
<tr>
<td><strong>价值函数 Value</strong></td>
<td>衡量状态或状态-动作组合的“长期价值”</td>
</tr>
<tr>
<td><strong>模型 Model</strong></td>
<td>预测环境未来的变化和反馈，用于模拟和规划</td>
</tr>
</tbody></table>
<p>强化学习就像是一个自主游戏的循环系统：<strong>环境提供舞台，奖励设定目标，状态记录局势，动作是决策，策略指引方向，价值函数评估局势，模型预测未来</strong>。它们构成了整个学习与决策的大闭环。</p>
<h2 id="6-工作流程伪代码示例"><a href="#6-工作流程伪代码示例" class="headerlink" title="6.工作流程伪代码示例"></a>6.工作流程伪代码示例</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for episode in range(num_episodes):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    done = False</span><br><span class="line"></span><br><span class="line">    while not done:</span><br><span class="line">        # 1. 根据策略选择动作</span><br><span class="line">        action = agent.select_action(state)</span><br><span class="line"></span><br><span class="line">        # 2. 执行动作，获得奖励和下一个状态</span><br><span class="line">        next_state, reward, done, info = env.step(action)</span><br><span class="line"></span><br><span class="line">        # 3. 存储经验并学习</span><br><span class="line">        agent.learn(state, action, reward, next_state, done)</span><br><span class="line"></span><br><span class="line">        # 4. 状态更新</span><br><span class="line">        state = next_state</span><br></pre></td></tr></table></figure>

<h2 id="7-举个例子：小白鼠找奶酪"><a href="#7-举个例子：小白鼠找奶酪" class="headerlink" title="7.举个例子：小白鼠找奶酪"></a>7.举个例子：小白鼠找奶酪</h2><div style="text-align:center">
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250714164216.png" width="300" />
</div>

<p>结合上面的几个关键组件举个例子，假设你是一只小老鼠，在一个迷宫中找奶酪：</p>
<ol>
<li>你看到前面有几个岔路口（状态）</li>
<li>你决定往左还是往右走（动作）</li>
<li>走了一段，你没找到奶酪，还被电了一下（奖励为负）</li>
<li>你记住这个教训，下次不再走这条路（学习策略）</li>
<li>多次尝试后，你发现一条路径总能吃到奶酪，于是你记住了（策略收敛）</li>
</ol>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><p>强化学习（RL）是让智能体通过试错与环境交互来学习最优策略的机器学习方法。其核心流程为：智能体观察环境状态→选择动作→获得奖励→更新策略，循环迭代直至收敛。<br>关键组件包括环境、状态、动作、奖励和策略。与监督学习不同，RL没有标注数据，仅依赖环境反馈的奖励信号。<br>典型算法分三类：基于价值（如Q-Learning）、基于策略（如PPO）和两者结合的Actor-Critic。<br>RL适用于游戏AI、机器人控制等序贯决策任务，但面临奖励稀疏、训练不稳定等挑战。而深度强化学习（DRL）通过神经网络处理高维状态，进一步扩展了RL的应用边界。</p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>非马尔可夫环境</tag>
        <tag>策略梯度</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习 — PPO策略优化算法</title>
    <url>/2025/07/22/025-reinforcement-learning-ppo/</url>
    <content><![CDATA[<h2 id="1-PPO-算法概述"><a href="#1-PPO-算法概述" class="headerlink" title="1.PPO 算法概述"></a>1.PPO 算法概述</h2><h3 id="1-PPO-的提出背景"><a href="#1-PPO-的提出背景" class="headerlink" title="1.PPO 的提出背景"></a>1.PPO 的提出背景</h3><p>我们还是以智能体如何控制飞船落地的小游戏为例，智能体的目标是通过一系列操作（如向左移动或向右移动）实现平稳着陆。在训练初期，智能体并不知道应该如何操作，它需要通过反复的试探操作，从环境中不断获得反馈并调整策略，最终掌握一套“高奖励”操作方式。</p>
<span id="more"></span>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/PPO_LunarLander-v2.gif"><br>虽然游戏过程在视觉上看起来非常快速，但实际上每一步都包含了大量计算与判断，比如，当前所处位置（状态）；当前可执行的动作；作执行后的环境反馈；下一步动作的选择。</p>
<h4 id="1-策略优化"><a href="#1-策略优化" class="headerlink" title="1.策略优化"></a>1.策略优化</h4><p>这些操作正是强化学习（Reinforcement Learning, RL）中<strong>策略优化</strong>需要解决的问题，即通过训练不断<strong>调整策略参数</strong>，使得智能体在与环境交互中获得的<strong>长期累积奖励最大化</strong>。<br>策略优化的基本流程：</p>
<ol>
<li>初始化策略 $πθ$</li>
<li>与环境交互，收集轨迹（状态-动作-奖励序列）</li>
<li>评估当前策略的表现（如回报或优势值）</li>
<li>根据表现更新策略参数 $θ$</li>
<li>重复步骤 2~4，直到收敛</li>
</ol>
<h4 id="2-常见的策略优化方法"><a href="#2-常见的策略优化方法" class="headerlink" title="2.常见的策略优化方法"></a>2.常见的策略优化方法</h4><table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>简介</strong></th>
<th><strong>问题</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>REINFORCE</strong> (Policy Gradient, 1992)</td>
<td>最基本的策略梯度算法，通过采样轨迹直接优化策略期望收益</td>
<td>高方差、收敛慢</td>
</tr>
<tr>
<td><strong>Actor-Critic (A2C&#x2F;A3C)</strong></td>
<td>使用一个 Critic 网络评估当前策略，减少 REINFORCE 的方差</td>
<td>依然可能导致策略不稳定、易陷入局部最优</td>
</tr>
<tr>
<td><strong>Trust Region Policy Optimization (TRPO)</strong> (2015)</td>
<td>引入信赖域约束，通过限制新旧策略 KL 散度，稳定策略更新</td>
<td>数学推导复杂，实际实现困难，约束不易控制</td>
</tr>
<tr>
<td><strong>PPO (2017)</strong></td>
<td>使用剪切目标函数（clip objective）近似信赖域，保持 TRPO 的稳定性优势，同时实现更简单高效的更新</td>
<td><br><br><br></td>
</tr>
</tbody></table>
<p><strong>TRPO（Trust Region Policy Optimization）</strong> 是第一个明确提出“策略更新不能太大”的强化学习方法。它通过约束策略之间的 KL 散度来控制新旧策略之间的距离，使训练更稳定。但还有如下问题：</p>
<ul>
<li>需要进行二阶优化（如共轭梯度法）计算 Fisher 信息矩阵，复杂且效率低。</li>
<li>实际应用中，不容易调节 KL 散度阈值，易导致过拟合或崩溃。</li>
</ul>
<p><strong>PPO（Proximal Policy Optimization）</strong> 正是为了解决 TRPO 的工程复杂性和策略优化的稳定性问题而提出的，目标是在<strong>保持 TRPO 稳定性的同时简化实现和提高效率</strong>。即可以不断试探 —— 收集经验 —— 调整策略，让策略更可能选择“能拿高奖励的动作”。</p>
<h3 id="2-强化学习中的基本要素"><a href="#2-强化学习中的基本要素" class="headerlink" title="2.强化学习中的基本要素"></a>2.强化学习中的基本要素</h3><h4 id="1-原始五要素"><a href="#1-原始五要素" class="headerlink" title="1.原始五要素"></a>1.原始五要素</h4><p>要理解 PPO 首先还要再熟悉一下强化学习框架中的五个基本要素，这源自经典马尔可夫决策过程（MDP）的定义，它们一起共同组成了<strong>基本强化学习交互系统</strong>。</p>
<ol>
<li><strong>智能体（Agent）</strong>：决策者。负责观察环境状态，基于当前策略选择动作。在 PPO 中，智能体由一个策略网络（通常是神经网络）表示，通过优化它的参数 $θ$ 来提升表现。</li>
<li><strong>环境（Environment）</strong>：智能体所处的世界，它接收智能体的动作，并返回新的状态和奖励。在 PPO 中，环境通常由 Gym 或 Unity ML 等平台提供。<br> <strong>作用</strong>：<ul>
<li>根据动作决定下一状态 $s_{t+1}$</li>
<li>给出即时奖励 $r_t$</li>
<li>判断是否结束一轮游戏（done）</li>
</ul>
</li>
<li><strong>状态（State, $s_t$）</strong>：环境在某一时刻的观察值。它反映了当前的环境信息。在 PPO 中，状态作为策略网络的输入，用来决定当前应采取的动作。<br> <strong>举例</strong>：<ul>
<li>棋盘的当前布局</li>
<li>游戏中小人的位置、速度、血量</li>
<li>自动驾驶中摄像头或雷达的观测数据</li>
</ul>
</li>
<li><strong>动作（Action, $a_t$）</strong>：智能体在状态 $s_t$ 下可以选择的行为。在 PPO 中，策略网络输出的是一个概率分布 $\pi_\theta(a|s)$，训练中通过采样 $a_t \sim \pi_\theta(\cdot|s_t)$决定行为，动作影响后续状态与奖励，因此是优化的核心变量。<br> <strong>两种类型</strong>：<ul>
<li>离散动作：如“向左&#x2F;右移动”、“跳跃”</li>
<li>连续动作：如“车速 &#x3D; 0.8”，“关节角度 &#x3D; 35°”</li>
</ul>
</li>
<li><strong>奖励（Reward, $r_t$）</strong>：环境对智能体行为的反馈。奖励的累积值衡量策略的好坏。在 PPO 中，奖励用来估计“优势函数” $A_t$，决定某个动作比平均行为好多少，从而更新策略。<br> <strong>举例</strong>：<ul>
<li>玩游戏得分 +1</li>
<li>棋局胜利奖励 +10</li>
<li>撞墙或掉入坑中给予负奖励 -1</li>
</ul>
</li>
</ol>
<h4 id="2-算法增强要素"><a href="#2-算法增强要素" class="headerlink" title="2.算法增强要素"></a>2.算法增强要素</h4><p>在实际强化学习算法（如 PPO）中，会<strong>引入两个额外要素</strong>（<strong>策略</strong>和<strong>回报与价值函数</strong>），用来辅助或实现优化目标，这两个是<strong>算法层面引入的学习结构</strong>，在现代 RL 中非常关键，尤其是在 PPO、A2C 等基于策略梯度的方法中。</p>
<ol>
<li><strong>策略（Policy, $\pi(a|s)$）</strong>：智能体选择动作的行为准则。可能是确定性的，也可能是概率性的。在 PPO 中，策略是可微的神经网络：$\pi_\theta(a|s)$。PPO 的目标是通过“剪切目标函数”更新策略，使其选择更优动作但又不剧烈偏移</li>
<li><strong>回报与价值函数（Return,$R_t$; Value Function）</strong>：回报 $R_t$，从时刻 t 开始未来累计奖励（可折扣），价值函数，某个动作相比平均行为好多少。在 PPO 中，价值函数用于构造优化目标，一般会结合 GAE（Generalized Advantage Estimation）进行平滑估计。</li>
</ol>
<h4 id="3-交互流程"><a href="#3-交互流程" class="headerlink" title="3.交互流程"></a>3.交互流程</h4><p>状态 $s_t$ → 策略 $πθ$ → 采样动作 $a_t$ → 交互环境 → 得到 $r_t$ 和 $s_{t+1}$ → 存储轨迹 → 策略更新</p>
<p>强化学习的核心是<strong>一个智能体根据策略与环境互动，在状态下选择动作、获得奖励，并用这些经验不断优化策略</strong>。而PPO 等策略优化算法正是这种优化过程中的关键方法。</p>
<h3 id="3-PPO-的核心任务与设计理念"><a href="#3-PPO-的核心任务与设计理念" class="headerlink" title="3.PPO 的核心任务与设计理念"></a>3.PPO 的核心任务与设计理念</h3><h4 id="1-核心任务"><a href="#1-核心任务" class="headerlink" title="1.核心任务"></a>1.核心任务</h4><p>PPO 属于<strong>策略优化类</strong>强化学习算法，其核心任务是：在智能体与环境的交互中，通过采样获得的经验轨迹，<strong>不断更新策略函数 πθ，使其输出更优的动作选择概率分布，从而最大化长期累积奖励。</strong><br>这意味着 PPO 的目标是实现：</p>
<ul>
<li><strong>策略更新要有方向感</strong> → 即优化方向要对</li>
<li><strong>策略更新不能太激进</strong> → 防止训练发散或性能崩塌</li>
<li><strong>策略更新还要高效</strong> → 能在大规模神经网络下快速迭代</li>
</ul>
<h4 id="2-设计理念"><a href="#2-设计理念" class="headerlink" title="2.设计理念"></a>2.设计理念</h4><p>PPO 的提出，是对早期策略梯度方法的<strong>一系列关键性改进与简化</strong>。它的设计理念可以归结为以下三点：</p>
<h5 id="1-稳定策略更新：不要走太远"><a href="#1-稳定策略更新：不要走太远" class="headerlink" title="1.稳定策略更新：不要走太远"></a>1.稳定策略更新：不要走太远</h5><p>在早期策略优化中（如 REINFORCE、A2C），策略每次更新都可能偏离旧策略太远，导致性能不稳定或策略崩溃。<br><strong>PPO 的理念</strong>：学习应该“靠近旧策略附近”，<strong>防止策略剧烈变化</strong>。这是对 TRPO “信赖域”思想的继承。</p>
<ul>
<li>PPO 不使用复杂的二阶优化和 KL 约束</li>
<li>而是引入 <strong>Clip 策略比值函数</strong>，控制策略更新的幅度</li>
</ul>
<p><strong>核心思想：限制策略比值的范围</strong> $r_t &#x3D; \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$ <strong>不要偏离 1 太多</strong></p>
<h5 id="2-设计剪切目标函数：软约束代替硬约束"><a href="#2-设计剪切目标函数：软约束代替硬约束" class="headerlink" title="2.设计剪切目标函数：软约束代替硬约束"></a>2.设计剪切目标函数：软约束代替硬约束</h5><p>PPO 用如下的目标函数来近似信赖域的思想：<br>$$L^{\text{CLIP}}(\theta) &#x3D; \mathbb{E}_t \left[ \min\left(r_t(\theta) \hat{A}_t,; \text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon) \cdot \hat{A}_t\right) \right]$$<br>其中：</p>
<ul>
<li>$r_t(\theta) &#x3D; \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$：其中$\pi_\theta(a_t|s_t)$ 表示当前的新策略概率。 其中$\pi_{\theta_{old}}(a_t|s_t)$ 表示旧策略的概率（用来收集数据）。整体表示随着策略参数$\theta$的改变，新策略选这个动作的概率，相比旧策略高了多少，如果 $r_t$ &#x3D; 1.2，新策略更偏爱这个动作，如果 $r_t$ &#x3D; 0.7，新策略则不喜欢这个动作</li>
<li>$\hat{A}_t$：优势函数（动作好坏的估计），表示这个动作比平均水平好多少；$\hat{A}_t$ &gt; 0：这是一个“好动作”，我们希望新策略更倾向它。$\hat{A}_t$ &lt; 0：这是“坏动作”，我们希望新策略更少选它</li>
<li>$\epsilon$：限制更新幅度的一小常数，通常设为 0.1 或 0.2</li>
<li>$\text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon)$：如果 $r_t(\theta)$ 落在 $[1 - \epsilon, 1 + \epsilon]$，就不变；如果超过了，就限制到边界上；这就像给更新加了“保险绳”，<strong>不要一次跳太远</strong>，比如新策略一下把概率提高太多，反而不稳定</li>
<li>$\min\left( r_t(\theta)\hat{A}_t,\ \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \cdot \hat{A}_t \right)$ 表达的是一个 <strong>保守策略</strong>：如果没有超过边界，我们就正常优化；如果超过边界，我们就用“剪切后的版本”替代；哪个小用哪个，从而防止策略过度更新</li>
</ul>
<p>举个简单例子，假设，优势函数 $\hat{A}_t$ &#x3D; 5，旧策略选某动作概率是 0.2，新策略更新后变成 0.4，那么$r_t$ &#x3D; 0.4 &#x2F; 0.2 &#x3D; 2.0，设置 $\epsilon$ &#x3D; 0.2，则 clip 后为 1.2，计算得到：$min(2.0<em>5, 1.2</em>5)$ &#x3D; 6。</p>
<p>当策略改变幅度适中时按正常梯度优化；当策略改变太大（超出剪切阈值）时抑制过度优化，截断回报。<strong>这就是 PPO 名称中 “Proximal”（邻近）的含义</strong>：策略的变化始终控制在邻近区域，防止训练不稳定。</p>
<h5 id="3-简洁实用：适配现代深度学习系统"><a href="#3-简洁实用：适配现代深度学习系统" class="headerlink" title="3.简洁实用：适配现代深度学习系统"></a>3.简洁实用：适配现代深度学习系统</h5><p>PPO 在设计上强调“工程上好用”，这也是它能在工业界广泛落地的关键：</p>
<table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>TRPO</strong></th>
<th><strong>PPO</strong></th>
</tr>
</thead>
<tbody><tr>
<td>使用的优化器</td>
<td>共轭梯度法（二阶优化）</td>
<td>任意一阶优化器（Adam 等）</td>
</tr>
<tr>
<td>是否需要 KL 约束</td>
<td>是，显式添加 KL 散度限制</td>
<td>否，使用剪切函数近似控制</td>
</tr>
<tr>
<td>代码复杂度</td>
<td>高，难以调参</td>
<td>低，容易调试</td>
</tr>
<tr>
<td>样本效率</td>
<td>高</td>
<td>较高</td>
</tr>
<tr>
<td>稳定性</td>
<td>高</td>
<td>稳定且高效</td>
</tr>
</tbody></table>
<p>PPO 被称为“TRPO 的近似简化版”，但其实际表现往往与甚至超过 TRPO。</p>
<h5 id="4-PPO-的整体目标函数"><a href="#4-PPO-的整体目标函数" class="headerlink" title="4.PPO 的整体目标函数"></a>4.PPO 的整体目标函数</h5><p>PPO 的实际损失函数通常包括三项：<br>$$L^{\text{PPO}}(\theta) &#x3D; \mathbb{E}_t \left[ L^{\text{CLIP}}_t(\theta) - c_1 \cdot \text{VF Loss}_t + c_2 \cdot \text{Entropy Bonus}_t \right]$$</p>
<ul>
<li>$L^{\text{CLIP}}_t(\theta)$：剪切后的策略优化目标（核心）</li>
<li>$VF Loss$：值函数损失（用于训练 Critic）</li>
<li>$Entropy Bonus$：鼓励策略的探索性（增加随机性）</li>
</ul>
<p>这体现了 PPO 的三个核心关注点：</p>
<ol>
<li><strong>优化策略但别太过火</strong></li>
<li><strong>训练 Critic 提高估值准确性</strong></li>
<li><strong>鼓励探索避免陷入局部最优</strong></li>
</ol>
<p>PPO 的核心任务是<strong>稳定高效地优化策略函数</strong>，其设计理念是在保持性能提升的同时，通过“剪切目标函数”防止策略剧烈变化，从而实现训练过程中的稳健性、可控性与实用性。</p>
<h2 id="2-PPO-策略网络与环境交互"><a href="#2-PPO-策略网络与环境交互" class="headerlink" title="2.PPO 策略网络与环境交互"></a>2.PPO 策略网络与环境交互</h2><p>在 PPO算法中，策略网络的核心任务是通过与环境的持续交互，从状态中提取信息，采样动作，并依据经验数据不断优化策略。下面我们围绕“智能体如何感知、决策与收集经验”这条主线，分三部分：</p>
<h3 id="1-状态、动作与策略网络建模"><a href="#1-状态、动作与策略网络建模" class="headerlink" title="1.状态、动作与策略网络建模"></a>1.状态、动作与策略网络建模</h3><p>策略优化的前提是智能体必须能够<strong>准确理解当前所处的状态，并基于状态做出合理的动作决策</strong>。下面说说在 PPO 中，如何建模状态、动作以及策略网络，构建整个感知——决策链路。</p>
<h4 id="1-状态空间（State-Space）"><a href="#1-状态空间（State-Space）" class="headerlink" title="1.状态空间（State Space）"></a>1.状态空间（State Space）</h4><p><strong>状态</strong>是智能体感知环境的输入，是决策的基础。在不同的任务中，状态可以是：</p>
<table>
<thead>
<tr>
<th><strong>任务类型</strong></th>
<th><strong>状态示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>经典控制</td>
<td>位置、速度、角度等数值数组（如 CartPole 的 4 维向量）</td>
</tr>
<tr>
<td>棋类游戏</td>
<td>当前棋盘的二维数组或编码</td>
</tr>
<tr>
<td>图像输入</td>
<td>原始像素矩阵（如 RGB 图像）</td>
</tr>
<tr>
<td>自定义环境</td>
<td>环境描述符、特征向量、传感器数据等</td>
</tr>
</tbody></table>
<p>在 PPO 中，我们通常将状态 $s$ 作为一个<strong>固定维度的向量输入策略网络</strong>，以便网络进行前向传播和策略输出。</p>
<h4 id="2-动作空间（Action-Space）"><a href="#2-动作空间（Action-Space）" class="headerlink" title="2.动作空间（Action Space）"></a>2.动作空间（Action Space）</h4><p>动作定义了智能体可以对环境采取的行为，其建模方式取决于环境类型：</p>
<h5 id="1-离散动作空间（Discrete）"><a href="#1-离散动作空间（Discrete）" class="headerlink" title="1. 离散动作空间（Discrete）"></a><strong>1. 离散动作空间（Discrete）</strong></h5><ul>
<li>例如：飞船落地case中动作只有两个（左或右）</li>
<li>PPO 中策略网络最后输出一组 <strong>softmax 概率分布</strong>，对所有可能动作进行建模</li>
<li>示例输出：$\pi_\theta(a|s)$ &#x3D; [0.4, 0.6]，表示选择动作 1 的概率为 60%</li>
</ul>
<h5 id="2-连续动作空间（Continuous）"><a href="#2-连续动作空间（Continuous）" class="headerlink" title="2.连续动作空间（Continuous）"></a><strong>2.连续动作空间（Continuous）</strong></h5><ul>
<li>例如：机器人控制中的加速度、关节角度等</li>
<li>PPO 中策略网络不直接输出动作，而是输出<strong>动作分布的参数</strong><ul>
<li>常见方式是：输出一个<strong>均值向量 μ 和对数标准差 logσ</strong></li>
<li>动作从该分布中采样：$a \sim \mathcal{N}(\mu, \sigma)$</li>
</ul>
</li>
<li>这种设计允许策略保持随机性，且便于求导</li>
</ul>
<h4 id="3-策略网络建模（Policy-Network）"><a href="#3-策略网络建模（Policy-Network）" class="headerlink" title="3.策略网络建模（Policy Network）"></a>3.策略网络建模（Policy Network）</h4><p>策略网络是 PPO 的核心部分，它是一个参数化函数 $\pi_\theta(a|s)$，用于对给定状态生成动作概率分布。</p>
<p><strong>PPO 中策略网络常用结构如下：</strong></p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>结构示意</strong></th>
<th><strong>应用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td>MLP（多层感知机）</td>
<td>state → Linear → ReLU → Linear → Softmax</td>
<td>状态为向量型任务，如控制类环境</td>
</tr>
<tr>
<td>CNN（卷积网络）</td>
<td>image → Conv → Pool → Flatten → Linear → Softmax</td>
<td>状态为图像，如 Atari 游戏</td>
</tr>
<tr>
<td>Actor-Critic 共用前缀</td>
<td>shared → actor head &#x2F; critic head</td>
<td>提高参数共享与训练效率</td>
</tr>
</tbody></table>
<p>PPO 通常采用 <strong>Actor-Critic 框架</strong>，即：</p>
<ul>
<li><strong>Actor 网络</strong>：策略网络 $\pi_\theta$，主要是根据当前状态 s 生成动作 a 的概率分布</li>
<li><strong>Critic 网络</strong>：值函数估计器 $V_\phi(s)$，用于估计当前状态的“好坏”，即预期的累计回报</li>
</ul>
<p>有时两者共享前几层网络，只在最后分出两个输出头（Head），分别输出动作分布参数与状态值。</p>
<h4 id="4-模型建模的关键要点"><a href="#4-模型建模的关键要点" class="headerlink" title="4.模型建模的关键要点"></a>4.模型建模的关键要点</h4><table>
<thead>
<tr>
<th><strong>模块</strong></th>
<th><strong>建模技巧</strong></th>
</tr>
</thead>
<tbody><tr>
<td>输入归一化</td>
<td>状态输入需归一化到相似尺度（如 [0, 1] 或 [-1, 1]）以稳定训练</td>
</tr>
<tr>
<td>输出处理</td>
<td>离散动作需加 softmax，连续动作需生成正态分布参数</td>
</tr>
<tr>
<td>初始化</td>
<td>用适当权重初始化策略输出层（如小权重、防止初期策略过于确定）</td>
</tr>
<tr>
<td>探索性</td>
<td>PPO 天然支持随机策略，但也可在输出中控制熵（entropy）来增强探索</td>
</tr>
</tbody></table>
<h4 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h4><p>PPO 中策略建模的三大核心：</p>
<ol>
<li><strong>状态建模</strong>：将环境状态编码为数值向量，作为策略网络输入</li>
<li><strong>动作建模</strong>：依据任务类型，输出动作概率分布或动作分布参数</li>
<li><strong>策略网络结构</strong>：采用深度神经网络建模 $\pi_\theta$，支持高维输入与复杂策略表达</li>
</ol>
<p>通过这套建模体系，PPO 的智能体才能在环境中感知状态、做出行动，并基于经验不断优化策略，实现强化学习的核心目标。</p>
<h3 id="2-游戏生命周期与轨迹采样"><a href="#2-游戏生命周期与轨迹采样" class="headerlink" title="2.游戏生命周期与轨迹采样"></a>2.游戏生命周期与轨迹采样</h3><p>在强化学习中，智能体的学习是建立在与环境反复交互所产生的“经验轨迹”之上的。下面介绍下PPO 中一个 episode（游戏生命周期）的全过程，以及如何通过与环境交互<strong>采样轨迹数据用于策略优化</strong>的。</p>
<h4 id="1-游戏生命周期（Episode-Lifecycle）"><a href="#1-游戏生命周期（Episode-Lifecycle）" class="headerlink" title="1.游戏生命周期（Episode Lifecycle）"></a>1.游戏生命周期（Episode Lifecycle）</h4><p>在 PPO 中，每一次与环境完整交互的过程称为一个 <strong>episode</strong>，也可以理解为一局“游戏”。每一局游戏的生命周期如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始化环境</span><br><span class="line">↓</span><br><span class="line">得到初始状态 s₀</span><br><span class="line">↓</span><br><span class="line">循环：</span><br><span class="line">    根据策略 πθ(s_t) 采样动作 a_t</span><br><span class="line">    环境执行动作，返回奖励 r_t 和新状态 s_&#123;t+1&#125;</span><br><span class="line">    存储 (s_t, a_t, r_t, s_&#123;t+1&#125;, done)</span><br><span class="line">    如果 done=True，终止 episode</span><br><span class="line">↓</span><br><span class="line">一轮结束</span><br></pre></td></tr></table></figure>
<p>这一过程体现了 RL 的核心闭环：<strong>状态 → 动作 → 奖励 + 新状态 → 再决策</strong>。</p>
<h4 id="2-轨迹与经验采样"><a href="#2-轨迹与经验采样" class="headerlink" title="2.轨迹与经验采样"></a>2.轨迹与经验采样</h4><p>PPO 是一种<strong>on-policy 策略梯度算法</strong>，它依赖于当前策略下采样的<strong>真实轨迹数据</strong>进行优化。因此，轨迹采样的质量直接影响训练效果。</p>
<h5 id="1-什么是轨迹（Trajectory）？"><a href="#1-什么是轨迹（Trajectory）？" class="headerlink" title="1.什么是轨迹（Trajectory）？"></a>1.什么是轨迹（Trajectory）？</h5><p>轨迹 τ​表示智能体与环境的一次完整交互序列，包含状态、动作、奖励三元组，一条轨迹通常表示为：$\tau &#x3D; { (s_0, a_0, r_0), (s_1, a_1, r_1), \dots, (s_T, a_T, r_T)}$<br>如果策略是随机的，轨迹本质上是从策略分布中采样得到的一条路径：$\tau \sim \pi_\theta$<br>概念：</p>
<ul>
<li>​<strong>初始 (s0​,a0​,r0​)​</strong>​：由环境初始化，策略选择第一个动作，环境返回第一个奖励</li>
<li><strong>终止 (sT​,aT​,rT​)</strong>：最后一个有效状态，可能影响最终奖励，之后环境终止</li>
</ul>
<p>轨迹是强化学习的<strong>核心数据单元</strong>，其质量直接影响训练效果。PPO 等 on-policy 算法尤其依赖<strong>当前策略采样的新鲜轨迹</strong>进行优化。</p>
<h5 id="2-PPO-中采样轨迹的目的"><a href="#2-PPO-中采样轨迹的目的" class="headerlink" title="2.PPO 中采样轨迹的目的"></a>2.PPO 中采样轨迹的目的</h5><p>采样轨迹（Trajectories）的核心目的是为策略优化提供<strong>真实交互数据</strong>，确保策略更新的<strong>稳定性</strong>和<strong>高效性</strong>。<br>采样的轨迹数据用于以下关键计算：</p>
<ul>
<li><strong>优势函数</strong> $\hat{A}_t$ ：动作好坏的估计。动作的惊喜程度（实际分 vs 预期分）</li>
<li><strong>目标值函数</strong> $\hat{V}_t$ 或 $R_t$：$\hat{V}_t$预测当前状态$st$​的<strong>未来总得分期望值</strong>(预测)，$R_t$实际从$st$​开始到结束的真实总得分（真实结果）。预期分 vs 真实分</li>
<li><strong>策略旧概率</strong> $\pi_{\theta_{\text{old}}}(a_t|s_t)$，用于构造剪切比值，记录<strong>更新策略前</strong>，在$st$​状态下选择$at$​的原始概率。更新策略时的”安全带”，防止AI瞎改</li>
</ul>
<h5 id="3-轨迹采样中的细节设计"><a href="#3-轨迹采样中的细节设计" class="headerlink" title="3.轨迹采样中的细节设计"></a>3.轨迹采样中的细节设计</h5><p>在 PPO 中，为了增强训练稳定性和样本利用效率，轨迹采样有以下几个常见设计点：</p>
<ul>
<li><strong>多环境并行采样</strong>：使用多个环境实例（如 vectorized Gym）同时生成轨迹，提高样本效率</li>
<li><strong>固定步长而非固定局数</strong>：PPO 通常采样固定步数（如 2048 步），不管中间 episode 是否终止</li>
<li><strong>状态标准化</strong>：对状态输入进行归一化处理，保持数值稳定</li>
<li><strong>记录旧策略概率</strong>：每一步记录旧策略下的动作概率，用于后续剪切目标计算</li>
<li><strong>缓存格式</strong>：使用 RolloutBuffer 等结构缓存状态、动作、奖励、done、log_prob、value 等信息</li>
</ul>
<p>智能体通过当前策略网络与环境反复交互，采样轨迹；利用采样数据估计策略梯度与值函数误差；进而优化策略网络，实现强化学习闭环。</p>
<h3 id="3-数据采集流程与交互代码示例"><a href="#3-数据采集流程与交互代码示例" class="headerlink" title="3.数据采集流程与交互代码示例"></a>3.数据采集流程与交互代码示例</h3><p>在 PPO 中，数据采集是策略优化的第一步。通过策略网络与环境的交互，采集大量高质量的状态-动作-奖励轨迹，是后续学习曲线收敛的关键。</p>
<p>一个完整的数据采样流程，通常包括以下核心步骤：</p>
<ol>
<li>初始化环境与策略网络</li>
<li>在当前策略下循环交互：<ul>
<li>根据状态 $s_t$，用策略网络输出动作 $a_t$</li>
<li>用该动作与环境交互，获得 $r_t$, $s_{t+1}$, done</li>
<li>将交互信息缓存至采样缓冲区</li>
</ul>
</li>
<li>重复以上过程直到采样足够时间步（如 2048）</li>
<li>结束本轮采样，开始策略优化阶段</li>
</ol>
<h4 id="1-采样结构设计：Rollout-Buffer"><a href="#1-采样结构设计：Rollout-Buffer" class="headerlink" title="1.采样结构设计：Rollout Buffer"></a>1.采样结构设计：Rollout Buffer</h4><p>为了高效组织采样的数据，我们通常使用一个数据结构 —— <strong>Rollout Buffer</strong>，用于存储每一轮采样的经验。<br><strong>典型缓存字段包括：</strong></p>
<ul>
<li>states：状态序列</li>
<li>actions：动作序列</li>
<li>rewards：即时奖励</li>
<li>dones：是否终止标志</li>
<li>log_probs：旧策略的动作概率（用于 Clip 比值）</li>
<li>values：值函数预测（用于计算优势）</li>
<li>next_states（可选）：用于 TD 估计</li>
</ul>
<h4 id="2-PyTorch-Gym-环境下的数据采样代码示例"><a href="#2-PyTorch-Gym-环境下的数据采样代码示例" class="headerlink" title="2.PyTorch + Gym 环境下的数据采样代码示例"></a>2.PyTorch + Gym 环境下的数据采样代码示例</h4><p>以下是一个简化的 PPO 数据采样代码流程，支持离散动作环境（如 CartPole）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RolloutBuffer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.clear()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clear</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.states, <span class="variable language_">self</span>.actions, <span class="variable language_">self</span>.rewards = [], [], []</span><br><span class="line">        <span class="variable language_">self</span>.dones, <span class="variable language_">self</span>.log_probs, <span class="variable language_">self</span>.values = [], [], []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, state, action, reward, done, log_prob, value</span>):</span><br><span class="line">        <span class="variable language_">self</span>.states.append(state)</span><br><span class="line">        <span class="variable language_">self</span>.actions.append(action)</span><br><span class="line">        <span class="variable language_">self</span>.rewards.append(reward)</span><br><span class="line">        <span class="variable language_">self</span>.dones.append(done)</span><br><span class="line">        <span class="variable language_">self</span>.log_probs.append(log_prob)</span><br><span class="line">        <span class="variable language_">self</span>.values.append(value)</span><br></pre></td></tr></table></figure>
<p>策略与环境交互采样过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collect_trajectories</span>(<span class="params">env, policy, buffer, rollout_steps</span>):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rollout_steps):</span><br><span class="line">        state_tensor = torch.FloatTensor(state).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 策略网络输出动作分布</span></span><br><span class="line">        dist, value = policy(state_tensor)</span><br><span class="line">        action = dist.sample()</span><br><span class="line">        log_prob = dist.log_prob(action)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 与环境交互</span></span><br><span class="line">        next_state, reward, done, _ = env.step(action.item())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 存储经验</span></span><br><span class="line">        buffer.add(state, action.item(), reward, done, log_prob.item(), value.item())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 状态更新</span></span><br><span class="line">        state = next_state <span class="keyword">if</span> <span class="keyword">not</span> done <span class="keyword">else</span> env.reset()</span><br></pre></td></tr></table></figure>
<h4 id="3-一些细节"><a href="#3-一些细节" class="headerlink" title="3.一些细节"></a>3.一些细节</h4><table>
<thead>
<tr>
<th><strong>点位</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>保持策略随机性</td>
<td>必须使用 sample() 而非 argmax，以保证策略梯度的可导性</td>
</tr>
<tr>
<td>记录 log_prob</td>
<td>是 PPO 中 $r_t &#x3D; π_θ(a_t)$</td>
</tr>
<tr>
<td>环境重置</td>
<td>遇到 done&#x3D;True 时应立即 env.reset()，否则状态将失效</td>
</tr>
<tr>
<td>状态归一化（可选）</td>
<td>统一状态维度、缩放数值区间，提高训练稳定性</td>
</tr>
<tr>
<td>采样步数设定</td>
<td>PPO 通常使用固定步数采样（如 2048）而非固定局数</td>
</tr>
</tbody></table>
<h2 id="3-PPO-的优化目标与策略梯度"><a href="#3-PPO-的优化目标与策略梯度" class="headerlink" title="3.PPO 的优化目标与策略梯度"></a>3.PPO 的优化目标与策略梯度</h2><p>在强化学习中，智能体的学习核心是<strong>策略优化</strong>，而策略优化的本质就是不断提升策略网络参数，使其在与环境的交互中获得更高的长期回报。本章将系统梳理强化学习中的优化目标，以及如何通过<strong>策略梯度方法</strong>实现对策略的可导性学习</p>
<h3 id="1-强化学习的目标函数定义"><a href="#1-强化学习的目标函数定义" class="headerlink" title="1.强化学习的目标函数定义"></a>1.强化学习的目标函数定义</h3><p>在RL中，智能体的目标并不是像监督学习那样最小化某个损失函数，而是<strong>最大化从环境中获得的长期累计奖励</strong>。下面将从基本原理出发，系统地推导并解释强化学习中策略优化的目标函数形式。</p>
<h4 id="1-策略优化的本质目标"><a href="#1-策略优化的本质目标" class="headerlink" title="1.策略优化的本质目标"></a>1.策略优化的本质目标</h4><p>强化学习中的策略由一个参数化的函数 $\pi_\theta(a|s)$ 表示，它给定当前状态 $s$ 时输出动作 $a$ 的概率分布。我们希望学习一组参数 $\theta$，使得该策略在环境中表现得尽可能好。</p>
<p>强化学习的优化目标是 <strong>最大化期望回报</strong>（Expected Return）：<br>$$J(\theta) &#x3D; \mathbb{E}{\tau \sim \pi\theta} \left[ \sum_{t&#x3D;0}^{T} \gamma^t r_t \right]$$<br>其中：</p>
<ul>
<li>$\theta$：策略网络的参数</li>
<li>$\tau &#x3D; (s_0, a_0, r_0, s_1, \dots)$：表示一条轨迹 trajectory</li>
<li>$\gamma \in (0, 1]$：折扣因子，用于权衡长期与短期奖励</li>
<li>$r_t$：智能体在第 t 步获得的即时奖励</li>
<li>$\mathbb{E}{\tau \sim \pi\theta}[\cdot]$：在当前策略下，对所有可能轨迹取期望</li>
</ul>
<h4 id="2-目标函数直观理解"><a href="#2-目标函数直观理解" class="headerlink" title="2.目标函数直观理解"></a>2.目标函数直观理解</h4><p>这个目标函数代表了智能体在当前策略下，预计可以获得的平均长期奖励。最大化它，就意味着让智能体倾向于采取能长期带来更高奖励的行为策略。<br>换句话说：</p>
<blockquote>
<p>强化学习 ≈ 找到一套动作决策规则，使得智能体在环境中获得的<strong>总奖励期望值最大化</strong>。</p>
</blockquote>
<h4 id="3-状态价值函数与动作价值函数"><a href="#3-状态价值函数与动作价值函数" class="headerlink" title="3.状态价值函数与动作价值函数"></a>3.状态价值函数与动作价值函数</h4><p>为了更细致地描述不同状态或动作的好坏，我们引入两个关键函数，它们都是目标函数的局部展开：</p>
<h5 id="1-状态价值函数（State-Value-Function）"><a href="#1-状态价值函数（State-Value-Function）" class="headerlink" title="1.状态价值函数（State Value Function）"></a><strong>1.状态价值函数（State Value Function）</strong></h5><p>$V^\pi(s) &#x3D; \mathbb{E}\pi \left[ \sum{t&#x3D;0}^\infty \gamma^t r_t ,\middle|, s_0 &#x3D; s \right]$<br>表示在状态 $s$ 下，使用策略 $\pi$ 所能获得的预期总奖励。</p>
<h5 id="2-动作价值函数（Action-Value-Function）"><a href="#2-动作价值函数（Action-Value-Function）" class="headerlink" title="2.动作价值函数（Action Value Function）"></a><strong>2.动作价值函数（Action Value Function）</strong></h5><p>$Q^\pi(s, a) &#x3D; \mathbb{E}\pi \left[ \sum{t&#x3D;0}^\infty \gamma^t r_t ,\middle|, s_0 &#x3D; s, a_0 &#x3D; a \right]$<br>表示在状态 $s$ 下选择动作 $a$，之后按照策略 $\pi$ 行动，能获得的期望回报。</p>
<blockquote>
<p>这两个函数会在后续优势函数和策略梯度中反复出现。</p>
</blockquote>
<h4 id="4-PPO-中使用的目标函数特点"><a href="#4-PPO-中使用的目标函数特点" class="headerlink" title="4.PPO 中使用的目标函数特点"></a>4.PPO 中使用的目标函数特点</h4><p>在 PPO 训练过程中，虽然最终优化的是剪切策略目标（Clip Objective），但仍然是围绕这个“期望回报最大化”的原始目标函数进行近似优化。这个原始目标提供了：</p>
<ul>
<li>理论基础：PPO 的损失项是从 $J(\theta)$ 推导出来的</li>
<li>导数依据：策略梯度就是对 $J(\theta)$ 求导数</li>
<li>稳定性参考：值函数分支用于估计状态回报 $V(s)$ 以减少方差</li>
</ul>
<h4 id="5-与监督学习目标的对比"><a href="#5-与监督学习目标的对比" class="headerlink" title="5.与监督学习目标的对比"></a>5.与监督学习目标的对比</h4><table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>监督学习</strong></th>
<th><strong>强化学习</strong></th>
</tr>
</thead>
<tbody><tr>
<td>目标函数</td>
<td>最小化预测误差（如 MSE）</td>
<td>最大化期望回报 $J(\theta)$</td>
</tr>
<tr>
<td>标签</td>
<td>明确给定的 ground truth</td>
<td>奖励由环境反馈，不稳定</td>
</tr>
<tr>
<td>样本依赖</td>
<td>样本独立 $i.i.d.$</td>
<td>样本依赖于策略，非独立</td>
</tr>
<tr>
<td>难点</td>
<td>特征建模</td>
<td>时序性、稀疏奖励、探索-利用权衡</td>
</tr>
</tbody></table>
<h3 id="2-期望计算与采样估计"><a href="#2-期望计算与采样估计" class="headerlink" title="2.期望计算与采样估计"></a>2.期望计算与采样估计</h3><p>在强化学习中，我们的目标是最大化如下策略目标函数：<br>$J(\theta) &#x3D; \mathbb{E}{\tau \sim \pi\theta} \left[ \sum_{t&#x3D;0}^{T} \gamma^t r_t \right]$<br>但由于轨迹分布$\tau \sim \pi_\theta$涉及环境动态与策略随机性，<strong>这个期望在实际中无法精确求解</strong>，因此必须通过<strong>采样近似</strong>来计算。</p>
<h4 id="1-为什么需要采样估计？"><a href="#1-为什么需要采样估计？" class="headerlink" title="1.为什么需要采样估计？"></a>1.为什么需要采样估计？</h4><p>强化学习不像监督学习那样拥有固定训练集。环境是一个黑箱，策略在其中不断与环境交互产生样本，因此：</p>
<ul>
<li><strong>分布不可知</strong>：轨迹 $\tau$ 的真实分布 $p(\tau)$ 无法直接获得</li>
<li><strong>动态生成数据</strong>：只能通过当前策略与环境互动收集数据</li>
<li><strong>期望不易解析</strong>：数学上无法求出对策略参数 $\theta$ 的解析梯度</li>
</ul>
<p>因此，我们必须依赖<strong>经验采样</strong>方式，用近似值替代期望与梯度。</p>
<h4 id="2-采样估计策略目标函数"><a href="#2-采样估计策略目标函数" class="headerlink" title="2.采样估计策略目标函数"></a>2.采样估计策略目标函数</h4><p>我们用<strong>经验平均值（Monte Carlo 估计）</strong> 来代替对轨迹的期望：<br>$J(\theta) \approx \frac{1}{N} \sum_{i&#x3D;1}^{N} \left[ \sum_{t&#x3D;0}^{T_i} \gamma^t r_t^{(i)} \right]$<br>其中：</p>
<ul>
<li>$N$：采样轨迹的数量</li>
<li>$T_i$：第 $i$ 条轨迹的终止时间步</li>
<li>$r_t^{(i)}$：第 i 条轨迹第 $t$ 步获得的奖励</li>
</ul>
<p>通过这种方式，我们可以估计在当前策略 $\pi_\theta$ 下，策略执行的表现。</p>
<h2 id="4-策略更新与训练流程"><a href="#4-策略更新与训练流程" class="headerlink" title="4.策略更新与训练流程"></a>4.策略更新与训练流程</h2><h3 id="1-多轮交互-多轮策略微调"><a href="#1-多轮交互-多轮策略微调" class="headerlink" title="1.多轮交互 + 多轮策略微调"></a>1.多轮交互 + 多轮策略微调</h3><p>一次完整的策略训练过程包含两大阶段：</p>
<ol>
<li><strong>与环境的交互采样阶段（rollout phase）</strong>：策略根据当前参数 $\theta$ 与环境互动，生成多个 episode 或 trajectory，每个时间步采集三类数据：状态 $s_t$、动作 $a_t$、回报&#x2F;优势 $A_t$。</li>
<li><strong>策略更新阶段（policy optimization phase）</strong>：使用采集到的样本数据，进行多次 epoch 的策略微调，即训练 PPO 的目标函数。</li>
</ol>
<h4 id="1-多轮交互的目的"><a href="#1-多轮交互的目的" class="headerlink" title="1.多轮交互的目的"></a>1.多轮交互的目的</h4><p>在传统的策略梯度方法（如 REINFORCE）中，通常每轮训练只使用一次采样数据，造成：</p>
<ul>
<li>样本利用率极低</li>
<li>更新方向受噪声影响大</li>
<li>不利于收敛与稳定性</li>
</ul>
<p>而 PPO 的改进之一是：<strong>一次采样数据可以用来进行多轮策略更新（Multiple Epochs）</strong>，极大提高训练效率。</p>
<h4 id="2-多轮策略微调"><a href="#2-多轮策略微调" class="headerlink" title="2.多轮策略微调"></a>2.多轮策略微调</h4><p>PPO 借助其 <strong>clip 剪切机制</strong>，可以在 <strong>不改变旧策略分布过快的前提下</strong>，使用同一批采样数据多次训练：</p>
<ul>
<li>将采样数据分为若干 minibatch（小批次）；</li>
<li>对每个小批次进行 3~10 轮更新（称为 multiple epochs）；</li>
<li>每次更新计算目标函数：$L^{\text{CLIP}}(\theta) &#x3D; \mathbb{E}_{(s,a) \sim \mathcal{D}} \left[ \min \left( r(\theta) A, \text{clip}(r(\theta), 1-\epsilon, 1+\epsilon) A \right) \right]$，其中 $\mathcal{D}$ 是采样的数据集。</li>
</ul>
<p>PPO 的训练采用 <strong>“一次采样 + 多轮更新”</strong> 的方式，在保持策略分布稳定的前提下，大大提高了样本利用效率，是其效率与稳定性兼得的核心优势。</p>
<h3 id="2-优势函数与稳定性优化"><a href="#2-优势函数与稳定性优化" class="headerlink" title="2.优势函数与稳定性优化"></a>2.优势函数与稳定性优化</h3><h4 id="1-什么是优势函数（Advantage-Function）？"><a href="#1-什么是优势函数（Advantage-Function）？" class="headerlink" title="1.什么是优势函数（Advantage Function）？"></a>1.什么是优势函数（Advantage Function）？</h4><p>优势函数 $A_t$ 是强化学习中用于衡量一个动作相对“平均水平”好坏的重要指标，定义为：<br>$A_t &#x3D; Q(s_t, a_t) - V(s_t)$<br>其中：</p>
<ul>
<li>$Q(s_t, a_t)$：表示在状态 $s_t$ 执行动作 $a_t$ 后的总期望回报</li>
<li>$V(s_t)$：表示在状态 $s_t$ 下采取任意策略的平均回报</li>
<li>所以 $A_t$ 表示「当前动作比平均水平好多少」</li>
</ul>
<p> 若 $A_t$ &gt; 0，说明当前动作优于平均水平；反之则劣于平均。</p>
<h4 id="2-为什么-PPO-要使用优势函数？"><a href="#2-为什么-PPO-要使用优势函数？" class="headerlink" title="2.为什么 PPO 要使用优势函数？"></a>2.为什么 PPO 要使用优势函数？</h4><p>PPO 的目标是最大化：<br>$L^{\text{CLIP}}(\theta) &#x3D; \mathbb{E}_t \left[ \min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t) \right]$<br>可以看出：</p>
<ul>
<li>PPO 的策略梯度方向完全依赖于 $A_t$</li>
<li>准确估计 $A_t$ 是训练稳定性与收敛性的关键</li>
</ul>
<h4 id="3-如何估计优势函数？"><a href="#3-如何估计优势函数？" class="headerlink" title="3.如何估计优势函数？"></a>3.如何估计优势函数？</h4><p>在实践中，我们无法直接得到 $Q(s_t, a_t)$，所以通常用<strong>经验回报</strong> $R_t$ 与状态值函数 $V(s_t)$ 的差值近似：<br>$A_t &#x3D; R_t - V(s_t)$<br>但这样会带来<strong>高方差问题</strong>。于是，提出了一种更平滑的优势估计方法——<strong>广义优势估计（GAE）</strong>。</p>
<p>PPO 中的优势函数不仅决定了策略的更新方向，还通过 GAE、归一化等方法提升了训练的稳定性与收敛速度，是连接策略目标与实际更新之间的“稳定桥梁”。</p>
<h3 id="3-训练中的常见技巧与超参数设置"><a href="#3-训练中的常见技巧与超参数设置" class="headerlink" title="3.训练中的常见技巧与超参数设置"></a>3.训练中的常见技巧与超参数设置</h3><p>在强化学习中，尤其是 PPO 这样的 on-policy 策略优化方法，由于每一次更新都依赖新鲜采样数据，因此<strong>训练效率和稳定性尤为重要</strong>。本节总结了一系列实践中广泛使用的技巧与推荐超参数，帮助你在实现 PPO 时取得更好效果。常见训练技巧有：</p>
<h4 id="1-标准化优势函数（Advantage-Normalization）"><a href="#1-标准化优势函数（Advantage-Normalization）" class="headerlink" title="1.标准化优势函数（Advantage Normalization）"></a>1.标准化优势函数（Advantage Normalization）</h4><ul>
<li><strong>作用</strong>：消除优势值的数值尺度影响，避免策略梯度方向失衡，通常效果显著，建议始终启用。</li>
<li><strong>做法</strong>：每个训练批次上，将优势函数 A_t 标准化为：$A_t \leftarrow \frac{A_t - \mu}{\sigma + \epsilon}$</li>
</ul>
<h4 id="2-熵奖励（Entropy-Bonus）"><a href="#2-熵奖励（Entropy-Bonus）" class="headerlink" title="2.熵奖励（Entropy Bonus）"></a>2.熵奖励（Entropy Bonus）</h4><ul>
<li><strong>作用</strong>：增加策略的随机性，防止策略过早陷入确定性，提升探索能力。</li>
<li><strong>添加到目标函数</strong> 中，完整形式为：$L^{\text{PPO}} &#x3D; L^{\text{CLIP}} - c_1 \cdot \text{VF Loss} + c_2 \cdot \text{Entropy Bonus}$</li>
<li><strong>超参数</strong> $c_2$ 控制熵奖励权重，典型值为：0.001 ~ 0.02</li>
</ul>
<h4 id="3-梯度裁剪（Gradient-Clipping）"><a href="#3-梯度裁剪（Gradient-Clipping）" class="headerlink" title="3.梯度裁剪（Gradient Clipping）"></a>3.梯度裁剪（Gradient Clipping）</h4><ul>
<li><strong>作用</strong>：防止策略梯度爆炸，保证每步更新平稳</li>
<li><strong>做法</strong>：对所有梯度统一做 L2 范数裁剪</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># max_grad_norm 推荐值 0.5</span></span><br><span class="line">torch.nn.utils.clip_grad_norm_(policy.parameters(), max_grad_norm)</span><br></pre></td></tr></table></figure>
<h4 id="4-Reward-Normalization（回报归一化）"><a href="#4-Reward-Normalization（回报归一化）" class="headerlink" title="4.Reward Normalization（回报归一化）"></a>4.Reward Normalization（回报归一化）</h4><ul>
<li>特别适用于 reward 数值波动较大或不同任务 reward 分布差异大的情况</li>
<li>可提升学习稳定性，但在 reward 分布已稳定时可略去</li>
</ul>
<h4 id="5-周期性评估与-early-stopping"><a href="#5-周期性评估与-early-stopping" class="headerlink" title="5.周期性评估与 early stopping"></a>5.周期性评估与 early stopping</h4><ul>
<li>在训练周期中设定验证环境，用于评估策略性能趋势</li>
<li>若策略在评估环境中长期不提升，可早停或调整学习率策略</li>
</ul>
<h4 id="6-PPO-中关键超参数推荐"><a href="#6-PPO-中关键超参数推荐" class="headerlink" title="6.PPO 中关键超参数推荐"></a>6.PPO 中关键超参数推荐</h4><p>以下为 PPO 中常用的重要超参数及其典型建议范围（可依据任务微调）：</p>
<table>
<thead>
<tr>
<th><strong>超参数</strong></th>
<th><strong>描述</strong></th>
<th><strong>推荐值</strong></th>
</tr>
</thead>
<tbody><tr>
<td>γ</td>
<td>折扣因子</td>
<td>0.99</td>
</tr>
<tr>
<td>λ</td>
<td>GAE 参数，控制 bias-variance 平衡</td>
<td>0.95</td>
</tr>
<tr>
<td>ε</td>
<td>PPO 剪切阈值</td>
<td>0.1 ~ 0.3</td>
</tr>
<tr>
<td>K_epochs</td>
<td>每轮数据的微调轮数</td>
<td>4 ~ 10</td>
</tr>
<tr>
<td>mini_batch_size</td>
<td>小批次样本大小</td>
<td>64 ~ 1024</td>
</tr>
<tr>
<td>learning_rate</td>
<td>学习率</td>
<td>1e-4 ~ 3e-4</td>
</tr>
<tr>
<td>c1</td>
<td>值函数损失权重</td>
<td>0.5</td>
</tr>
<tr>
<td>c2</td>
<td>熵正则项权重</td>
<td>0.01</td>
</tr>
<tr>
<td>max_grad_norm</td>
<td>梯度裁剪上限</td>
<td>0.5</td>
</tr>
</tbody></table>
<p>这些超参数会根据任务复杂度、action space 维度和 reward scale 做适当调整。</p>
<h2 id="5-总结-1"><a href="#5-总结-1" class="headerlink" title="5.总结"></a>5.总结</h2><p>PPO（Proximal Policy Optimization）是一种高效稳定的策略优化算法，通过剪切目标函数（clip objective）限制策略更新幅度，在保持训练稳定性的同时简化实现。<br>其核心设计包括：</p>
<ol>
<li>用策略比值剪切替代复杂的KL约束，防止策略突变</li>
<li>采用广义优势估计（GAE）平衡偏差与方差</li>
<li>支持多轮数据复用提升样本效率</li>
</ol>
<p>PPO通过Actor-Critic框架交互采样，结合值函数损失和熵奖励项，实现策略的渐进式优化。典型超参数如剪切阈值ε&#x3D;0.2、折扣因子γ&#x3D;0.99、GAE参数λ&#x3D;0.95，配合梯度裁剪和优势归一化等技巧，使其在连续&#x2F;离散动作任务中均表现优异，成为强化学习领域的基准算法。</p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>策略优化</tag>
        <tag>PPO</tag>
      </tags>
  </entry>
  <entry>
    <title>PPO算法在连续与离散动作空间中的案例实践</title>
    <url>/2025/07/30/026-rl-ppo-discrete-continuous-case/</url>
    <content><![CDATA[<h2 id="1-PPO算法与动作空间类型概览"><a href="#1-PPO算法与动作空间类型概览" class="headerlink" title="1.PPO算法与动作空间类型概览"></a>1.PPO算法与动作空间类型概览</h2><h3 id="1-PPO（Proximal-Policy-Optimization）简介"><a href="#1-PPO（Proximal-Policy-Optimization）简介" class="headerlink" title="1.PPO（Proximal Policy Optimization）简介"></a>1.PPO（Proximal Policy Optimization）简介</h3><p>PPO（近端策略优化）是OpenAI于2017年提出的强化学习算法，通过创新的”剪切目标函数”设计，在保证训练稳定性的同时实现高效策略优化。其核心思想是<strong>通过约束策略更新幅度，防止策略突变导致的性能崩溃，解决了传统策略梯度方法（如TRPO）的工程实现复杂性问题</strong>。</p>
<span id="more"></span>
<h4 id="1-剪切比值机制（Clip-Objective）"><a href="#1-剪切比值机制（Clip-Objective）" class="headerlink" title="1.剪切比值机制（Clip Objective）"></a>1.剪切比值机制（Clip Objective）</h4><p>$$L^{\text{CLIP}}(\theta) &#x3D; \mathbb{E}_t \left[ \min\left(r_t(\theta) \hat{A}_t,; \text{clip}(r_t(\theta), 1 - \epsilon, 1 + \epsilon) \cdot \hat{A}_t\right) \right]$$</p>
<p>其中  $r_t(\theta) &#x3D; \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$ 是新旧策略的概率比值。该设计的目的是：</p>
<ul>
<li>当策略更新幅度在阈值 ϵ（通常取0.1-0.3）内时正常优化</li>
<li>当策略更新幅度过大或过小时进行截断，避免策略突变</li>
</ul>
<h4 id="2-​广义优势估计（GAE）​"><a href="#2-​广义优势估计（GAE）​" class="headerlink" title="2.​广义优势估计（GAE）​"></a>2.​广义优势估计（GAE）​</h4><p>广义优势估计（Generalized Advantage Estimation，简称 <strong>GAE</strong>）是策略梯度方法中一种用于减少策略训练时方差、提高稳定性的技巧。<strong>GAE 的目标</strong>是 <strong>结合多个 n-step Advantage 的加权平均</strong>，在方差和偏差之间取得更好的平衡。<br>GAE 定义如下：<br>$$\hat{A}t^{\mathrm{GAE}(\gamma, \lambda)} &#x3D; \sum{l&#x3D;0}^{\infty} (\gamma \lambda)^l \delta_{t+l}$$<br>其中：</p>
<ul>
<li>$\delta_t &#x3D; r_t + \gamma V(s_{t+1}) - V(s_t)$：一阶 TD 残差</li>
<li>$\lambda \in [0, 1]$：控制偏差与方差的权衡参数<ul>
<li>$\lambda &#x3D; 0$：使用 1-step TD，偏差大但方差小</li>
<li>$\lambda &#x3D; 1$：类似 Monte Carlo 返回，偏差小但方差大</li>
<li>介于中间时，效果通常更好（如 PPO 默认 $\lambda &#x3D; 0.95$）</li>
</ul>
</li>
</ul>
<p>可以把 GAE 看成是 <strong>对未来奖励序列的指数加权平均</strong>，越靠近当前步的 TD 残差权重越大，远期的残差权重越小。通过调整 $\lambda$ 来控制对未来的“信任度”。<br>一个形象的比喻是：</p>
<ul>
<li>$\lambda$ 小 → “短视”：更相信当前的反馈</li>
<li>$\lambda$ 大 → “长视”：更相信未来回报的总体趋势</li>
</ul>
<h4 id="3-双网络架构与数据复用​"><a href="#3-双网络架构与数据复用​" class="headerlink" title="3.双网络架构与数据复用​"></a>3.双网络架构与数据复用​</h4><ul>
<li>​<strong>Actor-Critic框架</strong>​：策略网络（Actor）生成动作，价值网络（Critic）评估状态</li>
<li>​<strong>多轮优化机制</strong>​：单次采样数据支持3-10轮策略更新，提升样本效率</li>
</ul>
<h3 id="2-强化学习中的两类动作空间"><a href="#2-强化学习中的两类动作空间" class="headerlink" title="2.强化学习中的两类动作空间"></a>2.强化学习中的两类动作空间</h3><p>在强化学习中，“动作”就是智能体（agent）在每个时刻可以“做什么”。而<strong>动作空间</strong>，就是所有可能动作的集合——就像游戏角色能做哪些操作：走、跳、射击、转身……都在动作空间里。</p>
<h4 id="1-离散动作空间（Discrete-Action-Space）"><a href="#1-离散动作空间（Discrete-Action-Space）" class="headerlink" title="1.离散动作空间（Discrete Action Space）"></a>1.离散动作空间（Discrete Action Space）</h4><p>动作空间是<strong>有限个、不连续的动作选项</strong>。每个动作就像一个编号。像“菜单点菜”：选一个选项，编号是离散的，不能选半个动作或者1.7号动作。举例：</p>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>动作空间</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td>游戏角色控制</td>
<td>[0, 1, 2]</td>
<td>0&#x3D;前进，1&#x3D;后退，2&#x3D;跳跃</td>
</tr>
<tr>
<td>自动贩售机</td>
<td>[0, 1, 2, 3]</td>
<td>选择四种饮料中的一种</td>
</tr>
<tr>
<td>黑白棋</td>
<td>所有合法落子位置（最多 64 个）</td>
<td>每一步落子对应一个动作</td>
</tr>
</tbody></table>
<h4 id="2-连续动作空间（Continuous-Action-Space）"><a href="#2-连续动作空间（Continuous-Action-Space）" class="headerlink" title="2.连续动作空间（Continuous Action Space）"></a>2.连续动作空间（Continuous Action Space）</h4><p>动作是<strong>实数向量</strong>，可以是任意值，甚至是多个维度组成的动作向量。像“调音台旋钮”：你可以随意旋转旋钮，控制值是连续的，可以精调到任意数值。举例：</p>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>动作空间</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td>机械臂控制</td>
<td>[θ₁, θ₂, θ₃] ∈ ℝ³</td>
<td>每个关节旋转角度是一个连续值</td>
</tr>
<tr>
<td>飞船推进</td>
<td>[f₁, f₂] ∈ ℝ²</td>
<td>左右引擎推力，值从 0~1</td>
</tr>
<tr>
<td>自动驾驶</td>
<td>[加速度, 方向盘角度] ∈ ℝ²</td>
<td>任意控制强度和方向</td>
</tr>
</tbody></table>
<h2 id="2-LunarLander-v3-离散动作空间案例"><a href="#2-LunarLander-v3-离散动作空间案例" class="headerlink" title="2.LunarLander-v3(离散动作空间案例)"></a>2.LunarLander-v3(离散动作空间案例)</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/lunar_lander_ep2.gif"></p>
<h3 id="1-环境与任务"><a href="#1-环境与任务" class="headerlink" title="1.环境与任务"></a>1.环境与任务</h3><p>LunarLander-v3 是 OpenAI Gym&#x2F;Gymnasium 中的一个经典强化学习环境，模拟了一个飞船在月球上着陆的任务。任务目标是让飞船安全、平稳地降落在地面中央的着陆平台上。</p>
<h4 id="1-状态空间（state）"><a href="#1-状态空间（state）" class="headerlink" title="1.状态空间（state）"></a>1.状态空间（state）</h4><p>一个长度为 8 的浮点向量，表示飞船当前的物理状态：</p>
<ul>
<li>x：水平方向的位置</li>
<li>y：垂直方向的位置</li>
<li>vx：水平方向速度</li>
<li>vy：垂直方向速度</li>
<li>angle：飞船的旋转角度</li>
<li>angle_vel：飞船的角速度</li>
<li>left_leg_contact：左腿是否接触地面</li>
<li>right_leg_contact：右腿是否接触地面</li>
</ul>
<h4 id="2-动作空间（action-space）"><a href="#2-动作空间（action-space）" class="headerlink" title="2.动作空间（action space）"></a>2.动作空间（action space）</h4><p>动作是离散的，共有 <strong>4 个动作</strong>：</p>
<ul>
<li>0：不作为</li>
<li>2：主引擎向下喷气</li>
<li>3：左方向喷气</li>
<li>1：右方向喷气</li>
</ul>
<h4 id="3-奖励机制（reward）"><a href="#3-奖励机制（reward）" class="headerlink" title="3.奖励机制（reward）"></a>3.奖励机制（reward）</h4><ul>
<li><strong>+100~140</strong>：成功降落在平台中央</li>
<li><strong>-100</strong>：摔坏飞船</li>
<li><strong>-0.3 &#x2F; 每次喷气</strong>：惩罚使用燃料（节省能量）</li>
<li><strong>+10</strong>：每条腿接触地面</li>
</ul>
<p>所以整个着陆任务的最佳策略是如何平稳、省油地降落在中央区域（两个小旗子中间）。</p>
<h4 id="4-成功-终止条件"><a href="#4-成功-终止条件" class="headerlink" title="4.成功&#x2F;终止条件"></a>4.成功&#x2F;终止条件</h4><p>成功条件：飞船平稳降落在中央的目标平台，并且两个着陆腿都接触地面<br>终止条件：飞船成功着陆或坠毁或者飞船飞出屏幕外或者任务时间超限</p>
<h4 id="5-相关参数"><a href="#5-相关参数" class="headerlink" title="5.相关参数"></a>5.相关参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">env = gym.make(<span class="string">&quot;LunarLander-v3&quot;</span>, render_mode=<span class="string">&quot;human&quot;</span>) <span class="comment"># 创建环境</span></span><br><span class="line">action = <span class="number">3</span>  <span class="comment"># 向左推进</span></span><br><span class="line"><span class="comment"># terminated：任务完成 truncated：任务被结束</span></span><br><span class="line">obs, reward, terminated, truncated, info = env.step(action)</span><br><span class="line">x, y, vx, vy, angle, angle_vel, left_leg, right_leg = obs</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;横向:<span class="subst">&#123;x&#125;</span>, 纵向:<span class="subst">&#123;y&#125;</span>, 水平速度:<span class="subst">&#123;vx&#125;</span>, 垂直速度:<span class="subst">&#123;vy&#125;</span>, 朝向角度:<span class="subst">&#123;angle&#125;</span>, \n角速度:<span class="subst">&#123;angle_vel&#125;</span>, 左支架:<span class="subst">&#123;left_leg&#125;</span>, 右支架:<span class="subst">&#123;right_leg&#125;</span>,action:<span class="subst">&#123;action&#125;</span>,得分:<span class="subst">&#123;reward&#125;</span>&quot;</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">横向:-0.18395118415355682, 纵向:0.003272805130109191, 水平速度:-0.005371610634028912, 垂直速度:-0.001628089346922934, 朝向角度:-1.9359147548675537, 角速度:0.017528165131807327, 左支架:1.0, 右支架:0.0,action:3,得分:-100</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-经验缓存"><a href="#2-经验缓存" class="headerlink" title="2.经验缓存"></a>2.经验缓存</h3><p>Memory 类的作用是收集和存储智能体与环境交互过程中的经验数据，这也是为后续的策略更新（训练）提供数据支持。主要功能如下：</p>
<h4 id="1-主要用途"><a href="#1-主要用途" class="headerlink" title="1. 主要用途"></a>1. 主要用途</h4><ul>
<li>存储一批采样数据：包括每一步的状态、动作、动作概率、奖励、是否终止等信息</li>
<li>支持多轮优化：采集到一批数据后，可以多次利用这些数据进行策略网络的更新，提高样本利用率</li>
<li>便于批量处理：将采集到的数据整理为张量，方便后续神经网络的批量训练</li>
</ul>
<h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2.代码实现"></a>2.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Memory</span>:  </span><br><span class="line">    <span class="comment"># 经验缓存类  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.actions = []  <span class="comment"># 存储动作  </span></span><br><span class="line">        <span class="variable language_">self</span>.states = []  <span class="comment"># 存储状态  </span></span><br><span class="line">        <span class="variable language_">self</span>.logprobs = []  <span class="comment"># 存储旧策略下动作的对数概率  </span></span><br><span class="line">        <span class="variable language_">self</span>.rewards = []  <span class="comment"># 存储奖励  </span></span><br><span class="line">        <span class="variable language_">self</span>.is_terminals = []  <span class="comment"># 存储是否为终止状态标志  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clear_memory</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="comment"># 清空缓存（每次 update 后调用）  </span></span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.actions[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.states[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.logprobs[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.rewards[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.is_terminals[:]</span><br></pre></td></tr></table></figure>
<h4 id="3-工作流程"><a href="#3-工作流程" class="headerlink" title="3.工作流程"></a>3.工作流程</h4><ol>
<li>采样阶段：智能体与环境交互，每一步都把当前的状态、动作、动作概率、奖励、是否终止等信息存入Memory</li>
<li>更新阶段：达到一定步数后（如update_timestep），用Memory中存储的数据进行多轮策略更新</li>
<li>清空阶段：更新完毕后，调用clear_memory()清空缓存，为下一批采样做准备</li>
</ol>
<h3 id="3-策略网络结构（Actor）"><a href="#3-策略网络结构（Actor）" class="headerlink" title="3.策略网络结构（Actor）"></a>3.策略网络结构（Actor）</h3><p>在PPO中，策略网络（Actor）的作用是：输入当前环境状态，输出每个可选动作的概率分布。<br>对于LunarLander-v3（离散动作空间），策略网络输出4个动作的概率。</p>
<h4 id="1-代码实现"><a href="#1-代码实现" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输入层：输入维度state_dim（LunarLander-v3为8，即8维状态特征）</span></span><br><span class="line"><span class="comment"># 隐藏层：两个全连接层，每层后接Tanh激活函数（增加非线性表达能力），隐藏层宽度：n_latent_var（如64）</span></span><br><span class="line"><span class="comment"># 输出层：输出维度：action_dim（LunarLander-v3为4，即4个离散动作）Softmax激活：将输出转为概率分布，保证所有动作概率之和为1</span></span><br><span class="line"><span class="variable language_">self</span>.action_layer = nn.Sequential(  </span><br><span class="line">    nn.Linear(state_dim, n_latent_var),  </span><br><span class="line">    nn.Tanh(), <span class="comment"># Tanh 激活函数，给网络增加非线性表达能力，帮助网络学习更复杂的特征  </span></span><br><span class="line">    nn.Linear(n_latent_var, n_latent_var),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(n_latent_var, action_dim),  </span><br><span class="line">    nn.Softmax(dim=-<span class="number">1</span>)  <span class="comment"># 输出动作概率分布  </span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>策略网络<strong>输入8维状态特征，输出4维动作概率分布</strong></p>
<h4 id="2-前向推理与动作采样"><a href="#2-前向推理与动作采样" class="headerlink" title="2.前向推理与动作采样"></a>2.前向推理与动作采样</h4><p>先输入状态，经过上述网络，得到4个动作的概率分布，再用<strong>Categorical分布</strong>根据概率采样动作，实现探索，最后将采样的动作、对应的对数概率等信息存入Memory，用于后续PPO更新。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">act</span>(<span class="params">self, state, memory</span>):  </span><br><span class="line">    <span class="comment"># 用当前策略选择动作  </span></span><br><span class="line">    state = torch.from_numpy(state).<span class="built_in">float</span>().to(device)  </span><br><span class="line">    action_probs = <span class="variable language_">self</span>.action_layer(state)  <span class="comment"># 得到4维动作概率  </span></span><br><span class="line">    dist = Categorical(action_probs)  <span class="comment"># 创建了一个按策略概率采样动作的分布 </span></span><br><span class="line">    action = dist.sample() <span class="comment"># 从这个分布中随机抽取一个动作，以便进行策略执行和训练 </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 将动作与 log 概率存入 memory，用于后续更新  </span></span><br><span class="line">    memory.states.append(state)  </span><br><span class="line">    memory.actions.append(action)  </span><br><span class="line">    memory.logprobs.append(dist.log_prob(action))  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> action.item()</span><br></pre></td></tr></table></figure>

<p><strong>Categorical 策略</strong>是：</p>
<blockquote>
<p>“当前状态下，每个动作的概率是多少”，然后<strong>按这个分布随机选择一个动作</strong>。</p>
</blockquote>
<p><code>torch.distributions.Categorical</code> 是 PyTorch 中的一个<strong>离散概率分布类</strong>，用于处理<strong>一维离散随机变量</strong>。举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">probs = torch.tensor([<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>])</span><br><span class="line">dist = Categorical(probs) <span class="comment"># [0, 0.1] 动作0的概率是0.1 [1, 0.7], [2, 0.2]</span></span><br><span class="line">action = dist.sample()</span><br></pre></td></tr></table></figure>
<p>当执行 dist.sample()，我们就“按概率抽奖”选出一个动作编号。例如抽到action为1的概率是0.7.</p>
<h4 id="3-设计逻辑与优点"><a href="#3-设计逻辑与优点" class="headerlink" title="3.设计逻辑与优点"></a>3.设计逻辑与优点</h4><ul>
<li>多层感知机的结构，适合处理中等复杂度的状态特征</li>
<li>使用Tanh激活函数，有助于稳定训练</li>
<li>采用Softmax输出，天然适配离散动作空间</li>
<li>使用的概率采样，支持策略的探索性</li>
</ul>
<p>LunarLander-v3的策略网络本质是一个两层隐藏层的全连接神经网络，输入状态，输出每个动作的概率分布。</p>
<h3 id="4-价值网络结构（Critic）"><a href="#4-价值网络结构（Critic）" class="headerlink" title="4.价值网络结构（Critic）"></a>4.价值网络结构（Critic）</h3><p>输入当前环境状态，输出该状态的“价值估计”（state value），即智能体在该状态下能获得的期望累计回报。这个数值用于计算优势函数（Advantage），指导策略（Actor）如何去优化。</p>
<h4 id="1-代码实现-1"><a href="#1-代码实现-1" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Critic网络（价值网络）：用于输出当前状态的价值（state value）  </span></span><br><span class="line"><span class="comment"># 输入层 输入维度：state_dim（LunarLander-v3为8，即8维状态特征）</span></span><br><span class="line"><span class="comment"># 隐藏层 两个全连接层，每层后接Tanh激活函数 隐藏层宽度：n_latent_var（如64）</span></span><br><span class="line"><span class="comment"># 输出层 输出维度：1（标量，表示该状态的价值）</span></span><br><span class="line"><span class="variable language_">self</span>.value_layer = nn.Sequential(  </span><br><span class="line">    nn.Linear(state_dim, n_latent_var),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(n_latent_var, n_latent_var),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(n_latent_var, <span class="number">1</span>) <span class="comment"># 输出状态价值  </span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>输入一个状态向量，经过上述网络，输出一个标量，表示该状态的价值估计。这个值用于PPO损失函数中的优势计算和价值损失部分。</p>
<h4 id="2-评估旧策略"><a href="#2-评估旧策略" class="headerlink" title="2.评估旧策略"></a>2.评估旧策略</h4><p>评估旧策略在给定状态下选出某个动作的概率，以及当前状态的价值估计。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输入：状态和动作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, state, action</span>):  </span><br><span class="line">    <span class="comment"># 1.当前策略网络的前向传播结果，输出动作概率分布（Softmax输出）</span></span><br><span class="line">    action_probs = <span class="variable language_">self</span>.action_layer(state)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.基于动作概率，构建 PyTorch 的 离散概率分布对象。</span></span><br><span class="line">    <span class="comment"># 这个dist可以，计算动作的概率、log概率，计算整个分布的熵</span></span><br><span class="line">    dist = Categorical(action_probs)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.重点：计算旧动作在当前策略下的 log 概率</span></span><br><span class="line">    action_logprobs = dist.log_prob(action) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 熵衡量当前策略有多“随机”。</span></span><br><span class="line">    <span class="comment"># PPO 中通常会加上一个探索激励项:loss=policy_loss-c1*value_loss+c2*entropy</span></span><br><span class="line">    dist_entropy = dist.entropy() <span class="comment"># 概率分布熵（鼓励探索）  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.这是 Critic 网络的输出，对每个状态估计其“价值”</span></span><br><span class="line">    state_value = <span class="variable language_">self</span>.value_layer(state) <span class="comment"># 状态价值  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6.输出</span></span><br><span class="line">    <span class="comment"># action_logprobs：当前策略对旧动作的 log 概率（用于更新）</span></span><br><span class="line">    <span class="comment"># torch.squeeze(state_value)：当前状态的估值</span></span><br><span class="line">    <span class="comment"># dist_entropy：当前策略的分布熵（用于鼓励探索）</span></span><br><span class="line">    <span class="keyword">return</span> action_logprobs, torch.squeeze(state_value), dist_entropy</span><br></pre></td></tr></table></figure>
<p>evaluate() 是 PPO 算法在 <strong>训练更新阶段的核心评估函数</strong>，它用于：</p>
<ul>
<li><strong>计算 log概率</strong>（用于 PPO 的 clip ratio）</li>
<li><strong>计算 state value</strong>（用于 advantage）</li>
<li><strong>计算 entropy</strong>（用于策略的探索奖励）</li>
</ul>
<p>这些值都将直接进入 PPO 的损失函数，指导策略网络和价值网络进行反向传播和参数更新。</p>
<h3 id="5-PPO算法实现"><a href="#5-PPO算法实现" class="headerlink" title="5.PPO算法实现"></a>5.PPO算法实现</h3><h4 id="1-代码实现-2"><a href="#1-代码实现-2" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PPO</span>:  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, state_dim, action_dim, n_latent_var, lr, betas, gamma, k_epochs, eps_clip</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.lr = lr  </span><br><span class="line">        <span class="variable language_">self</span>.betas = betas  </span><br><span class="line">        <span class="variable language_">self</span>.gamma = gamma  </span><br><span class="line">        <span class="variable language_">self</span>.eps_clip = eps_clip  </span><br><span class="line">        <span class="variable language_">self</span>.K_epochs = k_epochs  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.policy = ActorCritic(state_dim, action_dim, n_latent_var).to(device) <span class="comment"># 当前策略网络（Actor-Critic结构）</span></span><br><span class="line">        <span class="variable language_">self</span>.optimizer = torch.optim.Adam(<span class="variable language_">self</span>.policy.parameters(), lr=lr, betas=betas)  <span class="comment"># 用于更新当前策略的 Adam 优化器</span></span><br><span class="line">        <span class="variable language_">self</span>.policy_old = ActorCritic(state_dim, action_dim, n_latent_var).to(device) <span class="comment"># 拷贝旧策略网络，采样时使用它（保证采样策略固定）</span></span><br><span class="line">        <span class="variable language_">self</span>.policy_old.load_state_dict(<span class="variable language_">self</span>.policy.state_dict())  </span><br><span class="line">        <span class="variable language_">self</span>.MseLoss = nn.MSELoss()   <span class="comment"># 用于 critic 的价值函数回归</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 策略更新核心函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, memory</span>):  </span><br><span class="line">        <span class="comment"># 1. 使用 GAE 估计每个状态的回报  </span></span><br><span class="line">        <span class="comment"># 如果是终止状态（done），则折扣回报归零重新累计</span></span><br><span class="line">        rewards = []  </span><br><span class="line">        discounted_reward = <span class="number">0</span>  </span><br><span class="line">        <span class="keyword">for</span> reward, is_terminal <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">reversed</span>(memory.rewards), <span class="built_in">reversed</span>(memory.is_terminals)):  </span><br><span class="line">            <span class="keyword">if</span> is_terminal:  </span><br><span class="line">                discounted_reward = <span class="number">0</span>  </span><br><span class="line">            discounted_reward = reward + (<span class="variable language_">self</span>.gamma * discounted_reward)  </span><br><span class="line">            rewards.insert(<span class="number">0</span>, discounted_reward)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.对回报进行标准化（加快收敛）:有助于更稳定的训练</span></span><br><span class="line">        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)  </span><br><span class="line">        rewards = (rewards - rewards.mean()) / (rewards.std() + <span class="number">1e-5</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 3.取出旧的数据（detach 防止反向传播）  </span></span><br><span class="line">        old_states = torch.stack(memory.states).to(device).detach()  </span><br><span class="line">        old_actions = torch.stack(memory.actions).to(device).detach()  </span><br><span class="line">        old_logprobs = torch.stack(memory.logprobs).to(device).detach()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 4.K次epoch的PPO更新：每次更新循环中，进行一次“策略评估 + 损失计算 + 反向传播”</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.K_epochs):  </span><br><span class="line">            <span class="comment"># 5.策略评估：计算新策略下动作的对数概率、state的value估计和策略的熵（鼓励探索）</span></span><br><span class="line">            logprobs, state_values, dist_entropy = <span class="variable language_">self</span>.policy.evaluate(old_states, old_actions)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 6.计算概率比率       </span></span><br><span class="line">            ratios = torch.exp(logprobs - old_logprobs.detach())  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 7.计算优势项，衡量动作比期望好多少</span></span><br><span class="line">            advantages = rewards - state_values.detach()  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 8.计算PPO剪切目标</span></span><br><span class="line">            <span class="comment"># PPO的核心是防止策略更新太快（剪切比率），所以取两者中较小的作为最终目标</span></span><br><span class="line">            surr1 = ratios * advantages  </span><br><span class="line">            surr2 = torch.clamp(ratios, <span class="number">1</span> - <span class="variable language_">self</span>.eps_clip, <span class="number">1</span> + <span class="variable language_">self</span>.eps_clip) * advantages  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 9.构造总损失函数</span></span><br><span class="line">            <span class="comment"># -torch.min(surr1, surr2)：策略损失（Actor）</span></span><br><span class="line">            <span class="comment"># 0.5 * self.MseLoss(state_values, rewards)：价值损失（Critic）</span></span><br><span class="line">            <span class="comment"># - 0.01 * dist_entropy：熵惩罚项，鼓励策略保持一定随机性（探索）</span></span><br><span class="line">            loss = -torch.<span class="built_in">min</span>(surr1, surr2) + <span class="number">0.5</span> * <span class="variable language_">self</span>.MseLoss(state_values, rewards) - <span class="number">0.01</span> * dist_entropy  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 10.执行梯度更新  </span></span><br><span class="line">            <span class="variable language_">self</span>.optimizer.zero_grad()  </span><br><span class="line">            loss.mean().backward()  </span><br><span class="line">            <span class="variable language_">self</span>.optimizer.step()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 11.更新旧策略参数，便于下一轮采样</span></span><br><span class="line">        <span class="variable language_">self</span>.policy_old.load_state_dict(<span class="variable language_">self</span>.policy.state_dict())</span><br></pre></td></tr></table></figure>

<p><code>PPO.update()</code>代码的核心是：<strong>用采样轨迹计算 advantage，构造 clipped surrogate loss，在保证稳定更新的前提下优化 actor-critic 网络。</strong></p>
<h4 id="2-举例说说-PPO-的ratio-剪切策略"><a href="#2-举例说说-PPO-的ratio-剪切策略" class="headerlink" title="2.举例说说 PPO 的ratio 剪切策略"></a>2.举例说说 PPO 的ratio 剪切策略</h4><p>在PPO算法中，策略更新的核心是限制新旧策略之间的变化幅度，以避免剧烈更新导致策略崩溃。这一策略的核心公式之一为：<br>$$\text{ratio} &#x3D; \frac{\pi_{\text{new}}(a|s)}{\pi_{\text{old}}(a|s)}$$<br>该比率表示新策略与旧策略在相同状态下选择某个动作的概率比值。</p>
<p>在 LunarLander-v3 环境中，飞船需要根据当前的状态（如高度、角度、速度）做出决策，选择激活哪些推进器以实现平稳着陆。策略网络 π 就是用于在每个状态下输出相应动作分布的模型。<br>在一次回合中，旧策略 π_old 对某个状态 s 采样了一个动作 a，比如“点燃主推进器”。随后，训练过程根据实际的环境反馈计算出该动作的优势（Advantage），即该动作相对于当前状态下平均动作的好坏程度。</p>
<p><strong>策略更新不宜过快</strong><br>如果该动作的优势为正（说明该动作是“好”的），策略应当提高该动作的概率以鼓励重复选择。然而，如果直接按照策略梯度进行无约束更新，可能会导致该动作的概率被显著放大，从而造成策略过拟合于当前经验，降低策略在未见过情形下的泛化能力，甚至使策略陷入崩溃。</p>
<p><strong>PPO 中的剪切机制</strong><br>为了抑制策略剧烈更新，PPO 引入了一个“剪切”机制，即限制 ratio 的值在一个范围内（例如 [0.8, 1.2]）。当更新导致的概率比率超过该范围时，会使用边界值替代，以实现“保守更新”。</p>
<p>这种剪切机制可类比为飞船的姿态控制系统：</p>
<table>
<thead>
<tr>
<th><strong>情形</strong></th>
<th><strong>含义</strong></th>
<th><strong>PPO 策略行为</strong></th>
</tr>
</thead>
<tbody><tr>
<td>$\text{ratio} \approx 1$</td>
<td>当前策略与旧策略差异不大，动作选择变化平稳</td>
<td>正常更新，鼓励优势动作</td>
</tr>
<tr>
<td>$\text{ratio} \gg 1$</td>
<td>策略剧烈放大某一动作的概率，容易造成策略偏移或不稳定</td>
<td>剪切 ratio，抑制剧烈变化</td>
</tr>
<tr>
<td>$\text{ratio} \ll 1$</td>
<td>策略对某一动作严重抑制，可能过度惩罚</td>
<td>剪切后保持稳定下降，避免过度惩罚</td>
</tr>
</tbody></table>
<h3 id="6-训练参数与控制变量"><a href="#6-训练参数与控制变量" class="headerlink" title="6.训练参数与控制变量"></a>6.训练参数与控制变量</h3><h4 id="1-训练参数"><a href="#1-训练参数" class="headerlink" title="1.训练参数"></a>1.训练参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">state_dim = env.observation_space.shape[<span class="number">0</span>] <span class="comment"># 状态向量长度（LunarLander 为 8）</span></span><br><span class="line">action_dim = <span class="number">4</span> <span class="comment"># 动作数量（离散 4 种：无、主推进器、左右推进器） </span></span><br><span class="line">n_latent_var = <span class="number">64</span>  <span class="comment"># 隐藏层宽度  </span></span><br><span class="line">lr = <span class="number">0.002</span> <span class="comment"># 学习率 控制每次参数更新的步长，影响训练速度和稳定性  </span></span><br><span class="line">betas = (<span class="number">0.9</span>, <span class="number">0.999</span>) <span class="comment"># Adam 优化器的动量参数，通常为 (0.9, 0.999)</span></span><br><span class="line">gamma = <span class="number">0.99</span>  <span class="comment"># 奖励折扣因子，控制未来奖励的衰减程度，越接近 1 越重视长期奖励  </span></span><br><span class="line">k_epochs = <span class="number">4</span>  <span class="comment"># 每次更新策略时的训练轮数，每收集一批数据后，策略网络要训练多少次，如 4（离散动作），80（连续动作）  </span></span><br><span class="line">eps_clip = <span class="number">0.2</span>  <span class="comment"># PPO 裁剪参数，限制新旧策略概率比的变化范围，防止策略更新过大，保证训练稳定 </span></span><br><span class="line">random_seed = <span class="literal">None</span> <span class="comment"># 是否设置随机种子（可复现性）</span></span><br></pre></td></tr></table></figure>
<h4 id="2-控制变量"><a href="#2-控制变量" class="headerlink" title="2.控制变量"></a>2.控制变量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">render = <span class="literal">False</span>  <span class="comment"># 是否渲染游戏UI</span></span><br><span class="line">solved_reward = <span class="number">230</span>  <span class="comment"># 平均奖励大于该值即认为任务完成</span></span><br><span class="line">log_interval = <span class="number">20</span>  <span class="comment"># 每多少个 episode 打印一次日志</span></span><br><span class="line">max_episodes = <span class="number">50000</span>  <span class="comment"># 训练的总轮数（每轮为一次游戏）</span></span><br><span class="line">max_timesteps = <span class="number">300</span>  <span class="comment"># 每轮最多多少步</span></span><br><span class="line">update_timestep = <span class="number">2000</span>  <span class="comment"># 策略更新步数间隔</span></span><br></pre></td></tr></table></figure>
<h3 id="7-训练流程"><a href="#7-训练流程" class="headerlink" title="7.训练流程"></a>7.训练流程</h3><h4 id="1-代码实现-3"><a href="#1-代码实现-3" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 训练参数与控制变量</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置随机种子  </span></span><br><span class="line">    <span class="keyword">if</span> random_seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">        torch.manual_seed(random_seed)  </span><br><span class="line">        env.reset(seed=random_seed)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;PyTorch随机数:<span class="subst">&#123;torch.rand(<span class="number">1</span>).item()&#125;</span>, 环境初始状态:<span class="subst">&#123;env.reset()[<span class="number">0</span>][:<span class="number">2</span>]&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 初始化 PPO、Memory、变量  </span></span><br><span class="line">    memory = Memory()  <span class="comment"># 存储一段时间内的经验轨迹（state、action、reward 等）</span></span><br><span class="line">    ppo = PPO(state_dim, action_dim, n_latent_var, lr, betas, gamma, k_epochs, eps_clip)  <span class="comment"># 初始化一个 PPO 对象，内部包含策略网络、优化器等</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># logging variables  </span></span><br><span class="line">    running_reward = <span class="number">0</span>  </span><br><span class="line">    total_length = <span class="number">0</span>  </span><br><span class="line">    timestep = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">    finished_step = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 训练循环</span></span><br><span class="line">    <span class="keyword">for</span> i_episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, max_episodes + <span class="number">1</span>): <span class="comment"># 每次循环表示飞船从头开始着陆一次</span></span><br><span class="line">        state, _ = env.reset()  <span class="comment"># 初始化  </span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps): <span class="comment"># 每一局最多能走max_timesteps步  </span></span><br><span class="line">            finished_step = t  </span><br><span class="line">            timestep += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 使用旧策略选择动作</span></span><br><span class="line">            action = ppo.policy_old.act(state, memory)  </span><br><span class="line">            <span class="comment"># next_state：执行动作后的新状态 r</span></span><br><span class="line">            <span class="comment"># reward：本步获得的奖励 </span></span><br><span class="line">            <span class="comment"># terminated：是否因为任务完成/失败而结束 </span></span><br><span class="line">            <span class="comment"># truncated：是否因为达到最大步数等外部原因而结束  </span></span><br><span class="line">            next_state, reward, terminated, truncated, _ = env.step(action)  </span><br><span class="line">            done = terminated <span class="keyword">or</span> truncated <span class="comment"># 是否终止</span></span><br><span class="line">            state = next_state  <span class="comment"># 更新状态</span></span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 存储奖励与终止标记 </span></span><br><span class="line">            memory.rewards.append(reward)  </span><br><span class="line">            memory.is_terminals.append(done)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 满足 update_timestep 时，更新策略并清空经验  </span></span><br><span class="line">            <span class="keyword">if</span> timestep % update_timestep == <span class="number">0</span>:  </span><br><span class="line">                ppo.update(memory)  </span><br><span class="line">                memory.clear_memory()  </span><br><span class="line">                timestep = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">            running_reward += reward  <span class="comment"># 奖励累加</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> render:  </span><br><span class="line">                env.render()  </span><br><span class="line">            <span class="keyword">if</span> done:  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        total_length += finished_step <span class="comment"># 累计每个 episode（回合）实际运行的步数  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 是否完成任务（Early Stop）</span></span><br><span class="line">        <span class="comment"># 如果最近 log_interval 个回合的总奖励超过设定阈值，认为已经训练成功，提前结束并保存模型</span></span><br><span class="line">        <span class="keyword">if</span> running_reward &gt; (log_interval * solved_reward):  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;########## Solved! ##########&quot;</span>)  </span><br><span class="line">            torch.save(ppo.policy.state_dict(), <span class="string">&#x27;./PPO_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(env_name)) </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 打印训练日志，</span></span><br><span class="line">        <span class="comment"># 每隔 log_interval 回合打印一次平均奖励和步数</span></span><br><span class="line">        <span class="comment"># 清零统计变量，进入下一轮计算</span></span><br><span class="line">        <span class="keyword">if</span> i_episode % log_interval == <span class="number">0</span>:  </span><br><span class="line">            avg_length = <span class="built_in">int</span>(total_length / log_interval)  </span><br><span class="line">            running_reward = <span class="built_in">int</span>((running_reward / log_interval))  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Episode &#123;&#125; \t avg length: &#123;&#125; \t reward: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i_episode, avg_length, running_reward))  </span><br><span class="line">            running_reward = <span class="number">0</span>  </span><br><span class="line">            total_length = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4 id="2-训练日志"><a href="#2-训练日志" class="headerlink" title="2.训练日志"></a>2.训练日志</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Episode 20 	 avg length: 95 	 reward: -264</span><br><span class="line">Episode 40 	 avg length: 92 	 reward: -173</span><br><span class="line">Episode 60 	 avg length: 90 	 reward: -147</span><br><span class="line">Episode 80 	 avg length: 93 	 reward: -134</span><br><span class="line">...</span><br><span class="line">Episode 420 	 avg length: 99 	 reward: -70</span><br><span class="line">Episode 440 	 avg length: 102 	 reward: -68</span><br><span class="line">Episode 460 	 avg length: 113 	 reward: -70</span><br><span class="line">...</span><br><span class="line">Episode 600 	 avg length: 216 	 reward: 6</span><br><span class="line">Episode 620 	 avg length: 237 	 reward: 68</span><br><span class="line">Episode 640 	 avg length: 261 	 reward: 100</span><br><span class="line">...</span><br><span class="line">Episode 820 	 avg length: 238 	 reward: 101</span><br><span class="line">Episode 840 	 avg length: 230 	 reward: 103</span><br><span class="line">Episode 860 	 avg length: 250 	 reward: 104</span><br><span class="line">...</span><br><span class="line">Episode 1360 	 avg length: 213 	 reward: 164</span><br><span class="line">Episode 1380 	 avg length: 232 	 reward: 174</span><br><span class="line">Episode 1400 	 avg length: 239 	 reward: 214</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">######### Solved! ##########</span></span></span><br></pre></td></tr></table></figure>
<h3 id="8-模型验证"><a href="#8-模型验证" class="headerlink" title="8.模型验证"></a>8.模型验证</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_lunar_lander</span>():  </span><br><span class="line"></span><br><span class="line">    env_name = <span class="string">&quot;LunarLander-v3&quot;</span>  </span><br><span class="line">    env = gym.make(env_name, render_mode=<span class="string">&quot;human&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    state_dim = env.observation_space.shape[<span class="number">0</span>]  <span class="comment"># 状态向量长度（=8）</span></span><br><span class="line">    action_dim = <span class="number">4</span>  <span class="comment"># 动作数量（4 个离散动作）</span></span><br><span class="line">    </span><br><span class="line">    n_latent_var = <span class="number">64</span>  <span class="comment"># 隐藏层宽度</span></span><br><span class="line">    lr = <span class="number">0.0007</span>  <span class="comment"># 学习率（略小于训练时使用的 0.002，测试时不重要）</span></span><br><span class="line">    betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)  <span class="comment"># Adam 优化器参数</span></span><br><span class="line">    gamma = <span class="number">0.99</span>  <span class="comment"># 奖励折扣因子</span></span><br><span class="line">    K_epochs = <span class="number">4</span>   <span class="comment"># 每次更新策略训练的轮数（此处无用，因不训练）</span></span><br><span class="line">    eps_clip = <span class="number">0.2</span>  <span class="comment"># PPO 的剪切比例</span></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">    n_episodes = <span class="number">3</span>  <span class="comment"># 测试回合数（让模型飞 3 次）</span></span><br><span class="line">    max_timesteps = <span class="number">300</span>  <span class="comment"># 每次最多模拟 300 步</span></span><br><span class="line">  </span><br><span class="line">    filename = <span class="string">f&quot;PPO_<span class="subst">&#123;env_name&#125;</span>.pth&quot;</span>  </span><br><span class="line">    directory = <span class="string">&quot;./&quot;</span>  </span><br><span class="line">  </span><br><span class="line">    memory = Memory()  <span class="comment"># 初始化空记忆（虽然不训练，但 act() 函数需要它）</span></span><br><span class="line">    ppo = PPO(state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip)  <span class="comment"># 构建 PPO 模型结构</span></span><br><span class="line">    ppo.policy_old.load_state_dict(torch.load(os.path.join(directory, filename)), strict=<span class="literal">False</span>)  <span class="comment"># 加载训练好的模型参数</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_episodes + <span class="number">1</span>):  </span><br><span class="line">        ep_reward = <span class="number">0</span>  <span class="comment"># 当前回合累计奖励</span></span><br><span class="line">        state, _ = env.reset()  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 飞行动作循环</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps):  </span><br><span class="line">            action = ppo.policy_old.act(state, memory)  <span class="comment"># 旧策略选择动作</span></span><br><span class="line">            <span class="comment"># 执行动作，获取新状态</span></span><br><span class="line">            state, reward, terminated, truncated, _ = env.step(action)  </span><br><span class="line">            ep_reward += reward  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">try</span>:  </span><br><span class="line">                env.render()  </span><br><span class="line">                pygame.event.pump()  <span class="comment"># 防止窗口卡死  </span></span><br><span class="line">            <span class="keyword">except</span> pygame.error:  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Render window was closed unexpectedly.&quot;</span>)  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 飞船坠毁或安全降落或 truncated：超过最大步数等强制终止</span></span><br><span class="line">            <span class="keyword">if</span> terminated <span class="keyword">or</span> truncated:</span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Episode: <span class="subst">&#123;ep&#125;</span>\tReward: <span class="subst">&#123;<span class="built_in">int</span>(ep_reward)&#125;</span>&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    env.close()  <span class="comment"># 正确地在最后统一关闭环境</span></span><br></pre></td></tr></table></figure>
<p>日志输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Episode: <span class="number">1</span>	Reward: <span class="number">223</span></span><br><span class="line">Episode: <span class="number">2</span>	Reward: <span class="number">39</span></span><br><span class="line">Episode: <span class="number">3</span>	Reward: <span class="number">261</span></span><br></pre></td></tr></table></figure>
<p>测试飞行三次，有两次可以安全降落在指定位置。</p>
<h2 id="3-BipedalWalker-v3（连续动作空间案例）"><a href="#3-BipedalWalker-v3（连续动作空间案例）" class="headerlink" title="3.BipedalWalker-v3（连续动作空间案例）"></a>3.BipedalWalker-v3（连续动作空间案例）</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/bipedal_walker_ep2.gif"></p>
<h3 id="1-环境与任务-1"><a href="#1-环境与任务-1" class="headerlink" title="1.环境与任务"></a>1.环境与任务</h3><p>BipedalWalker-v3 是 OpenAI Gym 提供的一个经典 <strong>连续控制</strong> 强化学习环境，任务目标是：<strong>控制一个双足机器人在崎岖地形上行走而不摔倒，并尽可能走得远</strong>。这是一个对智能体控制能力要求较高的环境。</p>
<h4 id="1-状态空间（state-space）"><a href="#1-状态空间（state-space）" class="headerlink" title="1.状态空间（state space）"></a>1.状态空间（state space）</h4><p>BipedalWalker-v3的状态空间是一个 24 维的浮点向量，包含：</p>
<table>
<thead>
<tr>
<th><strong>索引</strong></th>
<th><strong>含义</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>机器人躯干角度</td>
<td>单位：弧度，表示身体的旋转角</td>
</tr>
<tr>
<td>1</td>
<td>机器人躯干角速度</td>
<td>躯干旋转的速度</td>
</tr>
<tr>
<td>2</td>
<td>水平方向速度（vx）</td>
<td>躯干的水平移动速度</td>
</tr>
<tr>
<td>3</td>
<td>垂直方向速度（vy）</td>
<td>躯干的垂直移动速度</td>
</tr>
<tr>
<td>4</td>
<td>躯干到地面的水平距离</td>
<td>和目标区域的距离偏移</td>
</tr>
<tr>
<td>5</td>
<td>躯干到地面的垂直距离</td>
<td>着陆高度</td>
</tr>
<tr>
<td>6-13</td>
<td>4 个腿关节的角度（4 个关节）</td>
<td>分别表示前后腿的上&#x2F;下段关节</td>
</tr>
<tr>
<td>14-17</td>
<td>4 个腿关节的角速度</td>
<td>对应角度的变化速度</td>
</tr>
<tr>
<td>18-21</td>
<td>4 个地面接触传感器（布尔值）</td>
<td>是否接触地面（每条腿有两个脚趾）</td>
</tr>
<tr>
<td>22-23</td>
<td>最近 2 帧的躯干高度差</td>
<td>有些实现中添加，用于平滑动作判断（非标准）</td>
</tr>
</tbody></table>
<h4 id="2-动作空间（action-space）-1"><a href="#2-动作空间（action-space）-1" class="headerlink" title="2.动作空间（action space）"></a>2.动作空间（action space）</h4><p>BipedalWalker-v3的动作空间是一个 <strong>4维连续动作空间</strong>，范围是 [-1, 1]，分别控制：</p>
<ul>
<li>左髋关节的推力        </li>
<li>左膝关节的推力        </li>
<li>右髋关节的推力</li>
<li>右膝关节的推力</li>
</ul>
<p>每个数值控制一个电机的激活强度（可正可负），表示关节的力和方向。</p>
<h4 id="3-奖励函数（reward）"><a href="#3-奖励函数（reward）" class="headerlink" title="3.奖励函数（reward）"></a>3.奖励函数（reward）</h4><p>正奖励：右移动的距离（越走越远奖励越多），控制越稳，步态越自然，奖励越高<br>负奖励：每一步都会有小的惩罚（惩罚能量浪费），摔倒或行为不稳定将被惩罚或直接终止</p>
<h4 id="4-成功-终止条件-1"><a href="#4-成功-终止条件-1" class="headerlink" title="4.成功&#x2F;终止条件"></a>4.成功&#x2F;终止条件</h4><ul>
<li>成功：机器人走完整个地形</li>
<li>失败：摔倒或身体某部分触地</li>
</ul>
<h4 id="5-难点"><a href="#5-难点" class="headerlink" title="5.难点"></a>5.难点</h4><ol>
<li><strong>动作是连续的</strong>：不像“前进&#x2F;后退”这种离散选择，而是需要精确调控关节的力，这样容错率就低</li>
<li><strong>地形复杂</strong>：每次生成的地图都不同，有坑、坡、凸起，机器人需要学会灵活适应</li>
<li><strong>需要协调多个关节动作</strong>：形成合理步态（如：迈出一条腿的同时另一条支撑）</li>
<li><strong>平衡控制</strong>：摔倒即结束，类似倒立摆任务，强调稳定性与反馈控制</li>
</ol>
<h4 id="6-相关参数"><a href="#6-相关参数" class="headerlink" title="6.相关参数"></a>6.相关参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">env = gym.make(<span class="string">&quot;BipedalWalker-v3&quot;</span>, render_mode=<span class="string">&quot;human&quot;</span>)</span><br><span class="line"><span class="comment"># 分别对应：左髋 左膝 右髋 右膝</span></span><br><span class="line">action = [<span class="number">0.9765114</span>, -<span class="number">0.280038</span>, <span class="number">0.5163014</span>, -<span class="number">1.10301</span>]</span><br><span class="line">state, reward, terminated, truncated, _ = env.step(action)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;state:<span class="subst">&#123;state&#125;</span> reward:<span class="subst">&#123;reward&#125;</span> terminated:<span class="subst">&#123;terminated&#125;</span> truncated:<span class="subst">&#123;truncated&#125;</span>&quot;</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">state:[-0.02104758 -0.03126067 -0.02977715 -0.01362359  </span></span><br><span class="line"><span class="string">0.47771385  1.0004591 0.07091689 -1.0004667   </span></span><br><span class="line"><span class="string">1.  0.37952623  0.9994885   0.07574213</span></span><br><span class="line"><span class="string"> -0.99983853  1.          0.44616896  0.4512359 </span></span><br><span class="line"><span class="string">0.46702808  0.49549717 0.540591    0.60977966 </span></span><br><span class="line"><span class="string">0.71776354  0.896694    1.          1.    ]</span></span><br><span class="line"><span class="string">reward:-0.24856666951812803 terminated:False truncated:False</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-经验缓存-1"><a href="#2-经验缓存-1" class="headerlink" title="2.经验缓存"></a>2.经验缓存</h3><p>同LunarLander-v3案例的<strong>Memory</strong>类，也是收集和存储智能体与环境交互过程中的经验数据，为后续的策略更新（训练）提供数据支持：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Memory</span>:  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.actions = []</span><br><span class="line">        <span class="variable language_">self</span>.states = []  </span><br><span class="line">        <span class="variable language_">self</span>.logprobs = []</span><br><span class="line">        <span class="variable language_">self</span>.rewards = []</span><br><span class="line">        <span class="variable language_">self</span>.is_terminals = []  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clear_memory</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.actions[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.states[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.logprobs[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.rewards[:]  </span><br><span class="line">        <span class="keyword">del</span> <span class="variable language_">self</span>.is_terminals[:]</span><br></pre></td></tr></table></figure>
<h3 id="3-策略网络结构（Actor）-1"><a href="#3-策略网络结构（Actor）-1" class="headerlink" title="3.策略网络结构（Actor）"></a>3.策略网络结构（Actor）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.actor = nn.Sequential(  </span><br><span class="line">    nn.Linear(state_dim, <span class="number">64</span>),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(<span class="number">64</span>, <span class="number">32</span>),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(<span class="number">32</span>, action_dim),  </span><br><span class="line">    nn.Tanh()  <span class="comment"># 输出动作均值，范围[-1,1]</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>与<code>LunarLander-v3</code>的策略网络结构最大的不同是，前者输出的是输出动作概率分布，后者输出动作均值，范围[-1,1]</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>PPO_discrete</th>
<th>PPO_continuous</th>
</tr>
</thead>
<tbody><tr>
<td>输出激活</td>
<td>Softmax</td>
<td>Tanh</td>
</tr>
<tr>
<td>概率分布</td>
<td>Categorical</td>
<td>MultivariateNormal</td>
</tr>
<tr>
<td>探索方式</td>
<td>概率采样</td>
<td>方差控制</td>
</tr>
<tr>
<td>输出范围</td>
<td>[0,1]概率</td>
<td>[-1,1]均值</td>
</tr>
<tr>
<td>动作类型</td>
<td>离散整数</td>
<td>连续向量</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">act</span>(<span class="params">self, state, memory</span>):  </span><br><span class="line">    action_mean = <span class="variable language_">self</span>.actor(state)  </span><br><span class="line">    cov_mat = torch.diag(<span class="variable language_">self</span>.action_var).to(device)  <span class="comment"># 固定方差矩阵</span></span><br><span class="line">  </span><br><span class="line">    dist = MultivariateNormal(action_mean, cov_mat)  <span class="comment"># 多维正态分布</span></span><br><span class="line">    action = dist.sample()  </span><br><span class="line">    action_logprob = dist.log_prob(action)  </span><br><span class="line">  </span><br><span class="line">    memory.states.append(state)  </span><br><span class="line">    memory.actions.append(action)  </span><br><span class="line">    memory.logprobs.append(action_logprob)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> action.detach()</span><br></pre></td></tr></table></figure>
<p>与<code>LunarLander-v3</code>的概率分布类型也不同，前者是用的<code>Categorical</code>分类分布（从有限个离散动作中采样）是离散的，后者用的是MultivariateNormal分布（从连续动作空间中采样），是连续的。</p>
<h3 id="4-价值网络结构（Critic）-1"><a href="#4-价值网络结构（Critic）-1" class="headerlink" title="4.价值网络结构（Critic）"></a>4.价值网络结构（Critic）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.critic = nn.Sequential(  </span><br><span class="line">    nn.Linear(state_dim, <span class="number">64</span>),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(<span class="number">64</span>, <span class="number">32</span>),  </span><br><span class="line">    nn.Tanh(),  </span><br><span class="line">    nn.Linear(<span class="number">32</span>, <span class="number">1</span>)  </span><br><span class="line">)  </span><br><span class="line"><span class="variable language_">self</span>.action_var = torch.full((action_dim,), action_std * action_std).to(device)</span><br></pre></td></tr></table></figure>
<p><code>LunarLander-v3</code>中是通过Softmax输出的概率分布自然实现探索，不同动作有不同的采样概率。而这个例子中通过固定的方差矩阵控制探索，网络输出动作均值，方差固定（如0.5²）。</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>PPO_discrete</th>
<th>PPO_continuous</th>
</tr>
</thead>
<tbody><tr>
<td>网络结构</td>
<td>基本相同</td>
<td>基本相同</td>
</tr>
<tr>
<td>隐藏层</td>
<td>64→64</td>
<td>64→32</td>
</tr>
<tr>
<td>输出</td>
<td>状态价值（标量）</td>
<td>状态价值（标量）</td>
</tr>
<tr>
<td>功能</td>
<td>完全相同</td>
<td>完全相同</td>
</tr>
</tbody></table>
<p><strong>PPO 中策略评估（而非采样）阶段的核心</strong>，通常在更新策略前，对旧轨迹重新评估当前策略 π 的行为，以便计算 PPO 的剪切损失函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给定状态 state 和动作 action，评估当前策略对这些动作的 log 概率、状态值估计，以及策略分布的熵（用于鼓励探索）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, state, action</span>):  </span><br><span class="line">    <span class="comment"># 计算策略均值</span></span><br><span class="line">    action_mean = <span class="variable language_">self</span>.actor(state)  </span><br><span class="line">    <span class="comment"># 预设或可学习的方差张量</span></span><br><span class="line">    action_var = <span class="variable language_">self</span>.action_var.expand_as(action_mean)  </span><br><span class="line">    <span class="comment"># 构建对角协方差矩阵（只有对角线有值，代表各动作维度独立），用于构建多维正态分布</span></span><br><span class="line">    cov_mat = torch.diag_embed(action_var).to(device)  </span><br><span class="line">    <span class="comment"># 创建一个多维正态分布（动作策略分布），均值为 action_mean，协方差为 cov_mat</span></span><br><span class="line">    dist = MultivariateNormal(action_mean, cov_mat)  <span class="comment"># 多维正态分布</span></span><br><span class="line">    <span class="comment"># 计算 log 概率</span></span><br><span class="line">    action_logprobs = dist.log_prob(action)  </span><br><span class="line">    <span class="comment"># 计算分布的熵</span></span><br><span class="line">    dist_entropy = dist.entropy()  </span><br><span class="line">    <span class="comment"># 评估 Critic 值函数</span></span><br><span class="line">    state_value = <span class="variable language_">self</span>.critic(state)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># action_logprobs:当前策略下该动作的 log 概率（用于策略更新）</span></span><br><span class="line">    <span class="comment"># torch.squeeze(state_value) Critic 网络输出的状态值估计</span></span><br><span class="line">    <span class="comment"># dist_entropy 当前策略分布的熵（用于鼓励探索）</span></span><br><span class="line">    <span class="keyword">return</span> action_logprobs, torch.squeeze(state_value), dist_entropy</span><br></pre></td></tr></table></figure>
<h3 id="5-PPO算法实现-1"><a href="#5-PPO算法实现-1" class="headerlink" title="5.PPO算法实现"></a>5.PPO算法实现</h3><h4 id="1-代码实现-4"><a href="#1-代码实现-4" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PPO</span>:  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, state_dim, action_dim, action_std, lr, betas, gamma, K_epochs, eps_clip</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.lr = lr  </span><br><span class="line">        <span class="variable language_">self</span>.betas = betas  </span><br><span class="line">        <span class="variable language_">self</span>.gamma = gamma  <span class="comment"># 奖励折扣因子</span></span><br><span class="line">        <span class="variable language_">self</span>.eps_clip = eps_clip  <span class="comment"># PPO 剪切的 ε 参数</span></span><br><span class="line">        <span class="variable language_">self</span>.K_epochs = K_epochs  <span class="comment"># 每次更新中进行的迭代次数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当前策略</span></span><br><span class="line">        <span class="variable language_">self</span>.policy = ActorCritic(state_dim, action_dim, action_std).to(device)  </span><br><span class="line">        <span class="variable language_">self</span>.optimizer = torch.optim.Adam(<span class="variable language_">self</span>.policy.parameters(), lr=lr, betas=betas)  </span><br><span class="line">        <span class="comment"># 行动时用的旧策略（不更新）</span></span><br><span class="line">        <span class="variable language_">self</span>.policy_old = ActorCritic(state_dim, action_dim, action_std).to(device)  </span><br><span class="line">        <span class="variable language_">self</span>.policy_old.load_state_dict(<span class="variable language_">self</span>.policy.state_dict())  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.MseLoss = nn.MSELoss()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">self, state, memory</span>):  </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):  </span><br><span class="line">            state = state[<span class="number">0</span>]  </span><br><span class="line">        state = torch.FloatTensor(np.array(state).reshape(<span class="number">1</span>, -<span class="number">1</span>)).to(device)  </span><br><span class="line">        <span class="comment"># 输出的是一个连续动作向量，如 [0.23, -0.44]</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.policy_old.act(state, memory).cpu().data.numpy().flatten()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这部分与离散 PPO 大体一致</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, memory</span>):  <span class="comment"># PPO 策略更新</span></span><br><span class="line">        rewards = []  </span><br><span class="line">        discounted_reward = <span class="number">0</span>  </span><br><span class="line">        <span class="comment"># Monte Carlo 方式计算回报</span></span><br><span class="line">        <span class="keyword">for</span> reward, is_terminal <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">reversed</span>(memory.rewards), <span class="built_in">reversed</span>(memory.is_terminals)):  </span><br><span class="line">            <span class="keyword">if</span> is_terminal:  </span><br><span class="line">                discounted_reward = <span class="number">0</span>  </span><br><span class="line">            discounted_reward = reward + (<span class="variable language_">self</span>.gamma * discounted_reward)  </span><br><span class="line">            rewards.insert(<span class="number">0</span>, discounted_reward)  </span><br><span class="line">  </span><br><span class="line">        rewards = torch.tensor(rewards, dtype=torch.<span class="built_in">float</span>).to(device)  </span><br><span class="line">        <span class="comment"># 回报被标准化，以减少方差</span></span><br><span class="line">        rewards = (rewards - rewards.mean()) / (rewards.std() + <span class="number">1e-5</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 转换状态、动作、log_prob为 tensor</span></span><br><span class="line">        old_states = torch.squeeze(torch.stack(memory.states).to(device), <span class="number">1</span>).detach()  </span><br><span class="line">        old_actions = torch.squeeze(torch.stack(memory.actions).to(device), <span class="number">1</span>).detach()  </span><br><span class="line">        old_logprobs = torch.squeeze(torch.stack(memory.logprobs), <span class="number">1</span>).to(device).detach()  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.K_epochs):  </span><br><span class="line">            <span class="comment"># 评估当前策略  </span></span><br><span class="line">            <span class="comment"># logprobs: 当前策略对旧动作的 log π(a|s)</span></span><br><span class="line">            <span class="comment"># state_values: Critic 输出的 V(s)</span></span><br><span class="line">            <span class="comment"># dist_entropy: 多维高斯分布的熵，鼓励策略多样性</span></span><br><span class="line">            logprobs, state_values, dist_entropy = <span class="variable language_">self</span>.policy.evaluate(old_states, old_actions)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># PPO核心构造surrogate loss+剪切项</span></span><br><span class="line">            <span class="comment"># 剪切项控制策略更新幅度，防止新策略偏离旧策略太远，加入 value loss（Critic）和熵项（Actor 探索）</span></span><br><span class="line">            ratios = torch.exp(logprobs - old_logprobs.detach())  <span class="comment"># 概率比</span></span><br><span class="line">            advantages = rewards - state_values.detach()  </span><br><span class="line">            surr1 = ratios * advantages  </span><br><span class="line">            surr2 = torch.clamp(ratios, <span class="number">1</span> - <span class="variable language_">self</span>.eps_clip, <span class="number">1</span> + <span class="variable language_">self</span>.eps_clip) * advantages  </span><br><span class="line">            loss = -torch.<span class="built_in">min</span>(surr1, surr2) + <span class="number">0.5</span> * <span class="variable language_">self</span>.MseLoss(state_values, rewards) - <span class="number">0.01</span> * dist_entropy  </span><br><span class="line">            <span class="variable language_">self</span>.optimizer.zero_grad()  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 更新策略参数</span></span><br><span class="line">            loss.mean().backward()  </span><br><span class="line">            <span class="variable language_">self</span>.optimizer.step()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 最后更新策略，并将当前策略复制给 policy_old</span></span><br><span class="line">        <span class="variable language_">self</span>.policy_old.load_state_dict(<span class="variable language_">self</span>.policy.state_dict())</span><br></pre></td></tr></table></figure>
<h4 id="2-与离散动作-PPO的区别对比"><a href="#2-与离散动作-PPO的区别对比" class="headerlink" title="2.与离散动作 PPO的区别对比"></a>2.与离散动作 PPO的区别对比</h4><table>
<thead>
<tr>
<th><strong>项目</strong></th>
<th><strong>连续动作版</strong></th>
<th><strong>离散动作版</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>动作空间</strong></td>
<td>连续（多维向量）</td>
<td>离散（索引，如 0&#x2F;1&#x2F;2&#x2F;3）</td>
</tr>
<tr>
<td><strong>策略分布</strong></td>
<td>MultivariateNormal</td>
<td>Categorical</td>
</tr>
<tr>
<td><strong>动作采样</strong></td>
<td>高斯分布采样：dist.sample()</td>
<td>概率分布采样：dist.sample()</td>
</tr>
<tr>
<td><strong>log_prob</strong></td>
<td>dist.log_prob(action)（多维）</td>
<td>dist.log_prob(action)（离散）</td>
</tr>
<tr>
<td><strong>策略输出</strong></td>
<td>动作的<strong>均值</strong>（actor 输出）</td>
<td>动作的<strong>概率分布</strong>（softmax）</td>
</tr>
<tr>
<td><strong>方差来源</strong></td>
<td>固定或可学习的标准差 action_std</td>
<td>不需要方差</td>
</tr>
<tr>
<td><strong>evaluate()</strong></td>
<td>构建多维高斯分布（协方差矩阵）</td>
<td>构建离散分布（Categorical）</td>
</tr>
<tr>
<td><strong>适用环境</strong></td>
<td>如 LunarLanderContinuous-v2, BipedalWalker-v3</td>
<td>如 CartPole-v1, LunarLander-v3</td>
</tr>
</tbody></table>
<h3 id="6-训练参数与控制变量-1"><a href="#6-训练参数与控制变量-1" class="headerlink" title="6.训练参数与控制变量"></a>6.训练参数与控制变量</h3><h4 id="1-参数"><a href="#1-参数" class="headerlink" title="1.参数"></a>1.参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">render = <span class="literal">False</span>  <span class="comment"># 是否显示图形窗口（训练时通常关闭，测试时打开）</span></span><br><span class="line">solved_reward = <span class="number">300</span>  <span class="comment"># 如果过去若干轮的平均奖励超过 300，则认为任务完成</span></span><br><span class="line">log_interval = <span class="number">20</span>  <span class="comment"># 每训练多少回合打印一次日志</span></span><br><span class="line">max_episodes = <span class="number">10000</span>  <span class="comment"># 最大训练轮数（episode），每轮指一局游戏</span></span><br><span class="line">max_timesteps = <span class="number">1500</span>  <span class="comment"># 每局最多运行多少步，步数用完或 agent 死亡则 episode 结束</span></span><br><span class="line">  </span><br><span class="line">update_timestep = <span class="number">4000</span>  <span class="comment"># 每收集多少个环境步数后执行一次策略网络的更新  </span></span><br><span class="line">action_std = <span class="number">0.5</span>  <span class="comment"># 动作标准差（仅用于连续动作），控制策略输出高斯分布的探索强度。 </span></span><br><span class="line">K_epochs = <span class="number">80</span>  <span class="comment"># 每次策略更新时，进行多少轮优化 </span></span><br><span class="line">eps_clip = <span class="number">0.2</span>  <span class="comment"># PPO 的裁剪范围，用于限制新旧策略的变动，保持训练稳定。</span></span><br><span class="line">gamma = <span class="number">0.99</span>  <span class="comment"># 奖励折扣因子，控制未来奖励的重要性。0.99 表示非常看重长远回报。</span></span><br><span class="line">  </span><br><span class="line">lr = <span class="number">0.0003</span>  <span class="comment"># 学习率</span></span><br><span class="line">betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)  <span class="comment"># 动量</span></span><br><span class="line">  </span><br><span class="line">random_seed = <span class="literal">None</span>  <span class="comment"># 随机种子，控制训练的可复现性</span></span><br></pre></td></tr></table></figure>
<h4 id="2-区别"><a href="#2-区别" class="headerlink" title="2.区别"></a>2.区别</h4><table>
<thead>
<tr>
<th><strong>连续动作（如 BipedalWalker）</strong></th>
<th><strong>离散动作（如 LunarLander）</strong></th>
<th><strong>区别说明</strong></th>
<th><strong>解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td>action_std</td>
<td>有，设定高斯分布方差</td>
<td>无</td>
<td>离散动作不需要方差</td>
</tr>
<tr>
<td>K_epochs</td>
<td>通常较大（如 80）</td>
<td>较小（如 4）</td>
<td>连续动作难度大，更新次数多</td>
</tr>
<tr>
<td>update_timestep</td>
<td>大（如 4000）</td>
<td>小（如 2000）</td>
<td>连续动作需要积累更多经验再训练</td>
</tr>
<tr>
<td>action_dim</td>
<td>实数向量维度</td>
<td>整数类别数</td>
<td>连续动作需要输出一个动作向量</td>
</tr>
<tr>
<td>策略分布</td>
<td>MultivariateNormal</td>
<td>Categorical</td>
<td>前者生成连续动作，后者选择概率最大的动作</td>
</tr>
<tr>
<td>Actor 输出</td>
<td>动作的均值（连续向量）</td>
<td>动作的概率（Softmax）</td>
<td>连续 vs 离散策略网络结构不同</td>
</tr>
</tbody></table>
<h3 id="7-训练流程-1"><a href="#7-训练流程-1" class="headerlink" title="7.训练流程"></a>7.训练流程</h3><h4 id="1-代码实现-5"><a href="#1-代码实现-5" class="headerlink" title="1.代码实现"></a>1.代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 训练参数与控制变量</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建环境与状态空间、动作空间维度</span></span><br><span class="line">    env = gym.make(env_name)  </span><br><span class="line">    <span class="comment"># 状态维度，如 24（对 BipedalWalker）</span></span><br><span class="line">    state_dim = env.observation_space.shape[<span class="number">0</span>]  </span><br><span class="line">    action_dim = env.action_space.shape[<span class="number">0</span>]  <span class="comment"># 连续动作维度，如 4（对 BipedalWalker）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置随机种子（可选）</span></span><br><span class="line">    <span class="keyword">if</span> random_seed:  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Random Seed: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(random_seed))  </span><br><span class="line">        torch.manual_seed(random_seed)  </span><br><span class="line">        env.seed(random_seed)  </span><br><span class="line">        np.random.seed(random_seed)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 PPO、Memory</span></span><br><span class="line">    memory = Memory()  </span><br><span class="line">    ppo = PPO(state_dim, action_dim, action_std, lr, betas, gamma, K_epochs, eps_clip)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建日志变量</span></span><br><span class="line">    running_reward = <span class="number">0</span>  </span><br><span class="line">    avg_length = <span class="number">0</span>  </span><br><span class="line">    time_step = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 主训练循环（每个 episode）</span></span><br><span class="line">    <span class="keyword">for</span> i_episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, max_episodes + <span class="number">1</span>):  </span><br><span class="line">        state = env.reset()  <span class="comment"># 每轮开始时重置环境</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps):  </span><br><span class="line">            time_step += <span class="number">1</span>  </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 每个 timestep 采样动作并交互</span></span><br><span class="line">            action = ppo.select_action(state, memory)  </span><br><span class="line">            next_state, reward, done, truncated, _ = env.step(action)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 存储经验、更新策略 </span></span><br><span class="line">            memory.rewards.append(reward)  </span><br><span class="line">            memory.is_terminals.append(done)  </span><br><span class="line">            <span class="keyword">if</span> time_step % update_timestep == <span class="number">0</span>:  </span><br><span class="line">                ppo.update(memory)  </span><br><span class="line">                memory.clear_memory()  </span><br><span class="line">                time_step = <span class="number">0</span>  </span><br><span class="line">            </span><br><span class="line">            running_reward += reward  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 渲染与终止处理</span></span><br><span class="line">            <span class="keyword">if</span> render:  </span><br><span class="line">                env.render()  </span><br><span class="line">            <span class="keyword">if</span> done:  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        avg_length += t  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> running_reward &gt; (log_interval * solved_reward):  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;########## Solved! ##########&quot;</span>)  </span><br><span class="line">            torch.save(ppo.policy.state_dict(), <span class="string">&#x27;./PPO_continuous_solved_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(env_name))  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line">        <span class="keyword">if</span> i_episode % <span class="number">500</span> == <span class="number">0</span>:  </span><br><span class="line">            torch.save(ppo.policy.state_dict(), <span class="string">&#x27;./PPO_continuous_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(env_name))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 日志输出</span></span><br><span class="line">        <span class="keyword">if</span> i_episode % log_interval == <span class="number">0</span>:  </span><br><span class="line">            avg_length = <span class="built_in">int</span>(avg_length / log_interval)  </span><br><span class="line">            running_reward = <span class="built_in">int</span>((running_reward / log_interval))  </span><br><span class="line">  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Episode &#123;&#125; \t Avg length: &#123;&#125; \t Avg reward: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i_episode, avg_length, running_reward))  </span><br><span class="line">            running_reward = <span class="number">0</span>  </span><br><span class="line">            avg_length = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4 id="2-训练日志-1"><a href="#2-训练日志-1" class="headerlink" title="2.训练日志"></a>2.训练日志</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Episode 20 	 Avg length: 299 	 Avg reward: -100</span><br><span class="line">Episode 40 	 Avg length: 448 	 Avg reward: -96</span><br><span class="line">Episode 60 	 Avg length: 503 	 Avg reward: -94</span><br><span class="line">Episode 80 	 Avg length: 436 	 Avg reward: -95</span><br><span class="line">Episode 100 	 Avg length: 516 	 Avg reward: -91</span><br><span class="line">Episode 120 	 Avg length: 716 	 Avg reward: -84</span><br><span class="line">Episode 140 	 Avg length: 791 	 Avg reward: -81</span><br><span class="line">Episode 160 	 Avg length: 1069 	 Avg reward: -71</span><br><span class="line">Episode 180 	 Avg length: 1427 	 Avg reward: -61</span><br><span class="line">Episode 200 	 Avg length: 1357 	 Avg reward: -57</span><br><span class="line">Episode 220 	 Avg length: 1427 	 Avg reward: -57</span><br><span class="line">Episode 240 	 Avg length: 1285 	 Avg reward: -64</span><br><span class="line">Episode 260 	 Avg length: 1357 	 Avg reward: -56</span><br><span class="line">Episode 280 	 Avg length: 1004 	 Avg reward: -69</span><br><span class="line">Episode 300 	 Avg length: 1123 	 Avg reward: -75</span><br><span class="line">Episode 320 	 Avg length: 744 	 Avg reward: -90</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h4 id="3-与离散动作版本相比"><a href="#3-与离散动作版本相比" class="headerlink" title="3.与离散动作版本相比"></a>3.与离散动作版本相比</h4><table>
<thead>
<tr>
<th><strong>方面</strong></th>
<th><strong>连续动作 main()</strong></th>
<th><strong>离散动作 main()</strong></th>
<th><strong>区别说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>动作类型</td>
<td>实数向量（np.array）</td>
<td>整数（类别编号）</td>
<td>连续动作使用多元高斯策略，离散使用分类策略</td>
</tr>
<tr>
<td>action_dim</td>
<td>env.action_space.shape[0]</td>
<td>手动设为 4（动作数量）</td>
<td>离散动作为固定离散集合，连续动作为多维实数</td>
</tr>
<tr>
<td>策略网络输出</td>
<td>动作均值 μ</td>
<td>动作概率分布</td>
<td>连续输出用于高斯分布采样，离散输出用于 softmax</td>
</tr>
<tr>
<td>action_std</td>
<td>需要设定（探索强度）</td>
<td>不使用</td>
<td>连续策略的探索来自方差，离散策略来自随机采样概率</td>
</tr>
<tr>
<td>ppo.select_action()</td>
<td>返回实数向量</td>
<td>返回动作索引</td>
<td>两者行为一致，输出形式不同</td>
</tr>
<tr>
<td>策略更新频率</td>
<td>通常设较大 update_timestep&#x3D;4000</td>
<td>通常较小（如 2000）</td>
<td>连续策略收敛慢，需要更多经验和更新步</td>
</tr>
<tr>
<td>K_epochs</td>
<td>大（如 80）</td>
<td>小（如 4）</td>
<td>连续动作策略更新更频繁以稳定训练</td>
</tr>
</tbody></table>
<h3 id="8-模型验证-1"><a href="#8-模型验证-1" class="headerlink" title="8.模型验证"></a>8.模型验证</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">render_bipedal_walker</span>():  </span><br><span class="line">    env_name = <span class="string">&quot;BipedalWalker-v3&quot;</span>  </span><br><span class="line">    env = gym.make(env_name, render_mode=<span class="string">&quot;human&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    state_dim = env.observation_space.shape[<span class="number">0</span>]  <span class="comment"># 获取状态空间维度（如 24）</span></span><br><span class="line">    action_dim = env.action_space.shape[<span class="number">0</span>]  <span class="comment"># 动作空间维度（如 4）</span></span><br><span class="line">  </span><br><span class="line">    n_episodes = <span class="number">3</span>  </span><br><span class="line">    max_timesteps = <span class="number">1500</span>  </span><br><span class="line">  </span><br><span class="line">    filename = <span class="string">f&quot;PPO_continuous_<span class="subst">&#123;env_name&#125;</span>.pth&quot;</span>  <span class="comment"># 模型文件</span></span><br><span class="line">    directory = <span class="string">&quot;./&quot;</span>  </span><br><span class="line">  </span><br><span class="line">    action_std = <span class="number">0.5</span>  </span><br><span class="line">    K_epochs = <span class="number">80</span>  </span><br><span class="line">    eps_clip = <span class="number">0.2</span>  </span><br><span class="line">    gamma = <span class="number">0.99</span>  </span><br><span class="line">    lr = <span class="number">0.0003</span>  </span><br><span class="line">    betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)  </span><br><span class="line">  </span><br><span class="line">    memory = Memory()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载训练好的策略模型</span></span><br><span class="line">    ppo = PPO(state_dim, action_dim, action_std, lr, betas, gamma, K_epochs, eps_clip)  </span><br><span class="line">    ppo.policy_old.load_state_dict(torch.load(directory + filename, weights_only=<span class="literal">True</span>))  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 运行并渲染每个 Episode</span></span><br><span class="line">    <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_episodes + <span class="number">1</span>):  </span><br><span class="line">        ep_reward = <span class="number">0</span>  </span><br><span class="line">        state, _ = env.reset()  <span class="comment"># 重置环境开始新一轮</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每一步执行 PPO 策略并交互环境</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps):  </span><br><span class="line">            action = ppo.select_action(state, memory)  </span><br><span class="line">            state, reward, terminated, truncated, _ = env.step(action)  </span><br><span class="line">            ep_reward += reward  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">try</span>:  </span><br><span class="line">                env.render()  </span><br><span class="line">                pygame.event.pump()  <span class="comment"># 防止 Pygame 卡死或被系统关闭  </span></span><br><span class="line">            <span class="keyword">except</span> pygame.error:  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;⚠️ Pygame window was closed. Skipping rendering.&quot;</span>)  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 检查是否结束</span></span><br><span class="line">            <span class="keyword">if</span> terminated <span class="keyword">or</span> truncated:  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出当前 episode 总奖励</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Episode: <span class="subst">&#123;ep&#125;</span>\tReward: <span class="subst">&#123;<span class="built_in">int</span>(ep_reward)&#125;</span>&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    env.close()  <span class="comment"># 在所有 episode 后统一关闭</span></span><br></pre></td></tr></table></figure>
<p>日志输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Episode: 1	Reward: 37</span><br><span class="line">Episode: 2	Reward: 259</span><br><span class="line">Episode: 3	Reward: 263</span><br></pre></td></tr></table></figure>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><h3 id="1-PPO核心优势​"><a href="#1-PPO核心优势​" class="headerlink" title="1.PPO核心优势​"></a>1.PPO核心优势​</h3><ul>
<li>创新剪切机制：通过约束策略更新幅度（概率比剪切），解决策略突变问题</li>
<li>高效稳定：GAE平衡偏差&#x2F;方差，双网络架构实现多轮数据复用</li>
<li>工程友好：相比TRPO更易实现</li>
</ul>
<h3 id="2-动作空间关键差异​"><a href="#2-动作空间关键差异​" class="headerlink" title="2.动作空间关键差异​"></a>2.动作空间关键差异​</h3><table>
<thead>
<tr>
<th>​<strong>特性</strong>​</th>
<th>​<strong>离散动作空间</strong>​</th>
<th>​<strong>连续动作空间</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>策略输出</strong>​</td>
<td>Softmax概率分布</td>
<td>Tanh均值向量</td>
</tr>
<tr>
<td>​<strong>采样分布</strong>​</td>
<td>Categorical（分类分布）</td>
<td>MultivariateNormal（多元正态）</td>
</tr>
<tr>
<td>​<strong>探索机制</strong>​</td>
<td>概率采样</td>
<td>固定&#x2F;可学习方差</td>
</tr>
<tr>
<td>​<strong>环境举例</strong>​</td>
<td>LunarLander（飞船着陆）</td>
<td>BipedalWalker（双足行走）</td>
</tr>
<tr>
<td>​<strong>训练参数差异</strong>​</td>
<td>K_epochs小（≈4）</td>
<td>K_epochs大（≈80）</td>
</tr>
</tbody></table>
<h3 id="3-工程实现要点​"><a href="#3-工程实现要点​" class="headerlink" title="3. 工程实现要点​"></a>3. 工程实现要点​</h3><ul>
<li>​<strong>离散动作</strong>​：输出层Softmax → 动作概率 → Categorical采样 → 动作索引</li>
<li>​<strong>连续动作</strong>​：输出层Tanh → 动作均值 + 固定方差 → 多维正态分布采样 → 动作向量</li>
<li>​<strong>关键技巧</strong>​：通过GAE优化优势估计；通过回报标准化加速收敛；熵奖励项促进探索；通过旧策略冻结保证采样一致性</li>
</ul>
<h3 id="4-环境对比​"><a href="#4-环境对比​" class="headerlink" title="4. 环境对比​"></a>4. 环境对比​</h3><ul>
<li>​<strong>LunarLander</strong>​：8维状态&#x2F;4离散动作，300步内收敛</li>
<li>​<strong>BipedalWalker</strong>​：24维状态&#x2F;4连续动作，需&gt;1500步更复杂训练</li>
</ul>
<p>PPO通过统一框架适配两类动作空间，其剪切机制和双网络设计在保证稳定性的同时，为机器人控制、游戏AI等领域提供了高效解决方案。<br>离散&#x2F;连续实现的差异主要在于策略表征和采样机制。</p>
<h2 id="5-备注"><a href="#5-备注" class="headerlink" title="5.备注"></a>5.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>numpy: 1.26.4</li>
<li>gym: 0.26.2</li>
<li>box2d-py: 2.3.8</li>
</ul>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/026_PPO_code">https://github.com/keychankc/dl_code_for_blog/tree/main/026_PPO_code</a></p>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>策略优化</tag>
        <tag>PPO</tag>
        <tag>离散动作</tag>
        <tag>连续动作</tag>
      </tags>
  </entry>
  <entry>
    <title>DQN(Deep Q-Network)系列算法解析与实践</title>
    <url>/2025/08/14/027-rl-dqn-case/</url>
    <content><![CDATA[<h2 id="1-任务与背景介绍"><a href="#1-任务与背景介绍" class="headerlink" title="1. 任务与背景介绍"></a>1. 任务与背景介绍</h2><p>在 Gym&#x2F;Gymnasium 的 <strong>MountainCar-v0</strong> 环境中，有这样一个场景：一辆小车被困在两个山坡之间，目标是到达右侧山坡顶端的红旗位置。</p>
<p>乍一看，这似乎只需要踩油门往右冲就行，但现实并非如此，小车的发动机动力不足，单次加速无法直接登顶，它会在半途滑落回谷底。正确的策略是先向左加速爬上左坡，然后顺势向右冲下去，再反复摆动、积累动能，最终才能冲上右侧山顶。</p>
<span id="more"></span>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/mountaincar_ep3.gif"></p>
<h3 id="1-1-环境参数"><a href="#1-1-环境参数" class="headerlink" title="1.1 环境参数"></a>1.1 环境参数</h3><p>在 <strong>MountainCar-v0</strong> 中，环境由以下元素构成：</p>
<ul>
<li><strong>状态（State）</strong>：小车的水平位置与速度（连续值）</li>
<li><strong>动作（Action）</strong>：三个离散动作<ol>
<li>向左加速（0）</li>
<li>向右加速（2）</li>
<li>不加速（no push）</li>
</ol>
</li>
<li><strong>奖励（Reward）</strong>：<ul>
<li>每执行一步都会收到 <strong>-1</strong> 惩罚（鼓励尽快完成任务）</li>
<li>到达山顶时获得额外奖励并结束回合</li>
</ul>
</li>
</ul>
<h3 id="1-2-任务性质"><a href="#1-2-任务性质" class="headerlink" title="1.2 任务性质"></a>1.2 任务性质</h3><p>这是一个<strong>离散动作空间的决策问题</strong>，适合用 DQN 解决，原因如下：</p>
<ol>
<li><strong>动作空间小且离散</strong>（3 个动作），可直接用 Q 值表示各动作价值</li>
<li><strong>状态空间连续</strong>（位置、速度），传统 Q 表难以应用，需要神经网络来近似 Q 值函数</li>
<li><strong>延迟回报明显</strong>：到达山顶的奖励需要经过一系列操作才能获得，算法必须学会权衡眼前损失与未来收益</li>
</ol>
<h3 id="1-3-问题难点"><a href="#1-3-问题难点" class="headerlink" title="1.3 问题难点"></a>1.3 问题难点</h3><ul>
<li><strong>动力不足</strong>：无法直接登顶，必须借助坡道助跑</li>
<li><strong>积累动能</strong>：需要多次反向加速形成足够速度</li>
<li><strong>奖励稀疏</strong>：过程几乎全是负奖励，只有成功登顶才有正反馈</li>
<li><strong>探索必要性</strong>：如果只向右加速，几乎不可能完成任务，必须探索反向助跑策略</li>
</ul>
<h3 id="1-4-为什么用-DQN"><a href="#1-4-为什么用-DQN" class="headerlink" title="1.4 为什么用 DQN"></a>1.4 为什么用 DQN</h3><p>DQN 在此类任务中有天然优势：</p>
<ul>
<li>能学习<strong>长期回报</strong>，避免只追求即时收益</li>
<li><strong>ε-贪婪策略</strong>让智能体有机会探索看似“错误”的操作（如向左加速），发现更优路径</li>
<li>结合<strong>经验回放</strong>与<strong>目标网络</strong>，在连续状态空间中稳定学习高价值动作序列</li>
</ul>
<h2 id="2-DQN-基本原理"><a href="#2-DQN-基本原理" class="headerlink" title="2. DQN 基本原理"></a>2. DQN 基本原理</h2><h3 id="2-1-Q-Learning"><a href="#2-1-Q-Learning" class="headerlink" title="2.1 Q-Learning"></a>2.1 Q-Learning</h3><h4 id="2-1-1-Q-Learning回顾"><a href="#2-1-1-Q-Learning回顾" class="headerlink" title="2.1.1 Q-Learning回顾"></a>2.1.1 Q-Learning回顾</h4><p>在讲 DQN 之前，我们先回顾一下 <strong>Q-Learning</strong>，因为 DQN 其实就是 Q-Learning 在<strong>高维连续状态空间</strong>下的一种扩展。</p>
<p>Q-Learning 是一种 <strong>值迭代算法</strong>，核心思想是学习一个状态–动作价值函数 $Q(s,a)$，这个函数表示在状态 $s$ 下执行动作 $a$ 并按最优策略继续下去所能获得的期望回报。<br>它的更新公式为：<br>$$Q(s,a) \leftarrow Q(s,a) + \alpha \big[ r + \gamma \max{a’} Q(s’,a’) - Q(s,a) \big]$$<br>在离散、低维的状态空间里，Q 值可以直接用一个表（Q 表）存储，并在不断交互中更新。</p>
<p>如果省略学习率 α 并直接用目标替换原值，就得到核心形式：<br>$$Q(s, a) &#x3D; r + \gamma max_{a’} Q(s’, a’) $$<br>这里：</p>
<ul>
<li>$r$：当前动作的即时奖励</li>
<li>$\gamma$：折扣因子（0~1 之间），衡量未来奖励的重要性</li>
<li>$\max_{a’} Q(s’, a’)$表示：假设在下一个状态选择最优动作时的未来价值</li>
</ul>
<h4 id="2-1-2-即时奖励-vs-未来回报"><a href="#2-1-2-即时奖励-vs-未来回报" class="headerlink" title="2.1.2 即时奖励 vs. 未来回报"></a>2.1.2 即时奖励 vs. 未来回报</h4><p>在小车登山任务中：</p>
<ul>
<li><strong>即时奖励</strong>：每一步都是 -1（让你尽快到达山顶）</li>
<li><strong>未来回报</strong>：一旦到达山顶，获得额外奖励</li>
</ul>
<p>Q-Learning 的优势在于，它会同时考虑当前奖励和未来回报。<br>比如，如果现在向左加速会让你离山顶更远（即时奖励差），但能积累动能从而之后登顶（未来回报高），Q 值会判断这是值得的。<br>这正是强化学习解决延迟回报问题的关键。</p>
<h3 id="2-2-DQN"><a href="#2-2-DQN" class="headerlink" title="2.2 DQN"></a>2.2 DQN</h3><h4 id="2-2-1-为什么要用深度网络替代表格？"><a href="#2-2-1-为什么要用深度网络替代表格？" class="headerlink" title="2.2.1 为什么要用深度网络替代表格？"></a>2.2.1 为什么要用深度网络替代表格？</h4><p>在经典 Q-Learning 中，Q 值通常存储在一个<strong>状态-动作表</strong>（Q 表）里。但在小车登山任务中，<strong>状态是连续值</strong>（位置、速度），可能有无数个组合。如果用表格存储，每个状态都需要一行，不好存储。<br>于是，<strong>DQN（Deep Q-Network）</strong> 用一个神经网络来逼近 Q 值函数：</p>
<ul>
<li>输入：状态向量（位置、速度）</li>
<li>输出：该状态下每个动作的 Q 值（3 个数）</li>
<li>优势：不需要穷举所有状态，能在相似状态之间<strong>泛化</strong>学习成果</li>
</ul>
<h4 id="2-2-2-主网络-目标网络"><a href="#2-2-2-主网络-目标网络" class="headerlink" title="2.2.2 主网络 &amp; 目标网络"></a>2.2.2 主网络 &amp; 目标网络</h4><p>DQN 有两个几乎一模一样的网络：</p>
<ol>
<li><strong>主网络（Online Q-Network）</strong>：每次更新时使用它来预测当前状态的 Q 值，并进行梯度下降优化。</li>
<li><strong>目标网络（Target Q-Network）</strong>：在计算目标值时使用，参数更新得更慢（例如每隔 N 步从主网络复制一次）。</li>
</ol>
<p><strong>为什么要两个网络？</strong><br>如果目标值直接由主网络实时计算，会导致更新过程不稳定，因为目标和预测值来自同一个会不断变化的网络。引入目标网络可以让目标在一段时间内保持相对稳定，从而减少训练振荡。</p>
<p><strong>类比解释：“现在的自己” vs. “过去的自己”</strong><br>可以把两个网络类比成：</p>
<ul>
<li><strong>主网络</strong> &#x3D; 现在的自己（每天学习新知识，变化很快）</li>
<li><strong>目标网络</strong> &#x3D; 过去的自己（定期拍个快照，参考当时的想法）</li>
</ul>
<p>学习的时候：</p>
<ul>
<li>主网络负责提出<strong>当前的理解</strong>（预测 Q 值）</li>
<li>目标网络提供一个<strong>相对稳定的参考答案</strong>（计算目标值）</li>
<li>过一段时间，过去的自己会更新为现在的自己（同步参数）</li>
</ul>
<p>这种设计，让 DQN 既能快速学习，又不至于因为目标值不停抖动而陷入不稳定。</p>
<h2 id="3-DQN-核心组件"><a href="#3-DQN-核心组件" class="headerlink" title="3. DQN 核心组件"></a>3. DQN 核心组件</h2><h3 id="3-1-主网络（Online-Q-Network）"><a href="#3-1-主网络（Online-Q-Network）" class="headerlink" title="3.1 主网络（Online Q-Network）"></a>3.1 主网络（Online Q-Network）</h3><p><strong>主网络（Online Q-Network）</strong> 的作用是接收当前状态 $s$（位置、速度），输出该状态下每个可能动作的 Q 值。在训练中，主网络是实时更新的，利用梯度下降不断调整参数，让预测的 Q 值更接近目标 Q 值。</p>
<p>在小车登山这个例子中，当小车处于“靠近左坡顶、速度向右”的状态时，主网络会输出三个数：</p>
<ul>
<li>向左加速 Q 值</li>
<li>向右加速 Q 值</li>
<li>不动 Q 值</li>
</ul>
<p>算法会选择其中 Q 值最大的动作（除非在探索阶段）。</p>
<h3 id="3-2-目标网络（Target-Q-Network）"><a href="#3-2-目标网络（Target-Q-Network）" class="headerlink" title="3.2 目标网络（Target Q-Network）"></a>3.2 目标网络（Target Q-Network）</h3><p>目标网络主要是计算目标 Q 值时使用，目的是保持一段时间内不变，减少训练振荡。更新方式其实不是每次训练都更新，而是每隔固定步数，将主网络的参数复制给目标网络。</p>
<p><strong>小车登山类比</strong>：</p>
<ul>
<li>主网络 &#x3D; “现在的自己”，每次都在调整思路</li>
<li>目标网络 &#x3D; “过去的自己”，一段时间才更新一次观点</li>
</ul>
<p>这样，主网络在学习时总是参考一个相对稳定的“过去自己”，不至于因为目标值不断变化而陷入混乱。</p>
<h3 id="3-3-经验回放池（Replay-Buffer）"><a href="#3-3-经验回放池（Replay-Buffer）" class="headerlink" title="3.3 经验回放池（Replay Buffer）"></a>3.3 经验回放池（Replay Buffer）</h3><p>经验回放池的主要作用是存储过去的状态、动作、奖励、下一状态等（即 transition），并在训练时随机抽取一批样本进行学习。<br> 这样做的好处有：</p>
<ol>
<li><strong>打乱数据相关性</strong>：环境中的数据是连续的（比如小车一直在左坡上下摆动），直接用会导致模型过拟合特定轨迹</li>
<li><strong>提升样本利用率</strong>：同一条经验可以多次用于训练，而不是用一次就丢掉</li>
</ol>
<p><strong>还是以小车登山举例</strong>：<br>如果没有经验回放，小车可能连续 100 步都在左坡附近，这些相似数据会让模型短时间内“只记得左坡的事”。而有了 Replay Buffer，我们可以把过去不同位置的经验混合，让网络更全面地学习。</p>
<h3 id="3-4-ε-贪婪策略"><a href="#3-4-ε-贪婪策略" class="headerlink" title="3.4 ε-贪婪策略"></a>3.4 ε-贪婪策略</h3><p>ε-贪婪策略的主要作用是在训练过程中平衡 探索（<strong>Exploration</strong>）与利用（<strong>Exploitation</strong>）。<br><strong>规则</strong>：    </p>
<ul>
<li>以概率 $\varepsilon$ 随机选择一个动作（探索）        </li>
<li>以概率 $1 - \varepsilon$ 选择当前 Q 值最高的动作（利用）</li>
</ul>
<p><strong>动态调整</strong>：通常从较大的 $\varepsilon$ 开始（更多探索），然后逐渐减小（更多利用）。</p>
<p><strong>还是以小车登山例子</strong>：<br>刚开始，小车可能会随机向左冲、向右冲甚至不动——这有助于发现“先向左加速再向右冲顶”的策略。随着训练进行，ε 会逐渐降低，小车会更多地按照学到的最优策略去冲山顶。</p>
<p>这四个组件在 DQN 中缺一不可：</p>
<ol>
<li><strong>主网络</strong>：负责当前 Q 值预测    </li>
<li><strong>目标网络</strong>：提供稳定的学习目标</li>
<li><strong>经验回放池</strong>：打乱相关性、提升数据利用率</li>
<li><strong>ε-贪婪策略</strong>：保证探索与利用的平衡</li>
</ol>
<p>结合起来，DQN 能够在像小车登山这种<strong>连续状态 + 离散动作 + 延迟回报</strong>的任务中稳定、高效地学出策略。</p>
<h2 id="4-训练流程解析"><a href="#4-训练流程解析" class="headerlink" title="4.训练流程解析"></a>4.训练流程解析</h2><h3 id="4-1-DQN网络定义"><a href="#4-1-DQN网络定义" class="headerlink" title="4.1 DQN网络定义"></a>4.1 DQN网络定义</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DQN</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, state_dim, action_dim</span>):  </span><br><span class="line">        <span class="built_in">super</span>(DQN, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="comment"># 两层隐层 MLP，将连续状态映射到每个离散动作的 Q 值  </span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(state_dim, <span class="number">128</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">128</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">128</span>, action_dim)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc1(x))  </span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc2(x))  </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc3(x) <span class="comment"># 输出形状：[batch, action_dim]，即 Q(s, ·)  </span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-模型训练实现"><a href="#4-2-模型训练实现" class="headerlink" title="4.2 模型训练实现"></a>4.2 模型训练实现</h3><p>DQN 的大致训练流程：</p>
<ol>
<li>初始化网络、经验池、优化器</li>
<li>重置环境，得到初始状态</li>
<li>按 ε-贪婪策略选择动作</li>
<li>执行动作，获取下一状态、奖励、结束标记</li>
<li>存储 (s, a, r, s′) 到经验池</li>
<li>如果经验池样本数达阈值：采样 batch，计算目标，反向传播</li>
<li>每隔固定步数同步目标网络参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():  </span><br><span class="line">    <span class="comment"># ===== (1) 初始化网络、经验池、优化器 =====</span></span><br><span class="line">    env = gym.make(<span class="string">&quot;MountainCar-v0&quot;</span>)  </span><br><span class="line">    <span class="comment"># state: 2维 [position, velocity]</span></span><br><span class="line">    state_dim = env.observation_space.shape[<span class="number">0</span>]  </span><br><span class="line">    <span class="comment"># action: 3个离散动作：左推、无操作、右推</span></span><br><span class="line">    action_dim = env.action_space.n  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 超参数</span></span><br><span class="line">    gamma = <span class="number">0.99</span>  <span class="comment"># 折扣因子，衡量未来奖励在当前决策中的重要程度</span></span><br><span class="line">    epsilon = <span class="number">1.0</span>  <span class="comment"># ε-贪婪策略初始探索率，ε1.0意味着第一回合几乎全随机选动作</span></span><br><span class="line">    epsilon_min = <span class="number">0.01</span>  <span class="comment"># 最小探索率，保留一小部分随机动作（1% 概率），防止策略僵化</span></span><br><span class="line">    epsilon_decay = <span class="number">0.995</span>  <span class="comment"># 每回合结束后对 ε 做指数衰减（更快收敛）</span></span><br><span class="line">    lr = <span class="number">1e-3</span>  <span class="comment"># 学习率，控制每次参数更新的步幅大小</span></span><br><span class="line">    batch_size = <span class="number">64</span>  <span class="comment"># 批量大小，每次从经验池里采多少条样本来更新网络</span></span><br><span class="line">    target_update_freq = <span class="number">500</span>  <span class="comment"># 目标网络更新频率，每隔多少环境步同步一次目标网络</span></span><br><span class="line">    max_episodes = <span class="number">600</span>  <span class="comment"># 最大训练回合数</span></span><br><span class="line">    memory_size = <span class="number">50000</span>  <span class="comment"># 经验回放池容量</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 构建主网络 &amp; 目标网络（结构相同）  </span></span><br><span class="line">    online_net = DQN(state_dim, action_dim)  </span><br><span class="line">    target_net = DQN(state_dim, action_dim)  </span><br><span class="line">    target_net.load_state_dict(online_net.state_dict())  <span class="comment"># 初始先对齐</span></span><br><span class="line">    optimizer = optim.Adam(online_net.parameters(), lr=lr)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 经验回放池：存储 (s, a, r, s′, done)</span></span><br><span class="line">    memory = deque(maxlen=memory_size)  </span><br><span class="line">  </span><br><span class="line">    total_steps = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(max_episodes):  </span><br><span class="line">        <span class="comment"># ===== (2) 重置环境，得到初始状态 =====</span></span><br><span class="line">        state, _ = env.reset()  </span><br><span class="line">        total_reward = <span class="number">0</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 一个回合最多 200 步（MountainCar的默认上限）</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):  </span><br><span class="line">            total_steps += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ===== (3) 按ε-贪婪策略选择动作 =====</span></span><br><span class="line">            <span class="comment"># 以ε的概率做随机动作（探索），否则选Q值最大的动作</span></span><br><span class="line">            <span class="keyword">if</span> random.random() &lt; epsilon:  </span><br><span class="line">                <span class="comment"># 探索：从动作空间随机采一个动作，0（左加速）、1（不动）、2（右加速）</span></span><br><span class="line">                action = env.action_space.sample()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="comment"># 利用</span></span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">                    <span class="comment"># [position, velocity] -&gt; tensor</span></span><br><span class="line">                    state_tensor = torch.FloatTensor(state).unsqueeze(<span class="number">0</span>) </span><br><span class="line">                    <span class="comment"># 把当前状态输入DQN主网络，得到每个可能动作的Q值 -&gt; [1, action_dim]</span></span><br><span class="line">                    q_values = online_net(state_tensor)  </span><br><span class="line">                    <span class="comment"># 找出Q值最大的动作的索引(最优动作)</span></span><br><span class="line">                    action = q_values.argmax().item()  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ===== (4) 执行动作，获取下一状态、奖励、结束标记 =====</span></span><br><span class="line">            next_state, reward, terminated, truncated, _ = env.step(action)  </span><br><span class="line">            done = terminated <span class="keyword">or</span> truncated  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ---- 奖励塑形（可选）----</span></span><br><span class="line">            <span class="comment"># 这里额外加了 abs(position - (-0.5))，鼓励远离谷底（-0.5）向两侧移动，</span></span><br><span class="line">            <span class="comment"># 使学到“先左后右”的策略更容易出现（尤其在稀疏奖励场景）。 </span></span><br><span class="line">            position, velocity = next_state  </span><br><span class="line">            reward += <span class="built_in">abs</span>(position - (-<span class="number">0.5</span>))  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ===== (5) 存储 (s, a, r, s′, done) 到经验池 =====</span></span><br><span class="line">            memory.append((state, action, reward, next_state, done))  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 状态推进到下一步</span></span><br><span class="line">            state = next_state  </span><br><span class="line">            total_reward += reward  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ===== (6) 如果经验池样本数达阈值：开始学习 =====</span></span><br><span class="line">            <span class="comment"># 这里用“&gt; 1000”作为启动学习的阈值，避免一开始样本过少导致过拟合/发散</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(memory) &gt; <span class="number">1000</span>:  </span><br><span class="line">                batch = random.sample(memory, batch_size)  </span><br><span class="line">                states, actions, rewards, next_states, dones = <span class="built_in">zip</span>(*batch)  </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 转张量</span></span><br><span class="line">                states = torch.FloatTensor(states) <span class="comment"># [B, state_dim]</span></span><br><span class="line">                actions = torch.LongTensor(actions).unsqueeze(<span class="number">1</span>) <span class="comment"># [B, 1]</span></span><br><span class="line">                rewards = torch.FloatTensor(rewards).unsqueeze(<span class="number">1</span>) <span class="comment"># [B, 1]</span></span><br><span class="line">                next_states = torch.FloatTensor(next_states) <span class="comment"># [B, state_dim]</span></span><br><span class="line">                dones = torch.FloatTensor(dones).unsqueeze(<span class="number">1</span>) <span class="comment"># [B, 1] (1.0/0.0)</span></span><br><span class="line">  </span><br><span class="line">                <span class="comment"># (6-2) 主网络预测当前 Q 值：Q(s,a)</span></span><br><span class="line">                <span class="comment"># online_net(states) -&gt; [B, A]，gather挑出实际执行的动作a的Q值</span></span><br><span class="line">                q_values = online_net(states).gather(<span class="number">1</span>, actions)  <span class="comment"># [B, 1]</span></span><br><span class="line">  </span><br><span class="line">                <span class="comment"># (6-3) 目标网络计算下一个状态 s′ 的最大Q值：max_a&#x27; Q_target(s′, a′)</span></span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">                    next_q_values = target_net(next_states).<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].unsqueeze(<span class="number">1</span>)  <span class="comment"># [B, 1]</span></span><br><span class="line">                    <span class="comment"># 对终止状态不进行 bootstrap：*(1 - done)</span></span><br><span class="line">                    <span class="comment"># (6-4) 构造目标：y = r + γ * max Q_target(s′, a′)</span></span><br><span class="line">                    target_q = rewards + gamma * next_q_values * (<span class="number">1</span> - dones)  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># (6-5) 计算损失并反向传播（这里用 MSELoss）</span></span><br><span class="line">                loss = nn.MSELoss()(q_values, target_q)  </span><br><span class="line">                optimizer.zero_grad()  </span><br><span class="line">                loss.backward()  </span><br><span class="line">                optimizer.step()  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># ===== (7) 每隔固定步数同步一次目标网络参数 =====</span></span><br><span class="line">            <span class="keyword">if</span> total_steps % target_update_freq == <span class="number">0</span>:  </span><br><span class="line">                <span class="comment"># 将主网络的最新参数拷贝给目标网络，稳定目标值的估计</span></span><br><span class="line">                target_net.load_state_dict(online_net.state_dict())  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span> done:  </span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># ε 衰减：每回合结束后降低探索比例，最终不低于 epsilon_min</span></span><br><span class="line">        epsilon = <span class="built_in">max</span>(epsilon_min, epsilon * epsilon_decay)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 训练日志：Steps 是本回合步数；Reward 是“原始奖励 + 塑形奖励”的总和</span></span><br><span class="line">        <span class="built_in">print</span>(  </span><br><span class="line">            <span class="string">f&quot;Episode <span class="subst">&#123;episode + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;max_episodes&#125;</span> | Steps: <span class="subst">&#123;t + <span class="number">1</span>&#125;</span> | Reward: <span class="subst">&#123;total_reward:<span class="number">.2</span>f&#125;</span> | Epsilon: <span class="subst">&#123;epsilon:<span class="number">.3</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 训练完成，保存主网络（即推理时使用的在线网络）参数</span></span><br><span class="line">    torch.save(online_net.state_dict(), <span class="string">&quot;dqn_mountaincar_fast.pth&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型已保存到 dqn_mountaincar_fast.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-3-日志输出"><a href="#4-3-日志输出" class="headerlink" title="4.3 日志输出"></a>4.3 日志输出</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Episode 1/600 | Steps: 200 | Reward: -191.07 | Epsilon: 0.995</span><br><span class="line">Episode 2/600 | Steps: 200 | Reward: -181.50 | Epsilon: 0.990</span><br><span class="line">Episode 3/600 | Steps: 200 | Reward: -192.44 | Epsilon: 0.985</span><br><span class="line">...</span><br><span class="line">Episode 178/600 | Steps: 200 | Reward: -146.89 | Epsilon: 0.410</span><br><span class="line">Episode 179/600 | Steps: 163 | Reward: -112.88 | Epsilon: 0.408</span><br><span class="line">Episode 180/600 | Steps: 200 | Reward: -127.69 | Epsilon: 0.406</span><br><span class="line">...</span><br><span class="line">Episode 597/600 | Steps: 97 | Reward: -57.98 | Epsilon: 0.050</span><br><span class="line">Episode 598/600 | Steps: 134 | Reward: -93.57 | Epsilon: 0.050</span><br><span class="line">Episode 599/600 | Steps: 88 | Reward: -56.04 | Epsilon: 0.050</span><br><span class="line">Episode 600/600 | Steps: 112 | Reward: -74.69 | Epsilon: 0.049</span><br><span class="line">模型已保存到 dqn_mountaincar_fast.pth</span><br></pre></td></tr></table></figure>

<p>日志说明：</p>
<ul>
<li><strong>Episode X&#x2F;Y</strong>：第 X 回合，总共 Y 回合训练</li>
<li><strong>Steps: S</strong>：本回合用的步数（最多 200 步，MountainCar-v0 是默认 200 步终止）</li>
<li><strong>Reward: R</strong>：本回合的总奖励（这里是<strong>原始奖励 + 奖励塑形</strong>后的结果），MountainCar 原始奖励：每步 -1，到达终点额外奖励 0，所以当没有奖励塑形时，每步都会让总奖励更负。因为代码中加了奖励塑形，所以奖励值不是纯整数，而是会出现 -191.07、-57.98 这种小数。</li>
<li><strong>Epsilon: E</strong>：当前 ε-贪婪策略的探索率，随着回合增加而衰减，代表模型更倾向于利用而不是探索。</li>
</ul>
<h3 id="4-4-验证模型效果"><a href="#4-4-验证模型效果" class="headerlink" title="4.4 验证模型效果"></a>4.4 验证模型效果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>():</span><br><span class="line">    <span class="comment"># === 1. 加载训练好的 DQN 模型 ===</span></span><br><span class="line">    <span class="comment"># MountainCar 状态 2 维(位置、速度)，动作 3 种(左加速、右加速、不加速)</span></span><br><span class="line">    model = DQN(state_dim=<span class="number">2</span>, action_dim=<span class="number">3</span>)  </span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&quot;dqn_mountaincar_fast.pth&quot;</span>))</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 切换到评估模式（关闭 Dropout / BN 等训练特性）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># === 2. 创建环境（渲染模式） ===</span></span><br><span class="line">    env = gym.make(<span class="string">&quot;MountainCar-v0&quot;</span>, render_mode=<span class="string">&quot;human&quot;</span>)</span><br><span class="line"></span><br><span class="line">    num_episodes = <span class="number">10</span>      <span class="comment"># 测试回合数</span></span><br><span class="line">    success_count = <span class="number">0</span>      <span class="comment"># 成功登顶的次数计数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># === 3. 循环执行多个评估回合 ===</span></span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(num_episodes):</span><br><span class="line">        state, _ = env.reset()  <span class="comment"># 重置环境，获取初始状态</span></span><br><span class="line">        done = <span class="literal">False</span>            <span class="comment"># 回合是否结束</span></span><br><span class="line">        step = <span class="number">0</span>                <span class="comment"># 当前回合步数计数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># === 4. 单个回合循环 ===</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">            env.render()        <span class="comment"># 渲染画面（显示小车运动）</span></span><br><span class="line">            time.sleep(<span class="number">0.02</span>)    <span class="comment"># 控制动画播放速度（不然会很快看不清）</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将状态转换为张量，并加 batch 维度 [1, state_dim]</span></span><br><span class="line">            state_tensor = torch.FloatTensor(state).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 用训练好的模型计算 Q 值，并选择 Q 值最大的动作</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 评估时不计算梯度（节省内存和加速）</span></span><br><span class="line">                q_values = model(state_tensor)</span><br><span class="line">            action = q_values.argmax().item()  <span class="comment"># 取最大 Q 值对应的动作编号</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在环境中执行这个动作</span></span><br><span class="line">            state, reward, terminated, truncated, _ = env.step(action)</span><br><span class="line">            done = terminated <span class="keyword">or</span> truncated  <span class="comment"># 终止或超时都算回合结束</span></span><br><span class="line">            step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># === 5. 回合结束后，判断是否成功到达右侧山顶 ===</span></span><br><span class="line">        <span class="keyword">if</span> state[<span class="number">0</span>] &gt;= <span class="number">0.5</span>:  <span class="comment"># MountainCar 目标位置是 0.5</span></span><br><span class="line">            success_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印该回合的执行结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Episode <span class="subst">&#123;episode + <span class="number">1</span>&#125;</span> | Steps: <span class="subst">&#123;step&#125;</span> | Final Pos: <span class="subst">&#123;state[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># === 6. 计算总的成功率 ===</span></span><br><span class="line">    success_rate = success_count / num_episodes * <span class="number">100</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;成功率: <span class="subst">&#123;success_rate:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">    env.close()  <span class="comment"># 关闭环境窗口</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Episode 1 | Steps: 173 | Final Pos: 0.54</span><br><span class="line">Episode 2 | Steps: 152 | Final Pos: 0.54</span><br><span class="line">Episode 3 | Steps: 154 | Final Pos: 0.54</span><br><span class="line">Episode 4 | Steps: 87 | Final Pos: 0.51</span><br><span class="line">Episode 5 | Steps: 86 | Final Pos: 0.52</span><br><span class="line">Episode 6 | Steps: 86 | Final Pos: 0.51</span><br><span class="line">Episode 7 | Steps: 161 | Final Pos: 0.54</span><br><span class="line">Episode 8 | Steps: 179 | Final Pos: 0.54</span><br><span class="line">Episode 9 | Steps: 167 | Final Pos: 0.54</span><br><span class="line">Episode 10 | Steps: 156 | Final Pos: 0.54</span><br><span class="line">成功率: 100.00%</span><br></pre></td></tr></table></figure>
<p>日志说明：<br><strong>1. 成功率100%</strong> 表示模型已经学会稳定地冲上右侧山顶（终点位置 ≥ 0.5），每回合都完成任务，训练效果非常好，没有偶发失败的情况。</p>
<p><strong>2. 步数差异</strong></p>
<ul>
<li>步数范围 <strong>86 ~ 179</strong> 步 → 虽然都能成功，但到达速度不完全一致</li>
<li>较短的回合（86~87 步）说明模型走的是比较高效的冲顶路线</li>
<li>较长的回合（170+ 步）可能是因为初期动作探索了更多，不是最短路径，但仍能完成任务</li>
</ul>
<p><strong>3. 最终位置</strong></p>
<ul>
<li><strong>Final Pos 0.51~0.54</strong> → 每次登顶都刚好过终点线，MountainCar 到达 0.5 就算成功，所以模型倾向于“够用就好”，到达目标就停止</li>
<li>没有出现明显的“冲太远”或“差一点没到”的情况，策略很稳定</li>
</ul>
<p>模型已经完全学会 MountainCar 任务的关键策略（先反向加速积累动能，再加速冲顶），并且稳定性极高，几乎没有失败风险。不同回合的步数差异主要来自动作选择的细微差异，而非策略不稳定。</p>
<h2 id="5-目标函数与公式解析"><a href="#5-目标函数与公式解析" class="headerlink" title="5.目标函数与公式解析"></a>5.目标函数与公式解析</h2><h3 id="5-1-目标：让预测-Q-值更接近“正确答案”"><a href="#5-1-目标：让预测-Q-值更接近“正确答案”" class="headerlink" title="5.1 目标：让预测 Q 值更接近“正确答案”"></a>5.1 目标：让预测 Q 值更接近“正确答案”</h3><p>在 DQN 中，神经网络的任务是去拟合 $Q(s,a)$，也就是，当前状态 s 下执行动作 a，未来能获得多少回报。而我们希望 <strong>预测的 Q 值</strong> 和 <strong>目标 Q 值</strong> 越接近越好。<br>因此，用<strong>均方误差（MSE）</strong> 来衡量两者差距：<br>$$L(\theta) &#x3D; \big( Q(s,a;\theta) - y \big)^2$$<br>其中：</p>
<ul>
<li>$Q(s,a; \theta)$：当前 <strong>主网络</strong>（Online Q-Network）的预测值，即对未来回报的估计<ul>
<li>$s$：当前状态（比如小车的位置和速度）</li>
<li>$a$：当前动作（向左、向右、不动）</li>
<li>$\theta$：神经网络的参数（权重和偏置等）</li>
</ul>
</li>
<li>$y$：目标值（Target Q）</li>
</ul>
<h3 id="5-2-目标-Q-值的计算"><a href="#5-2-目标-Q-值的计算" class="headerlink" title="5.2 目标 Q 值的计算"></a>5.2 目标 Q 值的计算</h3><p>目标值 y 来源于 <strong>贝尔曼方程（Bellman Equation）</strong>：<br>$$y &#x3D; r + \gamma \cdot max_{a’} Q_{\text{target}}(s’, a’)$$<br>含义：</p>
<ol>
<li>$r$ ：当前动作获得的<strong>即时奖励</strong></li>
<li>$\gamma$ ：折扣因子（0~1），控制<strong>未来奖励的重要性</strong></li>
<li>$\max_{a’} Q_{\text{target}}(s’, a’)$：在下一个状态 s’ 中，选择最优动作 a’ 能获得的最大价值（由<strong>目标网络</strong>计算）<br>换句话说：目标 Q &#x3D; 即时奖励 + 未来可能的最大奖励（折扣后）</li>
</ol>
<h3 id="5-3-为什么要用目标网络（Target-Q-Network）"><a href="#5-3-为什么要用目标网络（Target-Q-Network）" class="headerlink" title="5.3 为什么要用目标网络（Target Q-Network）"></a>5.3 为什么要用目标网络（Target Q-Network）</h3><p>如果目标值也用当前网络计算，就会出现，当前网络的参数在更新，目标值也跟着变，这会导致训练过程不稳定（Q 值像踩着自己影子）。</p>
<p>解决办法是引入一个 <strong>延迟更新</strong> 的目标网络 $Q_{\text{target}}$，每隔 <strong>N 步</strong>，把主网络参数在复制到目标网络中。</p>
<h3 id="5-4-为什么要-detach-目标值"><a href="#5-4-为什么要-detach-目标值" class="headerlink" title="5.4 为什么要 detach() 目标值"></a>5.4 为什么要 detach() 目标值</h3><p>在 PyTorch 里，如果不加 .detach()，$y$ 会被认为是计算图的一部分，误差回传时，梯度会<strong>一路回传到目标网络</strong>，这样目标网络也会被更新（这不是我们想要的）。</p>
<p>而我们希望<strong>只更新主网络参数</strong> $\theta$，目标网络只是一个<strong>固定参考</strong>，不会被梯度影响。</p>
<p>所以在代码中是这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():  <span class="comment"># 或 .detach()</span></span><br><span class="line">    next_q_values = target_net(next_states).<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">    target_q = rewards + gamma * next_q_values * (<span class="number">1</span> - dones)</span><br></pre></td></tr></table></figure>
<p>这样，target_q 不会产生梯度。</p>
<h3 id="5-5-整个过程类比"><a href="#5-5-整个过程类比" class="headerlink" title="5.5 整个过程类比"></a>5.5 整个过程类比</h3><p>可以把主网络和目标网络想象成：</p>
<ul>
<li><strong>主网络（现在的自己）</strong>：正在学习，更新很频繁</li>
<li><strong>目标网络（过去的自己）</strong>：阶段性保存下来的“笔记”，在一段时间内不变，作为稳定的参考</li>
<li>训练目标：现在的自己尽量学得跟过去的“稳定版本”一致，但未来会更新过去的版本</li>
</ul>
<h2 id="6-Double-DQN（解决-Q-值过高估计）"><a href="#6-Double-DQN（解决-Q-值过高估计）" class="headerlink" title="6.Double DQN（解决 Q 值过高估计）"></a>6.Double DQN（解决 Q 值过高估计）</h2><h3 id="6-1-问题点"><a href="#6-1-问题点" class="headerlink" title="6.1 问题点"></a>6.1 问题点</h3><p><strong>DQN 目标值计算存在高估风险</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">	<span class="comment"># target_net(next_states) 是用 目标网络 预测所有可能动作的Q值</span></span><br><span class="line">	<span class="comment"># .max(1)[0] 直接选最大值，这个操作既选择动作又用这个最大值作为评估值</span></span><br><span class="line">	<span class="comment"># 如果预测里有噪声（预测值有偏差），max会偏向取偏高的那个，从而产生乐观偏差</span></span><br><span class="line">    next_q_values = target_net(next_states).<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">    target_q = rewards + gamma * next_q_values * (<span class="number">1</span> - dones)</span><br></pre></td></tr></table></figure>
<p>假设目标网络预测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">动作 <span class="number">0</span>: <span class="number">5.0</span>  (真实应是 <span class="number">4.8</span>)</span><br><span class="line">动作 <span class="number">1</span>: <span class="number">4.6</span>  (真实应是 <span class="number">4.6</span>)</span><br><span class="line">动作 <span class="number">2</span>: <span class="number">4.9</span>  (真实应是 <span class="number">4.9</span>)</span><br></pre></td></tr></table></figure>
<p>因为预测的噪声，动作 0 被预测得高了一点（5.0），max 会选它，并直接把 <strong>5.0 当作真实价值</strong>。<br>一次两次还好，但每轮更新都会<strong>不断把最大值往高的方向推</strong>这就会导致<strong>Q 值虚高</strong>。</p>
<h3 id="6-2-策略"><a href="#6-2-策略" class="headerlink" title="6.2 策略"></a>6.2 策略</h3><p>为了避免这个问题，Double DQN 分两步：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 用主网络选择下一个状态的最优动作</span></span><br><span class="line">next_actions = online_net(next_states).argmax(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 2. 用目标网络评估这个动作的 Q 值</span></span><br><span class="line">next_q_values = target_net(next_states).gather(<span class="number">1</span>, next_actions)</span><br><span class="line">target_q = rewards + gamma * next_q_values * (<span class="number">1</span> - dones)</span><br></pre></td></tr></table></figure>
<p>这样<strong>动作选择</strong>（argmax）用的是主网络，而<strong>动作评估</strong>（gather）用的是目标网络。两个网络参数不同，噪声就不会同步放大，从而可以降低过高估计，提高稳定性，在MountainCar-v0 case中， Double DQN可以让 Q 值估计更平稳，不会盲目认为某个方向的冲刺能立刻成功，从而减少无效尝试。</p>
<h3 id="6-3-完整实现"><a href="#6-3-完整实现" class="headerlink" title="6.3 完整实现"></a>6.3 完整实现</h3><p><a href="https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_double_DQN.py">https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_double_DQN.py</a></p>
<h3 id="6-4-成功率对比"><a href="#6-4-成功率对比" class="headerlink" title="6.4 成功率对比"></a>6.4 成功率对比</h3><p>DQN vs Double DQN 实现的成功率对比：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">===== 成功率对比（100 回合） =====</span><br><span class="line">DQN         | 成功率: 99.00%  | 平均步数: 125.60 | 平均终点位置: 0.52</span><br><span class="line">Double DQN  | 成功率: 100.00% | 平均步数: 115.60 | 平均终点位置: 0.51</span><br></pre></td></tr></table></figure>
<h2 id="7-Dueling-DQN（分离状态价值与动作优势）"><a href="#7-Dueling-DQN（分离状态价值与动作优势）" class="headerlink" title="7.Dueling DQN（分离状态价值与动作优势）"></a>7.Dueling DQN（分离状态价值与动作优势）</h2><p><strong>DQN</strong>是直接用一个神经网络输入状态 $s$，输出每个动作 $a$ 对应的 Q 值，所有 Q 值都是一层网络直接回归出来的，没有显式区分<strong>状态价值</strong>和<strong>动作优势</strong>。</p>
<p><strong>Dueling DQN</strong>则是改了最后几层的结构，把 Q 值拆分成：    </p>
<ol>
<li><strong>状态价值</strong> $V(s)$ ：当前状态本身的好坏，不依赖于具体动作        </li>
<li><strong>动作优势</strong> $A(s,a)$ ：在当前状态下，不同动作之间的相对优劣</li>
</ol>
<p>最后再合成：$Q(s,a) &#x3D; V(s) + A(s,a) - \frac{1}{|\mathcal{A}|} \sum_{a’} A(s,a’)$，减去平均优势是为了<strong>去中心化</strong>，避免 $V(s)$ 和 $A(s,a)$ 的数值相互冲突。<br>所以：</p>
<ul>
<li><strong>DQN</strong> “一个脑子同时管状态和动作的价值”</li>
<li><strong>Dueling DQN</strong> “一个脑子负责状态价值，另一个脑子负责动作差异”</li>
</ul>
<h3 id="7-1-为什么要这样拆分"><a href="#7-1-为什么要这样拆分" class="headerlink" title="7.1 为什么要这样拆分"></a>7.1 为什么要这样拆分</h3><p>在很多状态下，<strong>动作选择不敏感</strong>。<br>举个 MountainCar 例子：</p>
<ul>
<li>当小车已经在山顶或者刚出发速度很慢时，左右加速的效果差别不大，这时动作优势 $A(s,a)$ 接近 0，主要由 $V(s)$ 决定状态价值</li>
<li>DQN 在这些状态下还是会为每个动作都单独学 Q 值，效率低</li>
<li>Dueling DQN 可以直接先学 $V(s)$，不用反复去学相似的 Q 值，从而<strong>收敛更快</strong></li>
</ul>
<h3 id="7-2-Dueling-DQN-的优势"><a href="#7-2-Dueling-DQN-的优势" class="headerlink" title="7.2 Dueling DQN 的优势"></a>7.2 Dueling DQN 的优势</h3><ol>
<li><strong>泛化性更好</strong>：类似状态下的价值能被快速共享，减少重复学习</li>
<li><strong>学习更稳定</strong>：在动作选择不重要的状态里，仍能准确评估状态价值</li>
<li><strong>适用于在稀疏奖励任务</strong>：因为它能先学会哪些状态接近目标，再去细化动作优势</li>
</ol>
<p>MountainCar-v0 中的任务目标是先积累动能再冲顶。在上坡的中段，<strong>左右加速的效果差别很大</strong> → 依赖 $A(s,a)$ 来学优势。在坡底加速积能时，<strong>左右加速的差别没那么大</strong> → 依赖 $V(s)$ 来学状态价值。<br>结果就是，<strong>DQN</strong> 可能在不重要的状态浪费学习资源，而<strong>Dueling DQN</strong> 能更快聚焦在真正关键的动作选择时刻（比如冲顶前一两秒）。Dueling 架构能更快学到“山谷是低价值区域，山顶是高价值区域”。</p>
<h3 id="7-3-完整实现"><a href="#7-3-完整实现" class="headerlink" title="7.3 完整实现"></a>7.3 完整实现</h3><p><a href="https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_dueling_DQN.py">https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_dueling_DQN.py</a></p>
<h3 id="7-4-成功率对比"><a href="#7-4-成功率对比" class="headerlink" title="7.4 成功率对比"></a>7.4 成功率对比</h3><p>DQN vs Double DQN vs Dueling DQN 实现的成功率对比：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">===== 成功率对比（100 回合） =====</span><br><span class="line">DQN          | 成功率: 99.00% | 平均步数: 123.66 | 平均终点位置: 0.51</span><br><span class="line">Double DQN   | 成功率: 100.00% | 平均步数: 122.57 | 平均终点位置: 0.51</span><br><span class="line">Dueling DQN  | 成功率: 100.00% | 平均步数: 126.50 | 平均终点位置: 0.53</span><br></pre></td></tr></table></figure>
<h2 id="8-Prioritized-Experience-Replay（优先经验回放）"><a href="#8-Prioritized-Experience-Replay（优先经验回放）" class="headerlink" title="8. Prioritized Experience Replay（优先经验回放）"></a>8. Prioritized Experience Replay（优先经验回放）</h2><h3 id="8-1-PER-和-DQN-的关系"><a href="#8-1-PER-和-DQN-的关系" class="headerlink" title="8.1 PER 和 DQN 的关系"></a>8.1 PER 和 DQN 的关系</h3><p><strong>DQN</strong>的核心思想是用<strong>经验回放（Replay Buffer）</strong> 打破样本之间的时间相关性，提升样本利用率。但 DQN 默认 <strong>均匀随机采样</strong>（Uniform Sampling）——每个样本被选中的概率一样，不管它对学习有多重要。<br><strong>PER（Prioritized Experience Replay）</strong> 是 DQN 的<strong>一个改进策略</strong>，它只改“采样”这一步，把经验池里的样本按照<strong>学习价值高低</strong>来调整被采样的概率。</p>
<ul>
<li>学习价值高 → 采样概率高（重点训练难学的、错误大的样本）     </li>
<li>学习价值低 → 采样概率低（减少浪费在早就学会的简单样本上）</li>
</ul>
<p>所以，<strong>PER 是 DQN 的一个升级版本</strong>，DQN 的其他部分（Q 网络、目标网络、损失函数等）都可以保持不变，只要改“怎么从经验池抽样”。</p>
<h3 id="8-2-PER-的原理"><a href="#8-2-PER-的原理" class="headerlink" title="8.2 PER 的原理"></a>8.2 PER 的原理</h3><p>在 DQN 中，每个训练样本的 TD 误差（Temporal-Difference Error）是：<br>$$\delta_i &#x3D; y_i - Q(s_i, a_i)$$</p>
<ul>
<li>$Q(s_i, a_i)$：当前网络预测的 Q 值</li>
<li>$y_i &#x3D; r_i + \gamma \max_{a’} Q_{\text{target}}(s’_i, a’)$：目标 Q 值</li>
<li>$|\delta_i|$ 表示当前预测和真实目标的差距。</li>
</ul>
<p>PER 认为：</p>
<ul>
<li><strong>差距大（|δ| 大）</strong> → 当前模型预测不准，这个样本对学习的帮助大 → 采样概率应该高</li>
<li><strong>差距小（|δ| 小）</strong> → 模型已经学得差不多，这个样本对学习帮助有限 → 采样概率可以低一些</li>
</ul>
<p>采样概率公式：<br>$P(i) &#x3D; \frac{|\delta_i|^\alpha}{\sum_k |\delta_k|^\alpha}$</p>
<ul>
<li><strong>α</strong> 控制优先程度（α&#x3D;0 就退化为均匀采样）</li>
<li>TD 误差大 → 概率高</li>
</ul>
<p>另外，为了防止高概率样本被重复学习过多，PER 会配合<strong>重要性采样权重（IS weight）</strong> 做修正，保证训练无偏性。</p>
<h3 id="8-3-PER-在-MountainCar-v0-中的意义"><a href="#8-3-PER-在-MountainCar-v0-中的意义" class="headerlink" title="8.3 PER 在 MountainCar-v0 中的意义"></a>8.3 PER 在 MountainCar-v0 中的意义</h3><p>MountainCar 是一个<strong>稀疏奖励 + 延迟奖励</strong>任务，普通 DQN 学得慢的原因之一是：</p>
<ul>
<li>大部分时间，小车动作对最终奖励影响很小（例如卡在坡中间的微调动作）</li>
<li>真正关键的状态（比如冲顶前的几个动作、助跑的反向加速）出现概率很低，如果采样不够多，网络很难学到</li>
</ul>
<p>PER 的作用：</p>
<ul>
<li><strong>放大关键瞬间的学习频率</strong>：当网络第一次成功冲顶时，这些状态的 TD 误差会很大，PER 会让它们在后续训练中反复出现，强化记忆</li>
<li><strong>减少浪费时间在无关状态</strong>：对已经学会的坡底慢速动作，TD 误差会变小，采样概率降低</li>
</ul>
<p>这样，<strong>MountainCar 用 PER 收敛速度会比普通 DQN 快很多</strong>，尤其是在早期探索到关键路径时。</p>
<h3 id="8-4-完整实现"><a href="#8-4-完整实现" class="headerlink" title="8.4 完整实现"></a>8.4 完整实现</h3><p><a href="https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_PER_DQN.py">https://github.com/keychankc/dl_code_for_blog/blob/main/027_DQN_code/mountainCar_PER_DQN.py</a></p>
<h3 id="8-5-成功率对比"><a href="#8-5-成功率对比" class="headerlink" title="8.5 成功率对比"></a>8.5 成功率对比</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">===== 成功率对比（100 回合） =====</span><br><span class="line">DQN         | 成功率: 100.00% | 平均步数: 122.94 | 平均终点位置: 0.52</span><br><span class="line">Double DQN  | 成功率: 100.00% | 平均步数: 120.32 | 平均终点位置: 0.51</span><br><span class="line">Dueling DQN  | 成功率: 100.00% | 平均步数: 121.35 | 平均终点位置: 0.53</span><br><span class="line">PER DQN      | 成功率: 100.00% | 平均步数: 119.92 | 平均终点位置: 0.52</span><br></pre></td></tr></table></figure>
<p><strong>MountainCar-v0</strong> 这个任务太简单了，状态空间低维（2维），而且目标非常明确，DQN 本身就足够解决得很好， <strong>Double DQN、Dueling DQN、PER DQN</strong> 三个改进点在这里的性能提升几乎看不出来。</p>
<h2 id="9-总结与延伸"><a href="#9-总结与延伸" class="headerlink" title="9.总结与延伸"></a>9.总结与延伸</h2><table>
<thead>
<tr>
<th>​<strong>方法</strong>​</th>
<th>​<strong>核心改进</strong>​</th>
<th>​<strong>任务优势</strong>​</th>
<th>​<strong>适用场景</strong>​</th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>原始DQN</strong>​</td>
<td>神经网络拟合Q值函数</td>
<td>基础解决方案，适合简单任务</td>
<td>低维状态空间，动作选择明确的任务</td>
</tr>
<tr>
<td>​<strong>Double DQN</strong>​</td>
<td>解耦动作选择与价值评估</td>
<td>减少Q值高估，策略更稳定</td>
<td>需长期策略的任务（如延迟回报明显）</td>
</tr>
<tr>
<td>​<strong>Dueling DQN</strong>​</td>
<td>分离状态价值(V)和动作优势(A)</td>
<td>更快识别关键状态，减少冗余学习</td>
<td>动作影响差异大的任务（如冲刺关键期）</td>
</tr>
<tr>
<td>​<strong>优先经验回放(PER)​</strong>​</td>
<td>按TD误差优先级采样</td>
<td>加速收敛，聚焦关键经验</td>
<td>稀疏奖励或关键样本稀少的任务</td>
</tr>
<tr>
<td><strong>补充说明</strong>​：</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ol>
<li>在MountainCar-v0中，因任务简单（状态仅2维），所有方法均能100%成功，改进版优势不明显</li>
<li>若环境更复杂（如高维状态&#x2F;稀疏奖励），改进方法（尤其是Dueling+PER组合）的收敛速度和稳定性优势会更显著</li>
</ol>
<h2 id="10-备注"><a href="#10-备注" class="headerlink" title="10. 备注"></a>10. 备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>numpy: 1.26.4</li>
<li>gymnasium: 1.2.0</li>
<li>box2d-py: 2.3.8</li>
</ul>
<p>完整代码：<br>	<a href="https://github.com/keychankc/dl_code_for_blog/tree/main/027_DQN_code">https://github.com/keychankc/dl_code_for_blog/tree/main/027_DQN_code</a></p>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>PyTorch</tag>
        <tag>目标网络</tag>
        <tag>经验回放</tag>
      </tags>
  </entry>
  <entry>
    <title>A3C 算法原理与超级马里奥实践（下）</title>
    <url>/2025/08/29/029-rl-ac-a3c-mario-case-2/</url>
    <content><![CDATA[<h2 id="1-项目背景与目标"><a href="#1-项目背景与目标" class="headerlink" title="1. 项目背景与目标"></a>1. 项目背景与目标</h2><h3 id="1-1-为什么选择-A3C-来玩超级马里奥？"><a href="#1-1-为什么选择-A3C-来玩超级马里奥？" class="headerlink" title="1.1 为什么选择 A3C 来玩超级马里奥？"></a>1.1 为什么选择 A3C 来玩超级马里奥？</h3><p>超级马里奥是一个经典的横版过关游戏，玩法是简单，但是环境比较复杂：玩家要面对敌人、陷阱、跳跃平台，还要在有限时间内快速决策。<br>所以在强化学习中，它被认为是一个很好的 <strong>实验case</strong>：</p>
<ul>
<li>状态空间是高维的（游戏画面本身就是像素矩阵）</li>
<li>行动结果对未来奖励有长远影响（跳跃错过管道可能直接失败）</li>
<li>游戏场景变化多端，能充分考察智能体的泛化能力</li>
</ul>
<span id="more"></span>
<p>因此，我们打算用 <strong>A3C（Asynchronous Advantage Actor-Critic）</strong> 来实现，A3C 是一种经典的深度强化学习算法，能够通过 <strong>多线程并行采样</strong> 加速训练，并且结合 <strong>Actor-Critic 框架</strong> 来提升策略收敛的稳定性，具体可参考<a href="https://keychankc.github.io/2025/08/22/028-rl-ac-a3c-mario-case-1/">上篇</a>。用它来解决马里奥问题，顺便还可以实践强化学习的 <strong>理论价值</strong> 和 <strong>工程落地能力</strong>。</p>
<h3 id="1-2-马里奥环境中的难点"><a href="#1-2-马里奥环境中的难点" class="headerlink" title="1.2 马里奥环境中的难点"></a>1.2 马里奥环境中的难点</h3><p>在实现过程中，我们需要解决几个关键问题：</p>
<ol>
<li><strong>高维状态空间</strong>：输入是 240×256 的彩色像素画面，直接学习难度极高，必须通过卷积网络提取特征，并通过灰度化、缩放、帧堆叠等方式进行状态压缩</li>
<li><strong>稀疏奖励问题</strong>：游戏的“通关奖励”非常稀疏，大部分时间智能体得不到正向反馈。如果不加引导，智能体可能只会停留在原地或做无意义动作，这时就很需要 <strong>奖励塑形</strong>，例如根据分数、前进距离给予额外奖励</li>
<li><strong>实时决策与时序依赖</strong>：马里奥游戏是一个典型的 <strong>部分可观测环境</strong>：单帧图像不足以判断状态（如是否在跳跃过程中）。必须引入 <strong>LSTM</strong> 这样的时序模型，来帮助智能体记忆历史信息，做出更合理的决策</li>
</ol>
<h3 id="1-3-最终目标"><a href="#1-3-最终目标" class="headerlink" title="1.3 最终目标"></a>1.3 最终目标</h3><p>在这样的背景下，我们的目标还可以更高一些，不仅仅是“让 AI 过关”，而是可以构建一个 <strong>完整的强化学习训练-测试-评估系统</strong>。它应该具备以下特性：</p>
<ul>
<li><strong>能学会基本玩法</strong>：通过奖励塑形和多进程训练，让智能体逐渐掌握跳跃、移动、攻击等操作</li>
<li><strong>能被系统评估</strong>：不仅能通关，还能通过奖励曲线、通关率、视频回放等方式量化表现</li>
<li><strong>能支持扩展</strong>：模块化设计，便于切换算法、替换模型，甚至迁移到其他游戏环境中</li>
</ul>
<h2 id="2-游戏环境封装"><a href="#2-游戏环境封装" class="headerlink" title="2. 游戏环境封装"></a>2. 游戏环境封装</h2><h3 id="2-1-环境介绍"><a href="#2-1-环境介绍" class="headerlink" title="2.1 环境介绍"></a>2.1 环境介绍</h3><p>马里奥环境来自 <strong>gym_super_mario_bros</strong>，它是基于 OpenAI Gym 封装的 <strong>强化学习环境</strong>，在强化学习 (RL) 框架里，环境和智能体的交互遵循一个固定的规则：<strong>智能体选择一个动作 (action)</strong> → <strong>环境返回下一状态 (state)、奖励 (reward)、是否结束 (done)、额外信息 (info)</strong>。</p>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/super_mario_frame_0.jpg" width="50%"/>
基于此我们可以尝试用键盘玩马里奥，顺便熟悉一下环境。
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">play</span>():  </span><br><span class="line">    <span class="comment"># ===== (1) 环境初始化 =====</span></span><br><span class="line">    <span class="comment"># 游戏分为8个大关（World1~World8）每个大关里又有4个小关（Stage1~Stage4）</span></span><br><span class="line">    world, stage = <span class="number">1</span>, <span class="number">1</span>  </span><br><span class="line">    <span class="comment"># 加载马里奥游戏的某个关卡</span></span><br><span class="line">    env = gym_super_mario_bros.make(<span class="string">f&quot;SuperMarioBros-<span class="subst">&#123;world&#125;</span>-<span class="subst">&#123;stage&#125;</span>-v0&quot;</span>)  </span><br><span class="line">    </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    COMPLEX_MOVEMENT = [  </span></span><br><span class="line"><span class="string">	    [&#x27;NOOP&#x27;],            # 0: 什么也不做 (No Operation)    </span></span><br><span class="line"><span class="string">	    [&#x27;right&#x27;],           # 1: 向右走  </span></span><br><span class="line"><span class="string">	    [&#x27;right&#x27;, &#x27;A&#x27;],      # 2: 向右 + 跳  </span></span><br><span class="line"><span class="string">	    [&#x27;right&#x27;, &#x27;B&#x27;],      # 3: 向右 + 加速跑  </span></span><br><span class="line"><span class="string">	    [&#x27;right&#x27;, &#x27;A&#x27;, &#x27;B&#x27;], # 4: 向右 + 跳 + 跑 (助跑跳)  </span></span><br><span class="line"><span class="string">	    [&#x27;A&#x27;],               # 5: 原地跳  </span></span><br><span class="line"><span class="string">	    [&#x27;left&#x27;],            # 6: 向左走  </span></span><br><span class="line"><span class="string">	    [&#x27;left&#x27;, &#x27;A&#x27;],       # 7: 向左 + 跳  </span></span><br><span class="line"><span class="string">	    [&#x27;left&#x27;, &#x27;B&#x27;],       # 8: 向左 + 跑  </span></span><br><span class="line"><span class="string">	    [&#x27;left&#x27;, &#x27;A&#x27;, &#x27;B&#x27;],  # 9: 向左 + 跳 + 跑  </span></span><br><span class="line"><span class="string">	    [&#x27;down&#x27;],            # 10: 下 (蹲下，进水管/趴下)  </span></span><br><span class="line"><span class="string">	    [&#x27;up&#x27;],              # 11: 上 (例如爬藤蔓)  </span></span><br><span class="line"><span class="string">	]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 把复杂的组合键映射成离散的动作编号，例如 [向右 + 跳 + 跑] → action = 4</span></span><br><span class="line">    env = JoypadSpace(env, COMPLEX_MOVEMENT)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># ===== (2) 初始化pygame窗口 =====</span></span><br><span class="line">    pygame.init()  </span><br><span class="line">    screen = pygame.display.set_mode((<span class="number">256</span>, <span class="number">240</span>))  <span class="comment"># 马里奥原始分辨率</span></span><br><span class="line">    <span class="comment"># 窗口标题</span></span><br><span class="line">    pygame.display.set_caption(<span class="string">&quot;Keyboard Play Super Mario Bros (Complex)&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    clock = pygame.time.Clock()  </span><br><span class="line">    action = <span class="number">0</span>  <span class="comment"># 默认动作  </span></span><br><span class="line">  </span><br><span class="line">    done = <span class="literal">True</span>  </span><br><span class="line">    state = env.reset()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># ===== (3) 游戏主循环 =====</span></span><br><span class="line">    running = <span class="literal">True</span>  </span><br><span class="line">    <span class="keyword">while</span> running:  </span><br><span class="line">        <span class="keyword">for</span> event <span class="keyword">in</span> pygame.event.get():  </span><br><span class="line">            <span class="keyword">if</span> event.<span class="built_in">type</span> == pygame.QUIT:  </span><br><span class="line">                running = <span class="literal">False</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># ===== (4) 键盘控制 → 动作编号 =====        </span></span><br><span class="line">        keys = pygame.key.get_pressed()  </span><br><span class="line">        <span class="keyword">if</span> keys[pygame.K_LEFT] <span class="keyword">and</span> keys[pygame.K_SPACE]:  </span><br><span class="line">            action = <span class="number">7</span>   <span class="comment"># 左 + 跳  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_LEFT]:  </span><br><span class="line">            action = <span class="number">6</span>   <span class="comment"># 左  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_RIGHT] <span class="keyword">and</span> keys[pygame.K_SPACE] <span class="keyword">and</span> keys[pygame.K_LSHIFT]:  </span><br><span class="line">            action = <span class="number">4</span>   <span class="comment"># 右 + 跑 + 跳  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_RIGHT] <span class="keyword">and</span> keys[pygame.K_LSHIFT]:  </span><br><span class="line">            action = <span class="number">3</span>   <span class="comment"># 右 + 跑  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_RIGHT] <span class="keyword">and</span> keys[pygame.K_SPACE]:  </span><br><span class="line">            action = <span class="number">2</span>   <span class="comment"># 右 + 跳  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_RIGHT]:  </span><br><span class="line">            action = <span class="number">1</span>   <span class="comment"># 右  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_SPACE]:  </span><br><span class="line">            action = <span class="number">5</span>   <span class="comment"># 单跳  </span></span><br><span class="line">        <span class="keyword">elif</span> keys[pygame.K_DOWN]:  </span><br><span class="line">            action = <span class="number">10</span>  <span class="comment"># 下蹲  </span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            action = <span class="number">0</span>   <span class="comment"># 不动  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># ===== (5) 执行动作 =====        </span></span><br><span class="line">        state, reward, done, info = env.step(action)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;action: <span class="subst">&#123;action&#125;</span>, reward: <span class="subst">&#123;reward&#125;</span>, done: <span class="subst">&#123;done&#125;</span>, info: <span class="subst">&#123;info&#125;</span>&quot;</span>) </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            done: False,               # 回合还没有结束  </span></span><br><span class="line"><span class="string">            reward: 0.0,               # 本次动作得到的即时奖励  </span></span><br><span class="line"><span class="string">            action: 0,                 # 选择的动作编号  </span></span><br><span class="line"><span class="string">            info: &#123;&#x27;coins&#x27;: 0,         # 目前收集的金币数量  </span></span><br><span class="line"><span class="string">                   &#x27;flag_get&#x27;: False,  # 是否成功到达旗子，过关标志  </span></span><br><span class="line"><span class="string">                   &#x27;life&#x27;: 2,          # 当前剩余生命数  </span></span><br><span class="line"><span class="string">                   &#x27;score&#x27;: 0,         # 当前分数（环境内部累计的）  </span></span><br><span class="line"><span class="string">                   &#x27;stage&#x27;: 1,         # 当前关卡序号  </span></span><br><span class="line"><span class="string">                   &#x27;status&#x27;:           # 马里奥的状态，例如 &#x27;small&#x27;、&#x27;big&#x27;、&#x27;fire&#x27;  </span></span><br><span class="line"><span class="string">                   &#x27;time&#x27;: 398,        # 关卡剩余时间  </span></span><br><span class="line"><span class="string">                   &#x27;world&#x27;: 1,         # 当前世界序号  </span></span><br><span class="line"><span class="string">                   &#x27;x_pos&#x27;: 40,        # 横向位置（像素或格子）  </span></span><br><span class="line"><span class="string">                   &#x27;y_pos&#x27;: 79&#125;        # 纵向位置</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        env.render()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># ===== (6) 回合结束的处理 =====        </span></span><br><span class="line">        <span class="keyword">if</span> done:  </span><br><span class="line">            <span class="keyword">if</span> info.get(<span class="string">&#x27;flag_get&#x27;</span>, <span class="literal">False</span>):  <span class="comment"># 通关自动切下一关  </span></span><br><span class="line">                world, stage = info[<span class="string">&#x27;world&#x27;</span>], info[<span class="string">&#x27;stage&#x27;</span>] + <span class="number">1</span>  </span><br><span class="line">                <span class="comment"># 检查是否有下一关  </span></span><br><span class="line">                <span class="keyword">try</span>:  </span><br><span class="line">                    env.close()  </span><br><span class="line">                    env = gym_super_mario_bros.make(<span class="string">f&quot;SuperMarioBros-<span class="subst">&#123;world&#125;</span>-<span class="subst">&#123;stage&#125;</span>-v0&quot;</span>)  </span><br><span class="line">                    env = JoypadSpace(env, COMPLEX_MOVEMENT)  </span><br><span class="line">                    state = env.reset()  </span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;切换到下一关: World <span class="subst">&#123;world&#125;</span>-<span class="subst">&#123;stage&#125;</span>&quot;</span>)  </span><br><span class="line">                <span class="keyword">except</span>:  </span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;已通关全部关卡！&quot;</span>)  </span><br><span class="line">                    running = <span class="literal">False</span>  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                state = env.reset()  <span class="comment"># 没通关，重开这一关</span></span><br><span class="line">		</span><br><span class="line">        <span class="comment"># ===== (7) 控制帧率 =====        </span></span><br><span class="line">        clock.tick(<span class="number">60</span>)  <span class="comment"># 保持游戏运行在 60FPS，不然会跑得太快</span></span><br><span class="line">  </span><br><span class="line">    env.close()  </span><br><span class="line">    pygame.quit()  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    play()</span><br></pre></td></tr></table></figure>

<p>原始的马里奥游戏提供了几十种按键组合（向左、向右、跳跃、加速、攻击等），这对智能体来说就像让初学者一次学完所有武术招式，难度太大。为了降低学习难度，我们使用 <strong>JoypadSpace</strong> 对动作空间进行简化，只保留最核心的动作，例如：</p>
<ul>
<li>[向右走] → action &#x3D; 1</li>
<li>[向右 + 跳跃] → action &#x3D; 2</li>
<li>[向右 + 跑] → action &#x3D; 3</li>
<li>[原地跳] → action &#x3D; 5</li>
<li>[下蹲] → action &#x3D; 10</li>
</ul>
<p>这样，智能体可以专注于 <strong>前进、跳跃和避障</strong>，而不必分心去探索大量无关组合动作。简化后的动作空间不仅降低了探索难度，还显著加快了训练收敛速度。</p>
<h3 id="2-2-奖励塑形"><a href="#2-2-奖励塑形" class="headerlink" title="2.2 奖励塑形"></a>2.2 奖励塑形</h3><p>在强化学习中，奖励函数决定智能体学习方向。原始马里奥环境的奖励非常稀疏：智能体大部分时间得不到正向反馈（reward更新不及时），可能只会原地乱跳。<br>为此，我们需要 <strong>奖励塑形策略</strong>（自定义reward更新机制）：</p>
<ul>
<li><strong>分数奖励</strong>：根据吃金币、击败敌人等行为增加即时奖励</li>
<li><strong>通关奖励</strong>：成功通关时给大额正奖励，失败（掉坑、超时）则给负奖励</li>
<li><strong>奖励归一化</strong>：将奖励数值缩放，避免梯度过大导致训练不稳定</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_frame</span>(<span class="params">frame</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    把原始游戏画面做预处理，变成适合神经网络输入的数据  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)  </span><br><span class="line">        frame = cv2.resize(frame, (<span class="number">84</span>, <span class="number">84</span>))[<span class="literal">None</span>, :, :] / <span class="number">255.</span>  </span><br><span class="line">        <span class="keyword">return</span> frame  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        <span class="keyword">return</span> np.zeros((<span class="number">1</span>, <span class="number">84</span>, <span class="number">84</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomReward</span>(<span class="title class_ inherited__">Wrapper</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    把环境原始观测处理成灰度 84×84 的输入，同时修改奖励信号，让训练更稳定  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, env=<span class="literal">None</span>, monitor=<span class="literal">None</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(CustomReward, <span class="variable language_">self</span>).__init__(env)  </span><br><span class="line">        <span class="comment"># ===== (2.3.3) 灰度化+缩放 =====        </span></span><br><span class="line">        <span class="comment"># 把环境原始观测(240, 256, 3)的彩色帧改成 (84, 84, 1)灰度缩小帧  </span></span><br><span class="line">        <span class="variable language_">self</span>.observation_space = Box(low=<span class="number">0</span>, high=<span class="number">255</span>, shape=(<span class="number">1</span>, <span class="number">84</span>, <span class="number">84</span>))  </span><br><span class="line">        <span class="variable language_">self</span>.curr_score = <span class="number">0</span>  </span><br><span class="line">        <span class="keyword">if</span> monitor:  </span><br><span class="line">            <span class="variable language_">self</span>.monitor = monitor  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.monitor = <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):  </span><br><span class="line">        state, reward, done, info = <span class="variable language_">self</span>.env.step(action)  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.monitor:  </span><br><span class="line">            <span class="variable language_">self</span>.monitor.record(state) <span class="comment"># 录屏  </span></span><br><span class="line">  </span><br><span class="line">        state = process_frame(state) <span class="comment"># 游戏画面预处理  </span></span><br><span class="line">		</span><br><span class="line">        <span class="comment"># ===== (1) 分数奖励 =====        </span></span><br><span class="line">        <span class="comment"># 获取游戏中的分数，每一步奖励增加分数增长的一部分，</span></span><br><span class="line">        <span class="comment"># 这样智能体能在做出有意义行为（如吃金币、踩敌人）时获得即时反馈，提高学习效率      </span></span><br><span class="line">        reward += (info[<span class="string">&quot;score&quot;</span>] - <span class="variable language_">self</span>.curr_score) / <span class="number">40.</span>  </span><br><span class="line">        <span class="variable language_">self</span>.curr_score = info[<span class="string">&quot;score&quot;</span>]  </span><br><span class="line">        <span class="comment"># ===== (2) 通关奖励 =====        </span></span><br><span class="line">        <span class="comment"># 如果成功到达旗子，额外大额奖励 (+50) ，未通关（掉坑或超时）则惩罚 (-50)</span></span><br><span class="line">        <span class="keyword">if</span> done:  </span><br><span class="line">            <span class="keyword">if</span> info[<span class="string">&quot;flag_get&quot;</span>]:  </span><br><span class="line">                reward += <span class="number">50</span>  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                reward -= <span class="number">50</span>  </span><br><span class="line">        <span class="comment"># ===== (3) 奖励归一化 =====    </span></span><br><span class="line">        <span class="comment"># 奖励数值太大或波动过大会影响梯度更新，导致训练不稳定，</span></span><br><span class="line">        <span class="comment"># 把最终奖励统一缩放，例如除以 10，使其数值在合理范围内    </span></span><br><span class="line">        <span class="keyword">return</span> state, reward / <span class="number">10.</span>, done, info  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="variable language_">self</span>.curr_score = <span class="number">0</span>  </span><br><span class="line">        <span class="keyword">return</span> process_frame(<span class="variable language_">self</span>.env.reset()) <span class="comment"># 返回初始状态</span></span><br></pre></td></tr></table></figure>
<p>通过奖励塑形，智能体不仅能学到即时可见的动作好坏，还能朝着最终通关的长期目标努力。</p>
<h3 id="2-3-状态预处理"><a href="#2-3-状态预处理" class="headerlink" title="2.3 状态预处理"></a>2.3 状态预处理</h3><p>游戏原始画面是 240×256 的 RGB 图像，直接作为网络输入计算量大、信息冗余多。我们通过以下方法进行预处理：</p>
<ol>
<li><strong>帧跳跃（Frame Skip）</strong> ：每执行一次动作，跳过若干帧（例如 4 帧），减少交互次数，提高训练效率，并避免智能体关注不必要的“微小抖动”。 </li>
<li><strong>帧堆叠（Frame Stack）</strong>：将连续 4 帧画面堆叠作为状态输入，让智能体能感知运动趋势（例如判断马里奥是上升还是下落）。</li>
<li><strong>灰度化 + 缩放</strong>： 将彩色图像转为灰度，保留核心信息，减少输入维度，缩放到 84×84 的固定分辨率，更适合卷积网络处理，同时降低计算量。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomSkipFrame</span>(<span class="title class_ inherited__">Wrapper</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    跳帧 + 状态堆叠，让智能体不用每一帧都观察和决策  </span></span><br><span class="line"><span class="string">    1. 跳帧：一个动作连续执行多帧（skip 帧），减少环境计算量，提高训练效率。  </span></span><br><span class="line"><span class="string">    2. 堆叠帧：将多帧图像堆叠起来作为状态输入，使智能体能感知运动方向和速度。  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, env, skip=<span class="number">4</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(CustomSkipFrame, <span class="variable language_">self</span>).__init__(env)  </span><br><span class="line">        <span class="comment"># 堆叠4帧灰度图像 </span></span><br><span class="line">        <span class="variable language_">self</span>.observation_space = Box(low=<span class="number">0</span>, high=<span class="number">255</span>, shape=(<span class="number">4</span>, <span class="number">84</span>, <span class="number">84</span>)) </span><br><span class="line">        <span class="variable language_">self</span>.skip = skip  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):  </span><br><span class="line">        total_reward = <span class="number">0</span>  </span><br><span class="line">        states = []  </span><br><span class="line">        state, reward, done, info = <span class="variable language_">self</span>.env.step(action)  </span><br><span class="line">        <span class="comment"># ===== 帧跳跃 帧堆叠  =====    </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.skip):  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> done:  </span><br><span class="line">                state, reward, done, info = <span class="variable language_">self</span>.env.step(action)  </span><br><span class="line">                total_reward += reward  <span class="comment"># 多帧累积奖励</span></span><br><span class="line">                states.append(state)  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                states.append(state)  <span class="comment"># 提前结束用当前帧填充，保证长度固定</span></span><br><span class="line">        <span class="comment"># 堆叠成四通道张量</span></span><br><span class="line">        states = np.concatenate(states, <span class="number">0</span>)[<span class="literal">None</span>, :, :, :]  </span><br><span class="line">        <span class="comment"># states.astype(np.float32) 转换成浮点数，</span></span><br><span class="line">        <span class="keyword">return</span> states.astype(np.float32), reward, done, info  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):  </span><br><span class="line">        state = <span class="variable language_">self</span>.env.reset()  </span><br><span class="line">        states = np.concatenate([state <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.skip)], <span class="number">0</span>)[<span class="literal">None</span>, :, :, :]  </span><br><span class="line">        <span class="keyword">return</span> states.astype(np.float32)</span><br></pre></td></tr></table></figure>
<p>经过这些处理，原始画面被转化为一个 <strong>4×84×84 的张量</strong>，既保留了时序和关键信息，又方便神经网络高效学习。</p>
<h2 id="3-模型架构设计"><a href="#3-模型架构设计" class="headerlink" title="3. 模型架构设计"></a>3. 模型架构设计</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ActorCritic</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_inputs, num_actions</span>):  </span><br><span class="line">        <span class="built_in">super</span>(ActorCritic, <span class="variable language_">self</span>).__init__()  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== (1) CNN 提取特征 =====      </span></span><br><span class="line">        <span class="comment"># num_inputs为4，也是之前的4帧堆叠  </span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(num_inputs, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.conv3 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.conv4 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== (2) LSTM 时序建模 =====        </span></span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTMCell(<span class="number">32</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">512</span>)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== (3) 输出头：Actor + Critic =====       </span></span><br><span class="line">        <span class="variable language_">self</span>.critic_linear = nn.Linear(<span class="number">512</span>, <span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.actor_linear = nn.Linear(<span class="number">512</span>, num_actions)  </span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>._initialize_weights()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># ===== (4) 权重初始化 =====      </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="keyword">for</span> module <span class="keyword">in</span> <span class="variable language_">self</span>.modules():  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, nn.Conv2d) <span class="keyword">or</span> <span class="built_in">isinstance</span>(module, nn.Linear):  </span><br><span class="line">                nn.init.xavier_uniform_(module.weight)  </span><br><span class="line">                nn.init.constant_(module.bias, <span class="number">0</span>)  </span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, nn.LSTMCell):  </span><br><span class="line">                nn.init.constant_(module.bias_ih, <span class="number">0</span>)  </span><br><span class="line">                nn.init.constant_(module.bias_hh, <span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, hx, cx</span>):  </span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv1(x))  </span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv2(x))  </span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv3(x))  </span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv4(x))  <span class="comment"># 84 → 42 → 21 → 11 → 6</span></span><br><span class="line">        hx, cx = <span class="variable language_">self</span>.lstm(x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>), (hx, cx))  </span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.actor_linear(hx), <span class="variable language_">self</span>.critic_linear(hx), hx, cx</span><br></pre></td></tr></table></figure>

<h3 id="3-1-CNN-提取特征"><a href="#3-1-CNN-提取特征" class="headerlink" title="3.1 CNN 提取特征"></a>3.1 CNN 提取特征</h3><p>输入<code>(num_inputs, 84, 84)</code>，这里 num_inputs&#x3D;4，因为我们前面做了 <strong>4 帧堆叠</strong>，每层卷积核大小 3×3，步长 stride&#x3D;2 → 每过一层，特征图尺寸减半，经过 4 层卷积后，输出 32 × 6 × 6 的特征图。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">84 → 42 → 21 → 11 → 6 </span><br></pre></td></tr></table></figure>
<p>这部分的作用是把原始像素图压缩成一个抽象的空间表示（比如马里奥在哪、敌人在哪、速度方向），方便后面 LSTM 使用。</p>
<h3 id="3-2-LSTM-时序建模"><a href="#3-2-LSTM-时序建模" class="headerlink" title="3.2 LSTM 时序建模"></a>3.2 LSTM 时序建模</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.lstm = nn.LSTMCell(<span class="number">32</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">512</span>)</span><br></pre></td></tr></table></figure>
<p>输入维度：32 x 6 x 6 &#x3D; 1152，也就是 CNN 压缩出来的特征向量，输出维度：512，表示 LSTM 的隐藏状态大小。</p>
<p>LSTM 的作用：<br>游戏是一个连续过程，单帧状态不足以做出最优决策（比如马里奥在跳，是往上还是往下？需要时间信息）。LSTM 就可以通过记忆单元 (hx, cx) 维护“历史信息”，建模动作与结果之间的长期依赖。<br>可以理解为：CNN 负责“看清楚这一帧”，LSTM 负责“记住过去几秒发生了啥”。</p>
<h3 id="3-3-输出头Actor-Critic"><a href="#3-3-输出头Actor-Critic" class="headerlink" title="3.3 输出头Actor + Critic"></a>3.3 输出头Actor + Critic</h3><p><strong>Critic 头</strong>：输出一个标量，估计当前状态的价值 $V(s)$，用来评估 Actor 选择的动作好不好，减少训练的方差。<br><strong>Actor 头</strong>：输出一个 num_actions 维的向量 → softmax 后就是动作概率分布，表示智能体的“策略”。<br>Critic 是“裁判”，Actor 是“决策者”。二者配合就是 A3C 的核心思想。</p>
<h3 id="3-4-权重初始化"><a href="#3-4-权重初始化" class="headerlink" title="3.4 权重初始化"></a>3.4 权重初始化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> module <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, nn.Conv2d) <span class="keyword">or</span> <span class="built_in">isinstance</span>(module, nn.Linear):</span><br><span class="line">            nn.init.xavier_uniform_(module.weight)</span><br><span class="line">            nn.init.constant_(module.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, nn.LSTMCell):</span><br><span class="line">            nn.init.constant_(module.bias_ih, <span class="number">0</span>)</span><br><span class="line">            nn.init.constant_(module.bias_hh, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Xavier 初始化</strong>：保证权重方差在前后层之间保持一致，避免梯度消失&#x2F;爆炸<br><strong>偏置置零</strong>：保证初始时 LSTM 不带偏向，学习过程更稳定</p>
<p>初始化的好坏，直接决定训练能不能顺利收敛。</p>
<h2 id="4-多进程训练"><a href="#4-多进程训练" class="headerlink" title="4. 多进程训练"></a>4. 多进程训练</h2><h3 id="4-1-train-函数"><a href="#4-1-train-函数" class="headerlink" title="4.1 train()函数"></a>4.1 train()函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练入口</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">opt</span>):</span><br><span class="line">    torch.manual_seed(<span class="number">123</span>)  <span class="comment"># 固定随机种子，保证可复现</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果之前存在日志文件，先清理，重新创建</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(opt.log_path):</span><br><span class="line">        shutil.rmtree(opt.log_path)</span><br><span class="line">    os.makedirs(opt.log_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型保存目录</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(opt.saved_path):</span><br><span class="line">        os.makedirs(opt.saved_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建多进程环境，采用 &quot;spawn&quot; 启动方式（兼容性更好）</span></span><br><span class="line">    mp = _mp.get_context(<span class="string">&quot;spawn&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练环境（返回状态维度 num_states 和动作维度 num_actions）</span></span><br><span class="line">    env, num_states, num_actions = create_train_env(opt.world, opt.stage, opt.action_type)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全局共享模型（所有进程共享这个模型的参数）</span></span><br><span class="line">    global_model = ActorCritic(num_states, num_actions)</span><br><span class="line">    <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">        global_model.cuda()</span><br><span class="line">    global_model.share_memory()  <span class="comment"># 关键：允许多进程共享这份模型参数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果启用「从上一个关卡加载参数」</span></span><br><span class="line">    <span class="keyword">if</span> opt.load_from_previous_stage:</span><br><span class="line">        <span class="comment"># 1-1 关没法从上一个stage继续，只能从前一个world的4关</span></span><br><span class="line">        <span class="keyword">if</span> opt.stage == <span class="number">1</span>:</span><br><span class="line">            previous_world = opt.world - <span class="number">1</span></span><br><span class="line">            previous_stage = <span class="number">4</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            previous_world = opt.world</span><br><span class="line">            previous_stage = opt.stage - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拼接路径，加载 checkpoint</span></span><br><span class="line">        file_ = <span class="string">&quot;&#123;&#125;/a3c_super_mario_bros_&#123;&#125;_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(opt.saved_path, previous_world, previous_stage)</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(file_):</span><br><span class="line">            global_model.load_state_dict(torch.load(file_))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全局优化器（自定义的 Adam，用于多个进程梯度聚合）</span></span><br><span class="line">    optimizer = GlobalAdam(global_model.parameters(), lr=opt.lr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动一个「本地训练进程」和一个「测试进程」</span></span><br><span class="line">    local_train(<span class="number">0</span>, opt, global_model, optimizer, <span class="literal">True</span>)</span><br><span class="line">    local_test(opt.num_processes, opt, global_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动多个并行训练进程</span></span><br><span class="line">    processes = []</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(opt.num_processes):</span><br><span class="line">        <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 第 0 号进程：训练时保存模型</span></span><br><span class="line">            process = mp.Process(target=local_train, args=(index, opt, global_model, optimizer, <span class="literal">True</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 其他进程：只训练，不保存</span></span><br><span class="line">            process = mp.Process(target=local_train, args=(index, opt, global_model, optimizer))</span><br><span class="line">        process.start()</span><br><span class="line">        processes.append(process)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 单独启动一个测试进程，评估当前策略表现</span></span><br><span class="line">    process = mp.Process(target=local_test, args=(opt.num_processes, opt, global_model))</span><br><span class="line">    process.start()</span><br><span class="line">    processes.append(process)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 等待所有子进程结束</span></span><br><span class="line">    <span class="keyword">for</span> process <span class="keyword">in</span> processes:</span><br><span class="line">        process.join()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_train_env</span>(<span class="params">world, stage, action_type, output_path=<span class="literal">None</span></span>):  </span><br><span class="line">    env = gym_super_mario_bros.make(<span class="string">&quot;SuperMarioBros-&#123;&#125;-&#123;&#125;-v0&quot;</span>.<span class="built_in">format</span>(world, stage))  </span><br><span class="line">    <span class="keyword">if</span> output_path:  </span><br><span class="line">        <span class="comment"># 把环境的画面录制下来并保存成视频文件</span></span><br><span class="line">        monitor = Monitor(<span class="number">256</span>, <span class="number">240</span>, output_path)  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        monitor = <span class="literal">None</span>  </span><br><span class="line">    <span class="keyword">if</span> action_type == <span class="string">&quot;right&quot;</span>:  </span><br><span class="line">        actions = RIGHT_ONLY  </span><br><span class="line">    <span class="keyword">elif</span> action_type == <span class="string">&quot;simple&quot;</span>:  </span><br><span class="line">        actions = SIMPLE_MOVEMENT  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        actions = COMPLEX_MOVEMENT </span><br><span class="line">    <span class="comment"># 把复杂的按钮组合，封装成离散动作编号，方便后续强化学习训练或键盘控制   </span></span><br><span class="line">    env = JoypadSpace(env, actions)</span><br><span class="line">    env = CustomReward(env, monitor) <span class="comment"># 自定义奖励信号  </span></span><br><span class="line">    env = CustomSkipFrame(env) <span class="comment"># 跳帧+状态堆叠  </span></span><br><span class="line">    <span class="keyword">return</span> env, env.observation_space.shape[<span class="number">0</span>], <span class="built_in">len</span>(actions)</span><br></pre></td></tr></table></figure>
<h3 id="4-2-单个进程的训练"><a href="#4-2-单个进程的训练" class="headerlink" title="4.2 单个进程的训练"></a>4.2 单个进程的训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">local_train</span>(<span class="params">index, opt, global_model, optimizer, save=<span class="literal">False</span></span>):</span><br><span class="line">    torch.manual_seed(<span class="number">123</span> + index)  <span class="comment"># 每个进程用不同随机种子，保证探索多样性</span></span><br><span class="line">    <span class="keyword">if</span> save:</span><br><span class="line">        start_time = timeit.default_timer()</span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(opt.log_path)  <span class="comment"># TensorBoard 记录器</span></span><br><span class="line">    env, num_states, num_actions = create_train_env(opt.world, opt.stage, opt.action_type)</span><br><span class="line">    local_model = ActorCritic(num_states, num_actions)  <span class="comment"># 本地模型（Worker 的拷贝）</span></span><br><span class="line">    <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">        local_model.cuda()</span><br><span class="line">    local_model.train()</span><br><span class="line"></span><br><span class="line">    state = torch.from_numpy(env.reset())  <span class="comment"># 初始状态</span></span><br><span class="line">    <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">        state = state.cuda()</span><br><span class="line"></span><br><span class="line">    done = <span class="literal">True</span>  <span class="comment"># episode 结束标志</span></span><br><span class="line">    curr_step = <span class="number">0</span>  <span class="comment"># 全局步数计数器</span></span><br><span class="line">    curr_episode = <span class="number">0</span>  <span class="comment"># episode 计数器</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># =============== 主循环 ===============</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 每个 episode 初始化 LSTM 隐状态</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            h_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>), dtype=torch.<span class="built_in">float</span>)  <span class="comment"># 隐状态</span></span><br><span class="line">            c_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>), dtype=torch.<span class="built_in">float</span>)  <span class="comment"># 记忆单元</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            h_0 = h_0.detach()  <span class="comment"># 上一时刻的状态延续，但不反传梯度</span></span><br><span class="line">            c_0 = c_0.detach()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">            h_0, c_0 = h_0.cuda(), c_0.cuda()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每次训练前，把全局参数同步到本地</span></span><br><span class="line">        local_model.load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">        log_policies, values, rewards, entropies = [], [], [], []</span><br><span class="line">        episode_reward = <span class="number">0</span></span><br><span class="line">        cleared = <span class="literal">False</span>  <span class="comment"># 是否通关标志（过旗子）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 交互 num_local_steps（比如 50 步） =========</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(opt.num_local_steps):</span><br><span class="line">            curr_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 策略网络前向传播：输出动作分布和状态价值</span></span><br><span class="line">            logits, value, h_0, c_0 = local_model(state, h_0, c_0)</span><br><span class="line">            policy = F.softmax(logits, dim=<span class="number">1</span>)      <span class="comment"># 动作概率分布</span></span><br><span class="line">            log_policy = F.log_softmax(logits, <span class="number">1</span>)  <span class="comment"># 对数概率</span></span><br><span class="line">            entropy = -(policy * log_policy).<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># 策略熵</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 按概率采样动作（训练时随机，测试时可选贪婪）</span></span><br><span class="line">            m = Categorical(policy)</span><br><span class="line">            action = m.sample().item()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 与环境交互</span></span><br><span class="line">            state, reward, done, info = env.step(action)</span><br><span class="line">            state = torch.from_numpy(state)</span><br><span class="line">            <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">                state = state.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># ✅ 通关检测</span></span><br><span class="line">            <span class="keyword">if</span> info.get(<span class="string">&#x27;flag_get&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">                cleared = <span class="literal">True</span></span><br><span class="line">                done = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ✅ 达到全局最大步数，强制结束</span></span><br><span class="line">            <span class="keyword">if</span> curr_step &gt; opt.num_global_steps:</span><br><span class="line">                done = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ✅ Episode 结束时重置环境</span></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                curr_step = <span class="number">0</span></span><br><span class="line">                state = torch.from_numpy(env.reset())</span><br><span class="line">                <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">                    state = state.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 经验收集</span></span><br><span class="line">            episode_reward += reward</span><br><span class="line">            values.append(value)</span><br><span class="line">            log_policies.append(log_policy[<span class="number">0</span>, action])</span><br><span class="line">            rewards.append(reward)</span><br><span class="line">            entropies.append(entropy)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> done:  <span class="comment"># episode 结束 → 跳出</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 计算损失 =========</span></span><br><span class="line">        <span class="comment"># Bootstrap：如果没结束，用 Critic 估计未来价值</span></span><br><span class="line">        R = torch.zeros((<span class="number">1</span>, <span class="number">1</span>), dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">            R = R.cuda()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> done:</span><br><span class="line">            _, R, _, _ = local_model(state, h_0, c_0)</span><br><span class="line"></span><br><span class="line">        gae = torch.zeros((<span class="number">1</span>, <span class="number">1</span>), dtype=torch.<span class="built_in">float</span>)  <span class="comment"># 广义优势估计（GAE）</span></span><br><span class="line">        <span class="keyword">if</span> opt.use_gpu:</span><br><span class="line">            gae = gae.cuda()</span><br><span class="line"></span><br><span class="line">        actor_loss, critic_loss, entropy_loss = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        next_value = R</span><br><span class="line">        <span class="comment"># 🔁 逆序回溯（从最后一步往前算）</span></span><br><span class="line">        <span class="keyword">for</span> value, log_policy, reward, entropy <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(values, log_policies, rewards, entropies))[::-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># GAE 更新：δ + γτ * gae</span></span><br><span class="line">            gae = gae * opt.gamma * opt.tau + reward + opt.gamma * next_value.detach() - value.detach()</span><br><span class="line">            next_value = value</span><br><span class="line">            actor_loss += log_policy * gae  <span class="comment"># 策略梯度</span></span><br><span class="line">            R = R * opt.gamma + reward</span><br><span class="line">            critic_loss += (R - value) ** <span class="number">2</span> / <span class="number">2</span>  <span class="comment"># 值函数回归</span></span><br><span class="line">            entropy_loss += entropy  <span class="comment"># 探索奖励</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 总损失 = 策略损失 + 值函数损失 - 熵奖励</span></span><br><span class="line">        total_loss = -actor_loss + critic_loss - opt.beta * entropy_loss</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= TensorBoard 记录 =========</span></span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/TotalLoss&quot;</span>, total_loss.item(), curr_episode)</span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/ActorLoss&quot;</span>, actor_loss.item(), curr_episode)</span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/CriticLoss&quot;</span>, critic_loss.item(), curr_episode)</span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/Entropy&quot;</span>, entropy_loss.item(), curr_episode)</span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/EpisodeReward&quot;</span>, episode_reward, curr_episode)</span><br><span class="line">        writer.add_scalar(<span class="string">f&quot;Train_<span class="subst">&#123;index&#125;</span>/Cleared&quot;</span>, <span class="built_in">int</span>(cleared), curr_episode)  <span class="comment"># 1=通关, 0=失败</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 梯度上传到全局模型 =========</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        total_loss.backward()</span><br><span class="line">        <span class="keyword">for</span> local_param, global_param <span class="keyword">in</span> <span class="built_in">zip</span>(local_model.parameters(), global_model.parameters()):</span><br><span class="line">            <span class="keyword">if</span> global_param.grad <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                global_param._grad = local_param.grad  <span class="comment"># 拷贝梯度到全局</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新全局参数</span></span><br><span class="line"></span><br><span class="line">        curr_episode += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 日志输出 =========</span></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;[Process <span class="subst">&#123;index&#125;</span>] Episode <span class="subst">&#123;curr_episode&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;Reward: <span class="subst">&#123;episode_reward:<span class="number">.2</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;Cleared: <span class="subst">&#123;<span class="string">&#x27;Yes&#x27;</span> <span class="keyword">if</span> cleared <span class="keyword">else</span> <span class="string">&#x27;No&#x27;</span>&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;TotalLoss: <span class="subst">&#123;total_loss.item():<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;ActorLoss: <span class="subst">&#123;actor_loss.item():<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;CriticLoss: <span class="subst">&#123;critic_loss.item():<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;Entropy: <span class="subst">&#123;entropy_loss.item():<span class="number">.4</span>f&#125;</span>&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 模型保存 =========</span></span><br><span class="line">        <span class="keyword">if</span> save <span class="keyword">and</span> curr_episode % opt.save_interval == <span class="number">0</span>:</span><br><span class="line">            torch.save(global_model.state_dict(),</span><br><span class="line">                       <span class="string">f&quot;<span class="subst">&#123;opt.saved_path&#125;</span>/a3c_super_mario_bros_<span class="subst">&#123;opt.world&#125;</span>_<span class="subst">&#123;opt.stage&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ========= 训练结束条件 =========</span></span><br><span class="line">        <span class="keyword">if</span> curr_episode &gt;= <span class="built_in">int</span>(opt.num_global_steps / opt.num_local_steps):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Training process <span class="subst">&#123;index&#125;</span> terminated&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> save:</span><br><span class="line">                end_time = timeit.default_timer()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;Total training time: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> s&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>训练日志：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[Process 0] Episode 1 | Reward: -0.20 | Cleared: No | TotalLoss: 4.4672 | ActorLoss: -5.1896 | CriticLoss: 0.5195 | Entropy: 124.1912</span><br><span class="line">[Process 0] Episode 2 | Reward: 2.30 | Cleared: No | TotalLoss: 43.5234 | ActorLoss: -40.6037 | CriticLoss: 4.1615 | Entropy: 124.1819</span><br><span class="line">[Process 0] Episode 3 | Reward: 2.50 | Cleared: No | TotalLoss: 55.0827 | ActorLoss: -45.4405 | CriticLoss: 10.8840 | Entropy: 124.1825</span><br><span class="line">[Process 0] Episode 4 | Reward: -1.20 | Cleared: No | TotalLoss: -48.3509 | ActorLoss: 53.7558 | CriticLoss: 6.6465 | Entropy: 124.1659</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>[Process 0] Episode 1</strong>：来自 <strong>第 0 个 Worker 进程</strong>，这是它的 <strong>第 1 个 episode</strong>（从环境 reset 开始到终止）。</li>
<li><strong>Reward: -0.20</strong>：本次 episode 的累计奖励是 <strong>-0.20</strong>，表明智能体在第一轮尝试中表现很差（可能掉坑、被怪物碰到，奖励为负），这是正常现象，初期策略接近随机，几乎没有生存能力。</li>
<li><strong>Cleared: No</strong>：<strong>没有通关</strong>，早期训练阶段几乎所有 episode 都是失败的。</li>
<li><strong>TotalLoss: 4.4672</strong>：总的训练损失（Actor + Critic - β·Entropy），数值并不是越低越好，而是随着训练过程动态波动。</li>
<li><strong>ActorLoss: -5.1896</strong>：策略梯度损失（带优势函数的 $log π(a|s)$）。这里是 <strong>负值</strong>，说明模型在尝试调整策略去增加某些动作的概率，在 early stage，负的 actor loss 很常见，因为 GAE 给出的优势值可能是负的。</li>
<li><strong>CriticLoss: 0.5195</strong>： 价值函数（$V(s)$）的均方误差损失，数值不大，说明 Critic 对部分状态的价值估计已经在收敛。</li>
<li><strong>Entropy: 124.1912</strong>：策略分布的熵值（衡量探索程度），值很大，表示当前策略接近 <strong>均匀随机</strong>，几乎所有动作的概率差不多。这是好事，说明智能体在初期保持了充分探索，不会过早收敛到坏策略。</li>
</ul>
<h3 id="4-3-总结"><a href="#4-3-总结" class="headerlink" title="4.3 总结"></a>4.3 总结</h3><ul>
<li><strong>train()</strong>：负责环境准备、加载模型、启动多个进程（并行训练 + 测试）</li>
<li><strong>local_train()</strong>：单个进程的训练逻辑 → 环境交互 → 收集轨迹 → 计算损失 → 梯度上传 → 全局更新</li>
<li><strong>全局同步</strong>：本地模型参数从全局拉取，训练后梯度上传，保证所有进程共享一份最新策略</li>
<li><strong>测试流程</strong>：单独起一个 local_test 进程，不采样动作，而是用贪婪策略评估当前表现</li>
</ul>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/a3c_train_arch2025-08-29_17-48-21.jpg"></p>
<h2 id="5-优化器实现"><a href="#5-优化器实现" class="headerlink" title="5. 优化器实现"></a>5. 优化器实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 继承了 PyTorch 自带的 Adam，保留它的梯度更新规则</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GlobalAdam</span>(torch.optim.Adam):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params, lr</span>):  </span><br><span class="line">        <span class="comment"># foreach=False 是为了避免新版本API的冲突</span></span><br><span class="line">        <span class="built_in">super</span>(GlobalAdam, <span class="variable language_">self</span>).__init__(params, lr=lr, foreach=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> <span class="variable language_">self</span>.param_groups:  </span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> group[<span class="string">&#x27;params&#x27;</span>]:  </span><br><span class="line">                state = <span class="variable language_">self</span>.state[p]  </span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 初始化状态  </span></span><br><span class="line">                state[<span class="string">&#x27;step&#x27;</span>] = torch.tensor(<span class="number">0.</span>)  <span class="comment"># 记录每个参数更新的步数 t</span></span><br><span class="line">                state[<span class="string">&#x27;exp_avg&#x27;</span>] = torch.zeros_like(p.data)  <span class="comment"># 用于平滑梯度</span></span><br><span class="line">                state[<span class="string">&#x27;exp_avg_sq&#x27;</span>] = torch.zeros_like(p.data)  <span class="comment"># 用于自适应学习率</span></span><br><span class="line">  </span><br><span class="line">                <span class="comment"># 多进程共享，多Worker进程可以同时访问全局优化器状态</span></span><br><span class="line">                <span class="comment"># share_memory_()会把tensor放到共享内存，不同进程都能读写同一个内存区域</span></span><br><span class="line">                <span class="comment"># 这样每个Worker计算出的梯度，都可以正确累加到全局Adam的状态上，而不是各自独立</span></span><br><span class="line">                state[<span class="string">&#x27;step&#x27;</span>].share_memory_()  </span><br><span class="line">                state[<span class="string">&#x27;exp_avg&#x27;</span>].share_memory_()  </span><br><span class="line">                state[<span class="string">&#x27;exp_avg_sq&#x27;</span>].share_memory_()</span><br></pre></td></tr></table></figure>
<p>GlobalAdam 是为了 <strong>在多进程环境下安全地更新全局模型参数</strong>。它保留了 Adam 的梯度自适应能力，同时保证 <strong>每个 Worker 看到的是同一套动量和步数</strong>，保证 A3C 的训练稳定性，如果没有 <code>share_memory_()</code>，各 Worker 的梯度就只能独立更新本地模型，<strong>全局模型不会正确同步</strong>。</p>
<h2 id="6-测试与评估"><a href="#6-测试与评估" class="headerlink" title="6. 测试与评估"></a>6. 测试与评估</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">play</span>(<span class="params">opt</span>):  </span><br><span class="line">    torch.manual_seed(<span class="number">123</span>)  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ===== (1) 模型加载 =====      </span></span><br><span class="line">    model = ActorCritic(num_states, num_actions)  </span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">        model.load_state_dict(torch.load(<span class="string">&quot;&#123;&#125;/a3c_super_mario_bros_&#123;&#125;_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(opt.saved_path, opt.world, opt.stage)))  </span><br><span class="line">        model.cuda()  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        model.load_state_dict(torch.load(<span class="string">&quot;&#123;&#125;/a3c_super_mario_bros_&#123;&#125;_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(opt.saved_path, opt.world, opt.stage),  </span><br><span class="line">                                         map_location=<span class="keyword">lambda</span> storage, loc: storage))  </span><br><span class="line">    model.<span class="built_in">eval</span>()  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ===== (2) 环境准备与状态初始化 =====      </span></span><br><span class="line">    env, num_states, num_actions = create_train_env(opt.world, opt.stage, opt.action_type, <span class="string">&quot;&#123;&#125;/video_&#123;&#125;_&#123;&#125;.mp4&quot;</span>.<span class="built_in">format</span>(opt.output_path, opt.world, opt.stage))  </span><br><span class="line">    state = torch.from_numpy(env.reset())  </span><br><span class="line">    done = <span class="literal">True</span>  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="comment"># ===== (3) LSTM 隐状态初始化 =====      </span></span><br><span class="line">        <span class="keyword">if</span> done:  <span class="comment"># 游戏开始或者上一关结束，需要重置 LSTM 的隐藏状态</span></span><br><span class="line">            h_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>), dtype=torch.<span class="built_in">float</span>)  </span><br><span class="line">            c_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>), dtype=torch.<span class="built_in">float</span>)  </span><br><span class="line">            env.reset()  </span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 游戏进行中，保留上一帧的记忆信息，但 detach 防止梯度回传</span></span><br><span class="line">            h_0 = h_0.detach()  </span><br><span class="line">            c_0 = c_0.detach()  </span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">            h_0 = h_0.cuda()  </span><br><span class="line">            c_0 = c_0.cuda()  </span><br><span class="line">            state = state.cuda()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># ===== (4) 决策与动作选择 =====</span></span><br><span class="line">        <span class="comment"># 将 Actor 输出的 logits 转换为动作概率分布      </span></span><br><span class="line">        logits, value, h_0, c_0 = model(state, h_0, c_0)  </span><br><span class="line">        policy = F.softmax(logits, dim=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 贪婪策略 torch.argmax 选择概率最大的动作，适合评估阶段，避免随机探索</span></span><br><span class="line">        action = torch.argmax(policy).item()  </span><br><span class="line">        action = <span class="built_in">int</span>(action)  </span><br><span class="line">        <span class="comment"># 环境交互 把动作传给环境，得到下一帧状态、奖励和 done 标志</span></span><br><span class="line">        state, reward, done, info = env.step(action)  </span><br><span class="line">        state = torch.from_numpy(state)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== (5) 视频录制与可视化 =====      </span></span><br><span class="line">        env.render()  </span><br><span class="line">        time.sleep(<span class="number">1</span> / <span class="number">30</span>)  <span class="comment"># 控制为 30 FPS     </span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== (6) 性能指标与通关检测 =====      </span></span><br><span class="line">        <span class="keyword">if</span> info[<span class="string">&quot;flag_get&quot;</span>]:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;World &#123;&#125; stage &#123;&#125; completed, reward:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(opt.world, opt.stage, reward))</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>模型效果：<br><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/video_1_1_super_mario.mp4" controls="controls"></video></p>
<center> world 1 stage 1</center>
<video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/video_3_1_super_mario.mp4" controls="controls"></video>
<center>world 3 stage 1 </center>
<center> </center>
<video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/video_7_1_super_mario.mp4" controls="controls"></video>
<center>world 7 stage 1 </center>

<p>总结：</p>
<ul>
<li><strong>加载训练好的全局模型</strong> → 保证策略质量</li>
<li><strong>初始化环境与状态</strong> → 保持与训练一致</li>
<li><strong>初始化&#x2F;更新 LSTM 隐状态</strong> → 记忆连续动作信息</li>
<li><strong>选择动作 → 与环境交互 → 获取奖励</strong> → 执行策略并收集指标</li>
<li><strong>通关&#x2F;结束检测</strong> → 判断策略效果</li>
<li><strong>可视化 + 视频录制</strong> → 便于分析和展示</li>
</ul>
<p>评估阶段就是让训练好的模型去玩游戏，记录每一步表现，同时生成视频来观察策略是否稳健。</p>
<h2 id="7-实际训练表现"><a href="#7-实际训练表现" class="headerlink" title="7. 实际训练表现"></a>7. 实际训练表现</h2><h3 id="7-1-训练关卡的选择"><a href="#7-1-训练关卡的选择" class="headerlink" title="7.1 训练关卡的选择"></a>7.1 训练关卡的选择</h3><p>智能体的学习效果与环境复杂度密切相关。为了循序渐进地提升智能体的能力，我们通常会选择不同难度的关卡进行训练，比如：</p>
<ul>
<li><strong>世界 1-2</strong>：包含管道与天花板，强调 <strong>跳跃精度</strong> 与 <strong>避障</strong> 策略</li>
<li><strong>世界 3-1</strong>：出现飞行敌人和平台跳跃，考验智能体的 <strong>时机把握</strong> 与 <strong>动态环境适应能力</strong></li>
<li><strong>世界 7-1</strong>：敌人密集、地形复杂，属于 <strong>高难度场景</strong>，用于检验智能体在复杂环境中的泛化能力</li>
</ul>
<p>这种由浅入深的关卡设计，类似人类玩家的学习过程：先掌握基本操作，再逐步挑战更复杂的场景。</p>
<h3 id="7-2-训练时间与资源开销"><a href="#7-2-训练时间与资源开销" class="headerlink" title="7.2 训练时间与资源开销"></a>7.2 训练时间与资源开销</h3><p>训练时间的长短取决于 <strong>硬件条件</strong> 与 <strong>并行度</strong>：</p>
<ul>
<li><strong>数小时</strong>：智能体可以学会基础操作，例如避免直接碰撞敌人、尝试跳跃</li>
<li><strong>数十小时</strong>：策略逐渐成型，能够更合理地处理障碍，表现出较为稳定的存活能力</li>
<li><strong>几天</strong>：在多核 CPU + GPU 的支持下，智能体能够学习到较复杂的动作组合，甚至可以通关</li>
</ul>
<p>如果仅依靠单机 CPU，训练效率会显著下降，可能需要几天甚至更久的时间来完成同等水平的学习。</p>
<h3 id="7-3-训练成果"><a href="#7-3-训练成果" class="headerlink" title="7.3 训练成果"></a>7.3 训练成果</h3><p>经过充分训练后，智能体逐渐展现出与人类玩家类似的行为模式：</p>
<ul>
<li><strong>避障能力</strong>：面对前方的敌人，智能体能够选择跳跃或绕开，而不是盲目前进。</li>
<li><strong>跳跃掌握</strong>：能够在坑洞前做出恰当的起跳动作，并且学会通过踩击敌人获取奖励。</li>
<li><strong>通关能力</strong>：在部分关卡中，智能体可以稳定地完成整局游戏，并触发 flag_get &#x3D; True，即成功到达终点。</li>
</ul>
<p>与训练初期的“乱跑乱跳”相比，成熟的智能体表现更接近一个“熟练但偶尔失误”的人类玩家。</p>
<h2 id="8-工程化实现要点"><a href="#8-工程化实现要点" class="headerlink" title="8. 工程化实现要点"></a>8. 工程化实现要点</h2><h3 id="8-1-LSTM-状态管理：detach避免梯度爆炸"><a href="#8-1-LSTM-状态管理：detach避免梯度爆炸" class="headerlink" title="8.1 LSTM 状态管理：detach避免梯度爆炸"></a>8.1 LSTM 状态管理：detach避免梯度爆炸</h3><p>在 A3C 中，我们采用 <strong>LSTM 单元</strong>来建模时间依赖性，让智能体能够记忆过去的状态和动作。<br>但如果不加处理，LSTM 的隐藏状态会在时间维度上不断累积梯度，导致 <strong>梯度爆炸</strong> 或 <strong>显存泄漏</strong>。</p>
<p>解决办法是在每一轮 episode 开始时，显式执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> done:</span><br><span class="line">    h_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>))</span><br><span class="line">    c_0 = torch.zeros((<span class="number">1</span>, <span class="number">512</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    h_0 = h_0.detach()</span><br><span class="line">    c_0 = c_0.detach()</span><br></pre></td></tr></table></figure>

<p>这样，新的 episode 使用 <strong>干净的初始状态</strong>；未结束的 episode 则通过 detach 切断梯度回溯，避免跨 episode 梯度累计。</p>
<h3 id="8-2-容错机制：环境异常自动reset"><a href="#8-2-容错机制：环境异常自动reset" class="headerlink" title="8.2 容错机制：环境异常自动reset"></a>8.2 容错机制：环境异常自动reset</h3><p>游戏环境（特别是复古模拟器）可能会因为 <strong>非法动作</strong>、<strong>内存错误</strong> 或 <strong>渲染问题</strong> 崩溃。如果训练过程缺乏容错机制，整个多进程系统就会挂掉。</p>
<p>因此，代码中设计了 <strong>自动 reset</strong> 机制：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> done:</span><br><span class="line">    state = torch.from_numpy(env.reset())</span><br></pre></td></tr></table></figure>
<p>一旦游戏失败或环境异常，智能体立即重置到初始状态，继续学习。这样保证了训练过程的 <strong>鲁棒性</strong>，不会因为单个环境问题影响全局训练。</p>
<h3 id="8-3-模块化设计"><a href="#8-3-模块化设计" class="headerlink" title="8.3 模块化设计"></a>8.3 模块化设计</h3><p>为了便于维护与扩展，整个系统采用了 <strong>模块化设计</strong>：</p>
<ul>
<li><strong>env</strong>：环境封装层，负责状态预处理（灰度化、帧堆叠、缩放）和动作空间简化</li>
<li><strong>model</strong>：Actor-Critic 网络定义，包含 CNN 特征提取、LSTM 时序建模、Actor &amp; Critic 输出</li>
<li><strong>optimizer</strong>：自定义 GlobalAdam，支持多进程共享梯度更新</li>
<li><strong>process</strong>：多进程 Worker 管理，确保并行训练与测试正常运行</li>
<li><strong>train</strong>：训练逻辑，包括 rollout、GAE 优势估计、损失计算与梯度回传</li>
<li><strong>test</strong>：测试与评估，加载 checkpoint 并可视化智能体表现</li>
</ul>
<p>这种分层结构使得工程更接近 <strong>生产级系统</strong>，方便在未来替换不同算法（如 PPO、IMPALA）、接入不同环境（如 Atari、Gym Retro）。</p>
<h2 id="9-性能优化技巧"><a href="#9-性能优化技巧" class="headerlink" title="9. 性能优化技巧"></a>9. 性能优化技巧</h2><h3 id="9-1-帧跳跃-Frame-Skip-状态堆叠-Frame-Stack"><a href="#9-1-帧跳跃-Frame-Skip-状态堆叠-Frame-Stack" class="headerlink" title="9.1 帧跳跃 (Frame Skip) + 状态堆叠 (Frame Stack)"></a>9.1 帧跳跃 (Frame Skip) + 状态堆叠 (Frame Stack)</h3><p><strong>为什么需要帧跳跃？</strong><br>在原始游戏环境中，渲染速度往往是 <strong>60 FPS</strong>，如果每一帧都作为一步训练，计算量巨大，而且很多相邻帧几乎没有差别。因此，我们让智能体 <strong>每隔几帧执行一次动作</strong>，比如 skip&#x3D;4，这意味着智能体每 4 帧才更新一次决策。这样做有两个好处：</p>
<ul>
<li><strong>降低计算量</strong>：训练步数减少到 1&#x2F;4</li>
<li><strong>增强动作一致性</strong>：连续几帧保持相同动作，更符合人类操作习惯</li>
</ul>
<p><strong>为什么需要状态堆叠？</strong><br>单一帧无法体现“速度”和“方向”，比如马里奥的跳跃在一帧里和静止几乎一样。<br>于是我们堆叠最近 k 帧（常见为 4 帧），形成一个“时间窗口”，让智能体从图像序列中捕捉运动趋势。<br>这种组合相当于让 CNN + LSTM 同时“看到”<strong>短期局部时序</strong>和<strong>长期全局时序</strong>，大大提升学习效率。</p>
<h3 id="9-2-奖励塑形-Reward-Shaping"><a href="#9-2-奖励塑形-Reward-Shaping" class="headerlink" title="9.2 奖励塑形 (Reward Shaping)"></a>9.2 奖励塑形 (Reward Shaping)</h3><p><strong>原始奖励的问题</strong><br>在马里奥里，最直接的奖励是 <strong>到达终点旗子</strong>，但如果智能体只有在通关时才获得奖励，它会面临 <strong>稀疏奖励问题</strong>：前面几万步几乎得不到反馈，学习非常困难。</p>
<p><strong>奖励塑形的做法</strong><br>我们人为设计一些中间奖励，引导智能体更快地学到“正确方向”。例如：</p>
<ul>
<li><strong>前进奖励</strong>：向右走一步给一个小奖励，避免原地不动</li>
<li><strong>金币奖励</strong>：吃到金币&#x2F;道具给额外奖励，鼓励探索</li>
<li><strong>死亡惩罚</strong>：掉坑、碰怪物扣分，避免鲁莽尝试</li>
</ul>
<p>通过这种“奖励引导”，智能体会更快学会走、跳、避障，最终再通过通关奖励来强化全局目标。</p>
<h3 id="9-3-多进程并行-Asynchronous-Workers"><a href="#9-3-多进程并行-Asynchronous-Workers" class="headerlink" title="9.3 多进程并行 (Asynchronous Workers)"></a>9.3 多进程并行 (Asynchronous Workers)</h3><p>A3C 的核心思想就是 <strong>异步并行</strong>：同时运行多个环境，每个环境独立采样轨迹并更新全局模型。<br>优势有三点：</p>
<ol>
<li><strong>采样效率高</strong>：相比单线程采样，多进程能更快收集经验，GPU 不会闲置</li>
<li><strong>探索更全面</strong>：不同 Worker 的随机性让智能体走出不同路径，避免陷入局部最优</li>
<li><strong>训练更稳定</strong>：异步更新相当于一种“噪声正则化”，让全局参数更新不会被单一轨迹支配</li>
</ol>
<p>如果没有并行机制，智能体在复杂关卡（如 3-1、7-1）几乎不可能在合理时间内学会通关。</p>
<h2 id="10-扩展与改进方向"><a href="#10-扩展与改进方向" class="headerlink" title="10. 扩展与改进方向"></a>10. 扩展与改进方向</h2><p>在前面的实现中，我们已经基于 <strong>A3C + LSTM</strong> 搭建了一个能通关马里奥的智能体。但这并不是终点，强化学习在复杂环境中的探索还有很大空间。以下几个方向，可以作为改进或扩展的思路：</p>
<h3 id="10-1-算法替换：更强大的策略优化方法"><a href="#10-1-算法替换：更强大的策略优化方法" class="headerlink" title="10.1 算法替换：更强大的策略优化方法"></a>10.1 算法替换：更强大的策略优化方法</h3><p>A3C 是早期的经典算法，但随着研究进展，出现了许多更稳定、更高效的替代方案：</p>
<ul>
<li><strong>PPO（Proximal Policy Optimization）</strong>：在更新策略时加入「约束」，避免一次更新过大导致策略崩溃。相比 A3C，PPO 在样本效率和收敛速度上表现更好，是目前游戏和机器人领域的主流选择</li>
<li><strong>SAC（Soft Actor-Critic）</strong>：通过 <strong>最大化熵</strong> 来鼓励探索，让智能体更具鲁棒性。在连续动作空间任务（如机器人操作）中尤其有效</li>
<li><strong>IMPALA、APPO 等分布式方法</strong>：进一步放大并行规模，适合在大集群上运行，显著加快训练速度。</li>
</ul>
<p>换句话说，A3C 是“起点”，但在更高要求的场景中，可以逐步迁移到这些更先进的算法。</p>
<h3 id="10-2-结构优化：让模型更聪明"><a href="#10-2-结构优化：让模型更聪明" class="headerlink" title="10.2 结构优化：让模型更聪明"></a>10.2 结构优化：让模型更聪明</h3><p>当前的 Actor-Critic 模型通常由 CNN + LSTM 构成，但我们可以借鉴深度学习中的最新进展：</p>
<ul>
<li><strong>注意力机制（Attention）</strong>：让模型“选择性关注”画面中的关键区域，比如马里奥和怪物，而不是盲目处理整张画面。这样不仅提高决策效率，还能减少无关干扰</li>
<li><strong>残差连接（ResNet-style）</strong>：在深层 CNN 中加入残差结构，缓解梯度消失问题，让模型可以更轻松地训练得更深，从而提取更复杂的特征</li>
</ul>
<p>这类结构改进能让模型不仅“看得清”，还能“看得远”，在长时序任务中尤其有帮助。</p>
<h3 id="10-3-训练策略：让智能体学得更快"><a href="#10-3-训练策略：让智能体学得更快" class="headerlink" title="10.3 训练策略：让智能体学得更快"></a>10.3 训练策略：让智能体学得更快</h3><p>强化学习的难点在于探索效率低，而合理的训练策略能显著改善：</p>
<ul>
<li><strong>课程学习（Curriculum Learning）</strong>：像人类学习一样，从简单任务逐步过渡到复杂任务。例如先在 1-1 学会走和跳，再放到 3-1 学习避难度更高的障碍，最后挑战 7-1</li>
<li><strong>跨关卡训练（Multi-Task Learning）</strong>：不局限于单一关卡，而是让智能体在多个关卡中同时训练。这样能提升泛化能力，避免过拟合到某一地图</li>
<li><strong>模仿学习 + 强化学习结合</strong>：先通过模仿人类操作初始化策略，再用强化学习微调，能够大幅降低探索难度</li>
</ul>
<p>这些方法能显著缩短收敛时间，让智能体更快达到可用水平。</p>
<h3 id="10-4-应用拓展：从游戏到现实"><a href="#10-4-应用拓展：从游戏到现实" class="headerlink" title="10.4 应用拓展：从游戏到现实"></a>10.4 应用拓展：从游戏到现实</h3><p>虽然我们在马里奥上做实验，但本质上，这套框架可以推广到更广泛的领域：</p>
<ul>
<li><strong>通用游戏 AI</strong>：不仅限于马里奥，还可以用于 Atari、Minecraft、甚至 3D FPS 游戏，作为通用测试平台</li>
<li><strong>机器人控制</strong>：现实中的机器人同样需要感知（相机、传感器）和决策（运动控制），和马里奥环境高度相似。经过适配后，可以让机器人学会走路、抓取物体、避障等技能</li>
<li><strong>自动驾驶与智能体仿真</strong>：交通环境和复杂仿真同样依赖强化学习，算法优化和并行训练经验都可以迁移过去</li>
</ul>
<h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11. 总结"></a>11. 总结</h2><p>本文尝试构建一个完整的深度强化学习系统，使用 ​<strong>A3C（Asynchronous Advantage Actor-Critic）算法</strong>​ 训练智能体玩超级马里奥游戏。该系统解决了高维状态空间、稀疏奖励和时序依赖等关键问题，实现了从环境封装、模型设计、多进程训练到性能评估的全流程。</p>
<h3 id="核心要点"><a href="#核心要点" class="headerlink" title="核心要点"></a>核心要点</h3><ol>
<li>​<strong>环境封装与预处理</strong>​<ul>
<li>通过 <code>gym_super_mario_bros</code> 和 <code>JoypadSpace</code> 简化复杂动作空间，降低智能体探索难度</li>
<li>​<strong>奖励塑形 (Reward Shaping)​</strong>​：自定义奖励函数，结合即时分数奖励、通关大额奖励和失败惩罚，有效引导智能体学习</li>
<li>​<strong>状态预处理</strong>​：采用帧跳跃 (Frame Skip)、帧堆叠 (Frame Stack)、灰度化和缩放，将原始像素输入压缩为 4×84×84 的张量，大幅提升训练效率</li>
</ul>
</li>
<li>​<strong>模型架构 (Actor-Critic with LSTM)​</strong>​<ul>
<li>​<strong>CNN 特征提取器</strong>​：处理视觉输入，提取空间特征</li>
<li>​<strong>LSTM 时序建模</strong>​：记忆历史信息，解决部分可观测问题，使智能体能理解跳跃、移动等动作的连续性</li>
<li>​<strong>双输出头</strong>​：Actor 输出动作概率分布，Critic 评估状态价值，共同优化策略</li>
</ul>
</li>
<li>​<strong>多进程并行训练 (Asynchronous Parallelism)​</strong>​<ul>
<li>多个 Worker 进程并行与环境交互，收集经验，异步更新全局共享模型，极大加速样本收集和训练过程</li>
<li>自定义 ​<strong>GlobalAdam</strong>​ 优化器，通过 <code>share_memory()</code> 实现多进程间梯度同步和参数更新，确保训练稳定性</li>
</ul>
</li>
<li>​<strong>评估与可视化</strong>​<ul>
<li>独立的测试进程使用训练好的模型进行贪婪策略评估，生成通关视频和性能指标（如奖励曲线、通关率），直观展示智能体表现</li>
</ul>
</li>
<li>​<strong>工程化与性能优化</strong>​<ul>
<li>​<strong>模块化设计</strong>​：环境、模型、训练、测试分离，便于维护和扩展</li>
<li>​<strong>关键技巧</strong>​：LSTM 状态 <code>detach()</code> 防止梯度爆炸；帧跳跃与堆叠平衡效率与信息完整性；奖励塑形解决稀疏奖励问题</li>
<li>智能体最终能学会跳跃、避障、攻击等操作，在部分关卡达到稳定通关水平</li>
</ul>
</li>
</ol>
<h2 id="12-备注"><a href="#12-备注" class="headerlink" title="12.备注"></a>12.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>pytorch: 2.5.1</li>
<li>numpy: 1.26.4</li>
<li>gym_super_mario_bros: 7.4.0</li>
<li>gym：0.25.1</li>
<li>tensorboardX：2.6.2.2</li>
<li>opencv-python：4.11.0.86</li>
</ul>
<p>参考代码：<br><a href="https://github.com/vietnh1009/Super-mario-bros-A3C-pytorch">https://github.com/vietnh1009/Super-mario-bros-A3C-pytorch</a></p>
<p>完整代码：<br><a href="https://github.com/keychankc/dl_code_for_blog/tree/main/029-a3c_super_mario_code">https://github.com/keychankc/dl_code_for_blog/tree/main/029-a3c_super_mario_code</a></p>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>策略梯度</tag>
      </tags>
  </entry>
  <entry>
    <title>从Widget到Layer：Flutter引擎与渲染管线解析</title>
    <url>/2025/09/25/030-flutter-engine-and-rendering-pipeline/</url>
    <content><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-为什么要理解-Flutter-渲染原理"><a href="#1-1-为什么要理解-Flutter-渲染原理" class="headerlink" title="1.1 为什么要理解 Flutter 渲染原理"></a>1.1 为什么要理解 Flutter 渲染原理</h3><p>可能很多人刚接触 Flutter 时，往往只关心“怎么写 Widget”。但是当项目复杂度增加，就会遇到各种疑惑：为什么页面会掉帧？为什么某个布局报错“RenderBox was not laid out”？为什么同样的动画，有的流畅，有的卡顿？这些问题的根源，几乎都藏在 Flutter 的渲染机制里。</p>
<span id="more"></span>
<p>理解渲染管线，并不是要去改底层代码，而是让我们 <strong>写代码时更有预期</strong>，知道什么时候该优化 rebuild，什么时候该分离 RepaintBoundary，什么时候该避免不必要的 Layer。</p>
<h3 id="1-2-开发时常见的疑惑"><a href="#1-2-开发时常见的疑惑" class="headerlink" title="1.2 开发时常见的疑惑"></a>1.2 开发时常见的疑惑</h3><ul>
<li><strong>setState 为什么不立即重绘？</strong><br>  很多人以为 setState 调用后，Widget 会立刻刷新。实际上，setState 只是给框架打了个“脏标记”，真正的构建与绘制要等到下一帧（vsync 信号触发）才执行。这也是为什么频繁 setState 并不会逐条触发 GPU 绘制，而是合并进下一帧。</li>
<li><strong>build 调用频繁是不是性能差？</strong><br>  Flutter 的设计哲学是“build 便宜”。Widget 是轻量的不可变对象，频繁重建 Widget 并不等于浪费性能。真正昂贵的是 <strong>布局（layout）和绘制（paint）</strong>，这才会触发 RenderObject 的计算与 GPU 的工作。</li>
<li><strong>为什么某些 Widget（比如 IntrinsicHeight、Opacity）会“特别慢”？</strong><br>  看似只是一个简单的布局或透明度处理，实际上它们背后会触发额外的 <strong>多次布局测量</strong> 或 <strong>子树重绘</strong>，所以比普通 Widget 更耗性能。</li>
<li><strong>为什么图片滚动时容易掉帧？</strong><br>  不是因为 ListView 或 GridView 本身效率差，而是因为图片解码、缓存、GPU 上传等过程开销大。如果没有合适的缓存策略，或者大图直接解码，就会卡顿。</li>
<li><strong>为什么 RepaintBoundary 能优化性能？</strong><br>  因为它能让一棵子树单独缓存绘制结果，不随父节点一起重绘。这样能减少 GPU 重复工作，但如果滥用，反而增加内存与合成开销。</li>
<li><strong>为什么动画会卡顿，即使代码逻辑很简单？</strong><br>  大多数情况不是动画逻辑慢，而是 <strong>每一帧都触发了不必要的 rebuild&#x2F;layout&#x2F;paint</strong>。例如动画带动了大面积的 UI 更新，而不是局部更新。</li>
<li><strong>为什么 Flutter Web 和移动端性能差异大？</strong><br>  因为 Web 后端渲染方式不同：DOM 模式性能差，CanvasKit 模式更接近移动端，但依赖 WebAssembly 和 GPU，受浏览器环境影响。</li>
</ul>
<p>…等等。这些问题表面上像是直觉困惑，但只有把渲染链路串起来，才能看清真相，避免被“直觉误区”误导。</p>
<h3 id="1-3-对比其他-UI-框架"><a href="#1-3-对比其他-UI-框架" class="headerlink" title="1.3 对比其他 UI 框架"></a>1.3 对比其他 UI 框架</h3><p>Flutter 的特别之处在于：它不是调用原生控件，而是自己从零绘制 UI。React Native 依赖系统控件，SwiftUI &#x2F; Jetpack Compose 则构建在原生渲染栈之上，而 Flutter 拥有独立的 <strong>渲染引擎（Skia &#x2F; Impeller）</strong>，直接接管屏幕像素。</p>
<p>这种“自绘引擎”模式，意味着 Flutter 在跨平台上能保持高度一致的表现，但同时也让开发者必须理解 <strong>Widget → Element → RenderObject → Layer → GPU</strong> 这一整套管线，才能精准优化性能，并实现复杂的交互效果。</p>
<h3 id="1-4-Flutter-渲染链路"><a href="#1-4-Flutter-渲染链路" class="headerlink" title="1.4 Flutter 渲染链路"></a>1.4 Flutter 渲染链路</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setState() (setState 并不是立即重绘，而是“打脏标记”)</span><br><span class="line">   ↓</span><br><span class="line">标记 Element 脏（dirty）</span><br><span class="line">   ↓</span><br><span class="line">Framework 调度 build</span><br><span class="line">   ↓</span><br><span class="line">Widget → Element → RenderObject 更新</span><br><span class="line">   ↓</span><br><span class="line">markNeedsLayout / markNeedsPaint</span><br><span class="line">   ↓</span><br><span class="line">等待下一帧 vsync 信号</span><br><span class="line">   ↓</span><br><span class="line">SchedulerBinding.beginFrame()</span><br><span class="line">   ↓</span><br><span class="line">PipelineOwner 调度：(核心调度者，把layout/paint/composite串起来，批量渲染)</span><br><span class="line">   ├─ performLayout()         → 布局计算（layout）</span><br><span class="line">   ├─ updateCompositingBits() → 标记更新步骤</span><br><span class="line">   ├─ paint()                 → 生成绘制指令</span><br><span class="line">   └─ compositeFrame()        → 提交 Layer Tree</span><br><span class="line">   ↓</span><br><span class="line">Engine 接收 Layer Tree</span><br><span class="line">   ↓</span><br><span class="line">Skia / Impeller 光栅化（rasterize）</span><br><span class="line">   ↓</span><br><span class="line">GPU 执行绘制命令</span><br><span class="line">   ↓</span><br><span class="line">屏幕显示新的一帧画面</span><br></pre></td></tr></table></figure>
<h2 id="2-Flutter-三层架构概览"><a href="#2-Flutter-三层架构概览" class="headerlink" title="2. Flutter 三层架构概览"></a>2. Flutter 三层架构概览</h2><h3 id="2-1-Framework-Engine-Embedder-的分工"><a href="#2-1-Framework-Engine-Embedder-的分工" class="headerlink" title="2.1 Framework &#x2F; Engine &#x2F; Embedder 的分工"></a>2.1 Framework &#x2F; Engine &#x2F; Embedder 的分工</h3><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/archdiagram.png"><br>Flutter 从上到下分为三层：</p>
<ul>
<li><strong>Framework（Dart 实现）</strong><br>  这是开发者日常接触最多的一层，包含 widgets、rendering、animation 等核心库。它提供了声明式 UI 框架、Widget 树&#x2F;Element 树&#x2F;RenderObject 树的管理机制，以及动画、手势、布局等高层 API。<br>  对开发者来说：绝大多数业务逻辑和界面构建都停留在这层。</li>
<li><strong>Engine（C++ 实现）</strong><br>  Engine 负责底层渲染和系统交互，包括 Skia 2D 渲染引擎、文本排版（Harfbuzz、ICU）、图像解码（libpng&#x2F;jpg&#x2F;webp）、以及 Dart 运行时的对接。Framework 的绘制指令最终会转换为 Skia 的绘制命令。<br>  可以理解为“图形引擎 + Dart Runtime 支撑”。</li>
<li><strong>Embedder（平台适配层）</strong><br>  每个平台（iOS、Android、Windows、macOS、Linux、Fuchsia）都有对应的 Embedder，它负责把 Flutter Engine 嵌入到宿主应用中，处理输入事件（触摸&#x2F;键盘）、窗口管理、线程初始化，并把 Engine 渲染结果提交到系统的 GPU。<br>  简单说：Embedder 让 Flutter 能够“跑在不同系统里”。</li>
</ul>
<p>这三层之间通过 <strong>明确的 API 边界</strong> 协作，使 Flutter 拥有跨平台一致的运行表现。</p>
<h3 id="2-2-Dart-VM、AOT-JIT、运行模式"><a href="#2-2-Dart-VM、AOT-JIT、运行模式" class="headerlink" title="2.2 Dart VM、AOT&#x2F;JIT、运行模式"></a>2.2 Dart VM、AOT&#x2F;JIT、运行模式</h3><p>Flutter 依赖 Dart 语言提供的两种编译模式：</p>
<ul>
<li><strong>JIT（Just-in-Time，即时编译）</strong>：在开发阶段使用，支持 <strong>热重载</strong>，极大提升调试效率。但运行时需要 VM，启动速度较慢，性能也略逊。</li>
<li><strong>AOT（Ahead-of-Time，预编译）</strong>：在发布应用时使用，把 Dart 代码直接编译成机器码，摆脱 VM，启动速度快，运行效率接近原生。</li>
</ul>
<p>对应地，Flutter 提供三种运行模式：</p>
<ul>
<li><strong>Debug 模式</strong>：JIT 编译 + 各类调试检查（如边界检查、assert），性能最低但开发效率最高。</li>
<li><strong>Profile 模式</strong>：接近 Release，开启性能分析工具（如 Timeline、DevTools），主要用来调优。</li>
<li><strong>Release 模式</strong>：纯 AOT 编译，所有调试检查关闭，应用体积和性能最优。</li>
</ul>
<p>这套模式设计，很好的兼顾了开发体验与最终产品性能。</p>
<h3 id="2-3-Flutter-的线程模型：UI-GPU-IO-Platform"><a href="#2-3-Flutter-的线程模型：UI-GPU-IO-Platform" class="headerlink" title="2.3 Flutter 的线程模型：UI &#x2F; GPU &#x2F; IO &#x2F; Platform"></a>2.3 Flutter 的线程模型：UI &#x2F; GPU &#x2F; IO &#x2F; Platform</h3><p>Flutter Engine 采用多线程模型，以充分利用多核 CPU：</p>
<ul>
<li><strong>UI 线程</strong>：运行 Dart 代码，处理 Widget → Element → RenderObject 的构建与更新，以及布局计算和绘制命令生成。开发者调用的 setState、build、paint 都在这里执行。</li>
<li><strong>GPU 线程</strong>：接收 UI 线程生成的绘制指令，组装成 Layer Tree，并通过 Skia 提交给 OpenGL&#x2F;Metal&#x2F;Vulkan，最终交给系统的 GPU 渲染。</li>
<li><strong>IO 线程</strong>：负责异步文件&#x2F;网络 I&#x2F;O、图像解码等，避免阻塞 UI&#x2F;GPU。比如 Image.network 背后的下载和解码就跑在 IO 线程。</li>
<li><strong>Platform 线程</strong>：用于与宿主系统通信，处理 MethodChannel、插件调用、本地控件嵌入。</li>
</ul>
<p>这种线程分工让 Flutter 能在 UI 主线程高负载时，依旧保持渲染流畅，避免“掉帧”现象。</p>
<p>Flutter 的三层架构（Framework&#x2F;Engine&#x2F;Embedder）、两种编译模式（JIT&#x2F;AOT）、多线程调度模型，共同构成了它 <strong>跨平台、高性能、开发体验友好</strong> 的基础。</p>
<h2 id="3-Widget、Element、RenderObject-三棵树"><a href="#3-Widget、Element、RenderObject-三棵树" class="headerlink" title="3. Widget、Element、RenderObject 三棵树"></a>3. Widget、Element、RenderObject 三棵树</h2><p>在 Flutter 中，界面并不是一棵单一的树，而是通过 <strong>Widget 树、Element 树和 RenderObject 树</strong> 三棵树协同工作来完成的。理解它们的分工和关系，可以更好的掌握 Flutter 渲染原理。</p>
<h3 id="3-1-三棵树的职责与关系"><a href="#3-1-三棵树的职责与关系" class="headerlink" title="3.1 三棵树的职责与关系"></a>3.1 三棵树的职责与关系</h3><ol>
<li><strong>Widget：不可变的配置</strong><br> Widget 是日常开发要写的代码，例如 Text(“Hello”)、Container(color: Colors.red)。它本质上是一个 <strong>配置数据对象</strong>，描述“长什么样”，但自身不保存任何状态，也不参与绘制。特点是<strong>不可变</strong>，一旦创建不能修改，更新 UI 的方式就是生成一个新的 Widget。<br> Widget 就像甲方给的“我要一个 3 米宽的红墙”描述，不含具体施工细节。</li>
<li><strong>Element：连接器、持有状态、diff 逻辑</strong><br> Element 是 Widget 的运行时实例，负责在 Widget 与 RenderObject 之间搭桥。它保存了 Widget 的引用，管理生命周期（mount&#x2F;unmount），以及子节点关系。关键职责：<strong>diff 更新</strong>。当父 Widget 生成新的子 Widget 时，Element 负责决定是 <strong>复用旧节点</strong> 还是 <strong>销毁并创建新节点</strong>。<br> Element 就像施工经理，拿到需求说明，去比对之前的结构，决定是复用还是重建，并调度工人。</li>
<li><strong>RenderObject：负责 layout &#x2F; paint &#x2F; hitTest</strong><br> RenderObject 是真正的“干活的人”，负责计算尺寸与位置（layout）、绘制（paint）、事件处理（hitTest）。它有较复杂的生命周期和缓存机制，性能消耗也主要发生在这里。并非所有 Widget 都会创建 RenderObject，例如 Container 可能只是组合子 Widget，没有独立的 RenderObject。<br> 就像房屋的骨架 + 内部结构，负责确定尺寸（layout）、决定位置（排版）、准备表面材质（paint 指令），但还不是用户能直接看到的。只有到 Layer 阶段，才是粉刷好外观的房子，才能真正被“看到”。</li>
</ol>
<p><strong>三棵树的关系</strong></p>
<ul>
<li>Widget 树：声明式的 UI 配置。</li>
<li>Element 树：运行时的节点树，负责 diff 和状态管理。</li>
<li>RenderObject 树：真正的渲染树，驱动布局与绘制。</li>
</ul>
<p><strong>更新流程</strong>：开发者修改 Widget → Framework 生成新 Widget → Element diff → RenderObject 更新 → GPU 绘制。</p>
<h3 id="3-2-生命周期与更新机制"><a href="#3-2-生命周期与更新机制" class="headerlink" title="3.2 生命周期与更新机制"></a>3.2 生命周期与更新机制</h3><ol>
<li><strong>Element 生命周期</strong><ul>
<li><strong>mount</strong>：插入到树中，创建对应的 RenderObject。</li>
<li><strong>update</strong>：当 Widget 发生变化时，尝试复用旧的 Element 和 RenderObject。</li>
<li><strong>unmount</strong>：从树上移除，释放资源。</li>
</ul>
</li>
<li><strong>典型调用链（setState → GPU 绘制）</strong><br> 以开发时调用 setState 为例：<ul>
<li>setState：给 Element 打“脏标记”。</li>
<li>build：调用 Widget 的 build 方法，生成新的 Widget 子树。</li>
<li>updateChild：Element diff，决定复用还是重建。</li>
<li>markNeedsLayout&#x2F;paint：如果 RenderObject 需要重新布局或重绘，则进入渲染管线。</li>
<li>下一帧 vsync：Flutter Engine 调度 GPU，最终提交画面。<br> 这条链路解释了为什么 <strong>setState 不会立刻触发重绘，而是延迟到下一帧</strong>。</li>
</ul>
</li>
<li><strong>Element diff 与 Key 的作用</strong><ul>
<li>没有 Key：Element diff 时，通常按顺序匹配，可能出现“复用错误”。</li>
<li>使用 <strong>LocalKey</strong>（如 ValueKey）：在同一父节点下区分子节点，避免错误复用。</li>
<li>使用 <strong>GlobalKey</strong>：在全局范围内保持唯一，可以跨树复用（代价较大）。<br> 常见问题：ListView 里不用 Key，可能导致滚动复用时状态错乱。</li>
</ul>
</li>
<li><strong>RenderObject 更新 vs 替换</strong><ul>
<li>如果 Widget 类型相同，只是属性变化，例如 Container(color: red) → Container(color: blue)，Element 会调用 <strong>updateRenderObject</strong>，只更新属性，不替换 RenderObject。</li>
<li>如果 Widget 类型不同，例如 Text → Image，则必须销毁旧 RenderObject，重新创建。<br> 这也是性能优化的关键：<strong>属性更新比销毁重建更优</strong>。</li>
</ul>
</li>
</ol>
<h3 id="3-3-ParentData-与依赖关系"><a href="#3-3-ParentData-与依赖关系" class="headerlink" title="3.3 ParentData 与依赖关系"></a>3.3 ParentData 与依赖关系</h3><p>在布局系统中，有些子节点需要依赖父节点提供的额外信息，这就是 <strong>ParentData</strong>。</p>
<ol>
<li><strong>典型场景</strong><ul>
<li>在 Stack 中使用 Positioned，子节点需要额外的偏移量信息。</li>
<li>在 Flex（Row&#x2F;Column）中，子节点可以指定 flex 值。</li>
<li>这些额外信息都存储在子节点的 ParentData 中，由父 RenderObject 写入。</li>
</ul>
</li>
<li><strong>错误的 ParentData</strong><ul>
<li>如果把 Positioned 放到 Column 中，由于 Column 的 RenderObject 不理解 Positioned 的 ParentData，就会抛出异常。</li>
<li>这类错误能帮助开发者发现布局用法不当。</li>
</ul>
</li>
</ol>
<p>类比：ParentData 就像某个小区的物业规定——在 A 小区里能停电动车，但如果把规则拿到 B 小区就不适用，系统会直接报错提醒。</p>
<h3 id="3-4-调试工具"><a href="#3-4-调试工具" class="headerlink" title="3.4 调试工具"></a>3.4 调试工具</h3><p>理解三棵树，可以结合 Flutter 提供的 <strong>调试工具</strong>：</p>
<h4 id="3-4-1-Flutter-Inspector-的核心功能"><a href="#3-4-1-Flutter-Inspector-的核心功能" class="headerlink" title="3.4.1 Flutter Inspector 的核心功能"></a>3.4.1 Flutter Inspector 的核心功能</h4><ol>
<li><strong>Widget 树可视化</strong><ul>
<li>Inspector 默认展示 Widget 树，通过层级列表呈现当前界面上的所有 Widget。</li>
<li>可以点击界面上的元素，Inspector 会高亮对应的 Widget，并在树中定位源代码位置。<br> <img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250924140227.png"></li>
</ul>
</li>
<li><strong>查看对象属性和 ParentData</strong><ul>
<li>选中 Widget 后，可以查看其构造参数、尺寸约束、对齐方式等信息。</li>
<li>对于依赖父节点的 Widget（如 Positioned 或 Flexible），Inspector 会显示其 <strong>ParentData</strong>，帮助理解父子布局关系。</li>
<li>通过查看 ParentData，可以发现子节点被放错父节点或布局使用错误时抛出的异常。<br> <img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250924140339.png"></li>
</ul>
</li>
<li><strong>布局和绘制调试</strong><ul>
<li><strong>Layout Explorer</strong>：显示 Widget 的布局约束和尺寸，帮助分析布局行为。</li>
<li><strong>Debug Paint</strong>：在界面上绘制边界、内边距和对齐辅助线，直观观察 RenderObject 的布局和绘制范围。</li>
<li><strong>Repaint Rainbow &#x2F; Highlight Repaints</strong>：高亮频繁重绘的区域，辅助性能调优。<br> <img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250924145520.png"><br>具体可参考文档<a href="https://docs.flutter.dev/tools/devtools/inspector">Use the Flutter inspector</a></li>
</ul>
</li>
</ol>
<h2 id="4-布局系统与约束"><a href="#4-布局系统与约束" class="headerlink" title="4. 布局系统与约束"></a>4. 布局系统与约束</h2><h3 id="4-1-Constraints-传递机制"><a href="#4-1-Constraints-传递机制" class="headerlink" title="4.1 Constraints 传递机制"></a>4.1 Constraints 传递机制</h3><p>Flutter 的布局系统有一个核心原则：<strong>父控件给子控件传递约束（Constraints），子控件根据约束决定自己的尺寸，并将结果回传给父控件</strong>。理解这一点，就能把握整个布局链条的本质。</p>
<h4 id="4-1-1-Flutter-的单向约束模型"><a href="#4-1-1-Flutter-的单向约束模型" class="headerlink" title="4.1.1 Flutter 的单向约束模型"></a>4.1.1 Flutter 的单向约束模型</h4><p>在 Flutter 中，布局是一个<strong>基于约束的单向流程</strong>​：</p>
<ol>
<li>​<strong>父节点传递约束（Constraints）​</strong>，定义子节点的尺寸范围（如最小&#x2F;最大宽高）。</li>
<li>​<strong>子节点在约束范围内选择自身尺寸</strong>​（必须满足 <code>constraints.isSatisfiedBy(size)</code>）。</li>
<li>​<strong>父节点根据子节点返回的尺寸完成布局</strong>​（如定位、对齐）。</li>
</ol>
<p>这种模型不同于 iOS UIKit 的 AutoLayout（双向协商），而是由父节点严格约束子节点的可能性。例如：</p>
<ul>
<li><code>Container(width: 100)</code>会强制子节点宽度为 100（<strong>tight 约束</strong>）。</li>
<li><code>Center</code>则允许子节点选择任意大小（<strong>loose 约束</strong>）。</li>
</ul>
<p>​Flutter 的布局规则可以概括为 ​<strong>​「父定约束，子选尺寸」​</strong>，而非完全自由的「子定尺寸」。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Container(</span><br><span class="line">  width: <span class="number">100</span>, <span class="comment">// 父节点强制 tight 约束，Text 宽度必须为 100</span></span><br><span class="line">  color: Colors.red,</span><br><span class="line">  child: Text(<span class="string">&quot;Hello&quot;</span>), <span class="comment">// 子节点无法自由决定宽度</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在这里，Container 把一个 <strong>固定宽度 100 的约束</strong>传递给子 Text。即使 Text 的内容很短，它的宽度也会被“强制”撑成 100。</p>
<p><strong>对比 AutoLayout</strong>​：</p>
<ul>
<li>​<strong>Flutter</strong>​：父节点主导，子节点只能在约束范围内选择尺寸。</li>
<li>​<strong>AutoLayout</strong>​：父子节点互相协商，依赖约束关系（如 <code>A.centerX = B.centerX</code>）。</li>
</ul>
<p>这样的设计使 Flutter 布局更高效，但也要求开发者理解约束的传递机制，避免因约束冲突导致布局异常。</p>
<h4 id="4-1-2-双向沟通"><a href="#4-1-2-双向沟通" class="headerlink" title="4.1.2 双向沟通"></a>4.1.2 双向沟通</h4><p>虽然约束是单向传递的，但布局结果会“反哺”到父节点的排布。也就是说，<strong>父亲告诉孩子“你只能在这个范围内长大”，但孩子最终长了多少，还是要告诉父亲</strong>。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">SizedBox(  </span><br><span class="line">  height: <span class="number">100</span>,  </span><br><span class="line">  child: Row(  </span><br><span class="line">    children: [  </span><br><span class="line">      Expanded(child: Container(color: Colors.red)),  </span><br><span class="line">      Expanded(child: Container(color: Colors.blue)),  </span><br><span class="line">    ],  </span><br><span class="line">  ),  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>Row 的约束：告诉孩子「我一共只有屏幕这么宽」。</li>
<li>Expanded 的逻辑：两个孩子平分可用宽度。</li>
</ul>
<p>最终结果：每个子 Container 把「自己分到的宽度」回传给 Row，Row 再根据它们的宽度把它们并排放好。</p>
<p>这就是 Flutter 布局的<strong>单向约束 + 双向沟通</strong>模型。</p>
<h4 id="4-1-3-tight-vs-loose-约束"><a href="#4-1-3-tight-vs-loose-约束" class="headerlink" title="4.1.3 tight vs loose 约束"></a>4.1.3 tight vs loose 约束</h4><p>在 Flutter 的约束系统里，有两个关键概念：</p>
<ul>
<li><strong>loose（松约束）</strong>：子可以自己决定大小，但不能超过父允许的范围。</li>
<li><strong>tight（紧约束）</strong>：子必须是某个固定大小。</li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">// loose约束 宽松、保留、贴合</span></span><br><span class="line">Center(</span><br><span class="line">  child: Container(width: <span class="number">50</span>, height: <span class="number">50</span>, color: Colors.red),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// tight约束 强制、固定、拉伸</span></span><br><span class="line"><span class="comment">// Container 写的 width: 50 完全不起作用，它会被拉伸撑满 Row 的可用宽度</span></span><br><span class="line"><span class="comment">// 红色的 Container 占满整行宽度，高度是 50</span></span><br><span class="line">Row(</span><br><span class="line">  children: [</span><br><span class="line">    Expanded(</span><br><span class="line">      child: Container(width: <span class="number">50</span>, height: <span class="number">50</span>, color: Colors.red),</span><br><span class="line">    ),</span><br><span class="line">  ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>在 <strong>Center</strong> 中，子 Container 收到的约束是 <strong>loose</strong>，即“你可以小一点，只要不超过我允许的范围”。所以 Container 会保持 50×50 的大小。</li>
<li>在 <strong>Expanded</strong> 中，子 Container 收到的约束是 <strong>tight</strong>，即“必须填满我分给你的所有空间”。结果就是不管你写没写 width&#x2F;height，Container 都会被拉伸，去占满可用空间。</li>
</ul>
<p>这也是为什么很多初学者困惑：<strong>同样的 Container(width: 50)，放在不同父 Widget 里表现完全不一样</strong>。关键就在于父传下来的约束是 tight 还是 loose。</p>
<p>Flutter 常见 Widget 约束对照表：</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>Widget</strong></th>
<th><strong>约束行为</strong></th>
<th><strong>典型效果</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>tight 严格约束</strong></td>
<td><strong>Expanded</strong></td>
<td>填满 Row&#x2F;Column 剩余空间，忽略子组件尺寸</td>
<td>子组件被强制拉伸</td>
</tr>
<tr>
<td></td>
<td><strong>Flexible(fit: FlexFit.tight)</strong></td>
<td>等价于 Expanded</td>
<td>同上</td>
</tr>
<tr>
<td></td>
<td><strong>SizedBox(width&#x2F;height)</strong></td>
<td>固定大小，锁死宽高</td>
<td>子组件无法改变</td>
</tr>
<tr>
<td></td>
<td><strong>ConstrainedBox(BoxConstraints.tight(…))</strong></td>
<td>强制固定为指定大小</td>
<td>无视子组件本身</td>
</tr>
<tr>
<td></td>
<td><strong>AspectRatio</strong></td>
<td>按比例调整，填满约束范围</td>
<td>保持宽高比缩放</td>
</tr>
<tr>
<td></td>
<td><strong>IntrinsicWidth &#x2F; IntrinsicHeight</strong>（特定场景）</td>
<td>计算后“撑开”子组件尺寸</td>
<td>子组件被拉伸</td>
</tr>
<tr>
<td><strong>loose 宽松约束</strong></td>
<td><strong>Center</strong></td>
<td>子组件保持自身大小，不超过父约束</td>
<td>保持原始大小</td>
</tr>
<tr>
<td></td>
<td><strong>Align</strong></td>
<td>与 Center 类似，可指定对齐方式</td>
<td>子组件自定 + 定位</td>
</tr>
<tr>
<td></td>
<td><strong>Padding</strong></td>
<td>添加内边距后再传递 loose 约束</td>
<td>子组件大小 &#x3D; 自身 + padding</td>
</tr>
<tr>
<td></td>
<td><strong>Flexible(fit: FlexFit.loose)</strong></td>
<td>子组件可小可大，但不能超过分配空间</td>
<td>保留子组件设置</td>
</tr>
<tr>
<td></td>
<td><strong>UnconstrainedBox</strong></td>
<td>移除父约束，子组件自由决定</td>
<td>子组件恢复“原始”大小</td>
</tr>
</tbody></table>
<h3 id="4-2-常见布局模型"><a href="#4-2-常见布局模型" class="headerlink" title="4.2 常见布局模型"></a>4.2 常见布局模型</h3><h4 id="4-2-1-Flex（Row-Column）"><a href="#4-2-1-Flex（Row-Column）" class="headerlink" title="4.2.1 Flex（Row &#x2F; Column）"></a>4.2.1 Flex（Row &#x2F; Column）</h4><p>Flex 是 Flutter 最常用的布局模型，Row 和 Column 都是它的特例，分别在水平方向和垂直方向上排列子组件。</p>
<p>它的核心思路是：<strong>父控件分配主轴空间，子控件按规则占用；交叉轴则由对齐方式决定。</strong></p>
<ul>
<li><strong>主轴分配规则</strong><br>  子组件可以是固定宽&#x2F;高（如 Container(width: 50)），也可以通过 Expanded&#x2F;Flexible 参与伸缩。Expanded 会强制子组件填满剩余空间（tight 约束）。Flexible(fit: FlexFit.loose) 则允许子组件在“允许范围”内决定尺寸（loose 约束）。MainAxisAlignment 控制剩余空间的分配方式，比如：<br>  - spaceBetween：首尾贴边，中间均匀分布。<br>  - spaceAround：每个子前后有相等间距。<br>  - spaceEvenly：整体均匀分布，包括首尾。</li>
<li><strong>交叉轴对齐方式</strong><br>  CrossAxisAlignment.start&#x2F;end&#x2F;center：在交叉轴上靠头&#x2F;尾&#x2F;居中。stretch：强制子控件在交叉轴上拉伸到最大。</li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Container(  </span><br><span class="line">  height: <span class="number">100</span>,  </span><br><span class="line">  child: Row(  </span><br><span class="line">    mainAxisAlignment: MainAxisAlignment.spaceBetween,  </span><br><span class="line">    crossAxisAlignment: CrossAxisAlignment.stretch,  </span><br><span class="line">    children: [  </span><br><span class="line">      Container(width: <span class="number">50</span>, height: <span class="number">50</span>, color: Colors.red),  </span><br><span class="line">      Container(width: <span class="number">50</span>, height: <span class="number">80</span>, color: Colors.green),  </span><br><span class="line">      Container(width: <span class="number">50</span>, height: <span class="number">30</span>, color: Colors.blue),  </span><br><span class="line">    ],  </span><br><span class="line">  ),  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里红绿蓝方块会在水平上拉开间距（spaceBetween），而纵向则被拉伸到父容器的高度100（stretch）。</p>
<h4 id="4-2-2-Stack-Positioned"><a href="#4-2-2-Stack-Positioned" class="headerlink" title="4.2.2 Stack &#x2F; Positioned"></a>4.2.2 Stack &#x2F; Positioned</h4><p>Stack 提供了层叠布局能力，可以把多个子组件像“纸片”一样叠在一起。<br>它有两种定位方式：</p>
<ol>
<li><strong>非定位子组件</strong>：按照 alignment 对齐（默认左上角）。</li>
<li><strong>定位子组件</strong>：通过 Positioned 指定 left&#x2F;top&#x2F;right&#x2F;bottom，精确控制位置。</li>
</ol>
<p><strong>Positioned 与 ParentData</strong>    </p>
<ul>
<li>Positioned 依赖于 Stack 提供的 ParentData。</li>
<li>ParentData 是 RenderObject 系统里父子通信的“契约”，它告诉父控件如何摆放子控件。        </li>
<li>所以 Positioned <strong>只能用在 Stack 内部</strong>，否则会报错：<code>Incorrect use of ParentDataWidget</code></li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Stack(</span><br><span class="line">  children: [</span><br><span class="line">    Container(width: <span class="number">200</span>, height: <span class="number">200</span>, color: Colors.grey),</span><br><span class="line">    Positioned(left: <span class="number">20</span>, top: <span class="number">30</span>,</span><br><span class="line">      child: Container(width: <span class="number">50</span>, height: <span class="number">50</span>, color: Colors.red),</span><br><span class="line">    ),</span><br><span class="line">  ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>灰色方块作为背景，红色方块被定位到 (20, 30) 处。如果把 Positioned 放到 Column 里，运行时就会抛出 ParentData 错误。</p>
<h4 id="4-2-3-Intrinsic-系列-Widget"><a href="#4-2-3-Intrinsic-系列-Widget" class="headerlink" title="4.2.3 Intrinsic 系列 Widget"></a>4.2.3 Intrinsic 系列 Widget</h4><p>IntrinsicWidth 和 IntrinsicHeight 用来测量子组件的“固有大小”（intrinsic size），即在不受约束时的最小尺寸。<br>它们的实现方式是：<strong>对子组件多次测量，直到得出合适的尺寸</strong>。</p>
<ul>
<li><strong>优点</strong>：在不确定子组件尺寸时，能让布局“自动对齐”，比如表格场景。</li>
<li><strong>缺点</strong>：因为要进行多次 layout，性能开销很大。在复杂布局或长列表中使用，可能会严重卡顿。</li>
</ul>
<p>错误示例：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">IntrinsicHeight(</span><br><span class="line">  child: Row(</span><br><span class="line">    crossAxisAlignment: CrossAxisAlignment.stretch,</span><br><span class="line">    children: [</span><br><span class="line">      Text(<span class="string">&#x27;A&#x27;</span>),</span><br><span class="line">      Container(width: <span class="number">2</span>, color: Colors.black),</span><br><span class="line">      Expanded(child: ListView.builder(</span><br><span class="line">        itemCount: <span class="number">100</span>,</span><br><span class="line">        itemBuilder: (_, i) =&gt; Text(<span class="string">&#x27;Item <span class="subst">$i</span>&#x27;</span>),</span><br><span class="line">      )),</span><br><span class="line">    ],</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>报错：<code>RenderViewport does not support returning intrinsic dimensions.</code><br>这里 IntrinsicHeight 会强制 Row 的子组件对齐高度，但因为里面包裹了 ListView，Flutter 必须反复测量滚动列表，导致性能问题。这就是 Intrinsic 系列的“陷阱”。</p>
<p><strong>Intrinsic 系列的正确使用场景</strong></p>
<h5 id="4-2-3-1-行内对齐（IntrinsicHeight-Row）"><a href="#4-2-3-1-行内对齐（IntrinsicHeight-Row）" class="headerlink" title="4.2.3.1 行内对齐（IntrinsicHeight + Row）"></a>4.2.3.1 行内对齐（IntrinsicHeight + Row）</h5><p>让一行的子 Widget 高度一致（例如分隔线、文本、按钮需要等高）。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">IntrinsicHeight(</span><br><span class="line">  child: Row(</span><br><span class="line">    crossAxisAlignment: CrossAxisAlignment.stretch, <span class="comment">// 拉伸到相同高度</span></span><br><span class="line">    children: [</span><br><span class="line">      Expanded(child: Text(<span class="string">&#x27;Title&#x27;</span>)),</span><br><span class="line">      VerticalDivider(thickness: <span class="number">2</span>, color: Colors.black),</span><br><span class="line">      Expanded(child: Text(<span class="string">&#x27;Description&#x27;</span>)),</span><br><span class="line">    ],</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里 IntrinsicHeight 会强制测量 Row 的最高子元素，然后让其他子对齐。<br>常见于 <strong>表单行、左右对齐布局</strong>。</p>
<h5 id="4-2-3-2-列宽对齐（IntrinsicWidth-Column）"><a href="#4-2-3-2-列宽对齐（IntrinsicWidth-Column）" class="headerlink" title="4.2.3.2 列宽对齐（IntrinsicWidth + Column）"></a>4.2.3.2 列宽对齐（IntrinsicWidth + Column）</h5><p>让多行文字或控件宽度对齐，类似“表格”效果。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">IntrinsicWidth(</span><br><span class="line">  child: Column(</span><br><span class="line">    crossAxisAlignment: CrossAxisAlignment.stretch,</span><br><span class="line">    children: [</span><br><span class="line">      Row(children: [Text(<span class="string">&#x27;Name&#x27;</span>), SizedBox(width: <span class="number">10</span>), Expanded(child: Text(<span class="string">&#x27;Alice&#x27;</span>))]),</span><br><span class="line">      Row(children: [Text(<span class="string">&#x27;Age&#x27;</span>), SizedBox(width: <span class="number">10</span>), Expanded(child: Text(<span class="string">&#x27;23&#x27;</span>))]),</span><br><span class="line">      Row(children: [Text(<span class="string">&#x27;Gender&#x27;</span>), SizedBox(width: <span class="number">10</span>), Expanded(child: Text(<span class="string">&#x27;Female&#x27;</span>))]),</span><br><span class="line">    ],</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>IntrinsicWidth 会根据子元素最宽的一列计算宽度，保证多行对齐。<br>常见于 <strong>表单布局、属性列表</strong>。</p>
<h5 id="4-2-3-3-垂直自适应（IntrinsicHeight-自定义组合）"><a href="#4-2-3-3-垂直自适应（IntrinsicHeight-自定义组合）" class="headerlink" title="4.2.3.3 垂直自适应（IntrinsicHeight + 自定义组合）"></a>4.2.3.3 垂直自适应（IntrinsicHeight + 自定义组合）</h5><p>比如图文混排，右边文字可能很高，左边的图标要跟着等高显示。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">IntrinsicHeight(</span><br><span class="line">  child: Row(</span><br><span class="line">    crossAxisAlignment: CrossAxisAlignment.stretch,</span><br><span class="line">    children: [</span><br><span class="line">      Container(width: <span class="number">50</span>, color: Colors.blue), <span class="comment">// 图标区域</span></span><br><span class="line">      SizedBox(width: <span class="number">8</span>),</span><br><span class="line">      Expanded(</span><br><span class="line">        child: Text(</span><br><span class="line">          <span class="string">&quot;This is a long description that may wrap multiple lines.&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    ],</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>左边的图标容器会被拉伸到右边文字的高度，实现等高。<br>适合卡片、列表项的图文组合。</p>
<p><strong>Intrinsic 不推荐使用场景</strong><br>ListView、GridView、CustomScrollView → 会报错，因为这些需要懒加载。<br>动态子元素很多（100+） → Intrinsic 会导致多次测量，性能差。</p>
<p>注意点：<strong>Intrinsic 系列适合小规模布局对齐问题（Row &#x2F; Column &#x2F; Button）</strong>，不适合长列表、复杂滚动场景。</p>
<h4 id="4-2-4-自定义布局（RenderBox）"><a href="#4-2-4-自定义布局（RenderBox）" class="headerlink" title="4.2.4 自定义布局（RenderBox）"></a>4.2.4 自定义布局（RenderBox）</h4><p>有些时候，现成的布局组件不能满足需求，比如“流式布局（FlowLayout）”。这时就需要通过 <strong>自定义 RenderBox</strong> 来实现。</p>
<ul>
<li><strong>单子组件：RenderBox + performLayout</strong><br>  重写 performLayout，对子组件调用 child!.layout(constraints)。<br>  读取子组件的 size，再决定当前控件的大小。</li>
<li><strong>多子组件：MultiChildRenderObjectWidget</strong><br>  提供多个子节点，通过 ParentData 管理子控件布局。<br>  可以实现类似 Stack、Flow 的效果。</li>
</ul>
<p><strong>案例1</strong>：用单子组件 RenderBox来说明 performLayout 如何使用</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/rendering.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">单子组件的自定义 RenderBox</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">可以设置固定宽高，并可包含一个子组件</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyBox</span> <span class="keyword">extends</span> <span class="title">SingleChildRenderObjectWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> MyBox(&#123;</span><br><span class="line">    <span class="keyword">super</span>.key,</span><br><span class="line">    <span class="keyword">this</span>.width = <span class="number">100</span>,</span><br><span class="line">    <span class="keyword">this</span>.height = <span class="number">50</span>,</span><br><span class="line">    <span class="keyword">super</span>.child, <span class="comment">// 可选子组件</span></span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> width;  <span class="comment">// 自身宽度</span></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> height; <span class="comment">// 自身高度</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">创建对应的 RenderObject</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RenderMyBox createRenderObject(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> RenderMyBox(width: width, height: height);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">当 widget 更新时同步到 RenderObject</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> updateRenderObject(BuildContext context, RenderMyBox renderObject) &#123;</span><br><span class="line">    renderObject</span><br><span class="line">      ..width = width   <span class="comment">// 更新宽度</span></span><br><span class="line">      ..height = height; <span class="comment">// 更新高度</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">RenderObject：负责布局和绘制逻辑</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">继承 RenderProxyBox，因此自带 child 字段</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderMyBox</span> <span class="keyword">extends</span> <span class="title">RenderProxyBox</span> </span>&#123;</span><br><span class="line">  RenderMyBox(&#123;<span class="keyword">required</span> <span class="built_in">double</span> width, <span class="keyword">required</span> <span class="built_in">double</span> height&#125;)</span><br><span class="line">      : _width = width,</span><br><span class="line">        _height = height;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">double</span> _width;</span><br><span class="line">  <span class="built_in">double</span> _height;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">宽度 setter，修改后标记需要重新布局</span></span></span><br><span class="line">  <span class="keyword">set</span> width(<span class="built_in">double</span> value) &#123;</span><br><span class="line">    <span class="keyword">if</span> (_width != value) &#123;</span><br><span class="line">      _width = value;</span><br><span class="line">      markNeedsLayout(); <span class="comment">// 标记布局脏</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">高度 setter，修改后标记需要重新布局</span></span></span><br><span class="line">  <span class="keyword">set</span> height(<span class="built_in">double</span> value) &#123;</span><br><span class="line">    <span class="keyword">if</span> (_height != value) &#123;</span><br><span class="line">      _height = value;</span><br><span class="line">      markNeedsLayout();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">布局逻辑</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;</span><br><span class="line">    <span class="comment">// 设置自身大小</span></span><br><span class="line">    <span class="comment">// constraints.constrain 会根据父约束限制尺寸</span></span><br><span class="line">    size = constraints.constrain(Size(_width, _height));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果有子组件，则布局子组件</span></span><br><span class="line">    <span class="comment">// loosen() 表示放宽约束，让子组件尽量自由决定大小</span></span><br><span class="line">    child?.layout(constraints.loosen(), parentUsesSize: <span class="keyword">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">绘制逻辑</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    <span class="comment">// 绘制自身矩形</span></span><br><span class="line">    <span class="keyword">final</span> paint = Paint()..color = Colors.blue;</span><br><span class="line">    context.canvas.drawRect(offset &amp; size, paint);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 绘制子组件</span></span><br><span class="line">    <span class="keyword">if</span> (child != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// offset 表示父组件的偏移位置</span></span><br><span class="line">      context.paintChild(child!, offset);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何使用：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">MyBox(width: <span class="number">120</span>, height: <span class="number">80</span>)</span><br></pre></td></tr></table></figure>

<p><strong>案例2</strong>：自定义一个简单的 FlowLayout，实现流式换行布局</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;dart:math&#x27;</span> <span class="keyword">as</span> math;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/rendering.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">FlowLayout Widget</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">用于承载多个子 Widget，实现流式布局（自动换行）</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlowLayout</span> <span class="keyword">extends</span> <span class="title">MultiChildRenderObjectWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> FlowLayout(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">super</span>.children&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">创建对应的 RenderObject</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RenderFlowLayout createRenderObject(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> RenderFlowLayout();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">ParentData 用于存储子组件布局信息（偏移等）</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">每个子 RenderBox 都会有一个对应的 FlowParentData</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlowParentData</span> <span class="keyword">extends</span> <span class="title">ContainerBoxParentData</span>&lt;<span class="title">RenderBox</span>&gt; </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">RenderObject：FlowLayout 的核心布局逻辑</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">继承 RenderBox 并混入多子节点管理功能</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderFlowLayout</span> <span class="keyword">extends</span> <span class="title">RenderBox</span></span></span><br><span class="line"><span class="class">    <span class="title">with</span></span></span><br><span class="line"><span class="class">        <span class="title">ContainerRenderObjectMixin</span>&lt;<span class="title">RenderBox</span>, <span class="title">FlowParentData</span>&gt;,</span></span><br><span class="line"><span class="class">        <span class="title">RenderBoxContainerDefaultsMixin</span>&lt;<span class="title">RenderBox</span>, <span class="title">FlowParentData</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">核心布局逻辑</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;</span><br><span class="line">    <span class="built_in">double</span> dx = <span class="number">0</span>; <span class="comment">// 当前行 x 偏移</span></span><br><span class="line">    <span class="built_in">double</span> dy = <span class="number">0</span>; <span class="comment">// 当前行 y 偏移（行高累加）</span></span><br><span class="line">    <span class="built_in">double</span> maxDy = <span class="number">0</span>; <span class="comment">// 当前行最高的子 widget 高度</span></span><br><span class="line">    <span class="keyword">final</span> BoxConstraints constraints = <span class="keyword">this</span>.constraints;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 宽度限制，如果父组件宽度无限制，则使用无限宽度</span></span><br><span class="line">    <span class="built_in">double</span> containerWidth = constraints.hasBoundedWidth</span><br><span class="line">        ? constraints.maxWidth</span><br><span class="line">        : <span class="built_in">double</span>.infinity;</span><br><span class="line"></span><br><span class="line">    RenderBox? child = firstChild;</span><br><span class="line">    <span class="keyword">while</span> (child != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// 子组件布局</span></span><br><span class="line">      <span class="comment">// loosen() 将约束放宽，让子组件自由决定大小</span></span><br><span class="line">      child.layout(constraints.loosen(), parentUsesSize: <span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">final</span> childSize = child.size;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 换行逻辑：如果放不下，就换行</span></span><br><span class="line">      <span class="keyword">if</span> (dx + childSize.width &gt; containerWidth) &#123;</span><br><span class="line">        dx = <span class="number">0</span>;           <span class="comment">// x 重置</span></span><br><span class="line">        dy += maxDy;      <span class="comment">// y 下移一行</span></span><br><span class="line">        maxDy = <span class="number">0</span>;        <span class="comment">// 重置当前行最大高度</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 保存子组件偏移信息到 ParentData</span></span><br><span class="line">      <span class="keyword">final</span> FlowParentData childParentData = child.parentData <span class="keyword">as</span> FlowParentData;</span><br><span class="line">      childParentData.offset = Offset(dx, dy);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 更新 x 偏移和当前行最大高度</span></span><br><span class="line">      dx += childSize.width;</span><br><span class="line">      maxDy = math.max(maxDy, childSize.height);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 移动到下一个子组件</span></span><br><span class="line">      child = childParentData.nextSibling;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置 FlowLayout 自身大小</span></span><br><span class="line">    <span class="comment">// 如果父组件有约束宽度，取 maxWidth；否则取最后一行的实际宽度</span></span><br><span class="line">    size = constraints.constrain(</span><br><span class="line">      Size(</span><br><span class="line">        constraints.hasBoundedWidth ? constraints.maxWidth : dx,</span><br><span class="line">        dy + maxDy, <span class="comment">// 总高度 = 已排的行高累加 + 最后一行高度</span></span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">确保每个子节点的 parentData 类型正确</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> setupParentData(<span class="keyword">covariant</span> RenderObject child) &#123;</span><br><span class="line">    <span class="keyword">if</span> (child.parentData <span class="keyword">is</span>! FlowParentData) &#123;</span><br><span class="line">      child.parentData = FlowParentData();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">绘制子组件</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    RenderBox? child = firstChild;</span><br><span class="line">    <span class="keyword">while</span> (child != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> FlowParentData childParentData = child.parentData <span class="keyword">as</span> FlowParentData;</span><br><span class="line">      <span class="comment">// 将子组件绘制到它的偏移位置 + 父组件偏移</span></span><br><span class="line">      context.paintChild(child, childParentData.offset + offset);</span><br><span class="line">      child = childParentData.nextSibling;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">命中测试（点击、手势事件）</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> hitTestChildren(BoxHitTestResult result, &#123;<span class="keyword">required</span> Offset position&#125;) &#123;</span><br><span class="line">    RenderBox? child = lastChild; <span class="comment">// 从上往下检测</span></span><br><span class="line">    <span class="keyword">while</span> (child != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> FlowParentData childParentData = child.parentData <span class="keyword">as</span> FlowParentData;</span><br><span class="line">      <span class="keyword">final</span> <span class="built_in">bool</span> isHit = result.addWithPaintOffset(</span><br><span class="line">        offset: childParentData.offset,</span><br><span class="line">        position: position,</span><br><span class="line">        hitTest: (BoxHitTestResult result, Offset transformed) &#123;</span><br><span class="line">          <span class="comment">// 子组件的 hitTest</span></span><br><span class="line">          <span class="keyword">return</span> child!.hitTest(result, position: transformed);</span><br><span class="line">        &#125;,</span><br><span class="line">      );</span><br><span class="line">      <span class="keyword">if</span> (isHit) <span class="keyword">return</span> <span class="keyword">true</span>; <span class="comment">// 命中任意子组件返回 true</span></span><br><span class="line">      child = childParentData.previousSibling;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// 没有命中任何子组件</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何使用：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">FlowLayout(</span><br><span class="line">  children: <span class="built_in">List</span>.generate(</span><br><span class="line">    <span class="number">16</span>,</span><br><span class="line">    (index) =&gt; GestureDetector(</span><br><span class="line">      onTap: () &#123;</span><br><span class="line">        debugPrint(<span class="string">&#x27;Clicked child index: <span class="subst">$index</span>&#x27;</span>);</span><br><span class="line">      &#125;,</span><br><span class="line">      child: Container(</span><br><span class="line">        width: <span class="number">60</span> + (index % <span class="number">3</span>) * <span class="number">20.0</span>,</span><br><span class="line">        height: <span class="number">50</span>,</span><br><span class="line">        color: Colors.primaries[index % Colors.primaries.length],</span><br><span class="line">      ),</span><br><span class="line">    ),</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250924172335.png"></p>
<ul>
<li><strong>Flex</strong> 适合一维分布，主&#x2F;交叉轴明确。    </li>
<li><strong>Stack&#x2F;Positioned</strong> 用于层叠与绝对定位，核心在 ParentData。</li>
<li><strong>Intrinsic</strong> 提供自动对齐能力，但要注意性能开销。</li>
<li><strong>自定义 RenderBox</strong> 是最高级的扩展方式，能实现完全自定义布局逻辑。</li>
</ul>
<h3 id="4-3-Sliver-与滚动体系"><a href="#4-3-Sliver-与滚动体系" class="headerlink" title="4.3 Sliver 与滚动体系"></a>4.3 Sliver 与滚动体系</h3><p>Sliver 不是普通 Widget，而是一类 <strong>可伸缩的 RenderObject 布局协议</strong>。它只描述 <strong>可滚动区域的布局规则</strong>，由 Viewport 驱动显示内容。<br><strong>特点</strong>    </p>
<ul>
<li>惰性布局：只构建可见区域。</li>
<li>可与 Viewport 协同，实现滚动、吸顶、折叠等效果。</li>
</ul>
<p><strong>直观比喻</strong>：把可滚动区域看作“胶卷”，Sliver 就是胶卷上的每一帧，只渲染当前可见的部分。</p>
<h4 id="4-3-1-SliverConstraints-与-Viewport"><a href="#4-3-1-SliverConstraints-与-Viewport" class="headerlink" title="4.3.1 SliverConstraints 与 Viewport"></a>4.3.1 SliverConstraints 与 Viewport</h4><p><strong>SliverConstraints</strong>提供给 Sliver 布局的约束信息，包括：</p>
<ul>
<li>scrollOffset：滚动位置</li>
<li>overlap：前一个 Sliver 造成的重叠</li>
<li>viewportMainAxisExtent：可见区域长度<br><strong>Viewport</strong>：类似父容器，控制可见区域并驱动 Sliver 布局和渲染。<br>案例：展示 CustomScrollView + SliverAppBar，并且 SliverAppBar 会根据滚动收缩折叠，实现吸顶效果</li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SliverDemoPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> SliverDemoPage(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      body: CustomScrollView(</span><br><span class="line">        <span class="comment">// CustomScrollView 内部其实就是一个 Viewport</span></span><br><span class="line">        <span class="comment">//    它就像“相机取景框”，决定屏幕能看到多大范围的内容。</span></span><br><span class="line">        <span class="comment">//    滚动时，Viewport 会产生 SliverConstraints，</span></span><br><span class="line">        <span class="comment">//    并传给每一个 Sliver（SliverAppBar、SliverList）。</span></span><br><span class="line">        slivers: [</span><br><span class="line">          <span class="comment">// SliverAppBar</span></span><br><span class="line">          SliverAppBar(</span><br><span class="line">            pinned: <span class="keyword">true</span>, <span class="comment">// 吸顶效果 → Viewport 告诉它 scrollOffset &gt;= 阈值时固定在顶部</span></span><br><span class="line">            expandedHeight: <span class="number">200</span>, <span class="comment">// 展开高度</span></span><br><span class="line">            flexibleSpace: FlexibleSpaceBar(</span><br><span class="line">              title: <span class="keyword">const</span> Text(<span class="string">&#x27;SliverAppBar 示例&#x27;</span>),</span><br><span class="line">              background: Container(</span><br><span class="line">                color: Colors.blueAccent, <span class="comment">// 纯色背景</span></span><br><span class="line">              ),</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment">// SliverAppBar 在布局时会读取 SliverConstraints.scrollOffset</span></span><br><span class="line">            <span class="comment">//    根据滚动位置决定收缩多少，什么时候折叠成普通 AppBar。</span></span><br><span class="line">          ),</span><br><span class="line"></span><br><span class="line">          <span class="comment">// SliverList</span></span><br><span class="line">          SliverList(</span><br><span class="line">            delegate: SliverChildBuilderDelegate(</span><br><span class="line">              (context, index) =&gt; ListTile(</span><br><span class="line">                leading: CircleAvatar(child: Text(<span class="string">&#x27;<span class="subst">$&#123;index + <span class="number">1</span>&#125;</span>&#x27;</span>)),</span><br><span class="line">                title: Text(<span class="string">&#x27;列表项 <span class="subst">$&#123;index + <span class="number">1</span>&#125;</span>&#x27;</span>),</span><br><span class="line">              ),</span><br><span class="line">              childCount: <span class="number">30</span>,</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment">// SliverList 在布局时同样拿到 SliverConstraints：</span></span><br><span class="line">            <span class="comment">//    - scrollOffset：告诉它从第几个像素开始可见</span></span><br><span class="line">            <span class="comment">//    - overlap：前面 SliverAppBar 占据/折叠后的空间</span></span><br><span class="line">            <span class="comment">//    - viewportMainAxisExtent：当前屏幕能显示多少列表内容</span></span><br><span class="line">            <span class="comment">//    它会据此决定从第几个 item 开始渲染，避免把 30 个都画出来。</span></span><br><span class="line">          ),</span><br><span class="line">        ],</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-3-3-懒加载构建机制（Lazy-Build）"><a href="#4-3-3-懒加载构建机制（Lazy-Build）" class="headerlink" title="4.3.3 懒加载构建机制（Lazy Build）"></a>4.3.3 懒加载构建机制（Lazy Build）</h4><p>在 Flutter 的滚动体系里，SliverList 和 SliverGrid 并不会一次性把所有子元素都创建出来，而是采取 <strong>懒加载构建（Lazy Build）</strong> 策略。</p>
<p><strong>1. 什么是懒加载构建？</strong><br>“懒加载”指的是：<strong>只在需要的时候才去构建子 Widget</strong>。<br>当一个列表有成千上万个元素时，Flutter 不会一次性把它们全画到屏幕上，而是根据当前 <strong>可见区域（Viewport）</strong> 来决定构建多少个子元素。    </p>
<p>换句话说，屏幕能看到多少，就只构建多少；滑动到新的位置时，再动态创建对应的子元素。</p>
<p><strong>2. 为什么需要懒加载构建？</strong></p>
<ul>
<li><strong>节省内存</strong>：如果一次性创建 10000 个 ListTile，内存会瞬间飙升。</li>
<li><strong>提升性能</strong>：构建 Widget 的过程需要 CPU 计算，批量一次性构建会导致卡顿。</li>
<li><strong>按需加载</strong>：只保留可见范围附近的元素，大幅降低布局和绘制的压力。</li>
</ul>
<p>这就是为什么 Flutter 的 ListView 或 GridView 即便加载成千上万条数据，依旧能保持流畅。</p>
<p><strong>3. 懒加载构建是如何实现的？</strong><br>核心在于 <strong>SliverChildBuilderDelegate</strong>：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">SliverList(</span><br><span class="line">  delegate: SliverChildBuilderDelegate(</span><br><span class="line">    (context, index) &#123;</span><br><span class="line">      <span class="comment">// 只有当 item 出现在可见区域时，这里才会被调用</span></span><br><span class="line">      <span class="keyword">return</span> ListTile(title: Text(<span class="string">&#x27;Item <span class="subst">$index</span>&#x27;</span>));</span><br><span class="line">    &#125;,</span><br><span class="line">    childCount: <span class="number">10000</span>,</span><br><span class="line">  ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>SliverList 在布局时会收到 <strong>SliverConstraints</strong>，知道当前屏幕可见区域范围。它只会调用 builder 来构建可见区域内的子元素。<br>当用户继续滚动时，之前滑出屏幕的子元素会被回收（Element&#x2F;RenderObject 复用），新的子元素才会被创建。<br><strong>4. 案例：10000 条数据不卡顿</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">CustomScrollView(</span><br><span class="line">  slivers: [</span><br><span class="line">    SliverList(</span><br><span class="line">      delegate: SliverChildBuilderDelegate(</span><br><span class="line">        (context, index) =&gt; ListTile(title: Text(<span class="string">&#x27;Item <span class="subst">$index</span>&#x27;</span>)),</span><br><span class="line">        childCount: <span class="number">10000</span>,</span><br><span class="line">      ),</span><br><span class="line">    ),</span><br><span class="line">  ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>即使有 <strong>10000 条数据</strong>，屏幕一次最多渲染几十个 ListTile。其他数据并没有被真正构建，只是“等着”在滑动到对应位置时再出现。这就是为什么列表依然能保持流畅滚动。</p>
<p><strong>懒加载构建机制保证了 Flutter 列表的高性能与低内存占用。</strong> 它通过 <strong>Viewport + SliverConstraints</strong> 精确控制可见范围，只构建需要展示的子元素，让即使是超大规模数据列表也能流畅运行。</p>
<h4 id="4-3-4-常见-Sliver-类型"><a href="#4-3-4-常见-Sliver-类型" class="headerlink" title="4.3.4 常见 Sliver 类型"></a>4.3.4 常见 Sliver 类型</h4><p>在 CustomScrollView 中，Sliver 就像积木，可以自由组合。Flutter 内置了许多 Sliver 类型，常见的有：<br><strong>1. SliverPadding</strong><br>作用：在 Sliver 外层增加内边距。类似于普通 Widget 里的 Padding，但这里针对 Sliver 布局生效。<br>使用场景：想在列表最外层增加间距，而不是单独给每个子元素加 Padding。</p>
<p>示例：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">CustomScrollView(  </span><br><span class="line">  slivers: [  </span><br><span class="line">    SliverPadding(  </span><br><span class="line">      padding: <span class="keyword">const</span> EdgeInsets.all(<span class="number">16</span>),  </span><br><span class="line">      sliver: SliverList(  </span><br><span class="line">        delegate: SliverChildBuilderDelegate(  </span><br><span class="line">              (context, index) =&gt; ListTile(title: Text(<span class="string">&#x27;Item <span class="subst">$index</span>&#x27;</span>)),  </span><br><span class="line">          childCount: <span class="number">10</span>,  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    )  </span><br><span class="line">  ],  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>2.SliverFillRemaining</strong><br>作用：填充滚动区域剩余的空间。常用来在列表数据较少时，自动撑满屏幕，避免底部留白。<br>使用场景：登录页、详情页最后一块区域要“贴住底部”。</p>
<p>示例：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">CustomScrollView(  </span><br><span class="line">  slivers: [  </span><br><span class="line">    SliverFillRemaining(  </span><br><span class="line">      hasScrollBody: <span class="keyword">false</span>, <span class="comment">// 不再允许内部滚动，直接填满  </span></span><br><span class="line">      child: Center(child: Text(<span class="string">&quot;内容撑满剩余空间&quot;</span>)),  </span><br><span class="line">    )  </span><br><span class="line">  ],  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>3.SliverPersistentHeader</strong><br>作用：让一个 Widget 在滚动过程中“持久存在”，可以配置成：    </p>
<ul>
<li>一直固定在顶部（类似 pinned AppBar）。</li>
<li>随着滚动收缩&#x2F;展开。<br>使用场景：吸顶效果，例如固定的 TabBar、搜索框、筛选栏。</li>
</ul>
<p>案例：SliverPersistentHeader实现吸顶 TabBar</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SliverPersistentHeaderDemo</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> SliverPersistentHeaderDemo(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> DefaultTabController(</span><br><span class="line">      length: <span class="number">3</span>, <span class="comment">// Tab 数量</span></span><br><span class="line">      child: Scaffold(</span><br><span class="line">        body: CustomScrollView(</span><br><span class="line">          slivers: [</span><br><span class="line">            <span class="comment">// 顶部可伸缩的 AppBar</span></span><br><span class="line">            SliverAppBar(</span><br><span class="line">              title: <span class="keyword">const</span> Text(<span class="string">&#x27;SliverPersistentHeader 示例&#x27;</span>),</span><br><span class="line">              pinned: <span class="keyword">true</span>,  <span class="comment">// 吸顶，AppBar 收缩后仍然固定在顶部</span></span><br><span class="line">              expandedHeight: <span class="number">200</span>, <span class="comment">// 展开高度</span></span><br><span class="line">              flexibleSpace: Container(color: Colors.blueAccent), <span class="comment">// 展开背景</span></span><br><span class="line">            ),</span><br><span class="line"></span><br><span class="line">            <span class="comment">// TabBar 吸顶（通过 SliverPersistentHeader 实现）</span></span><br><span class="line">            SliverPersistentHeader(</span><br><span class="line">              pinned: <span class="keyword">true</span>, <span class="comment">// 关键：让 TabBar 固定在顶部</span></span><br><span class="line">              delegate: _SliverTabBarDelegate(</span><br><span class="line">                <span class="keyword">const</span> TabBar(</span><br><span class="line">                  tabs: [</span><br><span class="line">                    Tab(text: <span class="string">&#x27;Tab 1&#x27;</span>),</span><br><span class="line">                    Tab(text: <span class="string">&#x27;Tab 2&#x27;</span>),</span><br><span class="line">                    Tab(text: <span class="string">&#x27;Tab 3&#x27;</span>),</span><br><span class="line">                  ],</span><br><span class="line">                ),</span><br><span class="line">              ),</span><br><span class="line">            ),</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Tab 对应的内容区域</span></span><br><span class="line">            <span class="comment">// 注意：TabBarView 内部自带 PageView，与外层的 CustomScrollView 可能冲突，所以这里用 SliverFillRemaining 包裹</span></span><br><span class="line">            SliverFillRemaining(</span><br><span class="line">              child: TabBarView(</span><br><span class="line">                children: [</span><br><span class="line">                  <span class="comment">// 每个 Tab 对应一个独立的列表</span></span><br><span class="line">                  ListView.builder(</span><br><span class="line">                    itemCount: <span class="number">30</span>,</span><br><span class="line">                    itemBuilder: (_, i) =&gt; ListTile(title: Text(<span class="string">&#x27;Tab1-Item <span class="subst">$i</span>&#x27;</span>)),</span><br><span class="line">                  ),</span><br><span class="line">                  ListView.builder(</span><br><span class="line">                    itemCount: <span class="number">30</span>,</span><br><span class="line">                    itemBuilder: (_, i) =&gt; ListTile(title: Text(<span class="string">&#x27;Tab2-Item <span class="subst">$i</span>&#x27;</span>)),</span><br><span class="line">                  ),</span><br><span class="line">                  ListView.builder(</span><br><span class="line">                    itemCount: <span class="number">30</span>,</span><br><span class="line">                    itemBuilder: (_, i) =&gt; ListTile(title: Text(<span class="string">&#x27;Tab3-Item <span class="subst">$i</span>&#x27;</span>)),</span><br><span class="line">                  ),</span><br><span class="line">                ],</span><br><span class="line">              ),</span><br><span class="line">            ),</span><br><span class="line">          ],</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 Delegate 用于控制 SliverPersistentHeader 的布局和绘制</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_SliverTabBarDelegate</span> <span class="keyword">extends</span> <span class="title">SliverPersistentHeaderDelegate</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> TabBar tabBar;</span><br><span class="line"></span><br><span class="line">  _SliverTabBarDelegate(<span class="keyword">this</span>.tabBar);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构建实际显示的 TabBar</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context, <span class="built_in">double</span> shrinkOffset, <span class="built_in">bool</span> overlapsContent) &#123;</span><br><span class="line">    <span class="comment">// shrinkOffset：滚动时收缩的距离</span></span><br><span class="line">    <span class="comment">// overlapsContent：是否覆盖到内容区域</span></span><br><span class="line">    <span class="keyword">return</span> Container(</span><br><span class="line">      color: Colors.white, <span class="comment">// 给 TabBar 背景色，避免透明导致文字重叠</span></span><br><span class="line">      child: tabBar,</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 最大高度（这里直接用 TabBar 的高度）</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">double</span> <span class="keyword">get</span> maxExtent =&gt; tabBar.preferredSize.height;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 最小高度（同上，保持固定高度）</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">double</span> <span class="keyword">get</span> minExtent =&gt; tabBar.preferredSize.height;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 判断是否需要重建</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> shouldRebuild(<span class="keyword">covariant</span> _SliverTabBarDelegate oldDelegate) &#123;</span><br><span class="line">    <span class="keyword">return</span> tabBar != oldDelegate.tabBar;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以把 SliverPersistentHeader 想象成“钉子”，把某个 Widget（如 TabBar）钉在滚动区域的某个位置：</p>
<ul>
<li>设置 pinned: true → 钉在顶部。</li>
<li>设置 floating: true → 滑动时快速出现&#x2F;隐藏。</li>
<li>配合 delegate → 可以灵活定义高度和内容。</li>
</ul>
<p>总结：</p>
<ul>
<li>SliverPadding → 控制间距；</li>
<li>SliverFillRemaining → 填满剩余空间；</li>
<li>SliverPersistentHeader → 实现吸顶效果（常用于 TabBar、搜索栏）。<br>它们让 CustomScrollView 更加灵活，能组合出丰富的滚动交互效果。</li>
</ul>
<h3 id="4-5-性能优化建议"><a href="#4-5-性能优化建议" class="headerlink" title="4.5 性能优化建议"></a>4.5 性能优化建议</h3><p>Flutter 的渲染性能很大程度取决于 <strong>布局（layout）和绘制（paint）阶段的开销</strong>。如果我们在布局或绘制上做了不必要的工作，就可能导致卡顿（特别是列表滑动场景）。下面几条优化策略可以帮助我们构建更高效的 UI。</p>
<h4 id="4-5-1-避免过度使用-Intrinsic-与-GlobalKey"><a href="#4-5-1-避免过度使用-Intrinsic-与-GlobalKey" class="headerlink" title="4.5.1 避免过度使用 Intrinsic 与 GlobalKey"></a>4.5.1 避免过度使用 Intrinsic 与 GlobalKey</h4><p><strong>IntrinsicXXX Widget</strong>（如 IntrinsicHeight、IntrinsicWidth）会强制子节点进行多次测量，以确定最小&#x2F;最大大小 → 等于让整个子树多跑一遍 layout，代价很大。<br><strong>GlobalKey</strong> 会触发跨树查找和全局布局更新，过度使用会导致性能下降。</p>
<p><strong>优化建议</strong>：<br>能用 Expanded、Flexible、SizedBox 等约束就不要用 Intrinsic。<br>除非确实需要唯一标识（如表单保存状态），不要滥用 GlobalKey。</p>
<h4 id="4-5-2-合理使用-const-Widget"><a href="#4-5-2-合理使用-const-Widget" class="headerlink" title="4.5.2 合理使用 const Widget"></a>4.5.2 合理使用 const Widget</h4><p>Flutter 会在 Widget → Element → RenderObject 的过程中频繁创建对象。<br><strong>const Widget</strong> 表示该 Widget 是不可变的，Flutter 可以在编译期常量化，避免每次 rebuild 都重新创建。</p>
<p><strong>优化建议</strong>：<br>所有静态不变的 UI（如 Text(“标题”)、Icon(Icons.add)）都加上 const。<br>在大型列表中，const 可以显著减少对象分配和 GC 压力。</p>
<h4 id="4-5-3-利用-RepaintBoundary-与-Sliver"><a href="#4-5-3-利用-RepaintBoundary-与-Sliver" class="headerlink" title="4.5.3 利用 RepaintBoundary 与 Sliver"></a>4.5.3 利用 RepaintBoundary 与 Sliver</h4><p><strong>RepaintBoundary</strong>：为子树建立独立的绘制层，当子树内部发生变化时，不会影响到外部 → 避免“大面积重绘”。比如一个视频播放器区域更新帧画面时，外部的文字和按钮不应该被迫重绘。<br><strong>Sliver</strong>：提供懒加载构建机制（只渲染可见区域），避免创建和绘制不可见的 widget。</p>
<p><strong>优化建议</strong>：<br>在频繁更新的局部（如动画区、图表区）加上 RepaintBoundary。<br>在长列表、复杂滚动页面里优先使用 SliverList &#x2F; SliverGrid，而不是一次性构建整个列表。</p>
<h4 id="4-5-4-分层次布局"><a href="#4-5-4-分层次布局" class="headerlink" title="4.5.4 分层次布局"></a>4.5.4 分层次布局</h4><p>如果一个 Widget 树过于庞大，底层 RenderObject 也会变得复杂，导致一次重绘或重新布局耗时变长。将复杂 UI 拆分成多个独立 widget，可以缩小「受影响的范围」。</p>
<h2 id="5-渲染管线与-PipelineOwner"><a href="#5-渲染管线与-PipelineOwner" class="headerlink" title="5. 渲染管线与 PipelineOwner"></a>5. 渲染管线与 PipelineOwner</h2><p>Flutter 的渲染性能与体验，核心依赖于它的 <strong>渲染管线（Rendering Pipeline）</strong>。渲染管线就像一条流水线：UI 层的 Widget 描述，会依次经历构建、布局、绘制，最终交给 GPU 合成并显示在屏幕上。</p>
<p>在这条流水线上，<strong>PipelineOwner</strong> 扮演着「流水线管理者」的角色，负责调度 layout &#x2F; paint &#x2F; composite 等阶段的执行。</p>
<h3 id="5-1-Frame-Pipeline-调度流程"><a href="#5-1-Frame-Pipeline-调度流程" class="headerlink" title="5.1 Frame Pipeline 调度流程"></a>5.1 Frame Pipeline 调度流程</h3><p>Flutter 的一帧渲染就像一条工厂流水线，从「接到订单」到「产品上架」要经过多个环节。整个流程可以拆解为四个关键阶段：<strong>调度（scheduleFrame） → 驱动（vsync） → 渲染管线（build&#x2F;layout&#x2F;paint） → 光栅化（raster）</strong>。</p>
<h4 id="5-1-1-scheduleFrame：发起新的一帧"><a href="#5-1-1-scheduleFrame：发起新的一帧" class="headerlink" title="5.1.1 scheduleFrame：发起新的一帧"></a>5.1.1 scheduleFrame：发起新的一帧</h4><p>当我们调用 setState() 或动画驱动时，Flutter 会调用 <strong>SchedulerBinding.scheduleFrame()</strong> 请求渲染新的一帧。你可以把它想象成「告诉流水线工厂：有新订单需要生产」。这一步只是登记需求，真正的生产还要等工厂开工信号（vsync）。</p>
<h4 id="5-1-2-Animator-驱动-vsync：开工信号"><a href="#5-1-2-Animator-驱动-vsync：开工信号" class="headerlink" title="5.1.2 Animator 驱动 vsync：开工信号"></a>5.1.2 Animator 驱动 vsync：开工信号</h4><p>Flutter 通过 <strong>Window.onBeginFrame</strong> 接收来自系统的 <strong>vsync 信号</strong>（Vertical Synchronization，屏幕刷新同步信号）。    </p>
<p><strong>vsync 的作用</strong>：决定 Flutter 何时开始新的一帧；保证渲染和屏幕刷新节奏一致，避免出现「撕裂」（屏幕上半部分是旧画面，下半部分是新画面）。<br>可以把 vsync 理解成「工厂的节拍器」，工人们必须跟着节奏开工，不能提前也不能落后。</p>
<h4 id="5-1-3-三大阶段：Build-→-Layout-→-Paint"><a href="#5-1-3-三大阶段：Build-→-Layout-→-Paint" class="headerlink" title="5.1.3 三大阶段：Build → Layout → Paint"></a>5.1.3 三大阶段：Build → Layout → Paint</h4><p>拿到 vsync 的信号后，Flutter 进入渲染管线的三大阶段。这些工作由 <strong>PipelineOwner</strong> 统一调度。<br> <strong>(1) Build 阶段</strong></p>
<ul>
<li>目标：把最新的 <strong>状态（State）</strong> 转换为 UI 结构。</li>
<li>过程： Widget → Element → RenderObject，也就是「设计图 → 工程图 → 实体骨架」。</li>
<li>类比：建房子前先画设计图，然后生成施工图，最后搭建骨架。<br><strong>(2) Layout 阶段</strong></li>
<li>目标：确定每个 RenderObject 的大小和位置。</li>
<li>流程由 <strong>PipelineOwner.flushLayout()</strong> 驱动：先布局父节点，再递归子节点；并且处理 <strong>layout dirty</strong>（需要重新布局的节点）。</li>
<li>类比：工厂工人按照施工图，把每个零件安放到正确的位置，并量好尺寸。<br> <strong>(3) Paint 阶段</strong></li>
<li>目标：把绘制命令写入 Layer Tree。</li>
<li>流程由 <strong>PipelineOwner.flushPaint()</strong> 驱动：遍历需要重绘的节点（<strong>paint dirty</strong>），生成绘制指令。并将结果存放到 <strong>Layer Tree</strong>（图层树）。</li>
<li>类比：工人们在零件上刷颜色、画细节，最后把成品放到各个透明图层上。</li>
</ul>
<h4 id="5-1-4-Raster：GPU-光栅化"><a href="#5-1-4-Raster：GPU-光栅化" class="headerlink" title="5.1.4 Raster：GPU 光栅化"></a>5.1.4 Raster：GPU 光栅化</h4><p><strong>Layer Tree</strong> 会交给 GPU 线程，由 <strong>Skia&#x2F;Impeller</strong> 引擎将矢量绘制命令转换为像素位图。最终，生成的位图会显示到屏幕上。<br>类比：把透明的图层一张张叠好，然后交给打印机（GPU）打印出来，贴到屏幕上。</p>
<h3 id="5-2-PipelineOwner-的核心作用"><a href="#5-2-PipelineOwner-的核心作用" class="headerlink" title="5.2 PipelineOwner 的核心作用"></a>5.2 PipelineOwner 的核心作用</h3><p>PipelineOwner 就像流水线的调度中心，它维护着「脏标记」（dirty bits），确保只处理需要更新的部分，从而保证效率。</p>
<ul>
<li><strong>layout dirty</strong>：哪些节点需要重新布局。</li>
<li><strong>paint dirty</strong>：哪些节点需要重新绘制。</li>
<li><strong>compositing dirty</strong>：哪些节点需要重新合成 Layer。</li>
</ul>
<p>工作机制：</p>
<ol>
<li>在一帧内，Flutter 会批量收集所有「脏节点」。</li>
<li>PipelineOwner 会按照顺序（layout → paint → compositing）逐一清理这些脏标记。</li>
<li>避免全量重算，提升性能。</li>
</ol>
<p>类比：流水线调度员拿着订单表，只安排需要修改的工序，不会让所有工人都从头到尾再干一遍。</p>
<p>Flutter 的一帧渲染可以总结为：</p>
<ol>
<li><strong>调度</strong>：scheduleFrame() 提交新订单。</li>
<li><strong>驱动</strong>：vsync 发出节拍信号。</li>
<li><strong>流水线</strong>：PipelineOwner 调度 build&#x2F;layout&#x2F;paint，处理脏节点。</li>
<li><strong>光栅化</strong>：Skia&#x2F;Impeller 把 Layer Tree 转换为位图，由 GPU 显示到屏幕。</li>
</ol>
<h3 id="5-2-Layer-Tree-与合成"><a href="#5-2-Layer-Tree-与合成" class="headerlink" title="5.2 Layer Tree 与合成"></a>5.2 Layer Tree 与合成</h3><p>在 Flutter 的渲染管线中，RenderObject 并不会直接绘制到屏幕上，而是将绘制指令记录到 <strong>Layer Tree</strong>。Layer Tree 就像一张「图层拼贴图」，最后由 GPU 进行合成（composition）。<br>理解 Layer Tree 的层次结构和合成机制，也是掌握 Flutter 渲染性能的关键。</p>
<h4 id="5-2-1-Layer-的层次结构"><a href="#5-2-1-Layer-的层次结构" class="headerlink" title="5.2.1 Layer 的层次结构"></a>5.2.1 Layer 的层次结构</h4><p>Flutter 提供了多种 Layer，每种 Layer 都有不同的作用。<br>常见 Layer 包括：</p>
<ul>
<li><strong>OffsetLayer</strong>：表示「位移」操作，例如把一整个子树向下平移 100 像素。这样做的好处是避免对子树重新绘制，只需在合成时调整位置。</li>
<li><strong>TransformLayer</strong>：表示矩阵变换（旋转、缩放、倾斜等），例如实现 3D 卡片翻转动画时，就依赖 TransformLayer。</li>
<li><strong>ClipLayer</strong>：负责裁剪内容，比如圆角矩形裁剪、路径裁剪。通过 ClipLayer，Flutter 可以只渲染可见区域，减少 GPU 开销。</li>
<li><strong>PictureLayer</strong>：存储真正的绘制命令（Canvas drawRect、drawImage 等），最终交给 Skia 渲染。</li>
</ul>
<p>可以把 Layer 树类比为 <strong>Photoshop 图层结构</strong>：PictureLayer 是绘制好的「画布内容」，而Offset&#x2F;Transform&#x2F;ClipLayer 相当于「图层效果」，最终由合成器把这些图层叠加成一张完整的画面。</p>
<h4 id="5-2-2-RepaintBoundary-的作用与误用"><a href="#5-2-2-RepaintBoundary-的作用与误用" class="headerlink" title="5.2.2 RepaintBoundary 的作用与误用"></a>5.2.2 RepaintBoundary 的作用与误用</h4><p>在 Flutter 中，<strong>RepaintBoundary 是 Layer Tree 的一个重要优化工具</strong>。</p>
<p>当 Widget 树中插入 RepaintBoundary，该子树会单独生成一个 Layer。如果该子树内容发生变化，只需要重绘这个 Layer，而不是整个父树。典型场景：视频播放器区域、复杂动画组件、图表区域等。<br>这样做的好处是可以减少无关区域的重绘，提高性能。比如页面上有个计时器数字在跳动，如果没有 RepaintBoundary，整个页面都可能被标记为重绘；加上 RepaintBoundary，就只会重绘数字区域。<br>当然滥用 RepaintBoundary 会导致 Layer Tree 过于庞大。每个 Layer 都会增加内存和合成开销，如果长列表的每一项都包一层 RepaintBoundary，性能反而更差。</p>
<p>只在「更新频繁的局部」或「代价昂贵的子树」外面包裹 RepaintBoundary，而不是盲目到处用。</p>
<h4 id="5-2-3-Preroll-vs-Paint-阶段"><a href="#5-2-3-Preroll-vs-Paint-阶段" class="headerlink" title="5.2.3 Preroll vs Paint 阶段"></a>5.2.3 Preroll vs Paint 阶段</h4><p>Flutter 在构建 Layer Tree 时，并不是直接绘制，而是分成两个阶段：</p>
<ol>
<li><strong>Preroll 阶段</strong>（预处理阶段）<ul>
<li>遍历整个 Layer Tree，收集绘制范围、裁剪信息、缓存策略。</li>
<li>比如判断某个区域是否在屏幕之外，如果完全不可见，就可以跳过绘制。</li>
</ul>
</li>
<li><strong>Paint 阶段</strong>（绘制阶段）<ul>
<li>执行真正的绘制命令，把路径、颜色、图片等写入 Picture（由绘制引擎管理）。</li>
<li>这些 Picture 最终由 GPU 合成，显示在屏幕上。</li>
</ul>
</li>
</ol>
<p>这样做的好处是通过 Preroll → Paint 的分离，Flutter 可以在绘制前进行裁剪优化，避免「无效绘制」。比如一个被完全遮挡的 widget，在 Preroll 阶段就能被跳过，不会浪费绘制性能。</p>
<h3 id="5-3-多线程模型"><a href="#5-3-多线程模型" class="headerlink" title="5.3 多线程模型"></a>5.3 多线程模型</h3><p>Flutter 在渲染体系中，为了兼顾性能和流畅度，采用了多线程并行分工的方式。你可以把整个渲染流程想象成一个小工厂：有设计师（UI 线程）、绘图师（GPU 线程）、快递员（IO 线程），大家分工明确，流水线式协作。</p>
<h4 id="5-3-1-三大核心线程的分工"><a href="#5-3-1-三大核心线程的分工" class="headerlink" title="5.3.1. 三大核心线程的分工"></a>5.3.1. 三大核心线程的分工</h4><ol>
<li><strong>UI Thread（主线程 &#x2F; Dart 线程）</strong><br> 负责执行 Dart 代码，包括 Widget 构建、布局（layout）、绘制指令（paint）的生成。产出是一棵完整的 <strong>Layer Tree</strong>（层次结构，记录了需要绘制的内容和效果）。UI Thread 像是<strong>设计师</strong>，负责画设计图，把界面描述清楚。</li>
<li><strong>GPU Thread（渲染线程）</strong><br> 负责接收 UI Thread 生成的 Layer Tree，进行光栅化（Rasterization），把抽象的绘制指令转换为真正的像素。产出是一帧帧可以显示在屏幕上的图像。GPU Thread 像是<strong>绘图师</strong>，根据设计图真正用画笔把画布涂满。</li>
<li><strong>IO Thread（输入输出线程）</strong><br> 负责处理文件和资源的加载（例如图片解码、字体读取、网络数据缓存）。这样可以避免这些耗时操作阻塞 UI Thread。IO Thread 就是<strong>快递员</strong>，专门把外部资源（图片、文件）及时送到工厂里。</li>
</ol>
<h4 id="5-3-2-一帧是如何跨线程传递的？"><a href="#5-3-2-一帧是如何跨线程传递的？" class="headerlink" title="5.3.2 一帧是如何跨线程传递的？"></a>5.3.2 一帧是如何跨线程传递的？</h4><p>可以用“快照 + 接力赛”的方式理解。</p>
<ol>
<li><strong>UI Thread → 生成 Layer Tree</strong><br> 当 Flutter 要渲染一帧时，UI Thread 会执行：<ul>
<li>build → 构建 Widget Tree</li>
<li>layout → 计算位置大小</li>
<li>paint → 生成绘制指令<br> 最终把结果封装成 <strong>Layer Tree</strong>。这一步是“设计师完成设计图”。</li>
</ul>
</li>
<li><strong>UI Thread → GPU Thread</strong><br> UI Thread 把 Layer Tree 提交给 GPU Thread。UI Thread 提交后，就可以继续处理下一帧（不会被 GPU 阻塞）。就像“设计师把图纸交给绘图师，自己就去画下一张了”。</li>
<li><strong>GPU Thread → 光栅化</strong><br> GPU Thread 接过 Layer Tree，调用 Skia&#x2F;Impeller 引擎，把抽象的层级绘制信息翻译成实际的像素。“绘图师按照图纸认真上色、画线条，得到最终的成品画”。</li>
<li><strong>渲染到屏幕</strong><br> GPU Thread 完成像素渲染后，把结果交给系统的 <strong>GPU 驱动</strong>，显示到屏幕上。最终“画作挂到展览厅”，用户就能看到。</li>
</ol>
<h4 id="5-3-3-为什么要多线程？"><a href="#5-3-3-为什么要多线程？" class="headerlink" title="5.3.3 为什么要多线程？"></a>5.3.3 为什么要多线程？</h4><ul>
<li><strong>性能隔离</strong>：UI Thread 不会被图片解码、IO 阻塞 → 保证 16ms 内能产出 Layer Tree。</li>
<li><strong>并行执行</strong>：UI Thread 画下一帧的同时，GPU Thread 在光栅化上一帧 → 提高吞吐量。</li>
<li><strong>不卡顿体验</strong>：IO Thread 单独处理耗时任务，避免“卡一秒，掉一帧”的现象。</li>
</ul>
<h4 id="5-3-4-常见的误解与陷阱"><a href="#5-3-4-常见的误解与陷阱" class="headerlink" title="5.3.4 常见的误解与陷阱"></a>5.3.4 常见的误解与陷阱</h4><ol>
<li><strong>UI Thread 和 GPU Thread 是流水线，而不是同时处理同一帧</strong><br> 很多人以为 UI 和 GPU 一起画一帧，其实它们是“错位”的：UI Thread 处理 Frame N；GPU Thread 处理 Frame N-1</li>
<li><strong>图片解码在 IO Thread，不代表就“免费”</strong><br> IO Thread 解码完成后，结果还是要交给 GPU Thread 上传到显存 → 大图解码&#x2F;上传依然可能卡顿。</li>
<li><strong>UI Thread 过载 → 一切白搭</strong><br> 如果 build&#x2F;layout&#x2F;paint 太重，UI Thread 产出不了 Layer Tree，GPU 线程就没活干，屏幕就会掉帧。</li>
</ol>
<p>Flutter 渲染的多线程模型是一条高效的流水线：<strong>UI Thread 设计图 → GPU Thread 绘画 → IO Thread 运送材料</strong>。通过分工合作，保证了在 16ms 内尽可能平稳地产出和展示画面。</p>
<h3 id="5-4-PlatformView-与混合渲染"><a href="#5-4-PlatformView-与混合渲染" class="headerlink" title="5.4 PlatformView 与混合渲染"></a>5.4 PlatformView 与混合渲染</h3><p>在 Flutter 里，绝大多数 UI 元素都是 <strong>绘制在 Skia&#x2F;Impeller Canvas 上</strong> 的，最终由 Flutter 的渲染管线统一管理和合成。但在实际开发中，我们经常需要嵌入一些 <strong>原生控件</strong>（比如 WebView、MapView、VideoView 等），它们并不是 Flutter 自己画的，而是 <strong>系统原生平台的 View</strong>。</p>
<p>这类「外来元素」就是 <strong>PlatformView</strong>。由于它们的绘制方式和 Flutter 的渲染机制完全不同，所以需要特殊的处理策略，才能与 Flutter 的 UI 一起显示。这一过程就叫 <strong>混合渲染</strong>。</p>
<h4 id="5-4-1-为什么需要特殊处理？"><a href="#5-4-1-为什么需要特殊处理？" class="headerlink" title="5.4.1 为什么需要特殊处理？"></a>5.4.1 为什么需要特殊处理？</h4><p><strong>Flutter UI</strong>：由 Flutter 框架 + Skia 引擎绘制，走的是 Flutter 的 Frame Pipeline。<br><strong>原生控件</strong>：由 Android&#x2F;iOS 系统自己管理和渲染，不受 Flutter 渲染管线控制。</p>
<p>问题来了：<br>如果把 WebView&#x2F;MapView 直接塞进 Flutter 的 UI 树，Flutter 并不能用 Skia 把它绘制出来。所以需要一套「桥梁」机制，把原生控件的内容和 Flutter 的图层系统结合。</p>
<h4 id="5-4-2-Flutter-的混合渲染方案"><a href="#5-4-2-Flutter-的混合渲染方案" class="headerlink" title="5.4.2 Flutter 的混合渲染方案"></a>5.4.2 Flutter 的混合渲染方案</h4><p>Flutter 为了支持 PlatformView，提供了两种主要的混合渲染模式：</p>
<h5 id="Virtual-Display-模式"><a href="#Virtual-Display-模式" class="headerlink" title="Virtual Display 模式"></a>Virtual Display 模式</h5><p>在 Android&#x2F;iOS 上创建一个「虚拟窗口」（Offscreen Surface），让原生控件在这个窗口里绘制，然后再把内容当作一张纹理（Texture）传给 Flutter。<br>优点：    </p>
<ul>
<li>跨平台统一，几乎所有设备都支持。<br>缺点：</li>
<li>由于是「离屏渲染 → 纹理拷贝 → 再显示」，性能较差。 </li>
<li>和 Flutter UI 的交互（如手势、透明度、动画）存在限制。</li>
</ul>
<h5 id="Hybrid-Composition-模式"><a href="#Hybrid-Composition-模式" class="headerlink" title="Hybrid Composition 模式"></a>Hybrid Composition 模式</h5><p>把原生控件直接嵌入到系统的 View 层级，与 Flutter 的 Surface 一起由系统 Window 管理。<br>优点：    </p>
<ul>
<li>显示效果更好（本质上就是原生控件自己在窗口里画）。</li>
<li>支持复杂交互，比如 WebView 的滚动、缩放。<br>缺点：</li>
<li>成本高：需要平台支持，早期 Android 低版本兼容性差。     </li>
<li>和 Flutter 的合成层（Layer Tree）并不是完全统一。</li>
</ul>
<h4 id="5-4-3-常见应用场景"><a href="#5-4-3-常见应用场景" class="headerlink" title="5.4.3 常见应用场景"></a>5.4.3 常见应用场景</h4><ul>
<li><strong>WebView</strong>：嵌入网页内容。</li>
<li><strong>MapView</strong>：使用 Google Maps、高德地图 等原生地图。</li>
<li><strong>VideoPlayer</strong>：播放系统层的 Video 控件（部分播放器实现依赖 PlatformView）。</li>
</ul>
<p>这些场景都要求 <strong>原生控件保持完整渲染能力</strong>，比如 WebView 的 DOM 渲染、地图的手势交互、视频的硬件解码，无法简单用 Skia&#x2F;Impeller 模拟。</p>
<h4 id="5-4-4-开发时需要注意的问题"><a href="#5-4-4-开发时需要注意的问题" class="headerlink" title="5.4.4 开发时需要注意的问题"></a>5.4.4 开发时需要注意的问题</h4><p><strong>性能</strong>：PlatformView 的存在会打破 Flutter 渲染「全控」的高效机制，尤其是 Virtual Display 模式下，性能开销明显。<br><strong>手势冲突</strong>：Flutter 的手势系统（GestureArena）与原生控件的手势系统是两套机制，可能需要特殊处理。<br><strong>叠加效果</strong>：PlatformView 并不是普通的 Flutter Widget，透明叠加、裁剪、变换等效果往往会受限。</p>
<h2 id="6-事件与手势系统"><a href="#6-事件与手势系统" class="headerlink" title="6. 事件与手势系统"></a>6. 事件与手势系统</h2><p>Flutter 的交互体系大致分为两个层次：<strong>底层的 PointerEvent 分发与命中测试</strong>，以及 <strong>上层的手势识别（Gesture）</strong>。前者保证「事件能传递到正确的节点」，后者则负责「把一堆原始触摸点流组合成有意义的手势」。</p>
<h3 id="6-1-PointerEvent-流转与-HitTest-流程"><a href="#6-1-PointerEvent-流转与-HitTest-流程" class="headerlink" title="6.1 PointerEvent 流转与 HitTest 流程"></a>6.1 PointerEvent 流转与 HitTest 流程</h3><p>当用户点击屏幕时，触控事件会先由操作系统传递给 Flutter Engine，接着进入 <strong>PointerEvent 流</strong>。<br>事件流转大致如下：</p>
<ol>
<li><strong>Engine 层</strong>：接收原生触摸数据，包装成 PointerDownEvent、PointerMoveEvent、PointerUpEvent 等。</li>
<li><strong>RenderView</strong>：作为渲染树的根节点，负责触发 <strong>HitTest</strong>。</li>
<li><strong>HitTest 流程</strong>：从根向下遍历 RenderObject 树，逐层判断是否命中。比如：RenderPointerListener 判断命中区域；RenderBox 用 hitTestSelf 决定自己是否可交互；hitTestChildren 决定是否继续检查子节点。</li>
<li><strong>命中链路</strong>：最终形成一个 HitTestResult 列表，从最深的子节点到父节点依次记录下来。</li>
<li><strong>事件分发</strong>：PointerEvent 会沿着这条链路，从最内层的目标节点开始回调，父级也能选择拦截或响应。</li>
</ol>
<p>类比一下：HitTest 就像“扔石子砸水面”，RenderObject 树是一层层水波，事件往下沉，找到最深的点，再沿着气泡往上传。</p>
<h3 id="6-2-GestureArena"><a href="#6-2-GestureArena" class="headerlink" title="6.2 GestureArena"></a>6.2 GestureArena</h3><p>仅有 PointerEvent 还不够，因为用户手势往往由一连串事件组成。比如：单指点按 → 可能是 Tap，也可能演变成 Drag。</p>
<p>Flutter 的解决方案是 <strong>GestureArena（手势竞技场）</strong>：</p>
<ol>
<li><strong>事件收集</strong>：当一个 PointerDown 发生时，所有监听手势的识别器（TapGestureRecognizer、DragGestureRecognizer 等）都会被拉进「竞技场」。</li>
<li><strong>竞争机制</strong>：随着 PointerMove 的继续，识别器不断判断自己是否能「胜出」。如果手指几乎没移动，Tap 会赢；如果移动超过阈值，Drag 识别器会赢。</li>
<li><strong>裁决</strong>：一旦某个手势胜出，Arena 会通知它接管事件流，同时把失败者淘汰。</li>
</ol>
<p>举个例子：</p>
<ul>
<li><strong>Tap vs Drag 冲突</strong>：手指按下但没怎么动 → Tap 成功；手指稍微一拖 → Tap 失败，Drag 接管。</li>
<li><strong>双指缩放 vs 单指拖拽</strong>：当第二根手指加入，Zoom 识别器可能胜出，单指 Drag 退出。</li>
</ul>
<p>这种「先让所有候选者入场，再动态裁决」的机制，让复杂手势组合更灵活。</p>
<h3 id="6-3-自定义交互"><a href="#6-3-自定义交互" class="headerlink" title="6.3 自定义交互"></a>6.3 自定义交互</h3><p>有时我们需要超越内置的手势：</p>
<ol>
<li><strong>自定义手势识别器</strong>：可以继承 OneSequenceGestureRecognizer，自己定义事件处理逻辑。比如实现「长按后拖动」的特殊交互：先等 500ms 确认长按成立，再进入拖拽识别。</li>
<li><strong>自定义 hitTest 优化</strong>：默认情况下，事件会逐层检查命中区域，但在一些场景下可以优化，例如自定义 RenderObject，只在特定区域响应事件；或者跳过子节点命中，提高复杂 UI 的性能。</li>
</ol>
<p>自定义手势识别器就像「自己发明一项新运动规则」；自定义 hitTest 则像「在球场上设置特殊的得分区域」。</p>
<h2 id="7-底层图形引擎：Skia-vs-Impeller"><a href="#7-底层图形引擎：Skia-vs-Impeller" class="headerlink" title="7. 底层图形引擎：Skia vs Impeller"></a>7. 底层图形引擎：Skia vs Impeller</h2><p>Flutter 的渲染底层一直依赖 <strong>Skia</strong>，但从 3.10 开始，Google 推出了新的 <strong>Impeller 引擎</strong>，逐步替代 Skia。理解二者的区别，有助于我们理解 Flutter 性能演进的方向。</p>
<h3 id="7-1-Skia-工作原理"><a href="#7-1-Skia-工作原理" class="headerlink" title="7.1 Skia 工作原理"></a>7.1 Skia 工作原理</h3><p>Skia 是一个跨平台 2D 图形库，被 Chrome、Android、Flutter 广泛使用。它的工作流程大致分为三步：</p>
<ol>
<li><strong>Display List &#x2F; Picture</strong><br> Flutter 的 Canvas 绘制操作不会立即执行，而是记录在一个 <strong>Display List</strong> 中，可以理解为「绘图指令表」。这个 Display List 最终打包成 <strong>Picture</strong>，交给引擎。</li>
<li><strong>Raster（光栅化）</strong><br> Skia 接收 Picture 后，会在 GPU 上把向量指令（如 drawRect、drawPath）转换为实际像素填充。这一过程就是 <strong>Rasterization</strong>。</li>
<li><strong>后端 API</strong><br> Skia 自身不直接操作 GPU，而是调用平台的图形 API：    <ul>
<li>Android：OpenGL &#x2F; Vulkan    </li>
<li>iOS：Metal</li>
<li>桌面：OpenGL &#x2F; Vulkan &#x2F; Direct3D</li>
</ul>
</li>
</ol>
<p>打个比方，Skia 像是一个翻译官，先记下 Flutter 的绘画命令，再把它们翻译成「GPU 能理解的语言」。但 Skia 有一个痛点：<strong>Shader（着色器）在运行时编译</strong>。这可能导致 <strong>首次进入某个页面时出现卡顿（jank）</strong>，尤其在 iOS 上体验更明显。</p>
<h3 id="7-2-Impeller-的设计目标"><a href="#7-2-Impeller-的设计目标" class="headerlink" title="7.2 Impeller 的设计目标"></a>7.2 Impeller 的设计目标</h3><p>Impeller 的诞生就是为了解决 Skia 的缺陷。它的核心思路有两点：</p>
<ol>
<li><strong>避免 runtime shader 编译抖动</strong><ul>
<li>Impeller 将常见的 Shader 在编译阶段就准备好，运行时直接加载。这样进入新页面时就不会因为 Shader JIT 编译而掉帧。</li>
</ul>
</li>
<li><strong>Tile-based 渲染架构</strong><ul>
<li>现代 GPU（尤其是移动端 GPU）通常采用 <strong>基于 Tile 的渲染方式</strong>：把屏幕划分成小块（tiles），在 tile 内完成所有绘制再写回显存。而 Impeller 天然拥抱这种架构，能减少内存带宽消耗，提高能效。</li>
</ul>
</li>
</ol>
<p>Skia 像「现炒菜」，每次点菜（绘制）都要等厨师编译配方；Impeller 则是「提前备好半成品」，点菜时直接热锅上桌，更快更稳。</p>
<h3 id="7-3-Skia-vs-Impeller-对比"><a href="#7-3-Skia-vs-Impeller-对比" class="headerlink" title="7.3 Skia vs Impeller 对比"></a>7.3 Skia vs Impeller 对比</h3><table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>Skia</strong></th>
<th><strong>Impeller</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>渲染路径</strong></td>
<td>记录 Display List → Raster → GPU API</td>
<td>Display List → 预编译 Shader → GPU API</td>
</tr>
<tr>
<td><strong>Shader 管线</strong></td>
<td>运行时编译（可能卡顿）</td>
<td>预编译 + 缓存，避免 jank</td>
</tr>
<tr>
<td><strong>架构适配</strong></td>
<td>通用 2D 引擎，兼容多平台</td>
<td>针对 Tile-based GPU 优化（移动端更高效）</td>
</tr>
<tr>
<td><strong>开发者 API</strong></td>
<td>Canvas &#x2F; CustomPainter</td>
<td>完全兼容现有 Flutter API</td>
</tr>
<tr>
<td><strong>性能表现</strong></td>
<td>在复杂动画、大量渐变时可能掉帧</td>
<td>稳定帧率，特别是 iOS Metal 下更流畅</td>
</tr>
<tr>
<td><strong>兼容性</strong></td>
<td>成熟，跨平台验证多年</td>
<td>目前仍在逐步 rollout（Android 支持中，iOS 更稳定）</td>
</tr>
</tbody></table>
<p>对开发者来说，<strong>Flutter 的绘制 API 不变</strong>。依旧是 CustomPainter，但引擎底层从 Skia 换成 Impeller 后，Shader 编译、内存占用和动画流畅度会直接改善。</p>
<p>Skia 是一个成熟的跨平台 2D 引擎，但运行时 Shader 编译成为性能瓶颈；Impeller 则通过 <strong>预编译 Shader</strong> + <strong>Tile-based 渲染优化</strong>，带来了更稳定、更流畅的体验。未来随着 Impeller 在 Android 全面启用，Flutter 的渲染性能将进一步接近原生体验。</p>
<h2 id="8-平台差异与未来展望"><a href="#8-平台差异与未来展望" class="headerlink" title="8. 平台差异与未来展望"></a>8. 平台差异与未来展望</h2><p>Flutter 的一个最大优势，是「一次编写，跨平台运行」。但由于底层操作系统和渲染机制的差异，不同平台上的渲染表现并不完全一致。理解这些差异，能帮助开发者更好地调优应用体验。</p>
<h3 id="8-1-iOS-vs-Android-渲染差异"><a href="#8-1-iOS-vs-Android-渲染差异" class="headerlink" title="8.1 iOS vs Android 渲染差异"></a>8.1 iOS vs Android 渲染差异</h3><ul>
<li><strong>字体渲染</strong>：<br>  iOS 使用 CoreText 和系统字形渲染，字重、字距更贴近 Apple 生态习惯。<br>  Android 则依赖 Skia 字体栈，显示效果与原生 TextView 略有差别。</li>
<li><strong>混合视图（PlatformView）</strong>：<br>  在 Android 上，早期使用 Virtual Display，存在性能瓶颈；新版本支持 Hybrid Composition，效果更接近原生。<br>  在 iOS 上，PlatformView 与 UIKit View 更好地集成，但依旧存在透明层叠和手势传递的限制。</li>
<li><strong>系统交互</strong>：<br>  iOS 的「毛玻璃效果」(blur) 与原生弹性滚动很难复刻。<br>  Android 的沉浸式状态栏、返回手势则需要额外适配。</li>
</ul>
<h3 id="8-2-Flutter-Web-渲染模式"><a href="#8-2-Flutter-Web-渲染模式" class="headerlink" title="8.2 Flutter Web 渲染模式"></a>8.2 Flutter Web 渲染模式</h3><p>Flutter Web 有两种主要渲染模式：</p>
<ul>
<li><strong>DOM 模式</strong>：直接生成 HTML DOM + CSS。优点是轻量、可与现有 Web 生态融合；缺点是复杂动画、图形性能受限。</li>
<li><strong>CanvasKit 模式</strong>：基于 WebAssembly，把 Skia 移植到浏览器，用 canvas 直接绘制。优点是渲染效果高度一致；缺点是包体大、首次加载慢。</li>
</ul>
<p>如果应用是信息流、表单类，DOM 更合适；如果是图形密集型应用（图表、游戏），CanvasKit 更有优势。</p>
<h3 id="8-3-未来方向"><a href="#8-3-未来方向" class="headerlink" title="8.3 未来方向"></a>8.3 未来方向</h3><p><strong>Impeller 渲染引擎</strong>：Flutter 正逐步用 Impeller 替代 Skia，解决过往在 iOS 上的着色器预编译问题，提升帧率稳定性。未来在 Android 也将普及，实现跨平台一致的 GPU 加速。<br><strong>WebGPU 支持</strong>：随着浏览器逐渐支持 WebGPU，Flutter Web 有望获得接近原生的 3D 渲染和更高的图形性能。</p>
<p><strong>跨平台渲染趋势</strong>：    </p>
<ul>
<li>越来越多的渲染能力（如硬件加速、着色器编译）正在向跨平台标准收敛；     </li>
<li>Flutter 的定位也从「UI 框架」逐步演进为「跨平台渲染引擎」，覆盖移动、桌面、Web 乃至嵌入式设备。</li>
</ul>
<h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>Flutter渲染的核心是<strong>自绘引擎</strong>与<strong>三棵树机制</strong>。开发时写的声明式Widget只是配置，由轻量的Element树负责状态管理与差异化更新，最终由沉重的RenderObject树执行耗时的布局和绘制。</p>
<p>渲染流程由<strong>PipelineOwner</strong>调度：setState标记“脏”区域，在下一帧vsync信号触发后，依次进行构建、布局和绘制，生成图层树（Layer Tree），最终在GPU线程由Skia&#x2F;Impeller引擎光栅化为像素。</p>
<p>​<strong>性能关键</strong>在于避免不必要的RenderObject更新（布局&#x2F;重绘）。理解“约束传递”模型、利用Sliver懒加载、为频繁动画区域添加RepaintBoundary，是保障流畅体验的核心。这种从声明式UI到直接控制像素的完整控制力，是Flutter实现高性能跨端一致性的根基。</p>
<h2 id="10-备注"><a href="#10-备注" class="headerlink" title="10.备注"></a>10.备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>fluttter: 3.35.4<br>参考：</li>
<li><a href="https://docs.flutter.dev/">https://docs.flutter.dev/</a></li>
</ul>
]]></content>
      <categories>
        <category>跨平台框架</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
        <tag>GPU渲染</tag>
        <tag>Skia</tag>
        <tag>Impeller</tag>
        <tag>底层原理</tag>
      </tags>
  </entry>
  <entry>
    <title>路由、导航与多端协同：Navigator 2.0、嵌套路由与多端差异处理</title>
    <url>/2025/10/08/033-flutter-routing-navigation-multi-terminal-collaboration/</url>
    <content><![CDATA[<h2 id="1-为什么要声明式导航"><a href="#1-为什么要声明式导航" class="headerlink" title="1. 为什么要声明式导航"></a>1. 为什么要声明式导航</h2><p>在 Flutter 的早期开发中，我们几乎都是通过 <code>Navigator.push()</code> 来完成页面跳转的。<br>这种方式直观、易上手，但当应用体量一旦变大、业务流程变复杂，命令式导航（imperative navigation）就会开始暴露出一系列问题。</p>
<span id="more"></span>
<h3 id="1-1-Navigator-1-0-的局限"><a href="#1-1-Navigator-1-0-的局限" class="headerlink" title="1.1 Navigator 1.0 的局限"></a>1.1 Navigator 1.0 的局限</h3><h4 id="1-1-1-强依赖上下文，难以全局控制"><a href="#1-1-1-强依赖上下文，难以全局控制" class="headerlink" title="1.1.1 强依赖上下文，难以全局控制"></a>1.1.1 强依赖上下文，难以全局控制</h4><p>最常见的写法是这样的：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Navigator.push(context, MaterialPageRoute(builder: (_) =&gt; DetailPage()));</span><br></pre></td></tr></table></figure>
<p>这行代码看似简单，但其实隐藏了两个痛点：</p>
<ul>
<li><strong>需要拿到 context 才能跳转</strong> —— 在很多场景下（比如 ViewModel、全局控制器），根本拿不到合适的 BuildContext；</li>
<li><strong>无法全局感知当前导航状态</strong> —— 页面栈是 Navigator 内部私有的，外部无法直接读取或恢复。</li>
</ul>
<p>换句话说，我们虽然可以命令它“跳转”，但看不见它“现在在哪”。当业务线越来越多（例如：登录 → 支付 → 成功页 → 个人中心），这种盲目的导航就会让状态变得越来越混乱。</p>
<h4 id="1-1-2-导航状态与应用状态脱节"><a href="#1-1-2-导航状态与应用状态脱节" class="headerlink" title="1.1.2 导航状态与应用状态脱节"></a>1.1.2 导航状态与应用状态脱节</h4><p>在命令式模型中，页面栈是独立存在的。即使应用的业务状态已经变化（例如用户已登录），你仍需要手动去 pop 到对应页面或重新 push 正确的目标页。</p>
<p>这意味着 <strong>UI 不再由状态驱动，而是由命令驱动</strong>。当页面层级多、异步逻辑复杂时，就很容易出现“UI 状态和业务状态不同步”的情况。</p>
<h4 id="1-1-3-多端、多入口场景几乎无法应对"><a href="#1-1-3-多端、多入口场景几乎无法应对" class="headerlink" title="1.1.3 多端、多入口场景几乎无法应对"></a>1.1.3 多端、多入口场景几乎无法应对</h4><p>假设我们的应用要同时支持：</p>
<ul>
<li><strong>Web 深度链接</strong>（用户输入 &#x2F;profile&#x2F;123 打开用户详情）</li>
<li><strong>桌面端多窗口</strong>（每个窗口展示不同模块）</li>
<li><strong>App 启动参数唤起</strong>（从推送直接进入订单页）</li>
</ul>
<p>命令式导航就很难处理这些外部路径。我们只能在 onGenerateRoute 里写大量条件判断，或在全局单例中手动解析 URL 再跳转，这样既脆弱又难维护。</p>
<h3 id="1-2-声明式导航：“路由”状态"><a href="#1-2-声明式导航：“路由”状态" class="headerlink" title="1.2 声明式导航：“路由”状态"></a>1.2 声明式导航：“路由”状态</h3><p>为了解决这些问题，Flutter 从 Navigator 2.0 开始引入了 <strong>声明式（Declarative）导航模型</strong>。</p>
<p>它的核心思想是：</p>
<blockquote>
<p>“我们不再命令 Navigator 去做什么，而是描述当前应用<strong>应该是什么状态</strong>。”</p>
</blockquote>
<p>换句话说，页面不再是命令堆叠的结果，而是状态声明的反映。当状态变化时，框架会自动根据新状态重建页面栈。</p>
<h4 id="1-2-1-状态驱动-UI"><a href="#1-2-1-状态驱动-UI" class="headerlink" title="1.2.1 状态驱动 UI"></a>1.2.1 状态驱动 UI</h4><p>在声明式模式下，我们只需要告诉系统：“现在用户处于登录状态” 或 “当前选中的文章 ID 是 42”，RouterDelegate 就会根据这个状态渲染出对应页面。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Navigator 1.0</span></span><br><span class="line">Navigator.push(context, MaterialPageRoute(builder: (_) =&gt; DetailPage()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Navigator 2.0</span></span><br><span class="line">routerDelegate.setNewRoutePath(AppRoute.detail());</span><br></pre></td></tr></table></figure>
<p>区别在于，前者是命令式地“执行一次跳转”，后者是声明式地“更新路由状态”，框架自动重建页面栈。</p>
<h4 id="1-2-2-URL-↔-状态同步"><a href="#1-2-2-URL-↔-状态同步" class="headerlink" title="1.2.2 URL ↔ 状态同步"></a>1.2.2 URL ↔ 状态同步</h4><p>在 Navigator 2.0 中，<strong>路由状态与 URL 可以完全对齐</strong>。<br>RouteInformationParser 会解析浏览器地址栏或系统传入的路径，生成对应的内部状态对象。<br>RouterDelegate 再根据这个状态，重建页面栈。</p>
<p>这样一来：</p>
<ul>
<li>在 Web 端刷新不会丢失页面；</li>
<li>点击浏览器返回键会真正回到上一个状态；</li>
<li>甚至可以直接复制 URL 给别人，打开时显示完全相同的内容。</li>
</ul>
<h4 id="1-2-3-可预测、可测试的导航行为"><a href="#1-2-3-可预测、可测试的导航行为" class="headerlink" title="1.2.3 可预测、可测试的导航行为"></a>1.2.3 可预测、可测试的导航行为</h4><p>由于页面完全由状态描述构建，因此我们可以：</p>
<ul>
<li>直接通过状态判断应用当前“在哪一页”；</li>
<li>通过修改状态驱动跳转，无需操作 Navigator；</li>
<li>编写单元测试来验证“某状态下是否渲染了正确页面”。</li>
</ul>
<p>这让导航逻辑不再是一个黑盒，而是可以推理、可验证的系统。</p>
<h3 id="1-3-声明式导航优势"><a href="#1-3-声明式导航优势" class="headerlink" title="1.3 声明式导航优势"></a>1.3 声明式导航优势</h3><p>在中小型应用中，命令式导航仍然足够简单直接。但一旦进入大型工程，声明式导航带来会带来很多好处：</p>
<table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>1.0 的困难</strong></th>
<th><strong>2.0 的优势</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>多模块应用</strong></td>
<td>各模块 Navigator 独立，状态不同步</td>
<td>可用统一 AppState 控制全局路由</td>
</tr>
<tr>
<td><strong>登录&#x2F;支付流程</strong></td>
<td>路径跳转多、逻辑分支复杂</td>
<td>路由栈可通过状态直接定义</td>
</tr>
<tr>
<td><strong>Web &#x2F; 桌面端</strong></td>
<td>无法同步 URL 或窗口</td>
<td>URL 与状态天然绑定</td>
</tr>
<tr>
<td><strong>测试与恢复</strong></td>
<td>无法预设页面状态</td>
<td>可直接恢复路由配置</td>
</tr>
</tbody></table>
<p>我们可以把 Navigator 2.0 看作是 Flutter 导航体系的“架构级升级”：从“命令驱动的动作系统” → “状态驱动的声明系统”。</p>
<table>
<thead>
<tr>
<th><strong>命令式导航</strong></th>
<th><strong>声明式导航</strong></th>
</tr>
</thead>
<tbody><tr>
<td>点击按钮 → push() → 进入页面</td>
<td>改变状态 → RouterDelegate rebuild → 页面更新</td>
</tr>
<tr>
<td>左边是“指令驱动”的思路；右边是“状态驱动”的思路。</td>
<td></td>
</tr>
<tr>
<td>在小项目中，左边简单够用；但在多入口、多端协同的项目中，右边能保持一致性与可控性。</td>
<td></td>
</tr>
</tbody></table>
<h2 id="2-Navigator-2-0-核心机制详解"><a href="#2-Navigator-2-0-核心机制详解" class="headerlink" title="2. Navigator 2.0 核心机制详解"></a>2. Navigator 2.0 核心机制详解</h2><h3 id="2-1-从-push-pop-到状态驱动栈"><a href="#2-1-从-push-pop-到状态驱动栈" class="headerlink" title="2.1 从 push&#x2F;pop 到状态驱动栈"></a>2.1 从 push&#x2F;pop 到状态驱动栈</h3><p>上一章我们谈到“声明式导航”是以<strong>状态驱动页面栈</strong>。这一章，我们正式进入 Navigator 2.0 的核心机制——<br>理解 <strong>它是如何将状态 → 页面栈 → UI 渲染</strong> 串联起来的。</p>
<p>Navigator 2.0 的设计目标是：</p>
<blockquote>
<p>不再手动操作页面栈，而是由一个可追踪的状态系统来决定“页面栈该长什么样”。</p>
</blockquote>
<h3 id="2-2-Navigator-2-0-的三件核心组件"><a href="#2-2-Navigator-2-0-的三件核心组件" class="headerlink" title="2.2 Navigator 2.0 的三件核心组件"></a>2.2 Navigator 2.0 的三件核心组件</h3><p>Navigator 2.0 的底层是一个解耦的三层结构：</p>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>职责</strong></th>
<th><strong>类比</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>RouteInformationParser</strong></td>
<td>把 URL 解析为内部路由状态</td>
<td>导航“翻译官”</td>
</tr>
<tr>
<td><strong>RouterDelegate</strong></td>
<td>根据当前状态构建页面栈</td>
<td>导航“导演”</td>
</tr>
<tr>
<td><strong>BackButtonDispatcher</strong></td>
<td>管理系统返回行为</td>
<td>导航“交通警”</td>
</tr>
</tbody></table>
<p>三者构成一条完整的数据流：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">URL → RouteInformationParser → 应用状态 → RouterDelegate → Page 栈 → Navigator 渲染</span><br></pre></td></tr></table></figure>
<p>这条链路保证：</p>
<ul>
<li>用户输入 URL → 应用能还原对应页面；</li>
<li>应用状态改变 → URL 实时同步；</li>
<li>用户点击返回 → 页面状态与 URL 一致。</li>
</ul>
<h3 id="2-3-生命周期：从-URL-到页面"><a href="#2-3-生命周期：从-URL-到页面" class="headerlink" title="2.3 生命周期：从 URL 到页面"></a>2.3 生命周期：从 URL 到页面</h3><p>整个导航生命周期大致如下：</p>
<ol>
<li><strong>RouteInformationParser</strong>：接收系统的 URL（如 &#x2F;detail&#x2F;42），解析为内部状态对象（如 AppRoutePath.detail(id: 42)）。</li>
<li><strong>RouterDelegate</strong>：根据当前状态，重建 Page 列表，返回一个新的页面栈给 Navigator。</li>
<li><strong>Navigator</strong>：渲染这些 Page 对应的 UI，监听返回事件（onPopPage）。</li>
<li><strong>BackButtonDispatcher</strong>：当用户按下返回键或浏览器后退时，调用 RouterDelegate → 更新状态 → 同步 URL。</li>
</ol>
<blockquote>
<p>Navigator 2.0 并不“增删页面”，而是“根据状态重建页面栈”。</p>
</blockquote>
<h3 id="2-4-最小可运行骨架"><a href="#2-4-最小可运行骨架" class="headerlink" title="2.4 最小可运行骨架"></a>2.4 最小可运行骨架</h3><p>一个典型的 Navigator 2.0 实现只需三个类：RoutePath、RouteParser、RouterDelegate。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRoutePath</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String?</span> id;</span><br><span class="line">  AppRoutePath.home() : id = <span class="keyword">null</span>;</span><br><span class="line">  AppRoutePath.detail(<span class="keyword">this</span>.id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1️⃣ RouteInformationParser：解析 URL</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">AppRoutePath</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//  URL → 状态</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;AppRoutePath&gt; parseRouteInformation(RouteInformation info) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> uri = <span class="built_in">Uri</span>.parse(info.location ?? <span class="string">&#x27;&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.isEmpty) <span class="keyword">return</span> AppRoutePath.home();</span><br><span class="line">    <span class="keyword">return</span> AppRoutePath.detail(uri.pathSegments.last);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2️⃣ RouterDelegate：根据状态构建页面栈</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouterDelegate</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">AppRoutePath</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">AppRoutePath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey();</span><br><span class="line">  AppRoutePath _path = AppRoutePath.home();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据状态生成页面栈</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) =&gt; Navigator(</span><br><span class="line">        key: navigatorKey,</span><br><span class="line">        pages: [</span><br><span class="line">          MaterialPage(child: HomePage()),</span><br><span class="line">          <span class="keyword">if</span> (_path.id != <span class="keyword">null</span>)</span><br><span class="line">            MaterialPage(child: DetailPage(id: _path.id!)),</span><br><span class="line">        ],</span><br><span class="line">        onPopPage: (route, result) &#123;</span><br><span class="line">          _path = AppRoutePath.home();</span><br><span class="line">          notifyListeners();</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;,</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 外部状态变更时更新内部</span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(AppRoutePath configuration) <span class="keyword">async</span> &#123;</span><br><span class="line">    _path = configuration;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-5-数据流图示"><a href="#2-5-数据流图示" class="headerlink" title="2.5 数据流图示"></a>2.5 数据流图示</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[URL]</span><br><span class="line">   ↓</span><br><span class="line">[RouteInformationParser]</span><br><span class="line">   ↓</span><br><span class="line">[RouterDelegate]  ← 状态变化通知</span><br><span class="line">   ↓</span><br><span class="line">[Navigator]</span><br><span class="line">   ↑</span><br><span class="line">[BackButtonDispatcher]</span><br></pre></td></tr></table></figure>

<p>上图的重点是<strong>双向同步</strong>：URL 改变 → 页面重建；页面返回 → URL 更新</p>
<h3 id="2-6-为什么是“重建页面栈”，而不是-push-pop"><a href="#2-6-为什么是“重建页面栈”，而不是-push-pop" class="headerlink" title="2.6 为什么是“重建页面栈”，而不是 push&#x2F;pop"></a>2.6 为什么是“重建页面栈”，而不是 push&#x2F;pop</h3><p>在 Navigator 2.0 中，RouterDelegate.build() 每次都返回一个新的页面栈（<code>List&lt;Page&gt;</code>），看似“重建”，实则 Flutter 只会根据差异更新。</p>
<p>这种声明式机制让导航变得：</p>
<ul>
<li><strong>确定性更强</strong>（页面完全由状态决定）</li>
<li><strong>调试更方便</strong>（状态可追踪）</li>
<li><strong>多端更一致</strong>（URL、窗口、返回行为统一）</li>
</ul>
<p>这也是它支持 Web 与桌面端的关键。</p>
<h2 id="3-复杂导航与状态同步"><a href="#3-复杂导航与状态同步" class="headerlink" title="3. 复杂导航与状态同步"></a>3. 复杂导航与状态同步</h2><p>当应用从单页扩展到多页面、多流程、多模块后，导航系统的复杂度会呈指数级上升。在命令式（Navigator 1.0）体系下，开发者常常需要在多个地方 push()、pop()、popUntil()，代码不仅难以维护，还难以追踪页面状态。</p>
<p>而在 Navigator 2.0 的声明式模型中，我们可以通过<strong>状态同步 + 多层级 Navigator</strong> 来管理这些复杂交互。b本章将聚焦于实际工程中最常见的几种复杂场景。</p>
<h3 id="3-1-多导航栈场景：底部-Tab"><a href="#3-1-多导航栈场景：底部-Tab" class="headerlink" title="3.1 多导航栈场景：底部 Tab"></a>3.1 多导航栈场景：底部 Tab</h3><p>想象一个典型的多 Tab 应用：</p>
<ul>
<li>首页（Feed）</li>
<li>消息（Message）</li>
<li>我的（Profile）</li>
</ul>
<p>用户在 “Feed → Detail → Back” 后，再切到 “消息 → 对话 → 返回”，如果返回 Feed tab，希望还能回到刚才浏览的那篇内容，而不是重新进入首页。这时就需要：<strong>每个 tab 独立维护自己的 Navigator 栈</strong>。</p>
<h4 id="3-1-1-代码示例"><a href="#3-1-1-代码示例" class="headerlink" title="3.1.1 代码示例"></a>3.1.1 代码示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      title: <span class="string">&#x27;Multi Navigator Demo&#x27;</span>,  </span><br><span class="line">      home: <span class="keyword">const</span> MainScaffold(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">--- TabNavigator：每个 tab 都维护独立的 Navigator 栈 ---</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TabNavigator</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey;  </span><br><span class="line">  <span class="keyword">final</span> Widget child;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> TabNavigator(&#123;  </span><br><span class="line">    <span class="keyword">super</span>.key,  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.navigatorKey,  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.child,  </span><br><span class="line">  &#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Navigator(  </span><br><span class="line">      key: navigatorKey,  </span><br><span class="line">      <span class="comment">// ✅ 新写法：使用 onDidRemovePage 替代 onPopPage      </span></span><br><span class="line">      onDidRemovePage: (page) &#123;  </span><br><span class="line">        debugPrint(<span class="string">&#x27;Page removed: <span class="subst">$&#123;page.name&#125;</span>&#x27;</span>);  </span><br><span class="line">      &#125;,  </span><br><span class="line">      pages: [  </span><br><span class="line">        MaterialPage(child: child),  </span><br><span class="line">      ],  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainScaffold</span> <span class="keyword">extends</span> <span class="title">StatefulWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MainScaffold(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  State&lt;MainScaffold&gt; createState() =&gt; _MainScaffoldState();  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MainScaffoldState</span> <span class="keyword">extends</span> <span class="title">State</span>&lt;<span class="title">MainScaffold</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="built_in">int</span> currentIndex = <span class="number">0</span>;  </span><br><span class="line">  <span class="keyword">final</span> navigatorKeys = [  </span><br><span class="line">    GlobalKey&lt;NavigatorState&gt;(),  </span><br><span class="line">    GlobalKey&lt;NavigatorState&gt;(),  </span><br><span class="line">    GlobalKey&lt;NavigatorState&gt;(),  </span><br><span class="line">  ];  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      body: IndexedStack(  </span><br><span class="line">        index: currentIndex,  </span><br><span class="line">        children: [  </span><br><span class="line">          TabNavigator(navigatorKey: navigatorKeys[<span class="number">0</span>], child: FeedPage()),  </span><br><span class="line">          TabNavigator(navigatorKey: navigatorKeys[<span class="number">1</span>], child: MessagePage()),  </span><br><span class="line">          TabNavigator(navigatorKey: navigatorKeys[<span class="number">2</span>], child: ProfilePage()),  </span><br><span class="line">        ],  </span><br><span class="line">      ),  </span><br><span class="line">      bottomNavigationBar: BottomNavigationBar(  </span><br><span class="line">        currentIndex: currentIndex,  </span><br><span class="line">        onTap: (i) =&gt; setState(() =&gt; currentIndex = i),  </span><br><span class="line">        items: <span class="keyword">const</span> [  </span><br><span class="line">          BottomNavigationBarItem(icon: Icon(Icons.home), label: <span class="string">&#x27;Feed&#x27;</span>),  </span><br><span class="line">          BottomNavigationBarItem(icon: Icon(Icons.message), label: <span class="string">&#x27;Msg&#x27;</span>),  </span><br><span class="line">          BottomNavigationBarItem(icon: Icon(Icons.person), label: <span class="string">&#x27;Me&#x27;</span>),  </span><br><span class="line">        ],  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-1-2-理解要点"><a href="#3-1-2-理解要点" class="headerlink" title="3.1.2 理解要点"></a>3.1.2 理解要点</h4><p>每个 tab 是一个独立的 Navigator；IndexedStack 保留了所有 tab 的状态；用户切换 tab 时，不会丢失导航历史。</p>
<h3 id="3-2-嵌套路由：父层框架-子区域控制"><a href="#3-2-嵌套路由：父层框架-子区域控制" class="headerlink" title="3.2 嵌套路由：父层框架 + 子区域控制"></a>3.2 嵌套路由：父层框架 + 子区域控制</h3><p>一般应用还会有“主框架 + 内容区”两层导航结构。例如：</p>
<ul>
<li>外层：主导航（底部栏、Drawer）</li>
<li>内层：具体模块（如某个业务的多层子页面）</li>
</ul>
<p>在 Navigator 2.0 中，可以将 RouterDelegate 层层嵌套：<strong>父 RouterDelegate 管整体状态，子 RouterDelegate 只负责自己区域的页面栈。</strong></p>
<h4 id="3-2-1-代码示例"><a href="#3-2-1-代码示例" class="headerlink" title="3.2.1 代码示例"></a>3.2.1 代码示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// <span class="language-markdown">整个应用的入口，使用 Router API 构建声明式导航</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> MaterialApp.router(</span><br><span class="line">      <span class="comment">// RouterDelegate 负责“当前显示什么页面”</span></span><br><span class="line">      routerDelegate: HomeRouter(),</span><br><span class="line"></span><br><span class="line">      <span class="comment">// RouteInformationParser 负责“从 URL → 解析出业务路径对象（HomePath）”</span></span><br><span class="line">      routeInformationParser: HomeRouteParser(),</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 系统返回键（Android）事件分发器</span></span><br><span class="line">      backButtonDispatcher: RootBackButtonDispatcher(),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">路径模型对象：描述当前的业务状态（是否进入详情页）</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePath</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String?</span> id;</span><br><span class="line">  <span class="keyword">const</span> HomePath(&#123;<span class="keyword">this</span>.id&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">URL 与 HomePath 的双向映射器</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">parseRouteInformation：URL → HomePath</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">restoreRouteInformation：HomePath → URL</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomeRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">HomePath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;HomePath&gt; parseRouteInformation(RouteInformation routeInformation) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> uri = routeInformation.uri; <span class="comment">// Flutter 3.8+ 推荐使用 uri 属性</span></span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.isEmpty) <span class="keyword">return</span> <span class="keyword">const</span> HomePath(); <span class="comment">// 根路径：Feed 列表页</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 匹配形如 /detail/xxx 的路径</span></span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.length == <span class="number">2</span> &amp;&amp; uri.pathSegments.first == <span class="string">&#x27;detail&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> HomePath(id: uri.pathSegments[<span class="number">1</span>]); <span class="comment">// id = xxx</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const</span> HomePath();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RouteInformation restoreRouteInformation(HomePath configuration) &#123;</span><br><span class="line">    <span class="comment">// 将 HomePath 反向转换为 URL</span></span><br><span class="line">    <span class="keyword">if</span> (configuration.id != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/detail/<span class="subst">$&#123;configuration.id&#125;</span>&#x27;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/&#x27;</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">RouterDelegate 是整个声明式导航的核心：它根据“状态”构建页面栈（Navigator.pages）</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomeRouter</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">HomePath</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">HomePath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">bool</span> showDetail = <span class="keyword">false</span>; <span class="comment">// 是否展示详情页</span></span><br><span class="line">  <span class="built_in">String?</span> selectedId; <span class="comment">// 当前选中的 item ID</span></span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Navigator(</span><br><span class="line">      key: navigatorKey,</span><br><span class="line">      <span class="comment">/// <span class="language-markdown">声明式页面栈：根据状态决定有哪些页面</span></span></span><br><span class="line">      pages: [</span><br><span class="line">        <span class="comment">// 主列表页（FeedPage）</span></span><br><span class="line">        MaterialPage(</span><br><span class="line">          key: <span class="keyword">const</span> ValueKey(<span class="string">&#x27;FeedPage&#x27;</span>),</span><br><span class="line">          child: FeedPage(onSelect: (id) &#123;</span><br><span class="line">            <span class="comment">// 点击后进入详情页</span></span><br><span class="line">            selectedId = id;</span><br><span class="line">            showDetail = <span class="keyword">true</span>;</span><br><span class="line">            notifyListeners(); <span class="comment">// 通知 RouterDelegate 重建页面栈</span></span><br><span class="line">          &#125;),</span><br><span class="line">        ),</span><br><span class="line">        <span class="comment">// 如果状态为 showDetail，则压入详情页</span></span><br><span class="line">        <span class="keyword">if</span> (showDetail)</span><br><span class="line">          MaterialPage(</span><br><span class="line">            key: ValueKey(<span class="string">&#x27;DetailPage-<span class="subst">$selectedId</span>&#x27;</span>),</span><br><span class="line">            child: FeedDetailPage(id: selectedId!),</span><br><span class="line">          ),</span><br><span class="line">      ],</span><br><span class="line">      <span class="comment">/// <span class="language-markdown">Flutter 3.16+ 推荐使用 onDidRemovePage（替代 onPopPage）</span></span></span><br><span class="line">      <span class="comment">/// <span class="language-markdown">这个回调在页面被移除时触发</span></span></span><br><span class="line">      onDidRemovePage: (page) &#123;</span><br><span class="line">        debugPrint(<span class="string">&#x27;Page removed: <span class="subst">$&#123;page.key&#125;</span>&#x27;</span>);</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="comment">/// <span class="language-markdown">监听页面出栈行为（比如系统返回键）</span></span></span><br><span class="line">      observers: [</span><br><span class="line">        _RouterPopObserver(onPop: () &#123;</span><br><span class="line">          <span class="keyword">if</span> (showDetail) &#123;</span><br><span class="line">            showDetail = <span class="keyword">false</span>;</span><br><span class="line">            notifyListeners(); <span class="comment">// 返回列表页</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;),</span><br><span class="line">      ],</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">从外部（比如浏览器 URL 变化）更新应用状态</span></span></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(HomePath configuration) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (configuration.id != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// URL 含有 id，进入详情页</span></span><br><span class="line">      selectedId = configuration.id;</span><br><span class="line">      showDetail = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 否则回到列表页</span></span><br><span class="line">      showDetail = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">自定义的 NavigatorObserver，用于监听页面 pop 事件</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_RouterPopObserver</span> <span class="keyword">extends</span> <span class="title">NavigatorObserver</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> VoidCallback onPop;</span><br><span class="line">  _RouterPopObserver(&#123;<span class="keyword">required</span> <span class="keyword">this</span>.onPop&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> didPop(Route route, Route? previousRoute) &#123;</span><br><span class="line">    onPop(); <span class="comment">// 通知 RouterDelegate 状态变化</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">Feed 列表页</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">点击某个 item 后，通过回调触发状态更新</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ValueChanged&lt;<span class="built_in">String</span>&gt; onSelect;</span><br><span class="line">  <span class="keyword">const</span> FeedPage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.onSelect&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;Feed&#x27;</span>)),</span><br><span class="line">      body: ListView(</span><br><span class="line">        children: [</span><br><span class="line">          ListTile(title: <span class="keyword">const</span> Text(<span class="string">&#x27;Item 1&#x27;</span>), onTap: () =&gt; onSelect(<span class="string">&#x27;1&#x27;</span>)),</span><br><span class="line">          ListTile(title: <span class="keyword">const</span> Text(<span class="string">&#x27;Item 2&#x27;</span>), onTap: () =&gt; onSelect(<span class="string">&#x27;2&#x27;</span>)),</span><br><span class="line">        ],</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">Feed 详情页</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">展示选中 item 的详细内容</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedDetailPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> id;</span><br><span class="line">  <span class="keyword">const</span> FeedDetailPage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.id&#125;);</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: Text(<span class="string">&#x27;Detail <span class="subst">$id</span>&#x27;</span>)),</span><br><span class="line">      body: Center(child: Text(<span class="string">&#x27;Detail page for item <span class="subst">$id</span>&#x27;</span>)),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>父级 Router（例如整个 AppRouter）就能把这个 HomeRouter 当作一个独立模块管理。这样每个子模块都能自管理页面栈，互不干扰。</p>
<h3 id="3-3-模态与全屏页面"><a href="#3-3-模态与全屏页面" class="headerlink" title="3.3 模态与全屏页面"></a>3.3 模态与全屏页面</h3><p>Declarative 导航也可以优雅地表达模态层（Modal）或 Overlay。<br>例如支付流程中，“确认支付”页面应在现有页面之上展示。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// <span class="language-markdown">应用入口，使用 Router API 构建声明式导航  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp.router(  </span><br><span class="line">      routerDelegate: OrderRouter(),  </span><br><span class="line">      routeInformationParser: OrderRouteParser(),  </span><br><span class="line">      backButtonDispatcher: RootBackButtonDispatcher(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">路径状态对象：描述当前处于哪个页面状态  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrderPath</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">bool</span> showPayment; <span class="comment">// 是否显示支付弹窗  </span></span><br><span class="line">  <span class="keyword">const</span> OrderPath(&#123;<span class="keyword">this</span>.showPayment = <span class="keyword">false</span>&#125;);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">RouteInformationParser 负责 URL ↔ OrderPath 的转换  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrderRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">OrderPath</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Future&lt;OrderPath&gt; parseRouteInformation(RouteInformation routeInformation) <span class="keyword">async</span> &#123;  </span><br><span class="line">    <span class="keyword">final</span> uri = routeInformation.uri;  </span><br><span class="line">    <span class="comment">// 根路径 -&gt; 订单页  </span></span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.isEmpty) <span class="keyword">return</span> <span class="keyword">const</span> OrderPath();  </span><br><span class="line">    <span class="comment">// payment -&gt; 支付模态层  </span></span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.length == <span class="number">1</span> &amp;&amp; uri.pathSegments.first == <span class="string">&#x27;payment&#x27;</span>) &#123;  </span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">const</span> OrderPath(showPayment: <span class="keyword">true</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const</span> OrderPath();  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  RouteInformation? restoreRouteInformation(OrderPath configuration) &#123;  </span><br><span class="line">    <span class="comment">// 根据状态生成对应 URL    </span></span><br><span class="line">    <span class="keyword">if</span> (configuration.showPayment) &#123;  </span><br><span class="line">      <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/payment&#x27;</span>));  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/&#x27;</span>));  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">RouterDelegate：声明式地控制页面栈  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrderRouter</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">OrderPath</span>&gt;  </span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">OrderPath</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey&lt;NavigatorState&gt;();  </span><br><span class="line">  </span><br><span class="line">  <span class="built_in">bool</span> showPayment = <span class="keyword">false</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Navigator(  </span><br><span class="line">      key: navigatorKey,  </span><br><span class="line">      <span class="comment">/// <span class="language-markdown">根据状态声明页面栈  </span></span></span><br><span class="line">      pages: [  </span><br><span class="line">        <span class="comment">// 基础页面：订单页  </span></span><br><span class="line">        MaterialPage(  </span><br><span class="line">          key: <span class="keyword">const</span> ValueKey(<span class="string">&#x27;OrderPage&#x27;</span>),  </span><br><span class="line">          child: OrderPage(onPay: () &#123;  </span><br><span class="line">            showPayment = <span class="keyword">true</span>;  </span><br><span class="line">            notifyListeners(); <span class="comment">// 通知刷新页面栈  </span></span><br><span class="line">          &#125;),  </span><br><span class="line">        ),  </span><br><span class="line">        <span class="comment">// 模态页：支付页  </span></span><br><span class="line">        <span class="keyword">if</span> (showPayment)  </span><br><span class="line">          MaterialPage(  </span><br><span class="line">            key: <span class="keyword">const</span> ValueKey(<span class="string">&#x27;PaymentSheet&#x27;</span>),  </span><br><span class="line">            fullscreenDialog: <span class="keyword">true</span>, <span class="comment">// &lt;-- 核心参数：模态展示  </span></span><br><span class="line">            child: PaymentSheet(onClose: () &#123;  </span><br><span class="line">              showPayment = <span class="keyword">false</span>;  </span><br><span class="line">              notifyListeners();  </span><br><span class="line">            &#125;),  </span><br><span class="line">          ),  </span><br><span class="line">      ],  </span><br><span class="line">      <span class="comment">/// <span class="language-markdown">监听页面移除  </span></span></span><br><span class="line">      onDidRemovePage: (page) &#123;  </span><br><span class="line">        debugPrint(<span class="string">&#x27;Page removed: <span class="subst">$&#123;page.key&#125;</span>&#x27;</span>);  </span><br><span class="line">      &#125;,  </span><br><span class="line">      observers: [  </span><br><span class="line">        <span class="comment">// 监听返回（pop）操作  </span></span><br><span class="line">        _RouterPopObserver(onPop: () &#123;  </span><br><span class="line">          <span class="keyword">if</span> (showPayment) &#123;  </span><br><span class="line">            showPayment = <span class="keyword">false</span>;  </span><br><span class="line">            notifyListeners();  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;),  </span><br><span class="line">      ],  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">/// <span class="language-markdown">外部（URL变化）状态同步  </span></span></span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(OrderPath configuration) <span class="keyword">async</span> &#123;  </span><br><span class="line">    showPayment = configuration.showPayment;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">Navigator 观察者，监听页面出栈  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_RouterPopObserver</span> <span class="keyword">extends</span> <span class="title">NavigatorObserver</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> VoidCallback onPop;  </span><br><span class="line">  _RouterPopObserver(&#123;<span class="keyword">required</span> <span class="keyword">this</span>.onPop&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> didPop(Route route, Route? previousRoute) &#123;  </span><br><span class="line">    onPop();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">订单页：点击“去支付”打开模态层  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrderPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> VoidCallback onPay;  </span><br><span class="line">  <span class="keyword">const</span> OrderPage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.onPay&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;Order Page&#x27;</span>)),  </span><br><span class="line">      body: Center(  </span><br><span class="line">        child: ElevatedButton(  </span><br><span class="line">          onPressed: onPay,  </span><br><span class="line">          child: <span class="keyword">const</span> Text(<span class="string">&#x27;去支付&#x27;</span>),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">支付模态页：全屏对话框式展示  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PaymentSheet</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> VoidCallback onClose;  </span><br><span class="line">  <span class="keyword">const</span> PaymentSheet(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.onClose&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      appBar: AppBar(  </span><br><span class="line">        title: <span class="keyword">const</span> Text(<span class="string">&#x27;支付确认&#x27;</span>),  </span><br><span class="line">        leading: IconButton(  </span><br><span class="line">          icon: <span class="keyword">const</span> Icon(Icons.close),  </span><br><span class="line">          onPressed: onClose, <span class="comment">// 点击关闭  </span></span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">      body: Center(  </span><br><span class="line">        child: Column(  </span><br><span class="line">          mainAxisSize: MainAxisSize.min,  </span><br><span class="line">          children: [  </span><br><span class="line">            <span class="keyword">const</span> Text(<span class="string">&#x27;确认支付 ¥99.00&#x27;</span>),  </span><br><span class="line">            <span class="keyword">const</span> SizedBox(height: <span class="number">16</span>),  </span><br><span class="line">            ElevatedButton(  </span><br><span class="line">              onPressed: () &#123;  </span><br><span class="line">                ScaffoldMessenger.of(context).showSnackBar(  </span><br><span class="line">                  <span class="keyword">const</span> SnackBar(content: Text(<span class="string">&#x27;支付成功！&#x27;</span>)),  </span><br><span class="line">                );  </span><br><span class="line">                onClose();  </span><br><span class="line">              &#125;,  </span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;确认支付&#x27;</span>),  </span><br><span class="line">            ),  </span><br><span class="line">          ],  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/declarative_modal_251008.mp4" controls="controls" width="30%"></video><br>当 showPayment &#x3D; true 时，RouterDelegate 重建页面栈，自动展示支付弹窗。关闭弹窗时更新状态，然后rebuild，弹窗消失。</p>
<blockquote>
<p>这样做的优势：模态行为完全由状态驱动，无需手动 showDialog() 或 Navigator.push()。</p>
</blockquote>
<h3 id="3-4-参数与返回值：用状态而非回调"><a href="#3-4-参数与返回值：用状态而非回调" class="headerlink" title="3.4 参数与返回值：用状态而非回调"></a>3.4 参数与返回值：用状态而非回调</h3><p>在声明式导航中，没有 <code>Navigator.pop(result)</code> 这样的“回传机制”，而是通过<strong>共享状态（AppState、Provider、Riverpod）</strong> 传递结果。</p>
<p>例如，编辑个人资料的流程：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (state.editingProfile) &#123;</span><br><span class="line">  pages.add(MaterialPage(child: EditProfilePage(</span><br><span class="line">    onSubmit: (newProfile) &#123;</span><br><span class="line">      appState.updateProfile(newProfile);</span><br><span class="line">      appState.editingProfile = <span class="keyword">false</span>;</span><br><span class="line">      notifyListeners();</span><br><span class="line">    &#125;,</span><br><span class="line">  )));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>状态更新 → 页面自动关闭 → 数据同步，无需 callback 层层传递。</p>
<h3 id="3-5-动态路由注册与模块热更新"><a href="#3-5-动态路由注册与模块热更新" class="headerlink" title="3.5 动态路由注册与模块热更新"></a>3.5 动态路由注册与模块热更新</h3><p>在大型应用或插件化框架中，有时路由并非写死在代码中，而是<strong>根据配置动态加载</strong>。例如一个“活动中心”模块在运行时下发配置：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> featureRoutes = &#123;</span><br><span class="line">  <span class="string">&#x27;promo&#x27;</span>: (context) =&gt; PromoPage(),</span><br><span class="line">  <span class="string">&#x27;survey&#x27;</span>: (context) =&gt; SurveyPage(),</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (featureRoutes.containsKey(uri.pathSegments.first)) &#123;</span><br><span class="line">  <span class="keyword">return</span> MaterialPage(child: featureRoutes[uri.pathSegments.first]!(context));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种“动态注册”让 Navigator 2.0 更适合渐进式加载与灰度发布场景。</p>
<h2 id="4-鉴权与路由守卫"><a href="#4-鉴权与路由守卫" class="headerlink" title="4. 鉴权与路由守卫"></a>4. 鉴权与路由守卫</h2><p>在大型应用中，导航不仅仅是页面切换，更涉及<strong>权限控制</strong>：用户是否登录、是否有权限访问某些功能页。Navigator 2.0 提供的 <strong>声明式导航</strong> 可以非常自然地处理这些场景。</p>
<h3 id="4-1-为什么需要路由守卫"><a href="#4-1-为什么需要路由守卫" class="headerlink" title="4.1 为什么需要路由守卫"></a>4.1 为什么需要路由守卫</h3><p>在命令式导航中，我们通常在页面 push 之前检查登录状态：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!auth.isLoggedIn) &#123;</span><br><span class="line">  Navigator.push(context, MaterialPageRoute(builder: (_) =&gt; LoginPage()));</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  Navigator.push(context, MaterialPageRoute(builder: (_) =&gt; HomePage()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种做法存在几个问题：</p>
<ol>
<li><strong>分散逻辑</strong>：每个页面都要重复判断，容易遗漏。</li>
<li><strong>全局状态难控制</strong>：多栈&#x2F;模态页情况下，用户可能绕过判断。</li>
<li><strong>难以同步 URL</strong>：在 Web 或多端场景下，直接 push 并不能保证地址栏与状态一致。</li>
</ol>
<p><strong>解决方案</strong>：在 RouterDelegate 中统一判断登录状态，根据状态直接构建页面栈。</p>
<h3 id="4-2-声明式导航下的登录守卫策略"><a href="#4-2-声明式导航下的登录守卫策略" class="headerlink" title="4.2 声明式导航下的登录守卫策略"></a>4.2 声明式导航下的登录守卫策略</h3><p>核心思路：</p>
<ol>
<li><strong>统一状态管理</strong>：使用 Provider、Riverpod 或自己维护的 AppState，保存登录状态（如 isLoggedIn、token）。</li>
<li><strong>RouterDelegate 控制页面栈</strong>：根据登录状态决定页面栈内容，而不是每次 push&#x2F;pop 时检查：</li>
</ol>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthRouter</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">AppPath</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey();</span><br><span class="line">  <span class="keyword">final</span> AuthState auth;</span><br><span class="line"></span><br><span class="line">  AuthRouter(<span class="keyword">this</span>.auth);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="comment">// 登录态判断</span></span><br><span class="line">    <span class="built_in">List</span>&lt;Page&gt; pages;</span><br><span class="line">    <span class="keyword">if</span> (!auth.isLoggedIn) &#123;</span><br><span class="line">      <span class="comment">// 未登录 → 仅显示登录页</span></span><br><span class="line">      pages = [MaterialPage(child: LoginPage(onLogin: () &#123;</span><br><span class="line">        auth.login();       <span class="comment">// 更新状态</span></span><br><span class="line">        notifyListeners();  <span class="comment">// 重新构建页面栈</span></span><br><span class="line">      &#125;))];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 已登录 → 显示主页面</span></span><br><span class="line">      pages = [MaterialPage(child: HomePage())];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Navigator(</span><br><span class="line">      key: navigatorKey,</span><br><span class="line">      pages: pages,</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(AppPath configuration) <span class="keyword">async</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-3-典型登录流程"><a href="#4-3-典型登录流程" class="headerlink" title="4.3 典型登录流程"></a>4.3 典型登录流程</h3><ol>
<li><strong>应用启动</strong> → RouterDelegate 根据 auth.isLoggedIn 判断：<ul>
<li>已登录，构建主页面栈</li>
<li>未登录，构建登录页</li>
</ul>
</li>
<li><strong>用户操作登录</strong> → 更新 AuthState → 调用 notifyListeners() → 页面栈重建</li>
<li><strong>登录成功后</strong> → 可以自动导航到用户请求的目标页（deep link 或特定流程页）</li>
</ol>
<blockquote>
<p>这就是 <strong>声明式导航的优势</strong>：页面栈完全由状态驱动，避免散落在各处的权限检查逻辑。</p>
</blockquote>
<h3 id="4-4-用户体验优化"><a href="#4-4-用户体验优化" class="headerlink" title="4.4 用户体验优化"></a>4.4 用户体验优化</h3><ol>
<li><strong>加载页 &#x2F; 验证中间页</strong>：在检查 token 或刷新 session 时显示 Loading 页面，避免闪屏或错误跳转。</li>
</ol>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (auth.isChecking) &#123;</span><br><span class="line">  <span class="keyword">return</span> [MaterialPage(child: LoadingPage())];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>统一过渡动画</strong>：在 RouterDelegate 里统一管理 Page 的动画属性（fullscreenDialog &#x2F; CustomPage），保证不同流程页面切换效果一致。</li>
<li><strong>深链跳转处理</strong>：用户通过外部链接进入受限页面 → 先展示登录页 → 登录成功后自动跳转目标页。只需在 RouterDelegate 中维护一个 pendingPath 状态即可。</li>
</ol>
<h2 id="5-多端导航适配"><a href="#5-多端导航适配" class="headerlink" title="5. 多端导航适配"></a>5. 多端导航适配</h2><p>Declarative 导航（声明式导航）的一大优势，是它<strong>天然适配多端场景</strong>。无论是 <strong>Mobile、Web 还是 Desktop</strong>，本质上都可以通过统一的 <strong>状态驱动页面栈</strong>。</p>
<p>但在不同端上，<strong>导航机制与系统行为存在细微差异</strong>，尤其体现在 URL 同步、浏览器历史、系统事件唤起等方面。</p>
<h3 id="5-1-Web-端差异与适配"><a href="#5-1-Web-端差异与适配" class="headerlink" title="5.1 Web 端差异与适配"></a>5.1 Web 端差异与适配</h3><p>在 Web 上，主要是使用URL 。Router 2.0 提供了 RouteInformationParser 和 RouteInformationProvider，负责在 <strong>URL 与内部状态</strong>之间同步：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;AppPath&gt; parseRouteInformation(RouteInformation info) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> uri = info.uri;</span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.isEmpty) <span class="keyword">return</span> <span class="keyword">const</span> AppPath.home();</span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.first == <span class="string">&#x27;detail&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> AppPath.detail(uri.pathSegments.elementAt(<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const</span> AppPath.home();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RouteInformation restoreRouteInformation(AppPath path) &#123;</span><br><span class="line">    <span class="keyword">if</span> (path.id != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/detail/<span class="subst">$&#123;path.id&#125;</span>&#x27;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/&#x27;</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>关键特性：</strong></p>
<ul>
<li>支持浏览器刷新后状态恢复；</li>
<li>URL 直接访问 &#x2F;detail&#x2F;123 时能深链到详情页；</li>
<li>浏览器返回键会自动触发 setNewRoutePath，同步内部状态。</li>
</ul>
<blockquote>
<p>Flutter Web 下的返回键和浏览器地址栏行为依赖于 RouteInformationProvider，若发现无法同步，可检查 MaterialApp.router 是否配置 routeInformationParser。</p>
</blockquote>
<h3 id="5-2-Desktop-端差异与事件监听"><a href="#5-2-Desktop-端差异与事件监听" class="headerlink" title="5.2 Desktop 端差异与事件监听"></a>5.2 Desktop 端差异与事件监听</h3><p>在 Desktop（Windows &#x2F; macOS &#x2F; Linux）上，导航差异不体现在 URL，而在于<strong>系统事件</strong>：</p>
<ul>
<li>用户可能通过“打开文件”或“URL scheme”启动应用；</li>
<li>应用可能同时存在多个窗口，每个窗口对应独立 Navigator。</li>
</ul>
<p>Flutter 提供了 PlatformDispatcher 与 Window API，可以捕获这类事件：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DesktopRouterDelegate</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">AppPath</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;</span><br><span class="line">  DesktopRouterDelegate() &#123;</span><br><span class="line">    <span class="comment">// 监听系统事件，例如 macOS 上的文件打开</span></span><br><span class="line">    PlatformDispatcher.instance.onOpenUri = (<span class="built_in">Uri</span> uri) &#123;</span><br><span class="line">      <span class="keyword">if</span> (uri.pathSegments.first == <span class="string">&#x27;detail&#x27;</span>) &#123;</span><br><span class="line">        selectedId = uri.pathSegments.elementAt(<span class="number">1</span>);</span><br><span class="line">        showDetail = <span class="keyword">true</span>;</span><br><span class="line">        notifyListeners();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">String?</span> selectedId;</span><br><span class="line">  <span class="built_in">bool</span> showDetail = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Navigator(</span><br><span class="line">      key: navigatorKey,</span><br><span class="line">      pages: [</span><br><span class="line">        MaterialPage(child: HomePage(onSelect: _openDetail)),</span><br><span class="line">        <span class="keyword">if</span> (showDetail)</span><br><span class="line">          MaterialPage(child: DetailPage(id: selectedId!)),</span><br><span class="line">      ],</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> _openDetail(<span class="built_in">String</span> id) &#123;</span><br><span class="line">    selectedId = id;</span><br><span class="line">    showDetail = <span class="keyword">true</span>;</span><br><span class="line">    notifyListeners();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(AppPath configuration) <span class="keyword">async</span> &#123;</span><br><span class="line">    selectedId = configuration.id;</span><br><span class="line">    showDetail = selectedId != <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这意味着：我们可以让桌面端应用响应系统级行为（如「点击文件 → 打开详情页」），而不影响移动端的路由逻辑。</p>
</blockquote>
<h3 id="5-3-移动端与多端统一封装"><a href="#5-3-移动端与多端统一封装" class="headerlink" title="5.3 移动端与多端统一封装"></a>5.3 移动端与多端统一封装</h3><p>移动端（iOS &#x2F; Android）通常没有 URL，同样的导航逻辑就依赖在内存中维护的 <strong>App 状态</strong>。</p>
<p>为了兼容所有平台，可以定义一个抽象接口：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AppNavigator</span> </span>&#123;</span><br><span class="line">  <span class="keyword">void</span> toHome();</span><br><span class="line">  <span class="keyword">void</span> toDetail(<span class="built_in">String</span> id);</span><br><span class="line">  <span class="keyword">void</span> back();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeclarativeNavigator</span> <span class="keyword">extends</span> <span class="title">AppNavigator</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;AppPath&gt; state;</span><br><span class="line">  DeclarativeNavigator(<span class="keyword">this</span>.state);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> toHome() =&gt; state.value = <span class="keyword">const</span> AppPath.home();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> toDetail(<span class="built_in">String</span> id) =&gt; state.value = AppPath.detail(id);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> back() =&gt; state.value = <span class="keyword">const</span> AppPath.home();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后在主入口中统一使用：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> appState = ValueNotifier&lt;AppPath&gt;(<span class="keyword">const</span> AppPath.home());</span><br><span class="line"></span><br><span class="line">MaterialApp.router(</span><br><span class="line">  routerDelegate: AppRouterDelegate(appState),</span><br><span class="line">  routeInformationParser: AppRouteParser(),</span><br><span class="line">  routeInformationProvider: PlatformRouteProvider(appState),</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>这样，<strong>所有端的导航事件都可以通过 AppNavigator 调用</strong>，而底层根据平台差异分别实现 URL 更新、系统事件监听或状态切换。</p>
<h3 id="5-4-SEO-与路径可读性（Web-专属）"><a href="#5-4-SEO-与路径可读性（Web-专属）" class="headerlink" title="5.4 SEO 与路径可读性（Web 专属）"></a>5.4 SEO 与路径可读性（Web 专属）</h3><p>在 Web 下，Declarative Router 的另一优势是——<strong>路径可控、可读性强</strong>。相比传统的 hash 路由（如 <code>/#/detail?id=3</code>），Declarative Router 可以输出 <code>/detail/3</code> 这种结构化 URL，利于：</p>
<ul>
<li>搜索引擎索引；</li>
<li>页面直接分享；</li>
<li>SSR 或预渲染。</li>
</ul>
<blockquote>
<p>小技巧：可结合 go_router 等三方库进一步简化多端导航；若要支持静态资源预渲染，可配合 flutter build web –base-href 指定路径。</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>平台</strong></th>
<th><strong>导航差异点</strong></th>
<th><strong>解决方案</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Mobile</strong></td>
<td>内存状态驱动</td>
<td>RouterDelegate 状态管理</td>
</tr>
<tr>
<td><strong>Web</strong></td>
<td>URL 同步、刷新恢复</td>
<td>RouteInformationParser &#x2F; Provider</td>
</tr>
<tr>
<td><strong>Desktop</strong></td>
<td>系统事件、文件唤起</td>
<td>PlatformDispatcher 事件监听</td>
</tr>
</tbody></table>
<p>统一 Declarative 导航的核心，是“<strong>状态 → 页面栈的单向映射</strong>”。只要将平台特性（URL、系统事件）转化为统一的路由状态，就能在所有端上共享同一套逻辑。</p>
<h2 id="6-调试、测试与工程模板"><a href="#6-调试、测试与工程模板" class="headerlink" title="6. 调试、测试与工程模板"></a>6. 调试、测试与工程模板</h2><p>Declarative 导航的思路虽然清晰，但在真实项目中经常因为 <strong>状态不同步、URL 不更新、Pop 无效</strong> 等问题很难调试。</p>
<p>下面讲讲如何<strong>定位问题、测试导航逻辑、以及组织可扩展的工程结构</strong>。</p>
<h3 id="6-1-调试技巧"><a href="#6-1-调试技巧" class="headerlink" title="6.1 调试技巧"></a>6.1 调试技巧</h3><h4 id="6-1-1-RouterDelegate-的生命周期"><a href="#6-1-1-RouterDelegate-的生命周期" class="headerlink" title="6.1.1 RouterDelegate 的生命周期"></a>6.1.1 RouterDelegate 的生命周期</h4><p>Declarative 导航的核心在于状态驱动页面栈，因此最需要监控的是——<strong>状态何时变化、为何变化</strong>。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouterDelegate</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">AppPath</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;AppPath&gt; appState;</span><br><span class="line">  AppRouterDelegate(<span class="keyword">this</span>.appState) &#123;</span><br><span class="line">    appState.addListener(() &#123;</span><br><span class="line">      debugPrint(<span class="string">&#x27;🔄 Route changed to: <span class="subst">$&#123;appState.value&#125;</span>&#x27;</span>);</span><br><span class="line">      notifyListeners();</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    debugPrint(<span class="string">&#x27;🧩 Rebuilding Navigator with <span class="subst">$&#123;appState.value&#125;</span>&#x27;</span>);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(AppPath configuration) <span class="keyword">async</span> &#123;</span><br><span class="line">    debugPrint(<span class="string">&#x27;🌐 New route from URL: <span class="subst">$configuration</span>&#x27;</span>);</span><br><span class="line">    appState.value = configuration;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>调试重点：</strong><br>setNewRoutePath() 被调用说明来源是“URL 变化”或“浏览器返回”。<br>notifyListeners() → build() → Navigator 触发重建，是内部状态变化。</p>
</blockquote>
<h4 id="6-1-2-Flutter-DevTools-查看-rebuild"><a href="#6-1-2-Flutter-DevTools-查看-rebuild" class="headerlink" title="6.1.2 Flutter DevTools 查看 rebuild"></a>6.1.2 Flutter DevTools 查看 rebuild</h4><p>打开 DevTools 的 <strong>“Widget rebuild profiler”</strong>，你能看到 RouterDelegate、Navigator、Page 的 rebuild 频率。若某页面频繁重建，说明你的状态管理可能“太粗”，可考虑拆分子状态。</p>
<h4 id="6-1-3-常见-Bug-与排查"><a href="#6-1-3-常见-Bug-与排查" class="headerlink" title="6.1.3 常见 Bug 与排查"></a>6.1.3 常见 Bug 与排查</h4><table>
<thead>
<tr>
<th><strong>问题</strong></th>
<th><strong>原因</strong></th>
<th><strong>修复思路</strong></th>
</tr>
</thead>
<tbody><tr>
<td>页面反复 push</td>
<td>notifyListeners() 多次触发</td>
<td>在 setState 或异步回调中去重</td>
</tr>
<tr>
<td>pop 不生效</td>
<td>未正确实现 onDidRemovePage &#x2F; didPop</td>
<td>改为使用 NavigatorObserver</td>
</tr>
<tr>
<td>URL 不同步</td>
<td>RouteInformationParser 未实现 restoreRouteInformation()</td>
<td>确保状态更新时正确返回 URL</td>
</tr>
</tbody></table>
<h3 id="6-2-测试策略"><a href="#6-2-测试策略" class="headerlink" title="6.2 测试策略"></a>6.2 测试策略</h3><p>Declarative 导航最大的好处之一，就是逻辑可测试。传统 Navigator 1.0 的 push&#x2F;pop 很难验证，而现在，我们可以直接测试状态与解析。</p>
<h4 id="6-2-1-单元测试：验证-RouteParser-输入输出"><a href="#6-2-1-单元测试：验证-RouteParser-输入输出" class="headerlink" title="6.2.1 单元测试：验证 RouteParser 输入输出"></a>6.2.1 单元测试：验证 RouteParser 输入输出</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter_test/flutter_test.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  test(<span class="string">&#x27;should parse /detail/123 correctly&#x27;</span>, () <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> parser = AppRouteParser();</span><br><span class="line">    <span class="keyword">final</span> route = <span class="keyword">await</span> parser.parseRouteInformation(</span><br><span class="line">      <span class="keyword">const</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/detail/123&#x27;</span>)),</span><br><span class="line">    );</span><br><span class="line">    expect(route.id, <span class="string">&#x27;123&#x27;</span>);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  test(<span class="string">&#x27;should restore route information&#x27;</span>, () &#123;</span><br><span class="line">    <span class="keyword">final</span> parser = AppRouteParser();</span><br><span class="line">    <span class="keyword">final</span> info = parser.restoreRouteInformation(AppPath.detail(<span class="string">&#x27;99&#x27;</span>));</span><br><span class="line">    expect(info.uri.path, <span class="string">&#x27;/detail/99&#x27;</span>);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>测试要点：<br> 只需 Mock RouteInformation，无需真正构建 UI。<br>确保 &#x2F;detail&#x2F;xxx 与 AppPath.detail(id) 双向同步。</p>
</blockquote>
<h4 id="6-2-2-集成测试：模拟用户导航行为"><a href="#6-2-2-集成测试：模拟用户导航行为" class="headerlink" title="6.2.2 集成测试：模拟用户导航行为"></a>6.2.2 集成测试：模拟用户导航行为</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">testWidgets(<span class="string">&#x27;navigates from FeedPage to DetailPage&#x27;</span>, (tester) <span class="keyword">async</span> &#123;</span><br><span class="line">  <span class="keyword">await</span> tester.pumpWidget(<span class="keyword">const</span> MyApp());</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 点击第一个 item</span></span><br><span class="line">  <span class="keyword">await</span> tester.tap(find.text(<span class="string">&#x27;Item 1&#x27;</span>));</span><br><span class="line">  <span class="keyword">await</span> tester.pumpAndSettle();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 断言跳转到详情页</span></span><br><span class="line">  expect(find.text(<span class="string">&#x27;Detail page for item 1&#x27;</span>), findsOneWidget);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 模拟返回</span></span><br><span class="line">  <span class="keyword">await</span> tester.pageBack();</span><br><span class="line">  <span class="keyword">await</span> tester.pumpAndSettle();</span><br><span class="line"></span><br><span class="line">  expect(find.text(<span class="string">&#x27;Feed&#x27;</span>), findsOneWidget);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>建议</strong>：<br>在 MyApp 中暴露 ValueNotifier<code>&lt;AppPath&gt;</code>，便于测试时直接控制路由。<br>集成测试可以覆盖登录守卫、模态弹窗、深链跳转等复杂场景。</p>
</blockquote>
<h3 id="6-3-工程模板：从-Demo-到可维护架构"><a href="#6-3-工程模板：从-Demo-到可维护架构" class="headerlink" title="6.3 工程模板：从 Demo 到可维护架构"></a>6.3 工程模板：从 Demo 到可维护架构</h3><p>Declarative 导航最怕“一坨写在一个文件里”。合理的结构能让你轻松迁移到 go_router 或 auto_route，也方便后期接入权限、深链、A&#x2F;B 实验等逻辑。</p>
<p>下面是一个完整可运行的 Flutter Declarative Navigation 最小化项目结构，包含 <strong>3 个页面（Home &#x2F; Detail &#x2F; Login）</strong>、<strong>RouteParser + RouterDelegate</strong>、以及一个简单的状态管理。</p>
<p>项目结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lib/</span><br><span class="line">  main.dart</span><br><span class="line">  routes/</span><br><span class="line">    app_route_parser.dart</span><br><span class="line">    app_router_delegate.dart</span><br><span class="line">  models/</span><br><span class="line">    app_path.dart</span><br><span class="line">  pages/</span><br><span class="line">    home_page.dart</span><br><span class="line">    detail_page.dart</span><br><span class="line">    login_page.dart</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;main.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;models/app_path.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;routes/app_route_parser.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;routes/app_router_delegate.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;  </span><br><span class="line">  runApp(MyApp());  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;AppPath&gt; appState = ValueNotifier(<span class="keyword">const</span> AppPath.home());  </span><br><span class="line">  </span><br><span class="line">  MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp.router(  </span><br><span class="line">      title: <span class="string">&#x27;Declarative Nav Demo&#x27;</span>,  </span><br><span class="line">      routerDelegate: AppRouterDelegate(appState),  </span><br><span class="line">      routeInformationParser: AppRouteParser(),  </span><br><span class="line">      backButtonDispatcher: RootBackButtonDispatcher(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;models&#x2F;app_path.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/foundation.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">声明式路由路径结构体  </span></span></span><br><span class="line"><span class="meta">@immutable</span>  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppPath</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String?</span> detailId;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">bool</span> isLogin;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> AppPath.home()  </span><br><span class="line">      : detailId = <span class="keyword">null</span>,  </span><br><span class="line">        isLogin = <span class="keyword">false</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> AppPath.detail(<span class="keyword">this</span>.detailId) : isLogin = <span class="keyword">false</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> AppPath.login()  </span><br><span class="line">      : detailId = <span class="keyword">null</span>,  </span><br><span class="line">        isLogin = <span class="keyword">true</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="built_in">bool</span> <span class="keyword">get</span> isHomePage =&gt; !isLogin &amp;&amp; detailId == <span class="keyword">null</span>;  </span><br><span class="line">  <span class="built_in">bool</span> <span class="keyword">get</span> isDetailPage =&gt; !isLogin &amp;&amp; detailId != <span class="keyword">null</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;routes&#x2F;app_route_parser.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../models/app_path.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">URL &lt;-&gt; AppPath 转换器  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Future&lt;AppPath&gt; parseRouteInformation(RouteInformation routeInformation) <span class="keyword">async</span> &#123;  </span><br><span class="line">    <span class="keyword">final</span> uri = routeInformation.uri;  </span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.isEmpty) <span class="keyword">return</span> <span class="keyword">const</span> AppPath.home();  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.first == <span class="string">&#x27;login&#x27;</span>) &#123;  </span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">const</span> AppPath.login();  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.first == <span class="string">&#x27;detail&#x27;</span> &amp;&amp; uri.pathSegments.length == <span class="number">2</span>) &#123;  </span><br><span class="line">      <span class="keyword">return</span> AppPath.detail(uri.pathSegments[<span class="number">1</span>]);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const</span> AppPath.home();  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  RouteInformation? restoreRouteInformation(AppPath configuration) &#123;  </span><br><span class="line">    <span class="keyword">if</span> (configuration.isLogin) &#123;  </span><br><span class="line">      <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/login&#x27;</span>));  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">if</span> (configuration.isDetailPage) &#123;  </span><br><span class="line">      <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/detail/<span class="subst">$&#123;configuration.detailId&#125;</span>&#x27;</span>));  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> RouteInformation(uri: <span class="built_in">Uri</span>(path: <span class="string">&#x27;/&#x27;</span>));  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;routes&#x2F;app_router_delegate.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../models/app_path.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../pages/home_page.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../pages/detail_page.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../pages/login_page.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">核心路由委托：根据状态生成页面栈  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppRouterDelegate</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">AppPath</span>&gt;  </span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">AppPath</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">final</span> GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey&lt;NavigatorState&gt;();  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;AppPath&gt; appState;  </span><br><span class="line">  </span><br><span class="line">  AppRouterDelegate(<span class="keyword">this</span>.appState) &#123;  </span><br><span class="line">    appState.addListener(notifyListeners);  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  AppPath? <span class="keyword">get</span> currentConfiguration =&gt; appState.value;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">final</span> path = appState.value;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">final</span> pages = &lt;Page&gt;[  </span><br><span class="line">      <span class="keyword">if</span> (path.isLogin)  </span><br><span class="line">        <span class="keyword">const</span> MaterialPage(key: ValueKey(<span class="string">&#x27;LoginPage&#x27;</span>), child: LoginPage())  </span><br><span class="line">      <span class="keyword">else</span>  </span><br><span class="line">        <span class="keyword">const</span> MaterialPage(key: ValueKey(<span class="string">&#x27;HomePage&#x27;</span>), child: HomePage()),  </span><br><span class="line">      <span class="keyword">if</span> (path.isDetailPage)  </span><br><span class="line">        MaterialPage(  </span><br><span class="line">          key: ValueKey(<span class="string">&#x27;Detail-<span class="subst">$&#123;path.detailId&#125;</span>&#x27;</span>),  </span><br><span class="line">          child: DetailPage(id: path.detailId!),  </span><br><span class="line">        ),  </span><br><span class="line">    ];  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Navigator(  </span><br><span class="line">      key: navigatorKey,  </span><br><span class="line">      pages: pages,  </span><br><span class="line">  </span><br><span class="line">      onDidRemovePage: (page) &#123;  </span><br><span class="line">        debugPrint(<span class="string">&#x27;Page removed: <span class="subst">$&#123;page.key&#125;</span>&#x27;</span>);  </span><br><span class="line">        <span class="comment">// 根据被移除的页面类型更新状态  </span></span><br><span class="line">        <span class="keyword">if</span> (path.isDetailPage || path.isLogin) &#123;  </span><br><span class="line">          appState.value = <span class="keyword">const</span> AppPath.home();  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;,  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(AppPath configuration) <span class="keyword">async</span> &#123;  </span><br><span class="line">    appState.value = configuration;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> dispose() &#123;  </span><br><span class="line">    appState.removeListener(notifyListeners);  </span><br><span class="line">    <span class="keyword">super</span>.dispose();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;pages&#x2F;home_page.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../models/app_path.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> HomePage(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">final</span> delegate = Router.of(context).routerDelegate <span class="keyword">as</span> <span class="built_in">dynamic</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;🏠 Home&#x27;</span>)),  </span><br><span class="line">      body: Center(  </span><br><span class="line">        child: Column(  </span><br><span class="line">          mainAxisAlignment: MainAxisAlignment.center,  </span><br><span class="line">          children: [  </span><br><span class="line">            ElevatedButton(  </span><br><span class="line">              onPressed: () =&gt; delegate.appState.value = <span class="keyword">const</span> AppPath.detail(<span class="string">&#x27;42&#x27;</span>),  </span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;进入详情页 /detail/42&#x27;</span>),  </span><br><span class="line">            ),  </span><br><span class="line">            ElevatedButton(  </span><br><span class="line">              onPressed: () =&gt; delegate.appState.value = <span class="keyword">const</span> AppPath.login(),  </span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;退出登录 /login&#x27;</span>),  </span><br><span class="line">            ),  </span><br><span class="line">          ],  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;pages&#x2F;detail_page.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../models/app_path.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetailPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> id;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> DetailPage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.id&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">final</span> delegate = Router.of(context).routerDelegate <span class="keyword">as</span> <span class="built_in">dynamic</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      appBar: AppBar(title: Text(<span class="string">&#x27;📄 Detail <span class="subst">$id</span>&#x27;</span>)),  </span><br><span class="line">      body: Center(  </span><br><span class="line">        child: ElevatedButton(  </span><br><span class="line">          onPressed: () =&gt; delegate.appState.value = <span class="keyword">const</span> AppPath.home(),  </span><br><span class="line">          child: <span class="keyword">const</span> Text(<span class="string">&#x27;返回主页&#x27;</span>),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>lib&#x2F;pages&#x2F;login_page.dart</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../models/app_path.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoginPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> LoginPage(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">final</span> delegate = Router.of(context).routerDelegate <span class="keyword">as</span> <span class="built_in">dynamic</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;🔐 Login&#x27;</span>)),  </span><br><span class="line">      body: Center(  </span><br><span class="line">        child: ElevatedButton(  </span><br><span class="line">          onPressed: () &#123;  </span><br><span class="line">            <span class="comment">// 模拟登录成功  </span></span><br><span class="line">            delegate.appState.value = <span class="keyword">const</span> AppPath.home();  </span><br><span class="line">          &#125;,  </span><br><span class="line">          child: <span class="keyword">const</span> Text(<span class="string">&#x27;登录成功 → 返回首页&#x27;</span>),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>声明式导航的核心思想是：<strong>“页面不是被命令打开的，而是由状态自然生成的。”</strong><br>当应用状态发生变化（如用户登录、订单提交、或从外部链接唤起），RouterDelegate 会根据当前状态重建页面栈，使 UI 与数据保持同步。这意味着导航逻辑从“操作视图”变为“描述状态”，让代码更直观、更易维护。</p>
<p>其次，随着多导航栈、模态弹窗、深度链接等复杂场景的出现，Navigator 2.0 提供了一种可扩展的“统一建模”方式。无论是移动端、Web 还是桌面端，路由都可以通过 RouteInformationParser 与 RouterDelegate 共同驱动，实现状态、URL、页面栈三者的精确同步。</p>
<p>最后，声明式路由让调试与测试成为可能。我们可以直接验证“给定状态 → 构建页面栈”的正确性，而不再依赖手动点击或 push 流程。这使得导航逻辑正式进入工程化、可预测、可测试的时代。</p>
<blockquote>
<p><strong>一句话总结：Navigator 2.0 不只是新 API，而是让「导航」真正成为「应用状态」的一部分。</strong></p>
</blockquote>
<p>在此基础上，我们还可以继续探索更高层的封装，如 <strong>go_router</strong>、<strong>beamer</strong> 等，它们在 Navigator 2.0 的基础上实现了更强大的路由守卫、模块化注册和动画过渡机制。而在更大型的工程中，还可以尝试构建 <strong>“动态路由中心”</strong> —— 让每个功能模块自注册路由，进一步解耦与扩展应用架构。</p>
<h2 id="8-备注"><a href="#8-备注" class="headerlink" title="8. 备注"></a>8. 备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>fluttter: 3.35.4</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="https://docs.flutter.dev/">https://docs.flutter.dev/</a></li>
</ul>
]]></content>
      <categories>
        <category>跨平台框架</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
        <tag>状态管理</tag>
        <tag>路由</tag>
        <tag>模块化</tag>
      </tags>
  </entry>
  <entry>
    <title>约束与布局：深入理解 RenderObject、CustomPaint 与 Sliver 协议</title>
    <url>/2025/09/29/031-flutter-practical-constraints-and-layout/</url>
    <content><![CDATA[<h2 id="1-为什么要自定义-RenderObject"><a href="#1-为什么要自定义-RenderObject" class="headerlink" title="1. 为什么要自定义 RenderObject"></a>1. 为什么要自定义 RenderObject</h2><p>在 Flutter 中，我们平时开发中最常打交道的是 <strong>Widget</strong>。它们像是 UI 的“配置表”，描述界面要长什么样。但 Widget 并不真正负责绘制，它只是告诉框架“我要一个红色的方块”或者“我要一个可滚动的列表”。真正负责把这些需求落到屏幕上的，是底层的 <strong>RenderObject</strong>。</p>
<span id="more"></span>
<p>Flutter 的渲染体系大致可以理解为三层：</p>
<ul>
<li><strong>Widget</strong>：声明式配置，告诉框架“我要什么”。</li>
<li><strong>Element</strong>：连接桥梁，管理生命周期和树的更新。</li>
<li><strong>RenderObject</strong>：执行者，负责布局、绘制和事件响应。</li>
</ul>
<p>虽然在日常开发中，我们大多数场景只需要写 Widget 就够了，但有时候，会发现 <strong>Widget 层的封装并不能完全满足需求</strong>：</p>
<ul>
<li>比如说要画一个圆形进度条，官方库里没有现成组件。用 Container + Stack + 各种组合方式，性能和灵活性都不太理想</li>
<li>想在滚动场景下实现特殊效果（比如一个“可伸缩的头部”或“性能更优的超大网格”），用现成的 SliverList、GridView 就显得有点力不从心。</li>
<li>想在优化性能时，如果 Widget 组合太复杂，层级过深，就会导致频繁 rebuild &#x2F; relayout，渲染卡顿。</li>
</ul>
<p>这时候，就需要“下潜”到 <strong>RenderObject 层</strong>，去直接操作布局和绘制逻辑了。  </p>
<p>写自定义 RenderObject 看似“黑魔法”，但本质上它只是更贴近底层的工具：我们可以跳过 Widget 的限制，直接告诉 Flutter 如何计算子元素的大小、如何摆放、如何在画布上绘制。这样做既能提升性能，也能实现官方组件做不到的效果。</p>
<h2 id="2-RenderObject"><a href="#2-RenderObject" class="headerlink" title="2. RenderObject"></a>2. RenderObject</h2><p>在 Flutter 中，<strong>RenderObject 是真正负责布局与绘制的执行者</strong>，但它并不是单一的存在，而是一个体系，有着不同的分工与扩展。理解这些角色和它们的生命周期方法，是知道怎样自定义渲染器的前提。</p>
<h3 id="2-1-RenderObject-功能"><a href="#2-1-RenderObject-功能" class="headerlink" title="2.1 RenderObject 功能"></a>2.1 RenderObject 功能</h3><p>可以把 Widget 树想象成一份 <strong>设计图纸</strong>，而 RenderObject 树就是负责施工的 <strong>工程队</strong>。在工程队内部，不同工种各司其职：</p>
<ul>
<li><strong>RenderObject</strong><br>  所有渲染对象的基类。定义了最核心的接口：布局（layout）、绘制（paint）、事件响应（hitTest）等。但它本身比较抽象，很少直接继承。</li>
<li><strong>RenderBox</strong><br>  最常用的子类，它采用二维 <strong>盒模型（box model）</strong>，约束（constraints）决定宽高，最终计算出 size。大部分常见组件（Text、Container、Image）底层都是 RenderBox。</li>
<li><strong>RenderSliver</strong><br>  专为滚动场景设计。它不直接用宽高描述大小，而是使用 <strong>SliverConstraints &#x2F; SliverGeometry</strong>，能描述“在可见窗口里渲染多少像素”。像 ListView、GridView 的底层都是基于 RenderSliver。</li>
</ul>
<p>简而言之，RenderObject 是 <strong>抽象基类</strong>，RenderBox 负责 <strong>常规布局</strong>，RenderSliver 负责 <strong>滚动优化</strong>。</p>
<h3 id="2-2-生命周期的关键方法"><a href="#2-2-生命周期的关键方法" class="headerlink" title="2.2 生命周期的关键方法"></a>2.2 生命周期的关键方法</h3><p>RenderObject 的生命周期可以理解为一套流水线：<strong>布局 → 绘制 → 事件响应</strong>。</p>
<ul>
<li><strong>performLayout</strong>：负责测量和确定自身（以及子节点）的大小与位置。在 RenderBox 中，这通常就是根据 BoxConstraints 计算 size。</li>
<li><strong>paint</strong>：负责把内容画到画布（Canvas）上，例如绘制矩形、圆形、图片等，paint 不关心布局，只关心“怎么画”。</li>
<li><strong>hitTest</strong>：处理事件响应，判断点击、拖拽等交互是否落在当前区域，如果返回 true，事件就会被传递给对应的子节点。</li>
</ul>
<p>这三个方法是自定义 RenderObject 时最常 override 的。</p>
<h3 id="2-3-computeDryLayout-的意义"><a href="#2-3-computeDryLayout-的意义" class="headerlink" title="2.3 computeDryLayout 的意义"></a>2.3 computeDryLayout 的意义</h3><p>在 Flutter 2.0 之后，框架引入了 <strong>computeDryLayout</strong> 方法，用于在不真正触发布局的情况下 <strong>预估大小</strong>。</p>
<p>为什么需要这个？<br>因为某些父组件（比如 IntrinsicWidth、IntrinsicHeight）需要提前知道子组件的理想尺寸，但又不能真的触发 layout。而computeDryLayout 提供了一个“试算”机会，可以在不影响布局树的前提下返回一个 Size。<br>因此，当我们写 RenderBox 时，推荐同时实现 performLayout 和 computeDryLayout，确保你的控件在各种情况下表现一致。</p>
<h3 id="2-4-markNeedsLayout-markNeedsPaint"><a href="#2-4-markNeedsLayout-markNeedsPaint" class="headerlink" title="2.4 markNeedsLayout &#x2F; markNeedsPaint"></a>2.4 markNeedsLayout &#x2F; markNeedsPaint</h3><p>除了生命周期方法，RenderObject 还提供了“通知系统需要重新计算”的机制：</p>
<ul>
<li><strong>markNeedsLayout</strong>：告诉框架“我的布局无效了，需要重新走 performLayout”。常见于属性变化影响大小时。</li>
<li><strong>markNeedsPaint</strong>：告诉框架“我的绘制内容变了，需要重绘”。常见于颜色、进度值变化但不影响大小时。</li>
</ul>
<p>这两个方法会把节点标记为 dirty，等待下一帧统一处理，从而避免重复计算。</p>
<h3 id="2-5-自定义-RenderBox-生命周期"><a href="#2-5-自定义-RenderBox-生命周期" class="headerlink" title="2.5 自定义 RenderBox 生命周期"></a>2.5 自定义 RenderBox 生命周期</h3><p>下面是一个示例，打印布局和绘制的调用顺序：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DebugBox</span> <span class="keyword">extends</span> <span class="title">RenderBox</span> </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;</span><br><span class="line">    <span class="comment">// 假设固定大小 100x100</span></span><br><span class="line">    size = constraints.constrain(Size(<span class="number">100</span>, <span class="number">100</span>));</span><br><span class="line">    debugPrint(<span class="string">&#x27;performLayout called, size = <span class="subst">$size</span>&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    debugPrint(<span class="string">&#x27;paint called at <span class="subst">$offset</span>&#x27;</span>);</span><br><span class="line">    <span class="keyword">final</span> Paint paint = Paint()..color = <span class="keyword">const</span> Color(<span class="number">0xFF42A5F5</span>);</span><br><span class="line">    context.canvas.drawRect(offset &amp; size, paint);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> hitTestSelf(Offset position) &#123;</span><br><span class="line">    debugPrint(<span class="string">&#x27;hitTest at <span class="subst">$position</span>&#x27;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>; <span class="comment">// 点击区域有效</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们在界面中嵌入这个组件时，可以看到：先走 performLayout，接着 paint，最后在点击时触发 hitTest。这就是 RenderObject 的完整工作流程。</p>
<h2 id="3-CustomPainter-与-Canvas"><a href="#3-CustomPainter-与-Canvas" class="headerlink" title="3. CustomPainter 与 Canvas"></a>3. CustomPainter 与 Canvas</h2><p>在真正深入 RenderObject 的 paint 方法之前，我们先从一个更易上手的入口切入：<strong>CustomPainter</strong>。它是 Flutter 提供的“绘制接口”，我们可以在其中直接操作 Canvas，实现各种自定义图形，而不必一开始就写 RenderBox。</p>
<h3 id="3-1-CustomPainter-的定位"><a href="#3-1-CustomPainter-的定位" class="headerlink" title="3.1 CustomPainter 的定位"></a>3.1 CustomPainter 的定位</h3><p>如果把 Flutter 的绘制体系比作“造房子”：</p>
<ul>
<li><strong>Widget</strong> 是户型设计图</li>
<li><strong>RenderBox.paint</strong> 是工人亲手砌墙、刷漆</li>
<li><strong>CustomPainter</strong> 就像雇了一支“外包团队”，你只需定义绘制逻辑，它就能被插入到渲染流程中。</li>
</ul>
<p>使用 CustomPainter 有几个优点：</p>
<ul>
<li><strong>快速验证绘制逻辑</strong>，不用直接继承 RenderBox。</li>
<li><strong>高度灵活</strong>，可随时挂到 CustomPaint Widget 上。</li>
<li><strong>天然支持组合</strong>，一个界面可以有多个 CustomPainter 叠加绘制。</li>
</ul>
<p>因此，CustomPainter 往往是初学者进入 RenderObject 世界的第一步。</p>
<h3 id="3-2-生命周期与-shouldRepaint"><a href="#3-2-生命周期与-shouldRepaint" class="headerlink" title="3.2 生命周期与 shouldRepaint"></a>3.2 生命周期与 shouldRepaint</h3><p>编写 CustomPainter 时，必须实现 paint 和 shouldRepaint：</p>
<ul>
<li><code>paint(Canvas, Size)</code>：在这里写绘制逻辑，例如画矩形、圆形、路径等。</li>
<li><code>shouldRepaint(CustomPainter oldDelegate)</code>：用来判断“是否需要重绘”。如果返回 true，Flutter 会在下一帧重新调用 paint。</li>
</ul>
<p>很多初学者会偷懒，直接这样写：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line"><span class="built_in">bool</span> shouldRepaint(<span class="keyword">covariant</span> CustomPainter oldDelegate) =&gt; <span class="keyword">true</span>;</span><br></pre></td></tr></table></figure>
<p>这样虽然简单，但意味着 <strong>每一帧都会重绘</strong>，即使内容没变化，也会浪费性能。</p>
<p>正确做法是：比较关键属性是否变化。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingPainter</span> <span class="keyword">extends</span> <span class="title">CustomPainter</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> progress;</span><br><span class="line">  RingPainter(<span class="keyword">this</span>.progress);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(Canvas canvas, Size size) &#123;</span><br><span class="line">    <span class="keyword">final</span> Paint paint = Paint()</span><br><span class="line">      ..color = <span class="keyword">const</span> Color(<span class="number">0xFF42A5F5</span>)</span><br><span class="line">      ..strokeWidth = <span class="number">8</span></span><br><span class="line">      ..style = PaintingStyle.stroke;</span><br><span class="line">    <span class="keyword">final</span> Rect rect = Offset.zero &amp; size;</span><br><span class="line">    canvas.drawArc(rect, -<span class="number">3.14</span> / <span class="number">2</span>, <span class="number">2</span> * <span class="number">3.14</span> * progress, <span class="keyword">false</span>, paint);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> shouldRepaint(<span class="keyword">covariant</span> RingPainter oldDelegate) &#123;</span><br><span class="line">    <span class="keyword">return</span> oldDelegate.progress != progress;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样只有进度变化时才触发重绘，大大减少无效开销。</p>
<h3 id="3-3-PictureRecorder-与缓存思路"><a href="#3-3-PictureRecorder-与缓存思路" class="headerlink" title="3.3 PictureRecorder 与缓存思路"></a>3.3 PictureRecorder 与缓存思路</h3><p>有时绘制逻辑非常复杂（例如地图瓦片、复杂曲线），哪怕 shouldRepaint 正确实现，也可能导致性能瓶颈。<br>这时我们可以借助 <strong>PictureRecorder</strong>，它可以提前把绘制内容“录制”成 Picture 对象，下次需要绘制时，直接复用 Picture，而不是重新执行绘制逻辑。</p>
<p>例如：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> recorder = PictureRecorder();</span><br><span class="line"><span class="keyword">final</span> canvas = Canvas(recorder);</span><br><span class="line">drawSomething(canvas); <span class="comment">// 只绘制一次</span></span><br><span class="line"><span class="keyword">final</span> picture = recorder.endRecording();</span><br><span class="line"><span class="comment">// 下次复用 picture，避免重复计算</span></span><br></pre></td></tr></table></figure>
<p>这就是 Flutter 内部很多控件（如 Icon）的缓存思路。</p>
<h3 id="3-4-Layer-与绘制分层"><a href="#3-4-Layer-与绘制分层" class="headerlink" title="3.4 Layer 与绘制分层"></a>3.4 Layer 与绘制分层</h3><p>Flutter 的绘制不是一次性画到底，而是基于 <strong>Layer Tree</strong>。每个 Layer 都可以单独缓存和复用，例如：</p>
<ul>
<li><strong>PictureLayer</strong>：存放实际绘制内容</li>
<li><strong>TransformLayer</strong>：存放矩阵变换</li>
<li><strong>ClipLayer</strong>：存放裁剪区域</li>
</ul>
<p>得益于分层机制，Flutter 可以只重绘变化的部分，而不是整个画布。</p>
<p>例如一个固定背景 + 移动小球的场景：</p>
<ul>
<li>背景可以缓存到 PictureLayer，不必每帧重绘。</li>
<li>只有小球的 Layer 每帧更新，节省大量性能。</li>
</ul>
<p>这也是为什么在复杂界面中，合理拆分 Layer 和缓存，是性能优化的关键。</p>
<h3 id="3-5-示例：圆环进度条"><a href="#3-5-示例：圆环进度条" class="headerlink" title="3.5 示例：圆环进度条"></a>3.5 示例：圆环进度条</h3><h4 id="3-5-1-代码实现"><a href="#3-5-1-代码实现" class="headerlink" title="3.5.1 代码实现"></a>3.5.1 代码实现</h4><p>结合上面的知识，我们用 CustomPainter 实现一个圆环进度条：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// <span class="language-markdown">一个圆环进度条组件，外层还是普通的 StatelessWidget，  </span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">只是内部用 CustomPaint 来承载真正的绘制逻辑。  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingProgress</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> progress; <span class="comment">// 进度值：0.0 ~ 1.0  </span></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> strokeWidth; <span class="comment">// 圆环宽度  </span></span><br><span class="line">  <span class="keyword">final</span> Color color; <span class="comment">// 主色  </span></span><br><span class="line">  <span class="keyword">final</span> Size size; <span class="comment">// 尺寸  </span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">const</span> RingProgress(&#123;  </span><br><span class="line">    <span class="keyword">super</span>.key,  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.progress,  </span><br><span class="line">    <span class="keyword">this</span>.strokeWidth = <span class="number">6.0</span>,  </span><br><span class="line">    <span class="keyword">this</span>.color = Colors.blue,   </span><br><span class="line">    <span class="keyword">this</span>.size = <span class="keyword">const</span> Size(<span class="number">100.0</span>, <span class="number">100.0</span>),  </span><br><span class="line">  &#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> CustomPaint(  </span><br><span class="line">      <span class="comment">// 指定画布的大小（也可以由父布局约束决定）  </span></span><br><span class="line">      size: size,  </span><br><span class="line">      <span class="comment">// painter 就是具体的绘制逻辑  </span></span><br><span class="line">      painter: _RingPainter(  </span><br><span class="line">        progress: progress,  </span><br><span class="line">        strokeWidth: strokeWidth,  </span><br><span class="line">        color: color,  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">自定义 Painter，真正负责绘制  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_RingPainter</span> <span class="keyword">extends</span> <span class="title">CustomPainter</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> progress;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> strokeWidth;  </span><br><span class="line">  <span class="keyword">final</span> Color color;  </span><br><span class="line">  </span><br><span class="line">  _RingPainter(&#123;  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.progress,  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.strokeWidth,  </span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.color,  </span><br><span class="line">  &#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> paint(Canvas canvas, Size size) &#123;  </span><br><span class="line">    <span class="comment">// 圆心点  </span></span><br><span class="line">    <span class="keyword">final</span> Offset center = size.center(Offset.zero);  </span><br><span class="line">    <span class="comment">// 半径 = 最短边减去线宽的一半  </span></span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> radius = (size.shortestSide - strokeWidth) / <span class="number">2</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 创建画笔  </span></span><br><span class="line">    <span class="keyword">final</span> Paint paint = Paint()  </span><br><span class="line">      ..style = PaintingStyle  </span><br><span class="line">          .stroke <span class="comment">// 画线模式（不是填充）  </span></span><br><span class="line">      ..strokeWidth = strokeWidth  </span><br><span class="line">      ..strokeCap = StrokeCap.round; <span class="comment">// 圆角收尾  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 1. 先画一层半透明的背景圆环  </span></span><br><span class="line">    paint.color = color.withValues(alpha: <span class="number">0.2</span>);  </span><br><span class="line">    canvas.drawCircle(center, radius, paint);  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 2. 再画进度弧线  </span></span><br><span class="line">    paint.color = color;  </span><br><span class="line">    <span class="keyword">final</span> Rect rect = Rect.fromCircle(center: center, radius: radius);  </span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> sweepAngle = <span class="number">2</span> * math.pi * progress; <span class="comment">// 进度 → 弧度  </span></span><br><span class="line">    canvas.drawArc(  </span><br><span class="line">      rect,  </span><br><span class="line">      -math.pi / <span class="number">2</span>, <span class="comment">// 起点角度：-90°，让进度从正上方开始  </span></span><br><span class="line">      sweepAngle,  </span><br><span class="line">      <span class="keyword">false</span>, <span class="comment">// 只画弧线，不连接圆心  </span></span><br><span class="line">      paint,  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="built_in">bool</span> shouldRepaint(<span class="keyword">covariant</span> _RingPainter oldDelegate) &#123;  </span><br><span class="line">    <span class="comment">// 只有当进度、颜色或线宽变化时，才需要重绘  </span></span><br><span class="line">    <span class="keyword">return</span> oldDelegate.progress != progress ||  </span><br><span class="line">        oldDelegate.color != color ||  </span><br><span class="line">        oldDelegate.strokeWidth != strokeWidth;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当 progress 更新时，只有进度条需要重绘；如果保持不变，就不会触发多余的 paint，保证帧率稳定。</p>
<h4 id="3-5-2-使用示例"><a href="#3-5-2-使用示例" class="headerlink" title="3.5.2 使用示例"></a>3.5.2 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      title: <span class="string">&#x27;CustomPainter Demo&#x27;</span>,  </span><br><span class="line">      theme: ThemeData(primarySwatch: Colors.blue),  </span><br><span class="line">      home: <span class="keyword">const</span> Scaffold(body: Center(child: RingProgress(progress: <span class="number">0.4</span>),),),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250928161914.png" alt="圆环进度条" width="50%">

<h2 id="4-自定义-RenderBox"><a href="#4-自定义-RenderBox" class="headerlink" title="4. 自定义 RenderBox"></a>4. 自定义 RenderBox</h2><p>在上一节里，我们用 <strong>CustomPainter</strong> 画了一个圆环进度条。但 CustomPainter 仍然依赖于现成的 <strong>RenderBox</strong>，它只接管了绘制逻辑。要想彻底理解 Flutter 渲染体系，我们必须自己动手写一个 <strong>RenderBox</strong> ——从布局到绘制都掌控在手。</p>
<p>这一节，我们会通过两个案例，完整体验 RenderBox 的工作流程：</p>
<ol>
<li><strong>圆形进度条 RenderBox</strong>：无子组件，练习 constraints → size → paint 的基本流程。</li>
<li><strong>自定义两列网格 RenderBox</strong>：有子组件，演示如何调用 layoutChild。</li>
</ol>
<p>同时，我们还会穿插讲解一些常见坑（如约束报错、无限大小）和性能注意点。</p>
<h3 id="4-1-RenderBox-的定位"><a href="#4-1-RenderBox-的定位" class="headerlink" title="4.1 RenderBox 的定位"></a>4.1 RenderBox 的定位</h3><p>Flutter 的渲染管线是分层的：</p>
<ul>
<li><strong>Widget</strong>：配置数据，声明 UI。</li>
<li><strong>Element</strong>：Widget 的实例，负责管理生命周期。</li>
<li><strong>RenderObject</strong>：真正执行 <strong>布局和绘制</strong> 的对象。</li>
</ul>
<p>而 RenderBox 是 RenderObject 的一个子类，采用 <strong>盒模型（Box Constraints）</strong> 协议，最常见的 UI 元素（Container、Text、Image 等）都基于它。</p>
<h4 id="4-1-1-constraints-和-size-的关系"><a href="#4-1-1-constraints-和-size-的关系" class="headerlink" title="4.1.1 constraints 和 size 的关系"></a>4.1.1 constraints 和 size 的关系</h4><p>在 RenderBox 里，<strong>constraints（约束）决定了可用空间</strong>，而我们必须在 performLayout 里通过 size &#x3D; … 来给自己定一个最终尺寸。<br>BoxConstraints 提供了 <strong>最小&#x2F;最大宽高</strong>：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">constraints.minWidth, constraints.maxWidth</span><br><span class="line">constraints.minHeight, constraints.maxHeight</span><br></pre></td></tr></table></figure>
<p>规则：    </p>
<ol>
<li>不能超出 maxWidth &#x2F; maxHeight        </li>
<li>不能小于 minWidth &#x2F; minHeight        </li>
<li>如果你随便赋值一个 size 不满足 constraints，就会报错</li>
</ol>
<h4 id="4-1-2-如何调用layoutChild"><a href="#4-1-2-如何调用layoutChild" class="headerlink" title="4.1.2 如何调用layoutChild"></a>4.1.2 如何调用layoutChild</h4><p>子组件必须通过 <code>child.layout(constraints, parentUsesSize: true)</code> 来进行布局，constraints就是要给它分配的空间，parentUsesSize: true：表示父组件会依赖子组件的大小（否则访问 child.size 会报错）</p>
<p><strong>注意</strong>：layoutChild 本质就是上面这行，只不过在 MultiChildRenderObjectWidget 的封装里会帮我们循环调用。</p>
<h4 id="4-1-3-paint-阶段如何正确绘制"><a href="#4-1-3-paint-阶段如何正确绘制" class="headerlink" title="4.1.3 paint 阶段如何正确绘制"></a>4.1.3 paint 阶段如何正确绘制</h4><p>在 paint 方法里，你可以用 Canvas 来画东西，或者把子组件画出来。</p>
<ul>
<li>绘制自身：</li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line"><span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">  <span class="keyword">final</span> canvas = context.canvas;</span><br><span class="line">  <span class="keyword">final</span> Paint paint = Paint()..color = Colors.blue;</span><br><span class="line">  canvas.drawCircle(offset + size.center(Offset.zero), size.shortestSide / <span class="number">2</span>, paint);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>绘制子组件：</li>
</ul>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">context.paintChild(child, childParentData.offset + offset);</span><br></pre></td></tr></table></figure>
<p>这里 childParentData.offset 是在 performLayout 时保存的位置</p>
<p>我们写自定义 RenderBox，就是直接操作约束、大小和绘制逻辑，拥有很高的自由度。</p>
<h3 id="4-2-圆形进度条-RenderBox"><a href="#4-2-圆形进度条-RenderBox" class="headerlink" title="4.2 圆形进度条 RenderBox"></a>4.2 圆形进度条 RenderBox</h3><p>我们先从最简单的“无子节点” RenderBox 开始：一个圆环进度条。</p>
<h4 id="4-2-1-核心流程"><a href="#4-2-1-核心流程" class="headerlink" title="4.2.1 核心流程"></a>4.2.1 核心流程</h4><ol>
<li><strong>布局（performLayout）</strong><br> RenderBox 必须设置自己的 size，否则会报错。constraints 提供父组件给的最大&#x2F;最小宽高。 我们需要根据 constraints 决定最终大小。</li>
<li><strong>绘制（paint）</strong><br> 获取 Canvas，调用绘制 API。使用进度值决定圆弧角度。</li>
</ol>
<h4 id="4-2-2-代码实现"><a href="#4-2-2-代码实现" class="headerlink" title="4.2.2 代码实现"></a>4.2.2 代码实现</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;dart:math&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/rendering.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/widgets.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">圆形进度条 RenderObjectWidget</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingProgressBox</span> <span class="keyword">extends</span> <span class="title">LeafRenderObjectWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> progress; <span class="comment">// 0~1</span></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> strokeWidth;</span><br><span class="line">  <span class="keyword">final</span> Color color;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> RingProgressBox(&#123;</span><br><span class="line">    <span class="keyword">super</span>.key,</span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.progress,</span><br><span class="line">    <span class="keyword">this</span>.strokeWidth = <span class="number">10</span>,</span><br><span class="line">    <span class="keyword">this</span>.color = <span class="keyword">const</span> Color(<span class="number">0xFF2196F3</span>),</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RenderObject createRenderObject(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> _RenderRingProgress(progress, strokeWidth, color);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> updateRenderObject(</span><br><span class="line">      BuildContext context, <span class="keyword">covariant</span> _RenderRingProgress renderObject) &#123;</span><br><span class="line">    renderObject</span><br><span class="line">      ..progress = progress</span><br><span class="line">      ..strokeWidth = strokeWidth</span><br><span class="line">      ..color = color;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">真正的 RenderBox</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_RenderRingProgress</span> <span class="keyword">extends</span> <span class="title">RenderBox</span> </span>&#123;</span><br><span class="line">  <span class="built_in">double</span> _progress;</span><br><span class="line">  <span class="built_in">double</span> _strokeWidth;</span><br><span class="line">  Color _color;</span><br><span class="line"></span><br><span class="line">  _RenderRingProgress(<span class="keyword">this</span>._progress, <span class="keyword">this</span>._strokeWidth, <span class="keyword">this</span>._color);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">set</span> progress(<span class="built_in">double</span> value) &#123;</span><br><span class="line">    <span class="keyword">if</span> (_progress != value) &#123;</span><br><span class="line">      _progress = value;</span><br><span class="line">      markNeedsPaint(); <span class="comment">// 通知重绘</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">set</span> strokeWidth(<span class="built_in">double</span> value) &#123;</span><br><span class="line">    <span class="keyword">if</span> (_strokeWidth != value) &#123;</span><br><span class="line">      _strokeWidth = value;</span><br><span class="line">      markNeedsLayout(); <span class="comment">// 大小可能变化</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">set</span> color(Color value) &#123;</span><br><span class="line">    <span class="keyword">if</span> (_color != value) &#123;</span><br><span class="line">      _color = value;</span><br><span class="line">      markNeedsPaint();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;</span><br><span class="line">    <span class="comment">// 确定自己的大小</span></span><br><span class="line">    <span class="keyword">final</span> sizeValue = constraints.hasBoundedWidth &amp;&amp; constraints.hasBoundedHeight</span><br><span class="line">        ? Size(constraints.maxWidth, constraints.maxHeight)</span><br><span class="line">        : <span class="keyword">const</span> Size(<span class="number">100</span>, <span class="number">100</span>); <span class="comment">// 如果父约束无限，就默认 100×100</span></span><br><span class="line"></span><br><span class="line">    size = sizeValue;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    <span class="keyword">final</span> canvas = context.canvas;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> center = offset + Offset(size.width / <span class="number">2</span>, size.height / <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">final</span> radius = size.shortestSide / <span class="number">2</span> - _strokeWidth / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> backgroundPaint = Paint()</span><br><span class="line">      ..color = _color.withValues(alpha: <span class="number">0.2</span>)</span><br><span class="line">      ..style = PaintingStyle.stroke</span><br><span class="line">      ..strokeWidth = _strokeWidth;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> progressPaint = Paint()</span><br><span class="line">      ..color = _color</span><br><span class="line">      ..style = PaintingStyle.stroke</span><br><span class="line">      ..strokeCap = StrokeCap.round</span><br><span class="line">      ..strokeWidth = _strokeWidth;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 背景圆环</span></span><br><span class="line">    canvas.drawCircle(center, radius, backgroundPaint);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进度圆弧</span></span><br><span class="line">    <span class="keyword">final</span> sweepAngle = <span class="number">2</span> * pi * _progress;</span><br><span class="line">    canvas.drawArc(</span><br><span class="line">      Rect.fromCircle(center: center, radius: radius),</span><br><span class="line">      -pi / <span class="number">2</span>,</span><br><span class="line">      sweepAngle,</span><br><span class="line">      <span class="keyword">false</span>,</span><br><span class="line">      progressPaint,</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样我们就完全绕过了 CustomPainter，直接从 RenderBox 层实现了进度条。</p>
<h4 id="4-2-3-使用示例"><a href="#4-2-3-使用示例" class="headerlink" title="4.2.3 使用示例"></a>4.2.3 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Center(</span><br><span class="line">  child: RingProgressBox(progress: <span class="number">0.6</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="4-3-自定义两列网格-RenderBox"><a href="#4-3-自定义两列网格-RenderBox" class="headerlink" title="4.3 自定义两列网格 RenderBox"></a>4.3 自定义两列网格 RenderBox</h3><p>我们再来一个更复杂的例子：实现一个 <strong>两列网格布局</strong>，内部可以放子组件。</p>
<h4 id="4-3-1-关键点"><a href="#4-3-1-关键点" class="headerlink" title="4.3.1 关键点"></a>4.3.1 关键点</h4><ul>
<li>RenderBox 支持子组件时，需要继承 RenderBox + ContainerRenderObjectMixin。</li>
<li>调用 layoutChild(child, constraints) 来让子组件自己布局。</li>
<li>再根据子组件的大小，决定整个父 RenderBox 的大小。</li>
</ul>
<h4 id="4-3-2-代码实现"><a href="#4-3-2-代码实现" class="headerlink" title="4.3.2 代码实现"></a>4.3.2 代码实现</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/rendering.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;dart:math&#x27;</span> <span class="keyword">as</span> math;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown"><span class="bullet">1.</span> Widget 层：对外暴露的组件  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoColumnGrid</span> <span class="keyword">extends</span> <span class="title">MultiChildRenderObjectWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> TwoColumnGrid(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">super</span>.children&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  RenderObject createRenderObject(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> RenderTwoColumnGrid();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown"><span class="bullet">2.</span> 自定义 ParentData</span></span></span><br><span class="line"><span class="comment">/// <span class="language-markdown">每个子组件都会持有一份 ParentData，用于保存偏移量等信息  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoColumnParentData</span> <span class="keyword">extends</span> <span class="title">ContainerBoxParentData</span>&lt;<span class="title">RenderBox</span>&gt; </span>&#123;&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown"><span class="bullet">3.</span> RenderObject 层：真正的布局和绘制逻辑  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderTwoColumnGrid</span> <span class="keyword">extends</span> <span class="title">RenderBox</span> <span class="title">with</span>  </span></span><br><span class="line"><span class="class">        <span class="title">ContainerRenderObjectMixin</span>&lt;<span class="title">RenderBox</span>, <span class="title">TwoColumnParentData</span>&gt;,  </span></span><br><span class="line"><span class="class">        <span class="title">RenderBoxContainerDefaultsMixin</span>&lt;<span class="title">RenderBox</span>, <span class="title">TwoColumnParentData</span>&gt; </span>&#123;  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> setupParentData(RenderBox child) &#123;  </span><br><span class="line">    <span class="keyword">if</span> (child.parentData <span class="keyword">is</span>! TwoColumnParentData) &#123;  </span><br><span class="line">      child.parentData = TwoColumnParentData();  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;  </span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> maxWidth = constraints.hasBoundedWidth  </span><br><span class="line">        ? constraints.maxWidth : <span class="number">300</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> childMaxWidth = maxWidth / <span class="number">2</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">double</span> dx = <span class="number">0</span>; <span class="comment">// 当前子组件的横坐标  </span></span><br><span class="line">    <span class="built_in">double</span> dy = <span class="number">0</span>; <span class="comment">// 当前子组件的纵坐标  </span></span><br><span class="line">    <span class="built_in">double</span> rowHeight = <span class="number">0</span>; <span class="comment">// 当前行的最大高度  </span></span><br><span class="line">  </span><br><span class="line">    RenderBox? child = firstChild;  </span><br><span class="line">    <span class="built_in">int</span> column = <span class="number">0</span>; <span class="comment">// 当前列（0=左，1=右）  </span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">while</span> (child != <span class="keyword">null</span>) &#123;  </span><br><span class="line">      <span class="keyword">final</span> childParentData = child.parentData <span class="keyword">as</span> TwoColumnParentData;  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 给子组件传递约束  </span></span><br><span class="line">      child.layout(  </span><br><span class="line">        BoxConstraints(maxWidth: childMaxWidth),  </span><br><span class="line">        parentUsesSize: <span class="keyword">true</span>,  </span><br><span class="line">      );  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 设置子组件的位置  </span></span><br><span class="line">      childParentData.offset = Offset(dx, dy);  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 更新当前行的最大高度  </span></span><br><span class="line">      rowHeight = math.max(rowHeight, child.size.height);  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 切换到下一列 / 换行  </span></span><br><span class="line">      <span class="keyword">if</span> (column == <span class="number">0</span>) &#123;  </span><br><span class="line">        dx = childMaxWidth; <span class="comment">// 下一列  </span></span><br><span class="line">        column = <span class="number">1</span>;  </span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">        dx = <span class="number">0</span>;  </span><br><span class="line">        dy += rowHeight; <span class="comment">// 换行  </span></span><br><span class="line">        rowHeight = <span class="number">0</span>;  </span><br><span class="line">        column = <span class="number">0</span>;  </span><br><span class="line">      &#125;  </span><br><span class="line">  </span><br><span class="line">      child = childParentData.nextSibling;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 设置自身的 size    </span></span><br><span class="line">    size = constraints.constrain(Size(maxWidth, dy + rowHeight));  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;  </span><br><span class="line">    defaultPaint(context, offset);  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个例子展示了如何 <strong>遍历子组件 → 调用 layout → 决定偏移量 → 设定 size</strong>。</p>
<h4 id="4-3-3-使用示例"><a href="#4-3-3-使用示例" class="headerlink" title="4.3.3 使用示例"></a>4.3.3 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      home: Scaffold(  </span><br><span class="line">        body: Center(  </span><br><span class="line">          child: SizedBox(  </span><br><span class="line">            width: <span class="number">300</span>,  </span><br><span class="line">            child: TwoColumnGrid(  </span><br><span class="line">              children: <span class="built_in">List</span>.generate(  </span><br><span class="line">                <span class="number">5</span>,  </span><br><span class="line">                (i) =&gt; Container(  </span><br><span class="line">                  height: <span class="number">50.0</span> + (i * <span class="number">10</span>),  </span><br><span class="line">                  color: Colors.primaries[i % Colors.primaries.length],  </span><br><span class="line">                  alignment: Alignment.center,  </span><br><span class="line">                  child: Text(<span class="string">&quot;Item <span class="subst">$i</span>&quot;</span>),  </span><br><span class="line">                ),  </span><br><span class="line">              ),  </span><br><span class="line">            ),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250928171554.png" alt="自定义两列网格" width="50%">

<h3 id="4-4-常见坑"><a href="#4-4-常见坑" class="headerlink" title="4.4 常见坑"></a>4.4 常见坑</h3><ol>
<li><strong>忘记设置 size</strong><br> 如果 performLayout 里没有给 size 赋值，Flutter 会报错。所以需要始终保证 size &#x3D; …。</li>
<li><strong>遇到无限约束报错</strong><br> 例如放在 ListView 里时，可能 constraints 为 unbounded。一般需要给定一个默认大小（如 100×100）。</li>
<li><strong>重绘过多</strong><br> 不要在 paint 里做状态修改。属性变化时用 markNeedsPaint 或 markNeedsLayout，否则会造成死循环或性能问题</li>
</ol>
<h2 id="5-可交互的-RenderBox"><a href="#5-可交互的-RenderBox" class="headerlink" title="5. 可交互的 RenderBox"></a>5. 可交互的 RenderBox</h2><p>在前面，我们主要写的是 <strong>静态的 RenderBox</strong> ——它们能测量大小、布局子组件、在画布上绘制图形。但在实际业务里，很多控件需要 <strong>交互</strong>，比如点击、拖拽、滑动。要让 RenderBox 响应用户操作，就要深入理解 <strong>事件分发机制</strong> 和 <strong>hitTest 流程</strong>。</p>
<h3 id="5-1-事件分发模型回顾"><a href="#5-1-事件分发模型回顾" class="headerlink" title="5.1 事件分发模型回顾"></a>5.1 事件分发模型回顾</h3><p>Flutter 的事件分发路径大致分为三步：</p>
<ol>
<li><strong>PointerEvent 从引擎传入</strong> → 交给 RenderView 根节点。</li>
<li><strong>hitTest 阶段</strong>：从树顶往下遍历，判断哪些 RenderObject 被命中。每个 RenderBox 会根据自己是否包含触点决定是否加入 HitTestResult。顺序是“父先检查，再传给子”。</li>
<li><strong>事件派发阶段</strong>：事件会倒序传递给命中的对象（子优先），调用它们的 handleEvent 方法。</li>
</ol>
<p>一句话概括：<strong>hitTest 决定能不能点到，handleEvent 决定点到后做什么。</strong></p>
<h3 id="5-2-hitTest的实现"><a href="#5-2-hitTest的实现" class="headerlink" title="5.2 hitTest的实现"></a>5.2 hitTest的实现</h3><p>在 RenderBox 里，通常我们会重写 hitTestSelf 或 hitTestChildren。</p>
<ul>
<li><code>hitTestSelf(Offset position)</code>：决定当前控件是否接收事件（true 表示命中自己）。</li>
<li><code>hitTestChildren(HitTestResult result, Offset position)</code>：决定是否把事件继续传递给子组件。</li>
</ul>
<p><strong>例子：圆形区域命中检测</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line"><span class="built_in">bool</span> hitTestSelf(Offset position) &#123;</span><br><span class="line">  <span class="comment">// 只允许点击圆形区域</span></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> radius = size.shortestSide / <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">return</span> (position - size.center(Offset.zero)).distance &lt;= radius;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样，用户点击在圆圈外部时，事件就不会触发。</p>
<h3 id="5-3-事件处理：handleEvent"><a href="#5-3-事件处理：handleEvent" class="headerlink" title="5.3 事件处理：handleEvent"></a>5.3 事件处理：handleEvent</h3><p>当命中成功后，事件会传给 handleEvent。<br>这里我们可以判断事件类型（按下、移动、抬起），并执行相应逻辑：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line"><span class="keyword">void</span> handleEvent(PointerEvent event, HitTestEntry entry) &#123;</span><br><span class="line">  <span class="keyword">if</span> (event <span class="keyword">is</span> PointerDownEvent) &#123;</span><br><span class="line">    <span class="comment">// 记录按下位置</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (event <span class="keyword">is</span> PointerMoveEvent) &#123;</span><br><span class="line">    <span class="comment">// 根据拖动更新状态</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (event <span class="keyword">is</span> PointerUpEvent) &#123;</span><br><span class="line">    <span class="comment">// 松开时重置或触发回调</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-4-自定义-Slider"><a href="#5-4-自定义-Slider" class="headerlink" title="5.4 自定义 Slider"></a>5.4 自定义 Slider</h3><p>下面我们来实现一个Slider，包含一条线和一个可拖动的小圆点。</p>
<h4 id="5-4-1-代码实现"><a href="#5-4-1-代码实现" class="headerlink" title="5.4.1 代码实现"></a>5.4.1 代码实现</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">Widget 层包装 RenderBox</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomSlider</span> <span class="keyword">extends</span> <span class="title">LeafRenderObjectWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> CustomSlider(&#123;</span><br><span class="line">    <span class="keyword">super</span>.key,</span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.value,</span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.onChanged,</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> value;</span><br><span class="line">  <span class="keyword">final</span> ValueChanged&lt;<span class="built_in">double</span>&gt; onChanged;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  RenderObject createRenderObject(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> RenderCustomSlider()</span><br><span class="line">      ..value = value</span><br><span class="line">      ..onChanged = onChanged;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> updateRenderObject(</span><br><span class="line">      BuildContext context, <span class="keyword">covariant</span> RenderCustomSlider renderObject) &#123;</span><br><span class="line">    renderObject</span><br><span class="line">      ..value = value</span><br><span class="line">      ..onChanged = onChanged;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">RenderBox 层实现 Slider</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderCustomSlider</span> <span class="keyword">extends</span> <span class="title">RenderBox</span> </span>&#123;</span><br><span class="line">  <span class="built_in">double</span> _value = <span class="number">0.0</span>;</span><br><span class="line">  ValueChanged&lt;<span class="built_in">double</span>&gt;? _onChanged;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">double</span> <span class="keyword">get</span> value =&gt; _value;</span><br><span class="line">  <span class="keyword">set</span> value(<span class="built_in">double</span> v) &#123;</span><br><span class="line">    v = v.clamp(<span class="number">0.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    <span class="keyword">if</span> (_value == v) <span class="keyword">return</span>;</span><br><span class="line">    _value = v;</span><br><span class="line">    markNeedsPaint();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ValueChanged&lt;<span class="built_in">double</span>&gt;? <span class="keyword">get</span> onChanged =&gt; _onChanged;</span><br><span class="line">  <span class="keyword">set</span> onChanged(ValueChanged&lt;<span class="built_in">double</span>&gt;? cb) &#123;</span><br><span class="line">    _onChanged = cb;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> _thumbRadius = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> _trackHeight = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> height = constraints.hasBoundedHeight</span><br><span class="line">        ? constraints.maxHeight</span><br><span class="line">        : _thumbRadius * <span class="number">2</span> + <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> width =</span><br><span class="line">        constraints.hasBoundedWidth ? constraints.maxWidth : <span class="number">200</span>;</span><br><span class="line">    size = Size(width, height);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    <span class="keyword">final</span> Canvas canvas = context.canvas;</span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> centerY = size.height / <span class="number">2</span>; <span class="comment">// 局部坐标，offset 会加上</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 轨道背景</span></span><br><span class="line">    <span class="keyword">final</span> Paint trackPaint = Paint()</span><br><span class="line">      ..color = Colors.grey.shade300</span><br><span class="line">      ..strokeWidth = _trackHeight</span><br><span class="line">      ..strokeCap = StrokeCap.round;</span><br><span class="line">    canvas.drawLine(</span><br><span class="line">      offset + Offset(_thumbRadius, centerY),</span><br><span class="line">      offset + Offset(size.width - _thumbRadius, centerY),</span><br><span class="line">      trackPaint,</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 已完成进度</span></span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> progressX =</span><br><span class="line">        _thumbRadius + _value * (size.width - <span class="number">2</span> * _thumbRadius);</span><br><span class="line">    <span class="keyword">final</span> Paint progressPaint = Paint()</span><br><span class="line">      ..color = Colors.blue</span><br><span class="line">      ..strokeWidth = _trackHeight</span><br><span class="line">      ..strokeCap = StrokeCap.round;</span><br><span class="line">    canvas.drawLine(</span><br><span class="line">      offset + Offset(_thumbRadius, centerY),</span><br><span class="line">      offset + Offset(progressX, centerY),</span><br><span class="line">      progressPaint,</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 滑块</span></span><br><span class="line">    <span class="keyword">final</span> Paint thumbPaint = Paint()..color = Colors.blue;</span><br><span class="line">    canvas.drawCircle(offset + Offset(progressX, centerY), _thumbRadius, thumbPaint);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> hitTestSelf(Offset position) =&gt; <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> handleEvent(PointerEvent event, HitTestEntry entry) &#123;</span><br><span class="line">    <span class="keyword">if</span> (event <span class="keyword">is</span> PointerDownEvent || event <span class="keyword">is</span> PointerMoveEvent) &#123;</span><br><span class="line">      <span class="keyword">final</span> <span class="built_in">double</span> x =</span><br><span class="line">          (event.localPosition.dx - _thumbRadius).clamp(<span class="number">0.0</span>, size.width - <span class="number">2</span> * _thumbRadius);</span><br><span class="line">      value = x / (size.width - <span class="number">2</span> * _thumbRadius);</span><br><span class="line">      _onChanged?.call(value);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="5-4-2-使用示例"><a href="#5-4-2-使用示例" class="headerlink" title="5.4.2 使用示例"></a>5.4.2 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePage</span> <span class="keyword">extends</span> <span class="title">StatefulWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> HomePage(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  State&lt;HomePage&gt; createState() =&gt; _HomePageState();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_HomePageState</span> <span class="keyword">extends</span> <span class="title">State</span>&lt;<span class="title">HomePage</span>&gt; </span>&#123;</span><br><span class="line">  <span class="built_in">double</span> sliderValue = <span class="number">0.5</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&quot;Custom Slider Demo&quot;</span>)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: SizedBox(</span><br><span class="line">          width: <span class="number">300</span>,</span><br><span class="line">          height: <span class="number">60</span>,</span><br><span class="line">          child: CustomSlider(</span><br><span class="line">            value: sliderValue,</span><br><span class="line">            onChanged: (v) =&gt; setState(() =&gt; sliderValue = v),</span><br><span class="line">          ),</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250928193515.png" alt="自定义slider" width="50%">

<h3 id="5-5-拖拽小球"><a href="#5-5-拖拽小球" class="headerlink" title="5.5 拖拽小球"></a>5.5 拖拽小球</h3><p>再看一个更直观的例子：一个可拖动的小球。</p>
<h4 id="5-5-1-代码实现"><a href="#5-5-1-代码实现" class="headerlink" title="5.5.1 代码实现"></a>5.5.1 代码实现</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// <span class="language-markdown">LeafRenderObjectWidget 包装 RenderBox</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DraggableBallWidget</span> <span class="keyword">extends</span> <span class="title">LeafRenderObjectWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> DraggableBallWidget(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  RenderObject createRenderObject(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> RenderDraggableBall();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/// <span class="language-markdown">RenderBox 自定义控件  </span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderDraggableBall</span> <span class="keyword">extends</span> <span class="title">RenderBox</span> </span>&#123;  </span><br><span class="line">  Offset _center = <span class="keyword">const</span> Offset(<span class="number">50</span>, <span class="number">50</span>); <span class="comment">// 初始小球位置  </span></span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> _radius = <span class="number">20</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> performLayout() &#123;  </span><br><span class="line">    <span class="comment">// 设置 RenderBox 的大小  </span></span><br><span class="line">    size = constraints.constrain(<span class="keyword">const</span> Size(<span class="number">200</span>, <span class="number">200</span>));  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;  </span><br><span class="line">    <span class="keyword">final</span> Canvas canvas = context.canvas;  </span><br><span class="line">    <span class="keyword">final</span> Paint paint = Paint()..color = Colors.red;  </span><br><span class="line">    canvas.drawCircle(offset + _center, _radius, paint);  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="built_in">bool</span> hitTestSelf(Offset position) &#123;  </span><br><span class="line">    <span class="comment">// 仅当点击在小球内才响应事件  </span></span><br><span class="line">    <span class="keyword">return</span> (position - _center).distance &lt;= _radius;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="keyword">void</span> handleEvent(PointerEvent event, HitTestEntry entry) &#123;  </span><br><span class="line">    <span class="comment">// 只处理拖动事件  </span></span><br><span class="line">    <span class="keyword">if</span> (event <span class="keyword">is</span> PointerMoveEvent) &#123;  </span><br><span class="line">      _center = event.localPosition; <span class="comment">// 更新小球位置  </span></span><br><span class="line">      markNeedsPaint(); <span class="comment">// 触发重绘  </span></span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-5-2-使用示例"><a href="#5-5-2-使用示例" class="headerlink" title="5.5.2 使用示例"></a>5.5.2 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      title: <span class="string">&#x27;Draggable Ball Demo&#x27;</span>,  </span><br><span class="line">      home: Scaffold(  </span><br><span class="line">        appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;Draggable Ball Demo&#x27;</span>)),  </span><br><span class="line">        body: <span class="keyword">const</span> Center(  </span><br><span class="line">          child: SizedBox(  </span><br><span class="line">            width: <span class="number">200</span>,  </span><br><span class="line">            height: <span class="number">200</span>,  </span><br><span class="line">            child: DraggableBallWidget(),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行后，你可以直接拖动小球到区域内的任意位置。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250928194317.png" alt="Draggable Ball" width="50%"></p>
<h3 id="5-6-常见坑"><a href="#5-6-常见坑" class="headerlink" title="5.6 常见坑"></a>5.6 常见坑</h3><ol>
<li><strong>命中区域没写对</strong>：如果 hitTestSelf 一直返回 false，控件永远点不到。</li>
<li><strong>忘记 markNeedsPaint</strong>：事件更新了状态但没调用 markNeedsPaint()，UI 不会刷新。</li>
<li><strong>无限大小报错</strong>：交互组件也要有明确的 size，否则 hitTest 时坐标无法判断。</li>
</ol>
<h2 id="6-Sliver-协议与高性能滚动"><a href="#6-Sliver-协议与高性能滚动" class="headerlink" title="6. Sliver 协议与高性能滚动"></a>6. Sliver 协议与高性能滚动</h2><p>在 Flutter 中，滚动视图（ScrollView）不仅仅是简单地把 Widget 堆在一起，它内部有一个高性能的 <strong>Sliver 协议</strong> 来控制布局与渲染。Sliver 是 RenderObject 层的一类特殊布局协议，它关注的是 <strong>可见区域、滚动偏移和子元素管理</strong>。通过 Sliver，Flutter 能够只布局和绘制当前屏幕可见的部分，从而实现大列表的高性能滚动。</p>
<h3 id="6-1-Sliver-的约束系统"><a href="#6-1-Sliver-的约束系统" class="headerlink" title="6.1 Sliver 的约束系统"></a>6.1 Sliver 的约束系统</h3><p>Sliver 的核心是 <strong>SliverConstraints</strong> 和 <strong>SliverGeometry</strong>：</p>
<ul>
<li><p><strong>SliverConstraints</strong>：父（viewport）传给 Sliver 的约束信息，包括：</p>
<ul>
<li>scrollOffset：当前滚动偏移量</li>
<li>overlap：Sliver 与前一个 Sliver 的重叠</li>
<li>viewportMainAxisExtent：viewport 在主轴方向的长度</li>
<li>crossAxisExtent：cross 轴的尺寸</li>
<li>growthDirection：滚动方向（向前&#x2F;向后）</li>
</ul>
<p>  换句话说，它告诉 Sliver：“你的显示窗口范围是这里，你应该从什么偏移开始布局”。    </p>
</li>
<li><p><strong>SliverGeometry</strong>：Sliver 返回给父的信息，告诉 viewport：</p>
<ul>
<li>scrollExtent：当前 Sliver 占据的滚动空间</li>
<li>paintExtent：可见区域的长度</li>
<li>maxPaintExtent：内容的最大长度</li>
<li>hasVisualOverflow：内容是否超出 viewport</li>
<li>hitTestExtent：用于事件命中检测</li>
</ul>
<p>  打个比方：SliverConstraints 是父给你的“作业单”，SliverGeometry 是你交回的“作业完成情况”。通过这个机制，viewport 可以精确管理滚动、重绘和子组件可见性。</p>
</li>
</ul>
<h3 id="6-2-Viewport-与-child-管理"><a href="#6-2-Viewport-与-child-管理" class="headerlink" title="6.2 Viewport 与 child 管理"></a>6.2 Viewport 与 child 管理</h3><p>Viewport 是 Sliver 的父级容器，负责 <strong>滚动偏移和子组件管理</strong>：</p>
<ol>
<li>Viewport 根据滚动偏移（scrollOffset）确定 <strong>可见范围</strong>。</li>
<li>对每个子 Sliver 调用 layout 方法，传入 SliverConstraints。</li>
<li>子 Sliver 返回 SliverGeometry，告诉 viewport：<ul>
<li>我占用了多少滚动空间</li>
<li>可见区域在哪</li>
</ul>
</li>
<li>Viewport 根据 geometry 信息决定：<ul>
<li>哪些子 Sliver 可见 → 调用 paint</li>
<li>哪些子 Sliver 不可见 → 可能回收或缓存（keepAlive）</li>
</ul>
</li>
</ol>
<p>在大列表中，只有可见区域的子 Sliver 被 layout 和 paint，这就是 <strong>懒加载</strong>，也是高性能滚动的核心。</p>
<h3 id="6-3-KeepAlive-的意义"><a href="#6-3-KeepAlive-的意义" class="headerlink" title="6.3 KeepAlive 的意义"></a>6.3 KeepAlive 的意义</h3><p>在滚动中，如果一个 Sliver 内的子元素被移出可见区域，它可能会被销毁以节省内存。<strong>keepAlive</strong> 的作用是：</p>
<ul>
<li>保持移出屏幕的子元素状态（比如滑动位置、输入内容）。</li>
<li>避免重复布局和状态丢失，提高用户体验。</li>
</ul>
<p>在自定义 SliverList 或 SliverGrid 时，可以通过 RenderSliverMultiBoxAdaptor 提供的 keepAlive 机制管理子节点状态。</p>
<h3 id="6-4-自定义-SliverPersistentHeader（伸缩头部view）"><a href="#6-4-自定义-SliverPersistentHeader（伸缩头部view）" class="headerlink" title="6.4 自定义 SliverPersistentHeader（伸缩头部view）"></a>6.4 自定义 SliverPersistentHeader（伸缩头部view）</h3><h4 id="6-4-1-代码实现"><a href="#6-4-1-代码实现" class="headerlink" title="6.4.1 代码实现"></a>6.4.1 代码实现</h4><p>伸缩头部是 Sliver 中的经典用法，常见于 Collapsing Toolbar：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="comment">/// <span class="language-markdown">自定义 Header Delegate</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyHeaderDelegate</span> <span class="keyword">extends</span> <span class="title">SliverPersistentHeaderDelegate</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> maxHeight;  </span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">double</span> minHeight;  </span><br><span class="line">  </span><br><span class="line">  MyHeaderDelegate(&#123;<span class="keyword">this</span>.maxHeight = <span class="number">200</span>, <span class="keyword">this</span>.minHeight = <span class="number">80</span>&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="built_in">double</span> <span class="keyword">get</span> minExtent =&gt; minHeight;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="built_in">double</span> <span class="keyword">get</span> maxExtent =&gt; maxHeight;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context, <span class="built_in">double</span> shrinkOffset, <span class="built_in">bool</span> overlapsContent) &#123;  </span><br><span class="line">    <span class="comment">// 计算收缩进度 0~1    </span></span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> progress = (shrinkOffset / (maxExtent - minExtent)).clamp(<span class="number">0.0</span>, <span class="number">1.0</span>); </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 背景颜色渐变：深蓝 -&gt; 浅蓝  </span></span><br><span class="line">    <span class="keyword">final</span> Color backgroundColor = Color.lerp(Colors.blue, Colors.lightBlue, progress)!;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 文字大小渐变：24 -&gt; 16  </span></span><br><span class="line">    <span class="keyword">final</span> <span class="built_in">double</span> fontSize = <span class="number">24</span> * (<span class="number">1</span> - progress) + <span class="number">16</span> * progress;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Container(  </span><br><span class="line">      color: backgroundColor,  </span><br><span class="line">      alignment: Alignment.center,  </span><br><span class="line">      child: Text(  </span><br><span class="line">        <span class="string">&quot;Header&quot;</span>,  </span><br><span class="line">        style: TextStyle(  </span><br><span class="line">          color: Colors.white,  </span><br><span class="line">          fontSize: fontSize,  </span><br><span class="line">          fontWeight: FontWeight.bold,  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  <span class="built_in">bool</span> shouldRebuild(<span class="keyword">covariant</span> MyHeaderDelegate oldDelegate) &#123;  </span><br><span class="line">    <span class="keyword">return</span> maxHeight != oldDelegate.maxHeight || minHeight != oldDelegate.minHeight;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当滚动时，shrinkOffset 会增加，头部逐渐收缩。SliverPersistentHeader 会返回合适的 SliverGeometry，viewport 根据 geometry 控制可见范围和绘制。</p>
<h4 id="6-4-2-使用示例"><a href="#6-4-2-使用示例" class="headerlink" title="6.4.2 使用示例"></a>6.4.2 使用示例</h4><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> HomePage(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      body: CustomScrollView(  </span><br><span class="line">        slivers: [  </span><br><span class="line">          <span class="comment">// 伸缩头部  </span></span><br><span class="line">          SliverPersistentHeader(  </span><br><span class="line">            pinned: <span class="keyword">true</span>, <span class="comment">// 固定在顶部  </span></span><br><span class="line">            delegate: MyHeaderDelegate(  </span><br><span class="line">              maxHeight: <span class="number">200</span>,  </span><br><span class="line">              minHeight: <span class="number">80</span>,  </span><br><span class="line">            ),  </span><br><span class="line">          ),  </span><br><span class="line">          <span class="comment">// 列表内容  </span></span><br><span class="line">          SliverList(  </span><br><span class="line">            delegate: SliverChildBuilderDelegate(  </span><br><span class="line">                  (context, index) =&gt; ListTile(  </span><br><span class="line">                title: Text(<span class="string">&quot;Item <span class="subst">$index</span>&quot;</span>),  </span><br><span class="line">              ),  </span><br><span class="line">              childCount: <span class="number">30</span>,  </span><br><span class="line">            ),  </span><br><span class="line">          ),  </span><br><span class="line">        ],  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><video src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/sliver_persistent_header.mp4" controls="controls" width="50%"></video></p>
<h3 id="6-5-自定义-SliverList（懒加载）"><a href="#6-5-自定义-SliverList（懒加载）" class="headerlink" title="6.5 自定义 SliverList（懒加载）"></a>6.5 自定义 SliverList（懒加载）</h3><p>在大列表中，完全构建 1,000 个 Widget 会很慢。自定义 SliverList 可以只构建可见的子 Widget：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> HomePage(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      body: MySliverList(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySliverList</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MySliverList(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> CustomScrollView(  </span><br><span class="line">      slivers: [  </span><br><span class="line">        SliverList(  </span><br><span class="line">          delegate: SliverChildBuilderDelegate(  </span><br><span class="line">                (context, index) =&gt; ListTile(title: Text(<span class="string">&quot;Item <span class="subst">$index</span>&quot;</span>)),  </span><br><span class="line">            childCount: <span class="number">1000</span>, <span class="comment">// 数量很大也不会卡  </span></span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">      ],  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>SliverChildBuilderDelegate 会按需构建子 Widget。不可见的子 Widget 会被缓存或销毁，配合 keepAlive 可保持状态。</p>
<p>理解 Sliver 协议，就可以实现各种滚动效果，如 <strong>折叠头部、横向列表、瀑布流</strong>，同时保证 <strong>高性能滚动和可扩展性</strong>。</p>
<h2 id="7-复合渲染与合成优化"><a href="#7-复合渲染与合成优化" class="headerlink" title="7. 复合渲染与合成优化"></a>7. 复合渲染与合成优化</h2><h3 id="7-1-为什么需要-Layer"><a href="#7-1-为什么需要-Layer" class="headerlink" title="7.1 为什么需要 Layer"></a>7.1 为什么需要 Layer</h3><p>在 Flutter 的渲染管线中，RenderObject 负责布局与绘制，而最终交给 GPU 的并不是单个个体的绘制指令，而是一棵 <strong>Layer 树</strong>（Layer Tree）。</p>
<p>可以这么理解<strong>RenderObject Tree</strong>描述“该画什么”，而<strong>Layer Tree</strong>描述“如何组合这些画面”。<br>Layer 就像是“舞台布景”或“滤镜叠层”，它决定了最终画面如何被合成。</p>
<p>Flutter 中每一帧都会把 <strong>Layer Tree</strong> 提交给 GPU 合成（compositing）。因此，合理使用 Layer 可以带来 <strong>灵活的特效</strong>，但滥用则会增加内存与 GPU 的负担。</p>
<h3 id="7-2-常见的-Layer-类型"><a href="#7-2-常见的-Layer-类型" class="headerlink" title="7.2 常见的 Layer 类型"></a>7.2 常见的 Layer 类型</h3><p>Flutter 提供了多种常见 Layer，用来支持各种渲染效果：</p>
<ol>
<li><strong>OpacityLayer</strong>：让子节点整体透明，而不是逐个子节点单独绘制透明度。这样可以避免重复绘制，提升性能。<br> 典型应用：Opacity Widget、FadeTransition。</li>
<li><strong>TransformLayer</strong>：对子树进行缩放、旋转、平移等操作。<br> 应用场景：页面切换动画、缩放列表项。</li>
<li><strong>ClipRectLayer &#x2F; ClipRRectLayer &#x2F; ClipPathLayer</strong>：限定绘制区域。但过度使用裁剪会增加 GPU 负担。<br> 应用场景：圆角裁剪、图片遮罩。    </li>
<li><strong>BackdropFilterLayer</strong>：实现毛玻璃（模糊）等效果，比较耗性能，谨慎使用。<br> 应用场景：半透明背景、弹窗毛玻璃。</li>
</ol>
<h3 id="7-3-合成边界的意义"><a href="#7-3-合成边界的意义" class="headerlink" title="7.3 合成边界的意义"></a>7.3 合成边界的意义</h3><p>默认情况下，多个 RenderObject 会被合并到一个 Layer 里绘制。但在某些情况下，我们希望“强制隔离”，给某一部分单独建一个 Layer，这就是 <strong>合成边界</strong>（Compositing Boundary）。</p>
<p>典型例子：</p>
<ul>
<li><code>RepaintBoundary</code>：强制子树绘制结果缓存到一个独立的 Layer，下次如果没有变化就直接复用。</li>
<li><code>CompositedTransformTarget / CompositedTransformFollower</code>：依赖独立 Layer 来实现精准的坐标跟随。</li>
</ul>
<p>合成边界的好处有：避免重复绘制（缓存复用），还可以支持局部坐标系变换。代价是增加内存（每个 Layer 都要缓存位图），GPU 合成负担变大。<br>所以，如果小组件会频繁变动，建议不要随便加 Layer。如果大片区域有着稳定的内容（如复杂背景），就比较适合单独成 Layer。</p>
<h3 id="7-4-OpacityLayer-与直接绘制"><a href="#7-4-OpacityLayer-与直接绘制" class="headerlink" title="7.4 OpacityLayer 与直接绘制"></a>7.4 OpacityLayer 与直接绘制</h3><p>假设有一个自定义 RenderBox，需要整体半透明：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RenderOpacityBox</span> <span class="keyword">extends</span> <span class="title">RenderProxyBox</span> </span>&#123;</span><br><span class="line">  <span class="built_in">double</span> opacity;</span><br><span class="line">  RenderOpacityBox(&#123;<span class="keyword">this</span>.opacity = <span class="number">1.0</span>, RenderBox? child&#125;) : <span class="keyword">super</span>(child);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> paint(PaintingContext context, Offset offset) &#123;</span><br><span class="line">    <span class="keyword">if</span> (opacity == <span class="number">1.0</span>) &#123;</span><br><span class="line">      <span class="keyword">super</span>.paint(context, offset); <span class="comment">// 正常绘制</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 创建一个新的 OpacityLayer</span></span><br><span class="line">      context.pushOpacity(offset, (opacity * <span class="number">255</span>).toInt(), <span class="keyword">super</span>.paint);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果直接在每个子节点 paint 时设置 color.withOpacity，会导致 <strong>每个子节点都被重新绘制</strong>。用 OpacityLayer 则是先绘制子树到缓存，再整体应用透明度，性能更高。</p>
<h3 id="7-5-BackdropFilter-的性能消耗"><a href="#7-5-BackdropFilter-的性能消耗" class="headerlink" title="7.5 BackdropFilter 的性能消耗"></a>7.5 BackdropFilter 的性能消耗</h3><p>用作毛玻璃效果的 BackdropFilter 看起来很炫酷，但其实代价很大。因为它需要：</p>
<ol>
<li>先把背景内容先缓存到一个纹理。</li>
<li>再对纹理做 GPU 模糊。</li>
<li>再与前景内容合成。</li>
</ol>
<p>这意味着每一帧都要额外做一遍缓存 + 模糊运算。</p>
<p>因此，只适合用在小区域（如导航栏模糊背景），如果用在全屏背景（如整页模糊）则很可能掉帧。<br>如果只是想要“半透明”效果，可以用 <code>Colors.white.withOpacity(0.5)</code>，避免使用 BackdropFilter。</p>
<p>首先不要盲目加 Layer，对于<strong>复杂但不常变化</strong>的区域可以加合成边界。对于<strong>频繁更新</strong>的小组件，让系统自动合成即可。对于使用 BackdropFilter 等高成本 Layer要谨慎。<br>理解 Layer 的取舍，本质就是在 <strong>性能（减少绘制）</strong> 和 <strong>内存&#x2F;GPU 开销</strong> 之间做平衡。</p>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>RenderObject是Flutter渲染体系的底层核心，负责真正的布局和绘制。当需要极致性能或特殊效果时，就需要绕过Widget直接操作RenderObject。</p>
<p>​<strong>三个关键方法：​</strong>​</p>
<ul>
<li><code>performLayout</code>：根据约束计算大小</li>
<li><code>paint</code>：在画布上绘制内容</li>
<li><code>hitTest</code>：处理交互事件</li>
</ul>
<p>​<strong>性能要点：​</strong>​</p>
<ul>
<li>正确使用<code>markNeedsLayout</code>&#x2F;<code>markNeedsPaint</code>可以避免过度重绘</li>
<li>复杂内容考虑用<code>PictureRecorder</code>缓存</li>
<li>滚动场景使用Sliver协议实现懒加载</li>
</ul>
<p>​<strong>选择建议：​</strong>​</p>
<ul>
<li>简单绘制 → CustomPainter</li>
<li>复杂布局&#x2F;交互 → 自定义RenderBox</li>
<li>长列表优化 → RenderSliver</li>
</ul>
<p>掌握RenderObject让你能突破Widget限制，实现高性能自定义UI。</p>
<h2 id="9-备注"><a href="#9-备注" class="headerlink" title="9. 备注"></a>9. 备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>fluttter: 3.35.4</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="https://docs.flutter.dev/">https://docs.flutter.dev/</a></li>
</ul>
]]></content>
      <categories>
        <category>跨平台框架</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
        <tag>底层原理</tag>
        <tag>布局</tag>
      </tags>
  </entry>
  <entry>
    <title>状态管理与项目架构：模块化、依赖注入与可维护性实践</title>
    <url>/2025/10/07/032-flutter-state-management-project-architecture/</url>
    <content><![CDATA[<h2 id="1-从“能跑”到“可扩展、可维护”"><a href="#1-从“能跑”到“可扩展、可维护”" class="headerlink" title="1. 从“能跑”到“可扩展、可维护”"></a>1. 从“能跑”到“可扩展、可维护”</h2><p>平时开发中，很多开发者虽然能把视图（Widgets）按页面或组件拆成不同的文件，但业务逻辑和状态处理往往直接写在 Widget 内部，依赖 setState 或零散的单例&#x2F;全局变量来管理。这种“分文件但逻辑内聚”的灵活方式虽然能在小项目里能快速迭代、方便验证想法，但不讲究长期维护，就像临时搭建的一间小屋。</p>
<span id="more"></span>
<p>尤其当项目规模扩大到几十甚至上百个页面，复杂度骤然提升：</p>
<ul>
<li><strong>状态杂乱</strong>：多个页面依赖同一份数据，却各自管理更新，导致 UI 不一致；</li>
<li><strong>耦合严重</strong>：业务逻辑直接写在 Widget 里，牵一发动全身；</li>
<li><strong>难以测试</strong>：想单独测试一个功能，结果被页面渲染逻辑绑死；</li>
<li><strong>团队分工困难</strong>：多人开发时，改动一个模块可能牵连整个项目。</li>
</ul>
<p>这时候再用“小房子”的方式来搭建，往往会让项目变得难以维护，甚至寸步难行。真正要做大中型应用，就必须像建造大楼一样，有清晰的图纸、合理的分工和长期可扩展的架构。</p>
<h2 id="2-状态管理全景与设计决策"><a href="#2-状态管理全景与设计决策" class="headerlink" title="2. 状态管理全景与设计决策"></a>2. 状态管理全景与设计决策</h2><p>状态管理几乎是 Flutter 项目架构的核心问题。对于小型应用，用 setState 足够，但一旦应用复杂度提升，状态管理就决定了项目能否扩展、能否多人协作、能否长期维护。本章将从常见方案、状态分层、数据流模式和决策思路几个角度，建立状态管理的全景视图。</p>
<h3 id="2-1-常见方案概览"><a href="#2-1-常见方案概览" class="headerlink" title="2.1 常见方案概览"></a>2.1 常见方案概览</h3><p>Flutter 生态中涌现了多种状态管理方案，它们背后代表着不同的心智模型和工程哲学。</p>
<table>
<thead>
<tr>
<th><strong>方案</strong></th>
<th><strong>心智模型</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>setState</strong></td>
<td>手动触发刷新（局部重建）</td>
<td>简单直接，上手快，无需额外依赖</td>
<td>状态分散，逻辑耦合 UI，难以复用</td>
<td>Demo、小应用</td>
</tr>
<tr>
<td><strong>Provider</strong></td>
<td>依赖注入 + InheritedWidget</td>
<td>Flutter 官方推荐，社区成熟，和 MVVM 接近</td>
<td>模板代码偏多，状态监听不够灵活</td>
<td>中小型项目，团队协作起步</td>
</tr>
<tr>
<td><strong>Riverpod</strong></td>
<td>声明式 Provider + 自动依赖管理</td>
<td>编译时安全、无全局 context、测试友好</td>
<td>学习曲线稍高，API 迭代快</td>
<td>中大型项目，追求可维护性</td>
</tr>
<tr>
<td><strong>Bloc &#x2F; Cubit</strong></td>
<td>单向数据流（Event → State）</td>
<td>严格分层，状态可预测，适合复杂业务</td>
<td>模板代码多，学习门槛高</td>
<td>大型项目，追求可维护性</td>
</tr>
<tr>
<td><strong>GetX</strong></td>
<td>响应式 + 服务定位器</td>
<td>API 简洁，开发效率高</td>
<td>隐式依赖多，项目大后难控边界</td>
<td>小团队快速开发，原型验证</td>
</tr>
<tr>
<td><strong>MobX</strong></td>
<td>响应式编程（观察者模式）</td>
<td>响应式体验好，代码简洁</td>
<td>需代码生成，生态相对小</td>
<td>偏好响应式范式的团队</td>
</tr>
</tbody></table>
<h3 id="2-2-优缺点与协作适配度"><a href="#2-2-优缺点与协作适配度" class="headerlink" title="2.2 优缺点与协作适配度"></a>2.2 优缺点与协作适配度</h3><ul>
<li><strong>setState</strong>：适合简单 UI 交互，例如计数器 Demo。但一旦跨页面共享状态，就会陷入“全局变量”陷阱。</li>
<li><strong>Provider</strong>：逻辑与视图分离，依赖注入清晰，适合逐步工程化的中型项目。</li>
<li><strong>Riverpod</strong>：在 Provider 思路上进化，消除了 context 限制，依赖关系更自动化，测试性和长期维护性更强。</li>
<li><strong>Bloc</strong>：事件驱动，单向数据流清晰。非常适合大型、多人协作项目，因为它约束强，能减少团队分歧。</li>
<li><strong>GetX</strong>：极简 API，入门快，但项目大后依赖隐式化严重，容易产生“魔法”。</li>
<li><strong>MobX</strong>：响应式风格优雅，但需要生成代码，生态体量不如 Provider&#x2F;Riverpod。</li>
</ul>
<p>从协作角度看：</p>
<ul>
<li>小团队&#x2F;单人开发：Provider &#x2F; GetX；</li>
<li>中型团队（多人协作）：Riverpod；</li>
<li>大型团队（强规范、长生命周期）：Bloc。</li>
</ul>
<h3 id="2-3-状态分层"><a href="#2-3-状态分层" class="headerlink" title="2.3 状态分层"></a>2.3 状态分层</h3><p>在大中型项目里，单靠“选对框架”还不够，更关键的是要<strong>划清状态边界</strong>：</p>
<ol>
<li><strong>UI-State</strong>（界面临时状态）：一般是短生命周期，局限于某个页面或组件。比如说当前 Tab 索引、是否展开某个卡片。<br> 实现：setState 或局部 Provider 足够。</li>
<li><strong>Domain-State</strong>（业务状态）：可以跨页面共享，需要一致性和可追踪。比如说购物车商品列表、用户登录信息。<br> 实现：Provider、Riverpod、Bloc 等。</li>
<li><strong>Infra-State</strong>（基础设施状态）：一般是有全局性，与业务解耦。比如说网络连接状态、缓存是否加载完成。<br> 实现：DI 容器中的全局 service 提供。</li>
</ol>
<h3 id="2-4-单向数据流-vs-双向绑定"><a href="#2-4-单向数据流-vs-双向绑定" class="headerlink" title="2.4 单向数据流 vs 双向绑定"></a>2.4 单向数据流 vs 双向绑定</h3><ul>
<li><strong>单向数据流</strong>（如 Bloc、Redux 思路）：数据从 action → state → UI 单向流动，易追踪、调试方便。<br>  缺点：代码冗长、心智模型复杂。</li>
<li><strong>双向绑定</strong>（如 GetX、MobX）：数据改动即刻反映到 UI，开发效率高。<br>  缺点：数据流动路径隐式，调试困难。</li>
</ul>
<p>在大型团队协作中，<strong>单向数据流更利于维护</strong>；在快速迭代或原型场景，<strong>双向绑定更高效</strong>。</p>
<h3 id="2-5-选择思路"><a href="#2-5-选择思路" class="headerlink" title="2.5 选择思路"></a>2.5 选择思路</h3><p>那么，在实际项目中如何选择呢？</p>
<ul>
<li><strong>项目规模小 &#x2F; Demo &#x2F; MVP</strong> 可以选择 setState 或 GetX</li>
<li><strong>中型项目（多人协作，复杂度中等）</strong> 可以选择  Provider &#x2F; Riverpod</li>
<li><strong>大型项目（强制规范、可预测性要求高）</strong> 可以选择 Bloc</li>
<li><strong>偏好响应式编程风格</strong> 可以选择  MobX</li>
</ul>
<p>换句话说：<strong>没有“最佳”方案，只有最契合团队规模、协作方式和业务复杂度的方案</strong>。</p>
<h3 id="2-6-代码对比示例"><a href="#2-6-代码对比示例" class="headerlink" title="2.6 代码对比示例"></a>2.6 代码对比示例</h3><p>为了直观对比，来看一个最经典的“计数器”例子。</p>
<h4 id="2-6-1-用-setState-实现"><a href="#2-6-1-用-setState-实现" class="headerlink" title="2.6.1 用 setState 实现"></a>2.6.1 用 setState 实现</h4><p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterSetState</span> <span class="keyword">extends</span> <span class="title">StatefulWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> CounterSetState(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  State&lt;CounterSetState&gt; createState() =&gt; _CounterSetStateState();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_CounterSetStateState</span> <span class="keyword">extends</span> <span class="title">State</span>&lt;<span class="title">CounterSetState</span>&gt; </span>&#123;</span><br><span class="line">  <span class="built_in">int</span> _count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> _increment() &#123;</span><br><span class="line">    setState(() &#123;</span><br><span class="line">      _count++;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      body: Center(child: Text(<span class="string">&quot;Count: <span class="subst">$_count</span>&quot;</span>)),</span><br><span class="line">      floatingActionButton: FloatingActionButton(</span><br><span class="line">        onPressed: _increment,</span><br><span class="line">        child: <span class="keyword">const</span> Icon(Icons.add),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-6-2-用-Provider-实现"><a href="#2-6-2-用-Provider-实现" class="headerlink" title="2.6.2 用 Provider 实现"></a>2.6.2 用 Provider 实现</h4><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="attr">provider:</span> <span class="string">^6.1.5</span></span><br></pre></td></tr></table></figure>
<p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:provider/provider.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterModel</span> <span class="title">with</span> <span class="title">ChangeNotifier</span> </span>&#123;  </span><br><span class="line">  <span class="built_in">int</span> _count = <span class="number">0</span>;  </span><br><span class="line">  <span class="built_in">int</span> <span class="keyword">get</span> count =&gt; _count;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> increment() &#123;  </span><br><span class="line">    _count++;  </span><br><span class="line">    notifyListeners();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterProvider</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> CounterProvider(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> ChangeNotifierProvider(  </span><br><span class="line">      create: (_) =&gt; CounterModel(),  </span><br><span class="line">      child: Scaffold(  </span><br><span class="line">        body: Center(  </span><br><span class="line">          child: Consumer&lt;CounterModel&gt;(  </span><br><span class="line">            builder: (_, counter, __) =&gt; Text(<span class="string">&quot;Count: <span class="subst">$&#123;counter.count&#125;</span>&quot;</span>),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">        floatingActionButton: Consumer&lt;CounterModel&gt;(  </span><br><span class="line">          builder: (_, counter, __) =&gt; FloatingActionButton(  </span><br><span class="line">            onPressed: counter.increment,  </span><br><span class="line">            child: <span class="keyword">const</span> Icon(Icons.add),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-6-3-用-Riverpod-实现"><a href="#2-6-3-用-Riverpod-实现" class="headerlink" title="2.6.3 用 Riverpod 实现"></a>2.6.3 用 Riverpod 实现</h4><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="attr">flutter_riverpod:</span> <span class="string">^3.0.0</span></span><br></pre></td></tr></table></figure>
<p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter_riverpod/flutter_riverpod.dart&#x27;</span>;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">void</span> main() &#123;  </span><br><span class="line">  runApp(  </span><br><span class="line">    ProviderScope(  </span><br><span class="line">      child: MyApp(),  </span><br><span class="line">    ),  </span><br><span class="line">  );  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      home: CounterRiverpod(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">final</span> counterProvider = StateProvider&lt;<span class="built_in">int</span>&gt;((ref) =&gt; <span class="number">0</span>);  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterRiverpod</span> <span class="keyword">extends</span> <span class="title">ConsumerWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> CounterRiverpod(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context, WidgetRef ref) &#123;  </span><br><span class="line">    <span class="keyword">final</span> count = ref.watch(counterProvider);  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      body: Center(child: Text(<span class="string">&quot;Count: <span class="subst">$count</span>&quot;</span>)),  </span><br><span class="line">      floatingActionButton: FloatingActionButton(  </span><br><span class="line">        onPressed: () =&gt; ref.read(counterProvider.notifier).state++,  </span><br><span class="line">        child: <span class="keyword">const</span> Icon(Icons.add),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-6-4-用-Bloc-实现"><a href="#2-6-4-用-Bloc-实现" class="headerlink" title="2.6.4 用 Bloc 实现"></a>2.6.4 用 Bloc 实现</h4><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="attr">flutter_bloc:</span> <span class="string">^9.1.1</span></span><br></pre></td></tr></table></figure>
<p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter_bloc/flutter_bloc.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      home: BlocProvider(  </span><br><span class="line">        create: (_) =&gt; CounterCubit(),  </span><br><span class="line">        child: CounterBloc(),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterCubit</span> <span class="keyword">extends</span> <span class="title">Cubit</span>&lt;<span class="title">int</span>&gt; </span>&#123;  </span><br><span class="line">  CounterCubit() : <span class="keyword">super</span>(<span class="number">0</span>);  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> increment() =&gt; emit(state + <span class="number">1</span>);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterBloc</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> CounterBloc(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> BlocProvider(  </span><br><span class="line">      create: (_) =&gt; CounterCubit(),  </span><br><span class="line">      child: Scaffold(  </span><br><span class="line">        body: Center(  </span><br><span class="line">          child: BlocBuilder&lt;CounterCubit, <span class="built_in">int</span>&gt;(  </span><br><span class="line">            builder: (_, count) =&gt; Text(<span class="string">&quot;Count: <span class="subst">$count</span>&quot;</span>),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">        floatingActionButton: BlocBuilder&lt;CounterCubit, <span class="built_in">int</span>&gt;(  </span><br><span class="line">          builder: (context, _) =&gt; FloatingActionButton(  </span><br><span class="line">            onPressed: () =&gt; context.read&lt;CounterCubit&gt;().increment(),  </span><br><span class="line">            child: <span class="keyword">const</span> Icon(Icons.add),  </span><br><span class="line">          ),  </span><br><span class="line">        ),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-6-5-用-GetX-实现"><a href="#2-6-5-用-GetX-实现" class="headerlink" title="2.6.5 用 GetX 实现"></a>2.6.5 用 GetX 实现</h4><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="attr">get:</span> <span class="string">^4.7.2</span></span><br></pre></td></tr></table></figure>
<p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:get/get.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> MaterialApp(  </span><br><span class="line">      home: CounterGetX(),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterController</span> <span class="keyword">extends</span> <span class="title">GetxController</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">var</span> count = <span class="number">0</span>.obs;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> increment() =&gt; count++;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterGetX</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">final</span> CounterController controller = Get.put(CounterController());  </span><br><span class="line">  </span><br><span class="line">  CounterGetX(&#123;<span class="keyword">super</span>.key&#125;);  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@override</span>  </span><br><span class="line">  Widget build(BuildContext context) &#123;  </span><br><span class="line">    <span class="keyword">return</span> Scaffold(  </span><br><span class="line">      body: Center(child: Obx(() =&gt; Text(<span class="string">&quot;Count: <span class="subst">$&#123;controller.count&#125;</span>&quot;</span>))),  </span><br><span class="line">      floatingActionButton: FloatingActionButton(  </span><br><span class="line">        onPressed: controller.increment,  </span><br><span class="line">        child: <span class="keyword">const</span> Icon(Icons.add),  </span><br><span class="line">      ),  </span><br><span class="line">    );  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-6-6-用-MobX-实现"><a href="#2-6-6-用-MobX-实现" class="headerlink" title="2.6.6 用 MobX 实现"></a>2.6.6 用 MobX 实现</h4><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span>    </span><br><span class="line">  <span class="attr">mobx:</span> <span class="string">^2.5.0</span>          <span class="comment"># 状态管理核心库  </span></span><br><span class="line">  <span class="attr">flutter_mobx:</span> <span class="string">^2.3.0</span>  <span class="comment"># Flutter集成  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">dev_dependencies:</span>  </span><br><span class="line">  <span class="attr">build_runner:</span> <span class="string">^2.8.0</span>  </span><br><span class="line">  <span class="attr">mobx_codegen:</span> <span class="string">^2.7.4</span></span><br></pre></td></tr></table></figure>
<p>实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">lib/counter_store.dart</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:mobx/mobx.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">part</span> <span class="string">&#x27;counter_store.g.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Store</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterStore</span> = <span class="title">_CounterStore</span> <span class="title">with</span> <span class="title">_</span>$<span class="title">CounterStore</span>;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">abstract</span> <span class="title">class</span> <span class="title">_CounterStore</span> <span class="title">with</span> <span class="title">Store</span> </span>&#123;</span><br><span class="line">  <span class="meta">@observable</span></span><br><span class="line">  <span class="built_in">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@action</span></span><br><span class="line">  <span class="keyword">void</span> increment() =&gt; count++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>生成代码，在项目根目录运行：<code>flutter pub run build_runner build</code> 生成<code>counter_store.g.dart</code></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">lib/main.dart</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter_mobx/flutter_mobx.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;counter_store.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  runApp(<span class="keyword">const</span> MyApp());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> MaterialApp(</span><br><span class="line">      title: <span class="string">&#x27;MobX Counter Demo&#x27;</span>,</span><br><span class="line">      theme: ThemeData(primarySwatch: Colors.blue),</span><br><span class="line">      home: CounterMobX(),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CounterMobX</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> CounterStore store = CounterStore();</span><br><span class="line"></span><br><span class="line">  CounterMobX(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&quot;MobX Counter&quot;</span>)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: Observer(</span><br><span class="line">          builder: (_) =&gt; Text(</span><br><span class="line">            <span class="string">&quot;Count: <span class="subst">$&#123;store.count&#125;</span>&quot;</span>,</span><br><span class="line">            style: <span class="keyword">const</span> TextStyle(fontSize: <span class="number">24</span>),</span><br><span class="line">          ),</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">      floatingActionButton: FloatingActionButton(</span><br><span class="line">        onPressed: store.increment,</span><br><span class="line">        child: <span class="keyword">const</span> Icon(Icons.add),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过对比可以发现：</p>
<ul>
<li><strong>setState</strong> 胜在直观、上手快，但缺乏状态隔离和可维护性，一旦页面复杂就会迅速失控；</li>
<li><strong>Provider</strong> 相对规整，但仍依赖 ChangeNotifier，在状态拆分和复用上略显笨重；</li>
<li><strong>Riverpod</strong> 提供了灵活的依赖注入和无 BuildContext 的访问方式，更适合中大型项目的工程化实践；</li>
<li><strong>Bloc</strong> 以严格的单向数据流和事件驱动为核心，虽然开发心智负担更重，但换来良好的可测试性和团队协作规范，特别适合大型团队或长生命周期项目；</li>
<li><strong>GetX</strong> 以响应式变量和服务定位器为核心，API 简洁，上手快，开发效率高，适合小团队或快速迭代，但项目大后依赖隐式化较多，边界管理需谨慎；</li>
<li><strong>MobX</strong> 提供响应式编程模式，观察者自动更新 UI，代码简洁优雅，适合偏好响应式风格的团队，但需要代码生成工具，生态体量不如 Provider&#x2F;Riverpod。</li>
</ul>
<p>Flutter 状态管理方案多样，核心在于<strong>匹配场景</strong>而非追求“唯一最佳”，更关键的是<strong>状态分层</strong>，明确 UI、业务、基础设施的边界。单向流更适合长期维护，双向绑定更适合快速开发。选型时要考虑<strong>团队规模、项目复杂度、协作方式</strong>。</p>
<h2 id="3-依赖注入（DI）与服务定位"><a href="#3-依赖注入（DI）与服务定位" class="headerlink" title="3. 依赖注入（DI）与服务定位"></a>3. 依赖注入（DI）与服务定位</h2><p>在小项目中，我们常常会在某个类里直接 new ApiClient()，然后全局到处用。这种做法简单直观，但随着项目规模变大，问题就会出现：</p>
<ul>
<li>想换一个实现（比如从线上 API 换成本地 Mock），需要全局修改</li>
<li>想做单元测试，测试代码中不得不依赖真实网络请求</li>
<li>依赖关系杂乱，一个类可能直接 new 出好几个依赖，难以追踪</li>
</ul>
<p>这就是 <strong>依赖注入（Dependency Injection, DI）</strong> 要解决的问题。<br>DI 的核心思想是：<strong>类不自己创建依赖，而是“外部”提供依赖</strong>。这样做带来的好处有三点：</p>
<ol>
<li><strong>解耦</strong> —— 类与具体实现解耦，只依赖抽象接口。</li>
<li><strong>可替换</strong> —— 可以轻松替换实现，比如生产环境用真实服务，测试环境用 Mock。</li>
<li><strong>易维护</strong> —— 依赖关系清晰，方便管理生命周期。</li>
</ol>
<p>你可以把它类比成 <strong>水管接头</strong>：如果每个房间的水龙头都直接焊死在一根水管上，换水源会非常麻烦；如果在水龙头后装一个接头，就可以随时接不同水管（自来水&#x2F;过滤水&#x2F;热水），灵活可控。</p>
<h3 id="3-1-三种常见模式"><a href="#3-1-三种常见模式" class="headerlink" title="3.1 三种常见模式"></a>3.1 三种常见模式</h3><p>在 Flutter 项目里，DI 有三种主流实践方式：  </p>
<h4 id="3-1-1-get-it（服务定位器模式）"><a href="#3-1-1-get-it（服务定位器模式）" class="headerlink" title="3.1.1 get_it（服务定位器模式）"></a>3.1.1 get_it（服务定位器模式）</h4><p><a href="https://pub.dev/packages/get_it">get_it</a> 是 Flutter 里非常常见的服务定位器库，本质是一个全局的“依赖注册表”。你可以在项目启动时，把需要的服务注册进去，然后在任何地方获取。</p>
<p><strong>示例：注册与使用 API Client</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:get_it/get_it.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> getIt = GetIt.instance;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设有一个 ApiClient</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApiClient</span> </span>&#123;</span><br><span class="line">  <span class="keyword">void</span> fetchData() =&gt; <span class="built_in">print</span>(<span class="string">&quot;Fetching data from server...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> setup() &#123;</span><br><span class="line">  getIt.registerLazySingleton&lt;ApiClient&gt;(() =&gt; ApiClient());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  setup();</span><br><span class="line">  <span class="keyword">final</span> apiClient = getIt&lt;ApiClient&gt;();</span><br><span class="line">  apiClient.fetchData(); <span class="comment">// ✅ 直接获取依赖</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种方式的优点是上手快、用法简洁；全局单例管理方便。但缺点是过度使用可能导致依赖关系隐蔽，不利于追踪。</p>
<h4 id="3-1-2-Riverpod-Provider（依赖树管理）"><a href="#3-1-2-Riverpod-Provider（依赖树管理）" class="headerlink" title="3.1.2 Riverpod Provider（依赖树管理）"></a>3.1.2 Riverpod Provider（依赖树管理）</h4><p>Riverpod 不仅是状态管理工具，也能天然充当 DI 容器。它将依赖注册在 Provider 中，由框架保证生命周期和作用域。</p>
<p><strong>示例：用 Riverpod 提供 API Client</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter_riverpod/flutter_riverpod.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApiClient</span> </span>&#123;</span><br><span class="line">  <span class="keyword">void</span> fetchData() =&gt; <span class="built_in">print</span>(<span class="string">&quot;Fetching data from server...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个 provider</span></span><br><span class="line"><span class="keyword">final</span> apiClientProvider = Provider((ref) =&gt; ApiClient());</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">ConsumerWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> MyApp(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context, WidgetRef ref) &#123;</span><br><span class="line">    <span class="keyword">final</span> apiClient = ref.watch(apiClientProvider);</span><br><span class="line">    apiClient.fetchData();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const</span> MaterialApp(home: Scaffold(body: Center(child: Text(<span class="string">&quot;Demo&quot;</span>))));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  runApp(<span class="keyword">const</span> ProviderScope(child: MyApp()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种方式的优点是天然支持作用域（Scoped service）、生命周期跟随 Widget 树、依赖关系清晰。缺点是需要引入 Riverpod 框架；对初学者来说上手难度比较大。</p>
<h4 id="3-1-3-构造函数注入（纯-Dart-思路）"><a href="#3-1-3-构造函数注入（纯-Dart-思路）" class="headerlink" title="3.1.3 构造函数注入（纯 Dart 思路）"></a>3.1.3 构造函数注入（纯 Dart 思路）</h4><p>这是最“干净”的做法，完全不依赖第三方库。核心思路是：一个类需要的依赖全部通过构造函数传入，而不是自己创建。<br><strong>示例：构造函数注入</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApiClient</span> </span>&#123;</span><br><span class="line">  <span class="keyword">void</span> fetchData() =&gt; <span class="built_in">print</span>(<span class="string">&quot;Fetching data from server...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserRepository</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ApiClient apiClient;</span><br><span class="line"></span><br><span class="line">  UserRepository(<span class="keyword">this</span>.apiClient);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> loadUser() =&gt; apiClient.fetchData();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  <span class="keyword">final</span> apiClient = ApiClient();</span><br><span class="line">  <span class="keyword">final</span> repo = UserRepository(apiClient);</span><br><span class="line">  repo.loadUser();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种方式最直观、依赖关系显式、测试最友好。但缺点是随着依赖链增长，构造函数参数会越来越多，手动注入可能繁琐。</p>
<h3 id="3-2-生命周期管理"><a href="#3-2-生命周期管理" class="headerlink" title="3.2 生命周期管理"></a>3.2 生命周期管理</h3><p>在大项目中，依赖并不是一旦创建就永远存在。常见的生命周期策略有：</p>
<ul>
<li><strong>单例（Singleton）</strong>：应用全局共享一个实例（如日志、配置）。</li>
<li><strong>Scoped Service</strong>：跟随某个页面&#x2F;模块的作用域（如用户会话）。</li>
<li><strong>Transient</strong>：每次使用时都创建一个新实例。</li>
</ul>
<p>例如，在 get_it 中可以用 registerLazySingleton（单例）、registerFactory（每次创建），在 Riverpod 中则通过 Provider 的类型（Provider vs StateNotifierProvider 等）来决定生命周期。</p>
<h3 id="3-3-DI-在大项目中的角色"><a href="#3-3-DI-在大项目中的角色" class="headerlink" title="3.3 DI 在大项目中的角色"></a>3.3 DI 在大项目中的角色</h3><p>依赖注入并不是孤立存在的，它在大中型 Flutter 项目里扮演着“胶水”的角色：</p>
<ul>
<li><strong>连接状态管理</strong>：比如一个 UserNotifier 里依赖 UserRepository，而 UserRepository 依赖 ApiClient，这些都可以通过 DI 管理。</li>
<li><strong>支撑模块化架构</strong>：每个模块可以定义自己的服务和依赖，再通过 DI 框架统一注入。</li>
<li><strong>简化测试</strong>：测试时只需要替换掉依赖即可，例如把真实 API Client 换成 Mock。</li>
</ul>
<p><strong>示例：测试中的依赖替换</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MockApiClient</span> <span class="keyword">implements</span> <span class="title">ApiClient</span> </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">void</span> fetchData() =&gt; <span class="built_in">print</span>(<span class="string">&quot;Mock data for test&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  <span class="comment">// 在测试环境下注册 Mock</span></span><br><span class="line">  getIt.registerLazySingleton&lt;ApiClient&gt;(() =&gt; MockApiClient());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> apiClient = getIt&lt;ApiClient&gt;();</span><br><span class="line">  apiClient.fetchData(); <span class="comment">// 输出：Mock data for test</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>依赖注入就像“水管接头”，让我们的系统可以方便地切换不同实现（真实服务&#x2F;假服务），同时保持依赖关系清晰。</p>
<ul>
<li><strong>get_it</strong> 适合快速上手的小团队，灵活但容易滥用；</li>
<li><strong>Riverpod Provider</strong> 更加结构化，适合中大型项目；</li>
<li><strong>构造函数注入</strong> 最朴素，也最利于测试，但在复杂项目里需要搭配工厂模式或 DI 容器来减轻手工注入的负担。</li>
</ul>
<p>在实际工程中，往往会结合使用：比如底层依赖通过 get_it 或 Riverpod 注入，业务类通过构造函数传递，既灵活又可控。</p>
<h2 id="4-路由架构与页面解耦"><a href="#4-路由架构与页面解耦" class="headerlink" title="4. 路由架构与页面解耦"></a>4. 路由架构与页面解耦</h2><p>在小型 Flutter 应用中，页面跳转通常只需要一行 <code>Navigator.push()</code> 就能完成。然而，当项目逐渐增长、模块增多、功能复杂（例如登录态校验、角色切换、深度链接）时，“路由”不再只是导航问题，而是<strong>应用架构的核心组成</strong>。</p>
<p>下面将从 Flutter 路由体系的演进出发，逐步展开：</p>
<ul>
<li>从 <strong>Navigator 1.0 命令式导航</strong> 到 <strong>Navigator 2.0 声明式导航</strong> 的转变</li>
<li>如何实现 <strong>路由守卫（登录&#x2F;权限拦截）</strong>?</li>
<li>如何在大型工程中利用路由实现 <strong>模块化解耦</strong>?</li>
</ul>
<h3 id="4-1-Navigator-1-0"><a href="#4-1-Navigator-1-0" class="headerlink" title="4.1 Navigator 1.0"></a>4.1 Navigator 1.0</h3><p>Flutter 最早的路由系统可以叫 <strong>Navigator 1.0</strong>，以命令式方式管理页面栈。最常见的写法是：通过一个全局路由表映射字符串路径与页面组件。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// <span class="language-markdown">全局路由映射</span></span></span><br><span class="line"><span class="keyword">final</span> <span class="built_in">Map</span>&lt;<span class="built_in">String</span>, WidgetBuilder&gt; appRoutes = &#123;</span><br><span class="line">  <span class="string">&#x27;/&#x27;</span>: (context) =&gt; <span class="keyword">const</span> HomePage(),</span><br><span class="line">  <span class="string">&#x27;/user_home&#x27;</span>: (context) =&gt; <span class="keyword">const</span> UserHomePage(),</span><br><span class="line">  <span class="string">&#x27;/debug&#x27;</span>: (context) =&gt; <span class="keyword">const</span> DebugPage(),</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">MaterialApp(</span><br><span class="line">  initialRoute: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">  routes: appRoutes,</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>这种方式的特点是：</p>
<ul>
<li><strong>集中管理</strong>：页面路径清晰，结构简单；</li>
<li><strong>调用简洁</strong>：Navigator.pushNamed(context, ‘&#x2F;user_home’); 即可跳转；</li>
<li><strong>适合中小型项目</strong>：页面不多时维护轻松。</li>
</ul>
<p>但随着项目增长，这种命令式方式开始暴露出局限：</p>
<table>
<thead>
<tr>
<th><strong>问题</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>参数传递繁琐</td>
<td>需手动解析 ModalRoute.of(context)?.settings.arguments</td>
</tr>
<tr>
<td>无统一守卫</td>
<td>登录、权限逻辑需分散在每个跳转调用中</td>
</tr>
<tr>
<td>深度链接支持弱</td>
<td>处理外部 URI 或复杂授权流比较麻烦</td>
</tr>
</tbody></table>
<h3 id="4-2-onGenerateRoute-动态拦截"><a href="#4-2-onGenerateRoute-动态拦截" class="headerlink" title="4.2 onGenerateRoute 动态拦截"></a>4.2 onGenerateRoute 动态拦截</h3><p>为了解决登录等简单拦截场景，可以通过 onGenerateRoute 动态生成路由：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">MaterialApp(</span><br><span class="line">  initialRoute: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">  routes: appRoutes,</span><br><span class="line">  onGenerateRoute: (settings) &#123;</span><br><span class="line">    <span class="keyword">if</span> (settings.name == <span class="string">&#x27;/user_home&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!authService.isLoggedIn) &#123;</span><br><span class="line">        <span class="keyword">return</span> MaterialPageRoute(builder: (_) =&gt; <span class="keyword">const</span> LoginPage());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> MaterialPageRoute(builder: (_) =&gt; <span class="keyword">const</span> UserHomePage());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;,</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>这种方式可以让部分页面具备访问控制，但本质仍是命令式模式。页面跳转依旧依赖 push &#x2F; pop，无法与应用状态解耦。<br>当出现多角色、授权回调、外部跳转时，代码将变得难以维护。</p>
<h3 id="4-3-Navigator-2-0：声明式导航"><a href="#4-3-Navigator-2-0：声明式导航" class="headerlink" title="4.3 Navigator 2.0：声明式导航"></a>4.3 Navigator 2.0：声明式导航</h3><p>为解决上述问题，Flutter 推出了 <strong>Navigator 2.0</strong>。它引入声明式 API，将“页面栈”抽象为<strong>状态的函数</strong>：</p>
<blockquote>
<p><strong>页面不再由命令控制，而是由应用状态驱动。</strong></p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>Navigator 1.0</strong></th>
<th><strong>Navigator 2.0</strong></th>
</tr>
</thead>
<tbody><tr>
<td>导航方式</td>
<td>命令式：push&#x2F;pop</td>
<td>声明式：状态驱动页面</td>
</tr>
<tr>
<td>控制逻辑</td>
<td>手动调用跳转</td>
<td>状态变化自动刷新页面栈</td>
</tr>
<tr>
<td>适用场景</td>
<td>简单页面流转</td>
<td>多状态、深度链接、复杂授权</td>
</tr>
</tbody></table>
<h4 id="4-3-1-核心结构：RouterDelegate-与-RouteInformationParser"><a href="#4-3-1-核心结构：RouterDelegate-与-RouteInformationParser" class="headerlink" title="4.3.1 核心结构：RouterDelegate 与 RouteInformationParser"></a>4.3.1 核心结构：RouterDelegate 与 RouteInformationParser</h4><p>声明式路由由两大组件驱动：</p>
<ul>
<li><strong>RouteInformationParser</strong>：将 URL &#x2F; 路由信息解析为内部状态；</li>
<li><strong>RouterDelegate</strong>：根据状态构建页面栈。</li>
</ul>
<p>一个最小实现示例如下：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRouterDelegate</span> <span class="keyword">extends</span> <span class="title">RouterDelegate</span>&lt;<span class="title">RouteSettings</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="title">with</span> <span class="title">ChangeNotifier</span>, <span class="title">PopNavigatorRouterDelegateMixin</span>&lt;<span class="title">RouteSettings</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="keyword">final</span> navigatorKey = GlobalKey&lt;NavigatorState&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">bool</span> isLoggedIn = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Navigator(</span><br><span class="line">      key: navigatorKey,</span><br><span class="line">      pages: [</span><br><span class="line">        <span class="keyword">const</span> MaterialPage(child: HomePage()),</span><br><span class="line">        <span class="keyword">if</span> (!isLoggedIn) <span class="keyword">const</span> MaterialPage(child: LoginPage()),</span><br><span class="line">        <span class="keyword">if</span> (isLoggedIn) <span class="keyword">const</span> MaterialPage(child: UserHomePage()),</span><br><span class="line">      ],</span><br><span class="line">      onPopPage: (route, result) =&gt; route.didPop(result),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; setNewRoutePath(RouteSettings configuration) <span class="keyword">async</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当 isLoggedIn 状态改变时，页面栈会<strong>自动同步更新</strong>。无需再写 push &#x2F; pop 逻辑，路由守卫自然生效。</p>
<h3 id="4-4-路由守卫：登录与权限控制"><a href="#4-4-路由守卫：登录与权限控制" class="headerlink" title="4.4 路由守卫：登录与权限控制"></a>4.4 路由守卫：登录与权限控制</h3><p>声明式导航的一大优势是<strong>路由守卫天然内置在状态逻辑中</strong>。<br>例如：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line">Widget build(BuildContext context) &#123;</span><br><span class="line">  <span class="keyword">final</span> pages = &lt;Page&gt;[];</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!authService.isLoggedIn) &#123;</span><br><span class="line">    pages.add(MaterialPage(child: LoginPage(onLogin: () &#123;</span><br><span class="line">      authService.login();</span><br><span class="line">      notifyListeners();</span><br><span class="line">    &#125;)));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    pages.add(MaterialPage(child: HomePage()));</span><br><span class="line">    <span class="keyword">if</span> (_showDetails) pages.add(MaterialPage(child: DetailPage()));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Navigator(pages: pages, onPopPage: _onPopPage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>登录状态的变化会直接重构页面栈，不再需要在每个跳转处手动判断权限。这也是 Navigator 2.0 在工程化路由中的最大优势。</p>
<h4 id="4-4-1-示例"><a href="#4-4-1-示例" class="headerlink" title="4.4.1 示例"></a>4.4.1 示例</h4><p>接下来，我们通过一个例子来展示声明式路由——<strong>它不仅能定义页面跳转关系，还能以声明的方式表达页面层级和状态逻辑</strong>。</p>
<h5 id="4-4-1-1-场景需求"><a href="#4-4-1-1-场景需求" class="headerlink" title="4.4.1.1 场景需求"></a>4.4.1.1 场景需求</h5><p>假设我们正在开发一个简单的应用，包含以下页面：</p>
<ul>
<li><strong>首页 &#x2F;</strong></li>
<li><strong>登录页 &#x2F;login</strong></li>
<li><strong>用户中心 &#x2F;user</strong><ul>
<li>&#x2F;user&#x2F;profile：用户资料页</li>
<li>&#x2F;user&#x2F;orders：订单列表页<br>逻辑要求：</li>
</ul>
</li>
</ul>
<ol>
<li>未登录用户访问 &#x2F;user&#x2F;… 时，应自动跳转到 &#x2F;login；</li>
<li>登录后访问 &#x2F;login 时，应自动回到首页；</li>
<li>用户中心下的两个子页共享同一个顶部导航。</li>
</ol>
<h5 id="4-4-1-2-代码实现"><a href="#4-4-1-2-代码实现" class="headerlink" title="4.4.1.2 代码实现"></a>4.4.1.2 代码实现</h5><p>依赖：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span>  </span><br><span class="line">  <span class="attr">go_router:</span> <span class="string">^16.2.4</span></span><br></pre></td></tr></table></figure>
<p>路由配置：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:flutter/material.dart&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:go_router/go_router.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main() &#123;</span><br><span class="line">  runApp(MyApp());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyApp</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  MyApp(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">用 ValueNotifier 模拟登录状态（通常由 Provider 或 Riverpod 管理）</span></span></span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;<span class="built_in">bool</span>&gt; isLoggedIn = ValueNotifier(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// <span class="language-markdown">声明式路由配置</span></span></span><br><span class="line">  <span class="keyword">late</span> <span class="keyword">final</span> GoRouter _router = GoRouter(</span><br><span class="line">    refreshListenable: isLoggedIn, <span class="comment">// 登录状态变化时自动刷新路由</span></span><br><span class="line">    redirect: (context, state) &#123;</span><br><span class="line">      <span class="keyword">final</span> loggedIn = isLoggedIn.value;</span><br><span class="line">      <span class="keyword">final</span> loggingIn = state.matchedLocation == <span class="string">&#x27;/login&#x27;</span>;</span><br><span class="line">      <span class="keyword">final</span> isUserRoute = state.matchedLocation.startsWith(<span class="string">&#x27;/user&#x27;</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 未登录访问用户页 → 跳转登录</span></span><br><span class="line">      <span class="keyword">if</span> (!loggedIn &amp;&amp; isUserRoute) <span class="keyword">return</span> <span class="string">&#x27;/login&#x27;</span>;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 已登录访问登录页 → 跳转首页</span></span><br><span class="line">      <span class="keyword">if</span> (loggedIn &amp;&amp; loggingIn) <span class="keyword">return</span> <span class="string">&#x27;/&#x27;</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>; <span class="comment">// 其他情况不重定向</span></span><br><span class="line">    &#125;,</span><br><span class="line">    routes: [</span><br><span class="line">      <span class="comment">/// <span class="language-markdown">首页</span></span></span><br><span class="line">      GoRoute(</span><br><span class="line">        path: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">        name: <span class="string">&#x27;home&#x27;</span>,</span><br><span class="line">        builder: (context, state) =&gt; HomePage(isLoggedIn: isLoggedIn),</span><br><span class="line">      ),</span><br><span class="line"></span><br><span class="line">      <span class="comment">/// <span class="language-markdown">登录页</span></span></span><br><span class="line">      GoRoute(</span><br><span class="line">        path: <span class="string">&#x27;/login&#x27;</span>,</span><br><span class="line">        name: <span class="string">&#x27;login&#x27;</span>,</span><br><span class="line">        builder: (context, state) =&gt; LoginPage(isLoggedIn: isLoggedIn),</span><br><span class="line">      ),</span><br><span class="line"></span><br><span class="line">      <span class="comment">/// <span class="language-markdown">用户中心（嵌套路由）</span></span></span><br><span class="line">      GoRoute(</span><br><span class="line">        path: <span class="string">&#x27;/user&#x27;</span>,</span><br><span class="line">        name: <span class="string">&#x27;user&#x27;</span>,</span><br><span class="line">        builder: (context, state) =&gt; <span class="keyword">const</span> UserShellPage(),</span><br><span class="line">        routes: [</span><br><span class="line">          GoRoute(</span><br><span class="line">            path: <span class="string">&#x27;profile&#x27;</span>,</span><br><span class="line">            name: <span class="string">&#x27;profile&#x27;</span>,</span><br><span class="line">            builder: (context, state) =&gt; <span class="keyword">const</span> ProfilePage(),</span><br><span class="line">          ),</span><br><span class="line">          GoRoute(</span><br><span class="line">            path: <span class="string">&#x27;orders&#x27;</span>,</span><br><span class="line">            name: <span class="string">&#x27;orders&#x27;</span>,</span><br><span class="line">            builder: (context, state) =&gt; <span class="keyword">const</span> OrdersPage(),</span><br><span class="line">          ),</span><br><span class="line">        ],</span><br><span class="line">      ),</span><br><span class="line">    ],</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> MaterialApp.router(</span><br><span class="line">      title: <span class="string">&#x27;嵌套路由与登录守卫示例&#x27;</span>,</span><br><span class="line">      routerConfig: _router,</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>核心页面结构如下：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HomePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> HomePage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.isLoggedIn&#125;);</span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;<span class="built_in">bool</span>&gt; isLoggedIn;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;🏠 首页&#x27;</span>)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: Column(</span><br><span class="line">          mainAxisSize: MainAxisSize.min,</span><br><span class="line">          children: [</span><br><span class="line">            ValueListenableBuilder&lt;<span class="built_in">bool</span>&gt;(</span><br><span class="line">              valueListenable: isLoggedIn,</span><br><span class="line">              builder: (context, loggedIn, _) =&gt; Text(</span><br><span class="line">                loggedIn ? <span class="string">&#x27;✅ 已登录&#x27;</span> : <span class="string">&#x27;❌ 未登录&#x27;</span>,</span><br><span class="line">                style: <span class="keyword">const</span> TextStyle(fontSize: <span class="number">18</span>),</span><br><span class="line">              ),</span><br><span class="line">            ),</span><br><span class="line">            <span class="keyword">const</span> SizedBox(height: <span class="number">12</span>),</span><br><span class="line">            ElevatedButton(</span><br><span class="line">	          <span class="comment">// 这里使用 context.go(&#x27;/xxx&#x27;) 实现声明式跳转，代替传统的 Navigator.push</span></span><br><span class="line">              onPressed: () =&gt; context.go(<span class="string">&#x27;/user/profile&#x27;</span>),</span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;进入用户中心&#x27;</span>),</span><br><span class="line">            ),</span><br><span class="line">            <span class="keyword">const</span> SizedBox(height: <span class="number">12</span>),</span><br><span class="line">            ElevatedButton(</span><br><span class="line">              onPressed: () =&gt; context.go(<span class="string">&#x27;/login&#x27;</span>),</span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;去登录页&#x27;</span>),</span><br><span class="line">            ),</span><br><span class="line">          ],</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>登录页则模拟登录操作：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoginPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> LoginPage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.isLoggedIn&#125;);</span><br><span class="line">  <span class="keyword">final</span> ValueNotifier&lt;<span class="built_in">bool</span>&gt; isLoggedIn;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;🔐 登录页&#x27;</span>)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: ElevatedButton(</span><br><span class="line">          onPressed: () &#123;</span><br><span class="line">            isLoggedIn.value = <span class="keyword">true</span>; <span class="comment">// 模拟登录成功</span></span><br><span class="line">            context.go(<span class="string">&#x27;/&#x27;</span>); <span class="comment">// 登录后跳回首页</span></span><br><span class="line">          &#125;,</span><br><span class="line">          child: <span class="keyword">const</span> Text(<span class="string">&#x27;点击登录&#x27;</span>),</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用户中心的外壳页面（用于嵌套展示子页）：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserShellPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> UserShellPage(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: <span class="keyword">const</span> Text(<span class="string">&#x27;👤 用户中心&#x27;</span>)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: Column(</span><br><span class="line">          mainAxisSize: MainAxisSize.min,</span><br><span class="line">          children: [</span><br><span class="line">            ElevatedButton(</span><br><span class="line">              onPressed: () =&gt; context.go(<span class="string">&#x27;/user/profile&#x27;</span>),</span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;个人资料&#x27;</span>),</span><br><span class="line">            ),</span><br><span class="line">            ElevatedButton(</span><br><span class="line">              onPressed: () =&gt; context.go(<span class="string">&#x27;/user/orders&#x27;</span>),</span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;订单列表&#x27;</span>),</span><br><span class="line">            ),</span><br><span class="line">            ElevatedButton(</span><br><span class="line">              onPressed: () =&gt; context.go(<span class="string">&#x27;/&#x27;</span>),</span><br><span class="line">              child: <span class="keyword">const</span> Text(<span class="string">&#x27;返回首页&#x27;</span>),</span><br><span class="line">            ),</span><br><span class="line">          ],</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProfilePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> ProfilePage(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) =&gt; <span class="keyword">const</span> SimplePage(title: <span class="string">&#x27;📄 个人资料&#x27;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrdersPage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> OrdersPage(&#123;<span class="keyword">super</span>.key&#125;);</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) =&gt; <span class="keyword">const</span> SimplePage(title: <span class="string">&#x27;🧾 我的订单&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimplePage</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> SimplePage(&#123;<span class="keyword">super</span>.key, <span class="keyword">required</span> <span class="keyword">this</span>.title&#125;);</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> title;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> Scaffold(</span><br><span class="line">      appBar: AppBar(title: Text(title)),</span><br><span class="line">      body: Center(</span><br><span class="line">        child: ElevatedButton(</span><br><span class="line">          onPressed: () =&gt; context.pop(),</span><br><span class="line">          child: <span class="keyword">const</span> Text(<span class="string">&#x27;返回&#x27;</span>),</span><br><span class="line">        ),</span><br><span class="line">      ),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>相较于传统的命令式 <code>Navigator.push/pop</code>，声明式路由让「页面结构」与「状态逻辑」都能通过统一配置表达出来：</p>
<ul>
<li><strong>路由即状态映射</strong>：UI &#x3D; f(RouteState)</li>
<li><strong>逻辑集中化</strong>：不再散落在各处 Navigator 调用中</li>
<li><strong>天然支持状态监听</strong>：登录、权限、网络等状态变化都会自动触发路由更新</li>
</ul>
<p>这一特性使得大型 Flutter 应用的路由管理更加稳定、可维护。</p>
<h3 id="4-5-深度链接与授权流"><a href="#4-5-深度链接与授权流" class="headerlink" title="4.5 深度链接与授权流"></a>4.5 深度链接与授权流</h3><p>移动端常见的“外部跳转”或“授权回调”场景，也可以优雅地通过声明式路由实现。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRouteParser</span> <span class="keyword">extends</span> <span class="title">RouteInformationParser</span>&lt;<span class="title">MyRoutePath</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;MyRoutePath&gt; parseRouteInformation(</span><br><span class="line">      RouteInformation routeInformation) <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> uri = <span class="built_in">Uri</span>.parse(routeInformation.location!);</span><br><span class="line">    <span class="keyword">if</span> (uri.pathSegments.contains(<span class="string">&#x27;details&#x27;</span>)) &#123;</span><br><span class="line">      <span class="keyword">return</span> MyRoutePath.details();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> MyRoutePath.home();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当外部打开 myapp:&#x2F;&#x2F;details 时，RouteInformationParser 会自动识别并还原页面状态。</p>
<p>若需要登录验证，可与“路由守卫”联动，形成完整的 <strong>授权跳转流</strong>：</p>
<blockquote>
<p>外部 URI → 解析路由状态 → 检查登录态 → 登录页 → 重定向目标页。</p>
</blockquote>
<h3 id="4-6-路由与模块化架构"><a href="#4-6-路由与模块化架构" class="headerlink" title="4.6 路由与模块化架构"></a>4.6 路由与模块化架构</h3><p>在大型项目中，路由不仅是导航，更是<strong>模块边界</strong>。</p>
<p>一种常见的工程化方案是：</p>
<ul>
<li>每个业务模块（如用户、订单、支付）维护自己的路由表；</li>
<li>主路由统一整合模块暴露的页面入口；</li>
<li>其他模块只通过路由名访问，而不直接依赖页面类。</li>
</ul>
<p>这样就实现了模块之间低耦合，同样模块可替换、可单测，路由层也可以成为自然的<strong>模块通信网关</strong>。</p>
<h3 id="4-7-选型建议"><a href="#4-7-选型建议" class="headerlink" title="4.7 选型建议"></a>4.7 选型建议</h3><table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>推荐路由方式</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody><tr>
<td>页面 &lt; 30，逻辑简单</td>
<td>Navigator 1.0 + 全局路由表</td>
<td>直观轻便，快速实现</td>
</tr>
<tr>
<td>中型项目，需登录守卫</td>
<td>Navigator 1.0 + onGenerateRoute</td>
<td>增量增强，易过渡</td>
</tr>
<tr>
<td>大型项目，深度链接、多角色</td>
<td>Navigator 2.0 &#x2F; go_router &#x2F; beamer</td>
<td>声明式、状态驱动、易扩展</td>
</tr>
</tbody></table>
<p>从 push 与 pop 的命令式操作，到基于状态自动更新的声明式导航，Flutter 路由体系的演进，体现了框架从“事件驱动”到“状态驱动”的思维转变。</p>
<h2 id="5-模块化与包设计"><a href="#5-模块化与包设计" class="headerlink" title="5. 模块化与包设计"></a>5. 模块化与包设计</h2><h3 id="5-1-模块化的目标"><a href="#5-1-模块化的目标" class="headerlink" title="5.1 模块化的目标"></a>5.1 模块化的目标</h3><p>在大型 Flutter 应用中，模块化的核心目标是：</p>
<ul>
<li><strong>降低耦合</strong>：不同功能模块（如登录、购物车）独立演进，减少互相影响；</li>
<li><strong>提高协作效率</strong>：多人开发时，可以并行构建不同模块；</li>
<li><strong>可替换性与复用性</strong>：公共模块（如网络、UI 组件库）可被多个业务共用；</li>
<li><strong>加快构建速度</strong>：仅编译或测试改动过的模块，提升开发体验。</li>
</ul>
<p>换句话说，模块化让 Flutter 工程从“一碗面条”变成“积木拼图”——每个包只关心自己的一块拼图，最终组合成完整的应用。</p>
<h3 id="5-2-包划分方式"><a href="#5-2-包划分方式" class="headerlink" title="5.2 包划分方式"></a>5.2 包划分方式</h3><p>模块化设计常见两种思路：</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>特点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Feature-based</strong>（按功能拆）</td>
<td>每个包代表一个独立功能（auth、cart、catalog 等）</td>
<td>大型业务系统、多人协作项目</td>
</tr>
<tr>
<td><strong>Layer-based</strong>（按层拆）</td>
<td>按架构层拆分，如 core、data、ui、domain</td>
<td>技术架构清晰、模块较少的项目</td>
</tr>
</tbody></table>
<p>一般建议<strong>优先采用 Feature-based 模式</strong>，原因有三点：</p>
<ul>
<li>功能模块更符合团队分工</li>
<li>测试、发布、依赖管理更直观</li>
<li>容易逐步演进成插件化架构</li>
</ul>
<h3 id="5-3-Flutter-包类型选择"><a href="#5-3-Flutter-包类型选择" class="headerlink" title="5.3 Flutter 包类型选择"></a>5.3 Flutter 包类型选择</h3><table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>描述</strong></th>
<th><strong>典型用途</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Package</strong></td>
<td>纯 Dart 包，逻辑和 UI 都可包含</td>
<td>业务模块（如 cart、auth）</td>
</tr>
<tr>
<td><strong>Plugin</strong></td>
<td>含平台通道（Platform Channel）的包</td>
<td>原生功能（相机、定位、蓝牙）</td>
</tr>
<tr>
<td><strong>Module</strong></td>
<td>用于将 Flutter 集成进现有原生 App</td>
<td>混合开发场景（例如 iOS&#x2F;Android 原生项目中嵌 Flutter 页）</td>
</tr>
</tbody></table>
<p>在内部模块化中，<strong>大部分业务应使用 package</strong>，plugin 仅用于底层平台能力封装，module 则更多面向外部集成场景。</p>
<h3 id="5-4-插图式目录结构"><a href="#5-4-插图式目录结构" class="headerlink" title="5.4 插图式目录结构"></a>5.4 插图式目录结构</h3><p>假设我们在做一个电商应用，功能包括登录注册、商品展示、购物车和结算。<br>项目可拆成多个独立包，统一放在 packages&#x2F; 目录下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ecommerce_app/</span><br><span class="line">├── lib/</span><br><span class="line">│   └── main.dart                  # 入口：整合各功能模块</span><br><span class="line">│</span><br><span class="line">├── packages/</span><br><span class="line">│   ├── auth/                      # 登录注册模块：登录注册流程、用户信息缓存、权限校验</span><br><span class="line">│   │   ├── lib/</span><br><span class="line">│   │   │   ├── auth_page.dart</span><br><span class="line">│   │   │   └── auth_service.dart</span><br><span class="line">│   │   └── pubspec.yaml</span><br><span class="line">│   │</span><br><span class="line">│   ├── catalog/                   # 商品浏览模块：商品列表与详情展示</span><br><span class="line">│   │   ├── lib/</span><br><span class="line">│   │   │   ├── catalog_page.dart</span><br><span class="line">│   │   │   └── product_model.dart</span><br><span class="line">│   │   └── pubspec.yaml</span><br><span class="line">│   │</span><br><span class="line">│   ├── cart/                      # 购物车模块：购物车状态管理、商品增删改</span><br><span class="line">│   │   ├── lib/</span><br><span class="line">│   │   │   ├── cart_page.dart</span><br><span class="line">│   │   │   └── cart_provider.dart</span><br><span class="line">│   │   └── pubspec.yaml</span><br><span class="line">│   │</span><br><span class="line">│   ├── checkout/                  # 结算模块：订单生成、支付接口调用</span><br><span class="line">│   │   ├── lib/</span><br><span class="line">│   │   │   ├── checkout_page.dart</span><br><span class="line">│   │   │   └── order_service.dart</span><br><span class="line">│   │   └── pubspec.yaml</span><br><span class="line">│   │</span><br><span class="line">│   └── shared/                    # 公共模块：工具类、UI 组件、网络层等</span><br><span class="line">│       ├── lib/</span><br><span class="line">│       │   ├── network/</span><br><span class="line">│       │   ├── widgets/</span><br><span class="line">│       │   └── utils/</span><br><span class="line">│       └── pubspec.yaml</span><br><span class="line">│</span><br><span class="line">└── pubspec.yaml                   # 主应用配置</span><br></pre></td></tr></table></figure>
<h3 id="5-5-内部包管理与版本策略"><a href="#5-5-内部包管理与版本策略" class="headerlink" title="5.5 内部包管理与版本策略"></a>5.5 内部包管理与版本策略</h3><p>团队内部管理多个包时，应遵循以下策略：</p>
<ol>
<li><strong>语义化版本号（Semantic Versioning）</strong><br> MAJOR.MINOR.PATCH，例如，auth 从 1.2.0 → 1.3.0 表示新增功能；2.0.0 表示有破坏性更新。</li>
<li><strong>使用 path 依赖进行本地联调</strong> <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="attr">auth:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">../packages/auth</span></span><br></pre></td></tr></table></figure></li>
<li><strong>内部发布管理</strong><br> 若多个项目共用，可搭建私有 Pub 源，或者也可使用 Git tag 进行版本控制。</li>
<li><strong>兼容性策略</strong><br> 首先公共 API 要稳定，要避免跨模块直接访问内部类（保持封装边界），可以定义一个 shared_core 或 app_interface 包，统一暴露跨模块通信的模型和接口。</li>
</ol>
<h3 id="5-6-Checklist：何时抽成独立包？"><a href="#5-6-Checklist：何时抽成独立包？" class="headerlink" title="5.6 Checklist：何时抽成独立包？"></a>5.6 Checklist：何时抽成独立包？</h3><p><strong>建议抽包的情形</strong>：</p>
<ul>
<li>功能完整、边界清晰；</li>
<li>被多个业务依赖（如登录、支付）；</li>
<li>逻辑复杂、希望单独测试；</li>
<li>团队有专门成员负责开发</li>
</ul>
<p><strong>不建议抽包的情形</strong>：</p>
<ul>
<li>功能极小、仅局部使用；</li>
<li>模块间强耦合；</li>
<li>拆分会导致开发或调试成本过高。</li>
</ul>
<p>模块化不是目的，而是为了<strong>让项目结构更清晰、开发更高效、演进更安全</strong>。一个良好的包设计，应当像搭乐高一样：<strong>既能独立运作，又能无缝拼接成整体。</strong></p>
<h2 id="6-实战案例：单体-App-→-模块化工程"><a href="#6-实战案例：单体-App-→-模块化工程" class="headerlink" title="6. 实战案例：单体 App → 模块化工程"></a>6. 实战案例：单体 App → 模块化工程</h2><p>下面我们来看看一个典型的 Flutter <strong>单体项目</strong>，如何一步步演化为一个结构清晰、可扩展的<strong>模块化工程</strong>的。</p>
<h3 id="6-1-初始状态：单体应用的常见问题"><a href="#6-1-初始状态：单体应用的常见问题" class="headerlink" title="6.1 初始状态：单体应用的常见问题"></a>6.1 初始状态：单体应用的常见问题</h3><p>多数 Flutter 项目起初都长这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lib/</span><br><span class="line">├── main.dart</span><br><span class="line">├── screens/</span><br><span class="line">│   ├── login_page.dart</span><br><span class="line">│   ├── home_page.dart</span><br><span class="line">│   ├── cart_page.dart</span><br><span class="line">│   └── checkout_page.dart</span><br><span class="line">├── providers/</span><br><span class="line">│   ├── auth_provider.dart</span><br><span class="line">│   └── cart_provider.dart</span><br><span class="line">├── models/</span><br><span class="line">│   ├── product.dart</span><br><span class="line">│   └── order.dart</span><br><span class="line">└── services/</span><br><span class="line">    ├── api.dart</span><br><span class="line">    └── auth_service.dart</span><br></pre></td></tr></table></figure>
<p>这种结构没问题，但当业务一多，问题就出现了：</p>
<ul>
<li>状态分散：不同 Provider 之间相互引用；</li>
<li>依赖混乱：service 层和 UI 层容易“交叉感染”；</li>
<li>团队协作困难：不同人修改同一目录下的文件；</li>
<li>缺乏模块边界：难以单独测试或重用。</li>
</ul>
<p>最终，整个项目变成一个“胖胖的 lib 文件夹”，任何改动都有可能牵一发动全身。</p>
<h3 id="6-2-模块化迁移的总体路线"><a href="#6-2-模块化迁移的总体路线" class="headerlink" title="6.2 模块化迁移的总体路线"></a>6.2 模块化迁移的总体路线</h3><p>模块化迁移不需要“一刀切”，完全可以渐进式推进，下面是一个四步走方案：</p>
<h4 id="6-2-1-抽离状态管理"><a href="#6-2-1-抽离状态管理" class="headerlink" title="6.2.1 抽离状态管理"></a>6.2.1 抽离状态管理</h4><p>首先，让所有状态都“有组织地管理”起来。选择一个一致的状态管理方案（推荐 <strong>Riverpod</strong> 或 <strong>Provider</strong>），把散落在各处的局部状态收敛成<strong>全局容器统一注册</strong>。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> authProvider = StateNotifierProvider&lt;AuthController, AuthState&gt;((ref) &#123;</span><br><span class="line">  <span class="keyword">return</span> AuthController();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> cartProvider = StateNotifierProvider&lt;CartController, CartState&gt;((ref) &#123;</span><br><span class="line">  <span class="keyword">return</span> CartController();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>目标：所有状态入口统一、方便依赖注入和测试。</p>
</blockquote>
<h4 id="6-2-2-引入-DI-容器"><a href="#6-2-2-引入-DI-容器" class="headerlink" title="6.2.2 引入 DI 容器"></a>6.2.2 引入 DI 容器</h4><p>接着，用一个依赖注入容器（例如 get_it 或 Riverpod 的 ProviderContainer）<br>来统一管理 service、repository、controller 等核心对象。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> getIt = GetIt.instance;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> setupDI() &#123;</span><br><span class="line">  getIt.registerLazySingleton&lt;AuthService&gt;(() =&gt; AuthServiceImpl());</span><br><span class="line">  getIt.registerLazySingleton&lt;CartService&gt;(() =&gt; CartServiceImpl());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样模块之间不需要手动传 service，只要通过容器获取即可。模块内部逻辑清晰、外部依赖解耦。</p>
<h4 id="6-2-3-拆分目录-→-逐步抽成-packages"><a href="#6-2-3-拆分目录-→-逐步抽成-packages" class="headerlink" title="6.2.3 拆分目录 → 逐步抽成 packages"></a>6.2.3 拆分目录 → 逐步抽成 packages</h4><p>当状态与依赖都整理好后，就可以“切分”出功能模块了，先在 lib&#x2F;features&#x2F; 下分出子目录，再逐步抽到 packages&#x2F; 下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 拆分前</span><br><span class="line">lib/</span><br><span class="line">  ├── screens/</span><br><span class="line">  ├── providers/</span><br><span class="line">  ├── services/</span><br><span class="line">  └── models/</span><br><span class="line"></span><br><span class="line"># 拆分后</span><br><span class="line">lib/</span><br><span class="line">  └── features/</span><br><span class="line">      ├── auth/</span><br><span class="line">      │   ├── data/</span><br><span class="line">      │   ├── domain/</span><br><span class="line">      │   └── ui/</span><br><span class="line">      ├── cart/</span><br><span class="line">      ├── catalog/</span><br><span class="line">      └── checkout/</span><br><span class="line">packages/</span><br><span class="line">  ├── auth/</span><br><span class="line">  ├── cart/</span><br><span class="line">  ├── catalog/</span><br><span class="line">  └── shared/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>拆分节奏建议：一次抽一个模块，保证能独立运行与测试；优先拆复用率高、边界清晰的功能（如 auth、shared）。</p>
</blockquote>
<h4 id="6-2-4-配置路由守卫与模块边界"><a href="#6-2-4-配置路由守卫与模块边界" class="headerlink" title="6.2.4 配置路由守卫与模块边界"></a>6.2.4 配置路由守卫与模块边界</h4><p>当模块拆开后，路由也要跟着调整。例如使用 GoRouter 实现模块路由守卫：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> router = GoRouter(</span><br><span class="line">  routes: [</span><br><span class="line">    GoRoute(path: <span class="string">&#x27;/login&#x27;</span>, builder: (context, _) =&gt; <span class="keyword">const</span> LoginPage()),</span><br><span class="line">    GoRoute(</span><br><span class="line">      path: <span class="string">&#x27;/cart&#x27;</span>,</span><br><span class="line">      builder: (context, _) =&gt; <span class="keyword">const</span> CartPage(),</span><br><span class="line">      redirect: (context, state) &#123;</span><br><span class="line">        <span class="keyword">final</span> isLoggedIn = context.read(authProvider).isLoggedIn;</span><br><span class="line">        <span class="keyword">return</span> isLoggedIn ? <span class="keyword">null</span> : <span class="string">&#x27;/login&#x27;</span>;</span><br><span class="line">      &#125;,</span><br><span class="line">    ),</span><br><span class="line">  ],</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>这一步完成后，<strong>模块间通信、跳转和权限控制</strong>都有了明确的边界。整个 App 的依赖关系就从“线团”变成了“网格结构”。</p>
<h3 id="6-3-Before-vs-After：结构对比图"><a href="#6-3-Before-vs-After：结构对比图" class="headerlink" title="6.3 Before vs After：结构对比图"></a>6.3 Before vs After：结构对比图</h3><table>
<thead>
<tr>
<th><strong>单体结构（Before）</strong></th>
<th><strong>模块化结构（After）</strong></th>
<th><strong>优势</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>目录结构</strong></td>
<td>所有代码都在 lib&#x2F; 下</td>
<td>拆成多个独立包或 feature 目录</td>
</tr>
<tr>
<td><strong>状态管理</strong></td>
<td>各自维护 Provider</td>
<td>统一在 DI 容器中注册与管理</td>
</tr>
<tr>
<td><strong>依赖关系</strong></td>
<td>双向引用、循环依赖多</td>
<td>单向依赖、自上而下流动</td>
</tr>
<tr>
<td><strong>可测试性</strong></td>
<td>测试耦合度高</td>
<td>每个模块可独立测试</td>
</tr>
<tr>
<td><strong>团队协作</strong></td>
<td>文件冲突频繁</td>
<td>可按模块独立开发、合并</td>
</tr>
</tbody></table>
<p>可视化对比如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Before</span><br><span class="line">lib/</span><br><span class="line">├── screens/</span><br><span class="line">├── providers/</span><br><span class="line">├── models/</span><br><span class="line">└── services/</span><br><span class="line"></span><br><span class="line"># After</span><br><span class="line">lib/</span><br><span class="line">├── main.dart</span><br><span class="line">└── features/</span><br><span class="line">    ├── auth/</span><br><span class="line">    ├── catalog/</span><br><span class="line">    ├── cart/</span><br><span class="line">    ├── checkout/</span><br><span class="line">    └── shared/</span><br><span class="line">packages/</span><br><span class="line">├── auth/</span><br><span class="line">├── cart/</span><br><span class="line">├── catalog/</span><br><span class="line">└── shared/</span><br></pre></td></tr></table></figure>
<h3 id="6-4-迁移-Checklist"><a href="#6-4-迁移-Checklist" class="headerlink" title="6.4 迁移 Checklist"></a>6.4 迁移 Checklist</h3><table>
<thead>
<tr>
<th><strong>阶段</strong></th>
<th><strong>任务</strong></th>
<th><strong>完成标志</strong></th>
</tr>
</thead>
<tbody><tr>
<td>状态统一</td>
<td>引入 Provider&#x2F;Riverpod</td>
<td>全局状态集中在一个文件或目录中</td>
</tr>
<tr>
<td>依赖注入</td>
<td>建立 DI 容器</td>
<td>所有 service 统一注册</td>
</tr>
<tr>
<td>目录重组</td>
<td>建立 features 子目录</td>
<td>各功能模块分区明确</td>
</tr>
<tr>
<td>包抽取</td>
<td>抽取到 packages 下</td>
<td>可单独编译和测试</td>
</tr>
<tr>
<td>路由隔离</td>
<td>模块独立配置路由</td>
<td>支持登录守卫、模块跳转</td>
</tr>
<tr>
<td>公共层</td>
<td>创建 shared 包</td>
<td>工具类、样式、基础组件共用</td>
</tr>
<tr>
<td>文档化</td>
<td>补充 README &amp; 依赖图</td>
<td>模块接口边界清晰</td>
</tr>
</tbody></table>
<blockquote>
<p>最终目标：让你的 Flutter 项目不仅能“跑起来”，更能<strong>优雅地扩展、重构与长期维护</strong>。</p>
</blockquote>
<h3 id="6-5-模块间通信与依赖关系设计"><a href="#6-5-模块间通信与依赖关系设计" class="headerlink" title="6.5 模块间通信与依赖关系设计"></a>6.5 模块间通信与依赖关系设计</h3><p>当项目完成模块拆分后，新的问题出现了：</p>
<blockquote>
<p>模块之间如何安全通信？如何依赖彼此的能力，又不造成耦合？</p>
</blockquote>
<p>这就是模块化后的下一阶段挑战——<strong>跨模块协作设计</strong>。</p>
<h4 id="6-5-1-理想目标：高内聚、低耦合"><a href="#6-5-1-理想目标：高内聚、低耦合" class="headerlink" title="6.5.1 理想目标：高内聚、低耦合"></a>6.5.1 理想目标：高内聚、低耦合</h4><p>模块之间的关系应当是：</p>
<ul>
<li><strong>每个模块只暴露接口（Interface）或服务入口</strong>；</li>
<li><strong>不直接依赖对方内部实现</strong>；</li>
<li><strong>公共依赖由 shared 或 core 层统一管理</strong>。</li>
</ul>
<p>理想依赖方向如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UI 层 → Feature 模块 → Domain / Service 接口 → Shared/Core 层</span><br></pre></td></tr></table></figure>
<p>而不是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UI 层 → Feature 模块 A → Feature 模块 B → Feature 模块 C（循环依赖 ❌）</span><br></pre></td></tr></table></figure>
<h4 id="6-5-2-三种主流通信方式"><a href="#6-5-2-三种主流通信方式" class="headerlink" title="6.5.2 三种主流通信方式"></a>6.5.2 三种主流通信方式</h4><p>下面我们通过三个常用模式，说明 Flutter 模块间的依赖解耦思路。</p>
<h5 id="6-5-2-1-Interface-层"><a href="#6-5-2-1-Interface-层" class="headerlink" title="6.5.2.1 Interface 层"></a>6.5.2.1 Interface 层</h5><p>最推荐的方式是通过接口（抽象类）定义模块契约，让模块只依赖接口，而不是实现。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">// auth_interface.dart （在 shared_interfaces 包中）</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AuthService</span> </span>&#123;</span><br><span class="line">  <span class="built_in">bool</span> <span class="keyword">get</span> isLoggedIn;</span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; login(<span class="built_in">String</span> user, <span class="built_in">String</span> password);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每个模块只依赖接口包：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:shared_interfaces/auth_interface.dart&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>具体实现留在 auth 模块：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthServiceImpl</span> <span class="keyword">implements</span> <span class="title">AuthService</span> </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">bool</span> <span class="keyword">get</span> isLoggedIn =&gt; _token != <span class="keyword">null</span>;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;<span class="keyword">void</span>&gt; login(<span class="built_in">String</span> user, <span class="built_in">String</span> password) <span class="keyword">async</span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后通过 <strong>DI 容器（如 get_it 或 Riverpod）</strong> 在应用启动时注册实现：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">getIt.registerLazySingleton&lt;AuthService&gt;(() =&gt; AuthServiceImpl());</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这样做的好处是：编译时安全；可替换性强（mock 实现更容易）；模块完全解耦。</p>
</blockquote>
<h5 id="6-5-2-2-Event-Bus"><a href="#6-5-2-2-Event-Bus" class="headerlink" title="6.5.2.2 Event Bus"></a>6.5.2.2 Event Bus</h5><p>如果多个模块需要监听事件（例如“登录成功”或“购物车更新”），可以通过 Event Bus 进行广播式通信：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;package:event_bus/event_bus.dart&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> eventBus = EventBus();</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoginEvent</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CartUpdatedEvent</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">发送事件</span></span></span><br><span class="line">eventBus.fire(LoginEvent());</span><br><span class="line"></span><br><span class="line"><span class="comment">/// <span class="language-markdown">监听事件</span></span></span><br><span class="line">eventBus.<span class="keyword">on</span>&lt;LoginEvent&gt;().listen((event) &#123;</span><br><span class="line">  <span class="comment">// 响应登录成功</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>适用场景：一对多通知；异步广播（不依赖状态树）；临时跨模块同步。</p>
</blockquote>
<blockquote>
<p>注意点：不要滥用，复杂项目建议加事件命名空间；对关键依赖关系仍应优先使用接口模式。</p>
</blockquote>
<h5 id="6-5-2-3-Service-Locator"><a href="#6-5-2-3-Service-Locator" class="headerlink" title="6.5.2.3 Service Locator"></a>6.5.2.3 Service Locator</h5><p>对于需要跨模块访问的核心服务，可以用 <strong>Service Locator 模式</strong>，统一注册与获取（如 get_it）：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注册</span></span><br><span class="line">getIt.registerLazySingleton&lt;AnalyticsService&gt;(() =&gt; FirebaseAnalyticsImpl());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取</span></span><br><span class="line"><span class="keyword">final</span> analytics = getIt&lt;AnalyticsService&gt;();</span><br><span class="line">analytics.logEvent(<span class="string">&quot;view_cart&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这样任意模块都可以通过 locator 获取服务，而无需导入实现模块。</p>
<blockquote>
<p>适用场景：全局单例；服务访问（日志、网络、配置）；模块解耦但需要共享能力。</p>
</blockquote>
<blockquote>
<p>建议：只注册接口类型；在主入口（如 app.dart）集中注册，避免分散初始化。</p>
</blockquote>
<h4 id="6-5-3-模块依赖图示例"><a href="#6-5-3-模块依赖图示例" class="headerlink" title="6.5.3 模块依赖图示例"></a>6.5.3 模块依赖图示例</h4><p>下面是一张简化依赖结构图：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">packages/</span><br><span class="line">├── shared/</span><br><span class="line">│   ├── logger.dart</span><br><span class="line">│   ├── event_bus.dart</span><br><span class="line">│   └── interfaces/</span><br><span class="line">│       ├── auth_service.dart</span><br><span class="line">│       └── cart_service.dart</span><br><span class="line">├── auth/</span><br><span class="line">│   └── auth_service_impl.dart  (implements AuthService)</span><br><span class="line">├── cart/</span><br><span class="line">│   └── cart_service_impl.dart  (implements CartService)</span><br><span class="line">└── app/</span><br><span class="line">    ├── main.dart</span><br><span class="line">    └── di_setup.dart  (统一注册所有服务)</span><br></pre></td></tr></table></figure>
<p>依赖方向：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">auth ──┐</span><br><span class="line">cart ──┼──▶ shared/interfaces</span><br><span class="line">app  ──┘</span><br></pre></td></tr></table></figure>

<p>每个模块 <strong>依赖 shared 接口层</strong>，而不是彼此直接调用。</p>
<h4 id="6-5-4-推荐组合策略"><a href="#6-5-4-推荐组合策略" class="headerlink" title="6.5.4 推荐组合策略"></a>6.5.4 推荐组合策略</h4><table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>推荐模式</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>模块需要稳定对接</td>
<td>Interface + DI</td>
<td>通过统一的接口定义模块间“对话规则”，方便长期维护与替换</td>
</tr>
<tr>
<td>一次性事件通知</td>
<td>Event Bus</td>
<td>模块之间以广播方式传递事件，不需要直接依赖</td>
</tr>
<tr>
<td>全局服务（日志、配置）</td>
<td>Service Locator</td>
<td>集中管理全局服务，任何模块都可按需获取</td>
</tr>
</tbody></table>
<p>在大型项目中，这三者常常<strong>组合使用</strong>：</p>
<ul>
<li>用 <strong>Interface</strong> 定义模块之间的“接口约定”**（比如登录模块要提供哪些方法、返回什么数据）；</li>
<li>用 <strong>EventBus</strong> 处理松散事件通知，不建立直接依赖关系；</li>
<li>用 <strong>Service Locator</strong> 统一管理全局服务，方便模块共享。</li>
</ul>
<blockquote>
<p>可以把 “Interface + DI” 理解成“模块之间签了合同”。只要遵守这份“接口约定”，实现方式怎么变都不影响其他模块。</p>
</blockquote>
<p>最终，整个项目结构会像这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">App（入口）</span><br><span class="line"> ├── features/</span><br><span class="line"> │   ├── auth</span><br><span class="line"> │   ├── cart</span><br><span class="line"> │   ├── catalog</span><br><span class="line"> │   └── checkout</span><br><span class="line"> ├── shared/</span><br><span class="line"> │   ├── interfaces</span><br><span class="line"> │   ├── utils</span><br><span class="line"> │   └── event_bus</span><br><span class="line"> └── di_setup.dart</span><br></pre></td></tr></table></figure>
<h2 id="7-数据层与错误处理"><a href="#7-数据层与错误处理" class="headerlink" title="7. 数据层与错误处理"></a>7. 数据层与错误处理</h2><p>在 Flutter 工程中，数据层（Data Layer）是应用的“供能系统”——它负责从外部世界（如网络、数据库、缓存）收集数据，转化为业务层可用的结构。</p>
<p>一个合理的数据层设计，既要 <strong>分层清晰</strong>、又要 <strong>抗风险可恢复</strong>。</p>
<h3 id="7-1-数据分层"><a href="#7-1-数据分层" class="headerlink" title="7.1 数据分层"></a>7.1 数据分层</h3><p>数据层通常分为三部分：</p>
<table>
<thead>
<tr>
<th><strong>层级</strong></th>
<th><strong>作用</strong></th>
<th><strong>类比</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>DTO（Data Transfer Object）</strong></td>
<td>负责与外部接口（API&#x2F;DB）通信的数据模型。</td>
<td>像邮差信封，装着原始数据格式。</td>
</tr>
<tr>
<td><strong>Repository</strong></td>
<td>负责封装数据获取逻辑：调用远程接口、本地缓存、转换成业务实体。</td>
<td>像“变压器”，把复杂电流（API 数据）转成稳定电源（业务数据）。</td>
</tr>
<tr>
<td><strong>UseCase（或 Service）</strong></td>
<td>对业务层提供具体操作接口，比如 “登录”、“获取用户资料”。</td>
<td>像“总开关”，决定什么时候供电、怎么供电。</td>
</tr>
</tbody></table>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DTO：原始数据模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserDTO</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> name;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">int</span> age;</span><br><span class="line">  UserDTO.fromJson(<span class="built_in">Map</span>&lt;<span class="built_in">String</span>, <span class="built_in">dynamic</span>&gt; json)</span><br><span class="line">      : name = json[<span class="string">&#x27;name&#x27;</span>],</span><br><span class="line">        age = json[<span class="string">&#x27;age&#x27;</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Entity：业务层模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserEntity</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> name;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">int</span> age;</span><br><span class="line">  UserEntity(<span class="keyword">this</span>.name, <span class="keyword">this</span>.age);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Repository：负责数据获取与转换</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserRepository</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ApiClient api;</span><br><span class="line">  <span class="keyword">final</span> LocalCache cache;</span><br><span class="line"></span><br><span class="line">  UserRepository(<span class="keyword">this</span>.api, <span class="keyword">this</span>.cache);</span><br><span class="line"></span><br><span class="line">  Future&lt;UserEntity&gt; getUserProfile() <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">final</span> json = <span class="keyword">await</span> api.<span class="keyword">get</span>(<span class="string">&#x27;/user&#x27;</span>);</span><br><span class="line">      <span class="keyword">final</span> dto = UserDTO.fromJson(json);</span><br><span class="line">      <span class="keyword">return</span> UserEntity(dto.name, dto.age);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">      <span class="comment">// 网络失败时从缓存兜底</span></span><br><span class="line">      <span class="keyword">final</span> cached = <span class="keyword">await</span> cache.<span class="keyword">get</span>(<span class="string">&#x27;user_profile&#x27;</span>);</span><br><span class="line">      <span class="keyword">if</span> (cached != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">final</span> dto = UserDTO.fromJson(cached);</span><br><span class="line">        <span class="keyword">return</span> UserEntity(dto.name, dto.age);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">rethrow</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样分层后，业务逻辑和数据来源解耦，测试、替换都更容易。</p>
<h3 id="7-2-错误分类与处理策略"><a href="#7-2-错误分类与处理策略" class="headerlink" title="7.2 错误分类与处理策略"></a>7.2 错误分类与处理策略</h3><p>在数据流转过程中，错误不可避免。好的架构要<strong>区分错误类型</strong>，并提供<strong>恰当的恢复策略</strong>。</p>
<table>
<thead>
<tr>
<th><strong>错误类型</strong></th>
<th><strong>典型场景</strong></th>
<th><strong>处理方式</strong></th>
</tr>
</thead>
<tbody><tr>
<td>网络错误</td>
<td>超时、断网、DNS 解析失败</td>
<td>重试 &#x2F; 提示“请检查网络”</td>
</tr>
<tr>
<td>业务错误</td>
<td>登录失败、权限不足</td>
<td>显示后端返回的业务信息</td>
</tr>
<tr>
<td>不可恢复错误</td>
<td>解码异常、逻辑异常</td>
<td>上报错误日志并终止流程</td>
</tr>
</tbody></table>
<p>例如：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Future&lt;<span class="keyword">void</span>&gt; fetchUser() <span class="keyword">async</span> &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> user = <span class="keyword">await</span> repo.getUserProfile();</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;User loaded: <span class="subst">$&#123;user.name&#125;</span>&#x27;</span>);</span><br><span class="line">  &#125; <span class="keyword">on</span> NetworkException &#123;</span><br><span class="line">    showToast(<span class="string">&#x27;网络连接失败，请重试&#x27;</span>);</span><br><span class="line">    retry(fetchUser); <span class="comment">// 简单重试机制</span></span><br><span class="line">  &#125; <span class="keyword">on</span> BusinessException <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">    showToast(<span class="string">&#x27;操作失败：<span class="subst">$&#123;e.message&#125;</span>&#x27;</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">    logError(e); <span class="comment">// 记录未知错误</span></span><br><span class="line">    showToast(<span class="string">&#x27;出现未知问题，请稍后重试&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="7-3-离线缓存（Offline-first）策略"><a href="#7-3-离线缓存（Offline-first）策略" class="headerlink" title="7.3 离线缓存（Offline-first）策略"></a>7.3 离线缓存（Offline-first）策略</h3><p>在移动端项目中，“离线缓存”是一种常见的设计：即使用户没网，也能看到最近一次的数据。</p>
<p>实现思路：</p>
<ol>
<li><strong>优先读取缓存</strong>（LocalCache）；</li>
<li><strong>后台静默刷新远程数据</strong>；</li>
<li><strong>更新 UI + 缓存同步</strong>。</li>
</ol>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">Future&lt;UserEntity&gt; getUserProfileOfflineFirst() <span class="keyword">async</span> &#123;</span><br><span class="line">  <span class="comment">// Step 1: 先读缓存（快速响应）</span></span><br><span class="line">  <span class="keyword">final</span> cached = <span class="keyword">await</span> cache.<span class="keyword">get</span>(<span class="string">&#x27;user_profile&#x27;</span>);</span><br><span class="line">  <span class="keyword">if</span> (cached != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">final</span> dto = UserDTO.fromJson(cached);</span><br><span class="line">    emit(UserEntity(dto.name, dto.age)); <span class="comment">// 先显示旧数据</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step 2: 后台请求更新（最新数据）</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> json = <span class="keyword">await</span> api.<span class="keyword">get</span>(<span class="string">&#x27;/user&#x27;</span>);</span><br><span class="line">    cache.save(<span class="string">&#x27;user_profile&#x27;</span>, json);</span><br><span class="line">    <span class="keyword">final</span> dto = UserDTO.fromJson(json);</span><br><span class="line">    <span class="keyword">return</span> UserEntity(dto.name, dto.age);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (_) &#123;</span><br><span class="line">    <span class="comment">// 如果失败就用缓存结果兜底</span></span><br><span class="line">    <span class="keyword">if</span> (cached != <span class="keyword">null</span>) <span class="keyword">return</span> UserEntity.fromJson(cached);</span><br><span class="line">    <span class="keyword">rethrow</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="7-4-数据层的演进方向"><a href="#7-4-数据层的演进方向" class="headerlink" title="7.4 数据层的演进方向"></a>7.4 数据层的演进方向</h3><p>随着业务复杂化，数据层常进一步引入：</p>
<ul>
<li><strong>统一错误模型</strong>（如 Failure 类层次结构）；</li>
<li><strong>响应式流数据</strong>（用 Stream 或 RxDart 实现实时更新）；</li>
<li><strong>全局缓存策略中心</strong>（集中管理本地存储与刷新规则）。</li>
</ul>
<p>这让数据层不仅仅是“拉数据”，而是成为应用<strong>稳定与恢复能力的中枢</strong>。</p>
<pre class="mermaid">graph TD
    A[UseCase / Service 层<br>业务逻辑入口] --> B[Repository 层<br>统一数据访问接口]
    B --> C[Remote Data Source<br>API 网络请求]
    B --> D[Local Data Source<br>本地缓存 / 数据库]

    C --> E[(REST API / GraphQL / SDK)]
    D --> F[(SharedPreferences / SQLite / Hive)]

    style A fill:#f9f9f9,stroke:#333,stroke-width:1px
    style B fill:#e8f5e9,stroke:#2e7d32,stroke-width:1px
    style C fill:#e3f2fd,stroke:#1565c0,stroke-width:1px
    style D fill:#fff8e1,stroke:#f9a825,stroke-width:1px
    style E fill:#bbdefb,stroke:#1565c0,stroke-width:0.5px
    style F fill:#fff59d,stroke:#f9a825,stroke-width:0.5px</pre>
<h2 id="8-团队协作与工程效率"><a href="#8-团队协作与工程效率" class="headerlink" title="8. 团队协作与工程效率"></a>8. 团队协作与工程效率</h2><p>现代 Flutter 工程不仅仅是代码堆叠，更是<strong>协作与效率系统的建设</strong>。尤其是当项目成员超过 3 人、模块超过 5 个时，代码一致性、工作流顺畅度、构建效率都会直接影响项目质量。<br>下面三个关键词展开：<strong>代码质量、工程效率、团队分工</strong>。</p>
<h3 id="8-1-代码质量：从风格到体系"><a href="#8-1-代码质量：从风格到体系" class="headerlink" title="8.1 代码质量：从风格到体系"></a>8.1 代码质量：从风格到体系</h3><h4 id="8-1-1-统一与共享组件库"><a href="#8-1-1-统一与共享组件库" class="headerlink" title="8.1.1 统一与共享组件库"></a>8.1.1 统一与共享组件库</h4><p>在中大型项目中，最先失控的往往是 UI —— 每个页面的按钮都“差不多但不一样”。解决方式是建立 <strong>Design System</strong>或共享 <strong>UI Kit</strong>，将视觉规范和交互逻辑固化为组件库。</p>
<p><strong>示例：共享 Button 组件</strong></p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppButton</span> <span class="keyword">extends</span> <span class="title">StatelessWidget</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">String</span> label;</span><br><span class="line">  <span class="keyword">final</span> VoidCallback onPressed;</span><br><span class="line">  <span class="keyword">final</span> <span class="built_in">bool</span> primary;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> AppButton(&#123;</span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.label,</span><br><span class="line">    <span class="keyword">required</span> <span class="keyword">this</span>.onPressed,</span><br><span class="line">    <span class="keyword">this</span>.primary = <span class="keyword">true</span>,</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Widget build(BuildContext context) &#123;</span><br><span class="line">    <span class="keyword">return</span> ElevatedButton(</span><br><span class="line">      style: ElevatedButton.styleFrom(</span><br><span class="line">        backgroundColor: primary ? Colors.blue : Colors.grey[<span class="number">200</span>],</span><br><span class="line">        foregroundColor: primary ? Colors.white : Colors.black87,</span><br><span class="line">        padding: <span class="keyword">const</span> EdgeInsets.symmetric(horizontal: <span class="number">16</span>, vertical: <span class="number">12</span>),</span><br><span class="line">        shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(<span class="number">8</span>)),</span><br><span class="line">      ),</span><br><span class="line">      onPressed: onPressed,</span><br><span class="line">      child: Text(label),</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以将这些基础组件集中放在 packages&#x2F;ui_kit 或 common&#x2F;widgets 下，并配合设计稿同步版本（Figma Token &#x2F; Style Dictionary）。</p>
</blockquote>
<h4 id="8-1-2-Lint-与格式化"><a href="#8-1-2-Lint-与格式化" class="headerlink" title="8.1.2 Lint 与格式化"></a>8.1.2 Lint 与格式化</h4><p>为了避免团队在命名、缩进、import 顺序上反复争论，推荐引入 <strong>Lint + 格式化工具链</strong>。</p>
<p>在 Flutter 工程根目录创建 analysis_options.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">include:</span> <span class="string">package:flutter_lints/flutter.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">linter:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="attr">avoid_print:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">prefer_const_constructors:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">always_specify_types:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">public_member_api_docs:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>配合 flutter format . 与 CI 自动检测，可避免风格分歧、节省 code review 成本。</p>
</blockquote>
<h4 id="8-1-3-Review-与-Commit-规范"><a href="#8-1-3-Review-与-Commit-规范" class="headerlink" title="8.1.3 Review 与 Commit 规范"></a>8.1.3 Review 与 Commit 规范</h4><p>团队开发中，“写完代码 → 提 PR → 自动检测 → 人工 review” 是高质量输出的关键链路。<br>推荐结合 <strong>Git 提交规范</strong>，保证历史记录可追踪：</p>
<table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>含义</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>feat:</td>
<td>新功能</td>
<td>feat(auth): add OAuth2 login</td>
</tr>
<tr>
<td>fix:</td>
<td>修复 Bug</td>
<td>fix(cart): wrong item count display</td>
</tr>
<tr>
<td>chore:</td>
<td>工程事务</td>
<td>chore(ci): update build script</td>
</tr>
<tr>
<td>refactor:</td>
<td>重构代码</td>
<td>refactor(ui): simplify button style</td>
</tr>
</tbody></table>
<blockquote>
<p>可在 CI 中用 commit lint 或 lefthook 校验提交信息格式。</p>
</blockquote>
<h3 id="8-2-工程效率：让开发节奏更顺畅"><a href="#8-2-工程效率：让开发节奏更顺畅" class="headerlink" title="8.2 工程效率：让开发节奏更顺畅"></a>8.2 工程效率：让开发节奏更顺畅</h3><h4 id="8-2-1-本地-Mock-Stub-数据源"><a href="#8-2-1-本地-Mock-Stub-数据源" class="headerlink" title="8.2.1 本地 Mock &#x2F; Stub 数据源"></a>8.2.1 本地 Mock &#x2F; Stub 数据源</h4><p>开发初期或后端未联调时，可使用 <strong>本地 mock 数据层</strong>：</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MockUserRepository</span> <span class="keyword">implements</span> <span class="title">UserRepository</span> </span>&#123;</span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  Future&lt;User&gt; fetchProfile() <span class="keyword">async</span> &#123;</span><br><span class="line">    <span class="keyword">await</span> Future.delayed(<span class="built_in">Duration</span>(milliseconds: <span class="number">400</span>));</span><br><span class="line">    <span class="keyword">return</span> User(id: <span class="string">&#x27;001&#x27;</span>, name: <span class="string">&#x27;Mock User&#x27;</span>, email: <span class="string">&#x27;mock@demo.com&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可通过依赖注入（DI）或配置文件在 mock &#x2F; prod 间快速切换，不影响业务逻辑与接口层。</p>
</blockquote>
<h4 id="8-2-2-热重载-模块化工作流"><a href="#8-2-2-热重载-模块化工作流" class="headerlink" title="8.2.2 热重载 + 模块化工作流"></a>8.2.2 热重载 + 模块化工作流</h4><p>Flutter 的 <strong>Hot Reload</strong> 是快速迭代的利器，但在大型工程中模块依赖多时，重编译成本会上升。</p>
<p>优化方法：</p>
<ul>
<li>将每个业务拆成 <strong>独立 package</strong>，可单独运行；</li>
<li>在根项目中通过 dependency_overrides 指定本地路径；</li>
<li>只 reload 当前模块，缩短启动时间。</li>
</ul>
<p>示例结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">packages/</span><br><span class="line">├── auth/</span><br><span class="line">├── catalog/</span><br><span class="line">├── cart/</span><br><span class="line">├── checkout/</span><br><span class="line">app/</span><br></pre></td></tr></table></figure>
<h4 id="8-2-3-CI-CD-自动化"><a href="#8-2-3-CI-CD-自动化" class="headerlink" title="8.2.3 CI&#x2F;CD 自动化"></a>8.2.3 CI&#x2F;CD 自动化</h4><p>在多人协作中，自动化管线（Pipeline）能显著减少“人工出错率”。</p>
<p><strong>GitHub Actions 示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">name: Flutter CI</span><br><span class="line"></span><br><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches: [ main ]</span><br><span class="line">  pull_request:</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/checkout@v4</span><br><span class="line">      - uses: subosito/flutter-action@v2</span><br><span class="line">      - run: flutter pub get</span><br><span class="line">      - run: flutter analyze</span><br><span class="line">      - run: flutter test</span><br><span class="line">      - run: flutter build apk --release</span><br></pre></td></tr></table></figure>

<blockquote>
<p>每次提交自动执行静态检查、单元测试与打包，确保主分支永远可用。</p>
</blockquote>
<h3 id="8-3-团队分工与协作模式"><a href="#8-3-团队分工与协作模式" class="headerlink" title="8.3 团队分工与协作模式"></a>8.3 团队分工与协作模式</h3><h4 id="8-3-1-模块负责人制"><a href="#8-3-1-模块负责人制" class="headerlink" title="8.3.1 模块负责人制"></a>8.3.1 模块负责人制</h4><p>每个模块（如 auth、cart、catalog）指定一名负责人，负责模块内部结构设计和公共接口定义，并且Review 该模块的所有改动。<br>这种方式能保证模块边界清晰、代码风格统一。</p>
<h4 id="8-3-2-接口契约与联调机制"><a href="#8-3-2-接口契约与联调机制" class="headerlink" title="8.3.2 接口契约与联调机制"></a>8.3.2 接口契约与联调机制</h4><p>Flutter 前端与后端的协作重点在于<strong>接口契约（API Contract）</strong>。<br>建议团队使用以下机制：</p>
<ul>
<li>OpenAPI &#x2F; Swagger 自动生成接口文档；</li>
<li>定义固定的 Response 模板；</li>
<li>前后端通过 Mock Server（如 Swagger Mock &#x2F; Postman）提前联调。</li>
</ul>
<h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>我们从一个简单的 Flutter 应用出发，逐步走过了整个工程化路径：</p>
<ul>
<li>从 <strong>状态管理</strong> 的规范化，到 <strong>依赖注入（DI）</strong> 的引入；</li>
<li>从 <strong>路由体系</strong> 的演进，到 <strong>模块化与包管理</strong> 的落地；</li>
<li>再到 <strong>数据层设计、错误处理</strong> 与 <strong>团队协作工具链</strong> 的建设。</li>
</ul>
<p>这些内容串联起来，构成了一个 Flutter 工程的“生命循环”—— 不仅仅是能跑起来的应用，而是一套 <strong>可协作、可扩展、可演进的系统</strong>。</p>
<p>在实际项目中，其实我们不需要一开始就做到全面工程化，更现实的做法是 <strong>渐进式演化</strong>：</p>
<ul>
<li>当页面增多时，引入全局路由表；</li>
<li>当逻辑复杂时，引入 DI 与模块拆分；</li>
<li>当团队扩张时，补齐 CI&#x2F;CD、Lint 与 Review 规范。</li>
</ul>
<p>就像盖房子一样—— 小项目像帐篷，随便搭都能住；大项目像大楼，必须有蓝图、分工和质量监理。当工程的地基（架构）、管道（依赖关系）、电路（数据流）都铺设完善，就会发现：无论团队怎么扩张、需求如何变化，这个系统都能稳稳运行。</p>
<p>Flutter 工程化的终点，不是追求复杂，而是让每一行代码都有序、可靠、可持续。</p>
<h2 id="10-备注"><a href="#10-备注" class="headerlink" title="10. 备注"></a>10. 备注</h2><p>环境：</p>
<ul>
<li>mac: 15.2</li>
<li>fluttter: 3.35.4</li>
</ul>
<p>参考：</p>
<ul>
<li><a href="https://docs.flutter.dev/">https://docs.flutter.dev/</a></li>
</ul>
<script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';	mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); </script>]]></content>
      <categories>
        <category>跨平台框架</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
        <tag>状态管理</tag>
        <tag>路由</tag>
        <tag>模块化</tag>
        <tag>依赖注入</tag>
      </tags>
  </entry>
  <entry>
    <title>A3C 算法原理与超级马里奥实践（上）</title>
    <url>/2025/08/22/028-rl-ac-a3c-mario-case-1/</url>
    <content><![CDATA[<h2 id="1-AC-算法"><a href="#1-AC-算法" class="headerlink" title="1. AC 算法"></a>1. AC 算法</h2><h3 id="1-1-策略梯度"><a href="#1-1-策略梯度" class="headerlink" title="1.1 策略梯度"></a>1.1 策略梯度</h3><p>在强化学习中，如果我们想让智能体学会这样一个 <strong>策略</strong>（在不同状态下选什么动作）:</p>
<ul>
<li>一个动作能带来高奖励，就要让它以后更可能被选上</li>
<li>一个动作只能带来低回报，就要减少使用它的频率</li>
</ul>
<p>而策略梯度就是一个这样的工具，<strong>“根据奖励信号，调整策略参数，让好动作更可能被选中，坏动作少被选上。”</strong></p>
<span id="more"></span>
<p>策略梯度，为什么要加上“梯度”？<br>因为我们的目标是如何最大化期望奖励：$J(\theta) &#x3D; \mathbb{E}{\pi\theta}[R]$。这就像爬山——目标是爬到“最大奖励”的山顶，梯度就是指引方向的指南针：告诉我们“往哪个方向改策略，奖励会变大”。</p>
<p>策略梯度的公式：<br>$$\nabla_\theta J(\theta) &#x3D; \mathbb{E}{\pi\theta}\Big[\nabla_\theta \log \pi_\theta(a|s) \cdot Q^\pi(s,a)\Big]$$</p>
<ul>
<li>$\nabla_\theta \log \pi_\theta(a|s)$：表示如果我要让动作 $a$ 在状态 $s$ 下更常出现，参数该怎么调整？简单来说就是一个方向提示</li>
<li>$Q^\pi(s,a)$：这个动作到底值不值得？也就是动作的分数</li>
</ul>
<p>整个公式的意思是：<strong>调整参数，让高价值动作出现概率上升，低价值动作出现概率下降。</strong></p>
<h3 id="1-2-奖励期望"><a href="#1-2-奖励期望" class="headerlink" title="1.2 奖励期望"></a>1.2 奖励期望</h3><p>在强化学习中，每次智能体执行动作，环境会给出一个奖励 $r$</p>
<ul>
<li><strong>累积奖励</strong> $R$ ：一条轨迹（episode）里所有奖励的总和，或者折扣累积总和</li>
<li><strong>奖励期望</strong>：按照当前策略 $\pi$ 执行动作，智能体在长期平均下来可以获得的奖励的期望值</li>
</ul>
<p>用公式表示为：$J(\theta) &#x3D; \mathbb{E}{\pi\theta}[R]$<br>意思就是：<strong>如果按照策略</strong> $\pi_\theta$ <strong>玩很多次游戏，平均每次能得到多少奖励</strong>。<br>举个例子，就像某人每天做菜会选择不同食谱，而奖励就是吃的满意度，如果后面一周一直按某种做菜策略选择食谱，<strong>奖励期望</strong>就是这一周的总满意度 &#x2F; 7。</p>
<h3 id="1-3-Baseline-的引入与-Critic-的作用"><a href="#1-3-Baseline-的引入与-Critic-的作用" class="headerlink" title="1.3 Baseline 的引入与 Critic 的作用"></a>1.3 Baseline 的引入与 Critic 的作用</h3><p>在<strong>策略梯度</strong>里，如果动作 $a$ 的回报 $Q^\pi(s,a)$ 高，就增加它的概率，如果回报低，就减少它的概率。<br>但问题是如果$Q^\pi(s,a)$ 的数值波动大（高方差），训练就会变得很不稳定。比如某人今天心情好奖励高，明天环境差奖励低，这样就会导致梯度的更新方向乱跳。</p>
<p>为了让更新更稳定，我们引入一个 <strong>基准线（baseline）</strong>，公式变为：<br>$$\nabla_\theta J(\theta) &#x3D; \mathbb{E}{\pi\theta}\big[ \nabla_\theta \log \pi_\theta(a|s) \cdot (Q^\pi(s,a) - V^\pi(s)) \big]$$<br>这里的 baseline 最常用就是 <strong>状态值函数</strong> $V^\pi(s)$。</p>
<ul>
<li>$Q^\pi(s,a)$：<strong>在状态</strong> $s$ <strong>下，选择动作</strong> $a$ <strong>的概率分布</strong>，然后按照策略 $\pi$ 继续执行，能得到的 <strong>长期累计奖励的期望</strong>，Q 值并不是在算概率，而是在算 <strong>某个具体动作一旦发生后的表现</strong></li>
<li>$V^\pi(s)$：在当前状态下，不指定动作，<strong>平均水平</strong>的表现</li>
<li>两者相减 $(Q^\pi(s,a) - V^\pi(s))$：就是“动作 $a$ 相比平均水平，到底好多少或差多少”</li>
</ul>
<p>这样一来，如果动作比平均水平好 → 增加概率，如果动作比平均水平差 → 降低概率，如果差不多 → 不用大幅调整。这样的更新更有针对性，方差也大大降低。</p>
<p> 以上策略也是<strong>Actor-Critic</strong> 架构的由来：</p>
<ul>
<li><strong>Actor（演员）</strong>：负责学策略 $\pi_\theta(a|s)$，输出“我下一步该怎么做”，像一个舞台演员，他想尝试各种表演动作（策略）</li>
<li><strong>Critic（评论家）</strong>：负责学状态值函数 $V^\pi(s)$，用作 baseline，给 Actor 一个“基准参考”，像观众&#x2F;评论家，给出“这个动作比一般水平好&#x2F;差多少”的评价</li>
</ul>
<p>有了 Critic 的反馈，Actor 就能更稳定地提升自己的表现。</p>
<p>原始策略梯度只看“绝对奖励” → 学习抖动大，而引入 baseline 让更新看“相对奖励” → 更平稳。Critic 的任务就是提供这个 baseline（通常是 $V^\pi(s)$）。<br>所以 Actor-Critic 的本质就是：<strong>Actor 负责决策，Critic 负责评价，二者协作使得学习更快更稳。</strong></p>
<h3 id="1-4-Q-值与回报的近似关系"><a href="#1-4-Q-值与回报的近似关系" class="headerlink" title="1.4 Q 值与回报的近似关系"></a>1.4 Q 值与回报的近似关系</h3><p>在强化学习里，<strong>Q 值</strong> $Q^\pi(s,a)$ 的意思是在状态 $s$ 下执行动作 $a$，然后继续按照策略 $\pi$ 行动，能得到的 <strong>长期累计奖励的期望</strong>。但问题是，这个“长期累计奖励”通常需要跑完整条轨迹（可能很长）才能算出来，在实际应用中（比如玩游戏、机器人控制），这样做代价太大。</p>
<p>于是，有人想了个聪明的办法：<strong>不用看那么远，先近似一下</strong>。<br>公式：<br>$$Q^\pi(s,a) \approx r(s,a) + \gamma V^\pi(s’)$$<br>你在 $s$ 状态下做了动作 $a$，立刻得到了一个 <strong>即时奖励</strong> $r(s,a)$，然后环境跳转到新状态 $s’$，在这个新状态下，你还能继续获得未来的奖励，未来的奖励我们就用 Critic 学到的 <strong>状态值函数</strong> $V^\pi(s’)$ 来估计，折扣因子 $\gamma$ 表示“未来的奖励要打点折扣，因为不确定性更大”。<br>换句话说：<strong>Q 值 ≈ 当前得到的奖励 + 未来可能奖励的估计</strong>。</p>
<p>打个比方，想象你投资一个项目：今天投进去 100 块（即时奖励），明天这个项目的价值取决于市场行情（下一个状态的价值），你关心的不是仅仅今天的收益，而是 <strong>今天赚多少 + 明天可能的未来价值</strong>，但未来越远越不确定，所以要打折（$\gamma$）。</p>
<p>这样做的好处是不用等完整一局游戏打完再更新，可以 <strong>在线学习</strong>，这样更新速度会更快，更符合实际应用（比如实时决策）。这其实就是 <strong>时序差分（Temporal Difference, TD）方法</strong> 的核心思想。</p>
<h3 id="1-5-优势函数的定义与意义"><a href="#1-5-优势函数的定义与意义" class="headerlink" title="1.5 优势函数的定义与意义"></a>1.5 优势函数的定义与意义</h3><p>优势函数定义：<br>$$A^\pi(s,a) &#x3D; Q^\pi(s,a) - V^\pi(s)$$</p>
<ul>
<li>$Q^\pi(s,a)$：表示“在状态 $s$ 下，做动作 $a$，然后继续执行策略 $\pi$，能得到的总回报”</li>
<li>$V^\pi(s)$：表示“在状态 $s$ 下，按照策略 $\pi$ 的平均水平，能得到的总回报”</li>
</ul>
<p>所以，$A^\pi(s,a)$ 就是 <strong>动作</strong> $a$ <strong>相比平均水平，到底好多少或差多少</strong>。</p>
<p>想象一个同学在学校里考试，考了 90 分（对应 $Q^\pi(s,a)$），班级平均分是 85 分（对应 $V^\pi(s)$），那么他的优势就是 90 - 85 &#x3D; +5。如果另一个同学考了 70 分，相比平均分 85，他的优势就是 70 - 85 &#x3D; -15。所以 <strong>优势函数本质上就是一个“相对好坏的评价标准”</strong>。</p>
<p>在策略梯度更新里，原始版本用的是 $Q^\pi(s,a)$，但有问题，它只告诉你动作的“绝对表现”，没告诉你“相对表现”。<br>举个例子：假设某状态下所有动作回报都很高（环境奖励普遍高），那你更新时可能会把所有动作概率都加大，其实没有意义。<br>引入优势函数后，就变成了只关心某个动作比“平均水平”好多少。好就增加概率，差就减少概率，如果差不多，就别乱调。这样更新方向更精准，学习更高效。</p>
<p>策略梯度的最终公式：<br>$$\nabla_\theta J(\theta) &#x3D; \mathbb{E}{\pi\theta}\big[ \nabla_\theta \log \pi_\theta(a|s) \cdot A^\pi(s,a) \big]$$</p>
<ul>
<li>$\nabla_\theta \log \pi_\theta(a|s)$：如果要多做这个动作，应该怎样调整参数</li>
<li>$A^\pi(s,a)$：这个动作值得多做还是少做</li>
</ul>
<p>合起来就是：<strong>往“有优势”的动作方向调整策略</strong>。</p>
<p>优势函数衡量了“一个动作相对于平均水平的好坏”，它让策略更新更精准、更稳定，是 Actor-Critic 系列算法的核心工具。</p>
<h3 id="1-6-Actor-与-Critic-的分工"><a href="#1-6-Actor-与-Critic-的分工" class="headerlink" title="1.6 Actor 与 Critic 的分工"></a>1.6 Actor 与 Critic 的分工</h3><ul>
<li><strong>Actor</strong>：根据策略 $\pi_\theta$ 选择动作，并通过梯度更新策略。</li>
<li><strong>Critic</strong>：估计状态值函数 $V^\pi(s)$，帮助构造 baseline，从而降低方差。</li>
<li><strong>优势函数 $A(s,a)$</strong>：把 Actor 的学习信号调节成“比平均水平好多少”，让训练更加高效。</li>
</ul>
<p>我们想最大化回报 $\mathbb{E}[R]$，于是引出 <strong>策略梯度方法</strong>，但带来了一个方差太大的问题。为了解决方差太大、训练不稳定的问题，自然引出了 <strong>Critic</strong> 的角色。Critic 通过学习状态值函数 $V^\pi(s)$，作为一个 <strong>baseline</strong>，帮助我们在更新策略时不直接依赖高方差的 $Q^\pi(s,a)$。进一步地，借助近似关系 $Q^\pi(s,a) \approx r + \gamma V^\pi(s’)$，Critic 估计的 $V$ 还能被用来间接构造 $Q$，从而让 Actor 的更新既可计算、又更稳定。</p>
<h2 id="2-优势函数深入解析"><a href="#2-优势函数深入解析" class="headerlink" title="2. 优势函数深入解析"></a>2. 优势函数深入解析</h2><p>在前面我们已经聊过策略梯度、baseline 以及 Actor-Critic，现在再看看 <strong>优势函数（Advantage Function）</strong> 。它其实是 Actor-Critic 中的一个关键工具，帮助我们判断 <strong>某个动作到底值不值得选</strong>。</p>
<h3 id="2-1-优势函数的定义"><a href="#2-1-优势函数的定义" class="headerlink" title="2.1 优势函数的定义"></a>2.1 优势函数的定义</h3><p>$$A^\pi(s,a) &#x3D; Q^\pi(s,a) - V^\pi(s)$$</p>
<ul>
<li><strong>$Q^\pi(s,a)$</strong>：在状态 $s$ 下执行动作 $a$，然后继续按照策略 $\pi$ 行动，能拿到的<strong>长期累计奖励的期望</strong>。可以理解为：<strong>“这个动作的绝对表现”</strong>。</li>
<li><strong>$V^\pi(s)$</strong>：在状态 $s$ 下，不管选什么动作，按照策略 $\pi$ 的整体水平，能拿到的平均回报。可以理解为：<strong>“这个状态下的平均水平”</strong>。</li>
</ul>
<p>于是，优势函数就是：“某个动作的表现” - “当前状态的平均表现”。</p>
<h3 id="2-2-Q-的近似"><a href="#2-2-Q-的近似" class="headerlink" title="2.2 Q 的近似"></a>2.2 Q 的近似</h3><p>在实际计算中，Q 值不好直接估。怎么办？<br>我们可以用 <strong>一步回报加上后续状态的价值</strong> 来近似：<br>$$Q^\pi(s,a) \approx r(s,a) + \gamma V^\pi(s’)$$<br>意思是：<strong>这次动作拿到的即时奖励 + 后续状态的价值折扣</strong>。</p>
<h3 id="2-3-优势函数的近似"><a href="#2-3-优势函数的近似" class="headerlink" title="2.3 优势函数的近似"></a>2.3 优势函数的近似</h3><p>把上面这个近似放进优势函数里：<br>$$A^\pi(s,a) \approx r(s,a) + \gamma V^\pi(s’) - V^\pi(s)$$<br>看出来没？我们只需要知道：</p>
<ul>
<li>当前的即时奖励 $r(s,a)$</li>
<li>下一步的价值 $V^\pi(s’)$</li>
<li>当前的价值 $V^\pi(s)$</li>
</ul>
<p>就能估出来优势函数。</p>
<p>这意味着我们根本不需要再去训练一个庞大的 Critic 来估 Q。只要 Critic 能学好 <strong>$V(s)$</strong>，我们就能间接得到 $Q$ 和 $A$。这就极大降低了复杂度。因为 $V(s)$ 只跟状态有关，估计起来比 $Q(s,a)$ （既依赖状态又依赖动作）要简单得多。</p>
<h2 id="3-A3C-中的计算流程"><a href="#3-A3C-中的计算流程" class="headerlink" title="3. A3C 中的计算流程"></a>3. A3C 中的计算流程</h2><h3 id="3-1-数据采集与轨迹生成"><a href="#3-1-数据采集与轨迹生成" class="headerlink" title="3.1 数据采集与轨迹生成"></a>3.1 数据采集与轨迹生成</h3><p>A3C 的核心思想之一是 <strong>多线程异步采集数据</strong>，即每个线程（worker）在环境里独立运行自己的 Actor，按照当前策略 π 采样动作。线程不断生成 <strong>状态-动作-奖励序列</strong>（trajectory），比如：$s_0, a_0, r_0, s_1, a_1, r_1, …, s_T$</p>
<p>异步采样优势：</p>
<ol>
<li>提高训练效率</li>
<li>避免单线程样本相关性太强导致训练不稳定</li>
<li>不同线程探索不同策略，增加策略多样性</li>
</ol>
<h3 id="3-2-优势函数计算（近似化原因）"><a href="#3-2-优势函数计算（近似化原因）" class="headerlink" title="3.2 优势函数计算（近似化原因）"></a>3.2 优势函数计算（近似化原因）</h3><p>前面讲过优势函数 $A^\pi(s,a) \approx r + \gamma V(s’) - V(s)$，可以理解为：“这次动作比平均水平多拿了多少分”。</p>
<p>如果只用一步回报，优势函数可能 <strong>噪声大</strong>，因为单步奖励可能波动很大。例如，你走了一步，突然踩到陷阱，$r$ 很小，但后续可能有大回报，单步估计会误导 Actor，策略更新不稳定。<br>n-step 回报就是折中方案：既考虑了短期奖励，也引入了未来价值的估计。公式是：<br>$$R_t^{(n)} &#x3D; r_t + \gamma r_{t+1} + \dots + \gamma^{n-1} r_{t+n-1} + \gamma^n V(s_{t+n})$$<br>然后优势函数用它计算：$A(s_t, a_t) &#x3D; R_t^{(n)} - V(s_t)$</p>
<h3 id="3-3-双网络更新（Actor-Critic）"><a href="#3-3-双网络更新（Actor-Critic）" class="headerlink" title="3.3 双网络更新（Actor + Critic）"></a>3.3 双网络更新（Actor + Critic）</h3><h4 id="3-3-1-Actor-更新：学会选好动作"><a href="#3-3-1-Actor-更新：学会选好动作" class="headerlink" title="3.3.1 Actor 更新：学会选好动作"></a>3.3.1 Actor 更新：学会选好动作</h4><p>公式：$L_\text{actor} &#x3D; - \log \pi(a|s) \cdot A(s,a)$<br>Actor 的任务就是学会策略 $π(a|s)$，让“好动作”更容易被选。<br>我们用优势函数 $A(s,a)$ 来告诉 Actor：        </p>
<ul>
<li>A &gt; 0 → 这个动作比平均水平好 → 提高它被选的概率</li>
<li>A &lt; 0 → 这个动作比平均水平差 → 降低它被选的概率</li>
</ul>
<h4 id="3-3-2-Critic-更新：学会评估状态"><a href="#3-3-2-Critic-更新：学会评估状态" class="headerlink" title="3.3.2 Critic 更新：学会评估状态"></a>3.3.2 Critic 更新：学会评估状态</h4><p>公式：$L_\text{critic} &#x3D; (R - V(s))^2$<br>Critic 负责估计状态价值 $V(s)$，告诉 Actor “当前状态的平均表现是多少”。<br>更新目标是尽量让 $V(s)$ 接近实际的 n-step 回报 R（即未来奖励的估计值）。</p>
<h4 id="3-3-3-Actor-Critic-共享主干网络"><a href="#3-3-3-Actor-Critic-共享主干网络" class="headerlink" title="3.3.3 Actor + Critic 共享主干网络"></a>3.3.3 Actor + Critic 共享主干网络</h4><p><strong>共享主干网络</strong>：卷积层或全连接层，用来提取状态特征，好处是避免重复计算，提升效率。<br><strong>两条分支</strong>：    </p>
<ol>
<li><strong>Actor 分支</strong>：输出动作概率 $π(a|s)$</li>
<li><strong>Critic 分支</strong>：输出状态价值 $V(s)$</li>
</ol>
<p>优势：状态表示一致，Actor 和 Critic 可以互相辅助；Critic 提供优势函数给 Actor，Actor 产生的策略又反过来指导 Critic 更新。</p>
<h3 id="3-4-稳定性问题与解决方案"><a href="#3-4-稳定性问题与解决方案" class="headerlink" title="3.4 稳定性问题与解决方案"></a>3.4 稳定性问题与解决方案</h3><p>A3C 的训练本质是异步更新，可能出现：</p>
<ul>
<li><strong>梯度噪声大</strong>：多个线程同时更新全局网络</li>
<li><strong>策略崩塌</strong>：Actor 在探索不足或优势估计不稳定时，策略可能退化</li>
</ul>
<p>解决方案：</p>
<ol>
<li><strong>异步多线程</strong>：各线程采样不同轨迹，互相平均梯度，减小方差</li>
<li><strong>优势函数减方差</strong>：用 $V(s)$ 做 baseline</li>
<li><strong>熵正则化（Entropy Regularization）</strong>：鼓励策略保持一定随机性，避免过早收敛$L_\text{entropy} &#x3D; -\beta \sum_a \pi(a|s) \log \pi(a|s)$</li>
</ol>
<p>A3C 就像多个小队同时在不同战场打仗，各自收集战况（数据），把战况汇报给总部（全局网络）更新策略。Critic 提供参考评分（优势函数），n-step 回报让评分更稳，熵正则保证队伍不太偏激。</p>
<h2 id="4-A3C-整体架构"><a href="#4-A3C-整体架构" class="headerlink" title="4. A3C 整体架构"></a>4. A3C 整体架构</h2><h3 id="4-1-与-AC-的关系"><a href="#4-1-与-AC-的关系" class="headerlink" title="4.1 与 AC 的关系"></a>4.1 与 AC 的关系</h3><ul>
<li><strong>AC（Actor-Critic）</strong>：单线程版本，Actor 负责策略 $π$，Critic 负责状态价值 $V(s)$。</li>
<li><strong>A3C（Asynchronous Advantage Actor-Critic）</strong>：在 AC 的基础上有两个关键增强：<ol>
<li><strong>Asynchronous（异步）</strong>：引入多线程异步更新，同时启动多个 <strong>本地 Actor-Critic</strong> 线程，每个线程在自己环境里采集数据，然后把梯度异步更新到全局网络；</li>
<li><strong>Advantage（优势函数）</strong>：不用直接学习 $Q(s,a)$，而是通过 $A(s,a) &#x3D; Q(s,a) - V(s)$ 来衡量动作相对好坏，从而降低方差、提升训练稳定性。</li>
</ol>
</li>
</ul>
<p>A3C &#x3D; “多人同时玩游戏，每个人自己练，同时把经验汇报给总部”，而 AC 只能一个人玩。</p>
<h3 id="4-2-全局网络-vs-本地网络"><a href="#4-2-全局网络-vs-本地网络" class="headerlink" title="4.2 全局网络 vs 本地网络"></a>4.2 全局网络 vs 本地网络</h3><p>A3C 有两个层次的网络：</p>
<ol>
<li><strong>全局网络（Global Network）</strong>，负责存储全局的策略 $π$ 和状态价值 $V(s)$，接收各线程上传的梯度，更新权重，充当“策略大脑”或总部</li>
<li><strong>本地网络（Local Network）</strong>，每个线程有自己一份副本，用于与环境交互采样，采集完数据后计算梯度，然后异步发送给全局网络，最后更新后同步全局网络的参数，保证策略一致</li>
</ol>
<p>全局网络是总部，本地网络是各个分队，每个分队都在前线收集信息、训练经验，然后把梯度发回总部，总部更新策略后再下发给各分队。</p>
<h3 id="4-3-异步更新流程"><a href="#4-3-异步更新流程" class="headerlink" title="4.3 异步更新流程"></a>4.3 异步更新流程</h3><p>整体流程可以拆成四步：</p>
<ol>
<li><strong>采集</strong>：每个线程独立与环境交互，生成 状态-动作-奖励序列</li>
<li><strong>梯度计算</strong>：用采集到的轨迹计算优势函数 $A(s,a)$，得到 Actor&#x2F;Critic 的梯度</li>
<li><strong>异步更新</strong>：把梯度发送给全局网络，更新全局策略和价值网络</li>
<li><strong>同步</strong>：本地线程把更新后的全局网络参数同步回来，继续采集下一轮数据</li>
</ol>
<p>就像“前线特工 → 发送报告 → 总部更新策略 → 特工拿到新指令再行动”，循环往复。</p>
<h3 id="4-4-多智能体并行的好处"><a href="#4-4-多智能体并行的好处" class="headerlink" title="4.4 多智能体并行的好处"></a>4.4 多智能体并行的好处</h3><ol>
<li><strong>降低样本相关性</strong>：单线程 AC 连续采样的数据强相关，容易导致训练不稳定，多线程采样的数据彼此独立或弱相关，梯度更新更稳健</li>
<li><strong>提升策略探索能力</strong>：每个线程探索不同状态、动作，能发现更多策略组合，避免单线程陷入局部最优</li>
</ol>
<h2 id="5-A3C-的损失函数"><a href="#5-A3C-的损失函数" class="headerlink" title="5. A3C 的损失函数"></a>5. A3C 的损失函数</h2><h3 id="5-1-策略损失（Policy-Loss）"><a href="#5-1-策略损失（Policy-Loss）" class="headerlink" title="5.1 策略损失（Policy Loss）"></a>5.1 策略损失（Policy Loss）</h3><p>公式：$L_{policy} &#x3D; - \log \pi(a|s) \cdot A(s,a)$<br>作用：让 Actor 学会选“好动作”，放大优势动作的概率，抑制劣势动作。</p>
<ul>
<li>优势函数 $A(s,a)$ &gt; 0 → 这个动作比平均水平好 → Actor 提高被选概率     </li>
<li>优势函数 $A(s,a)$ &lt; 0 → 动作比平均水平差 → Actor 降低被选概率</li>
</ul>
<p>Actor 就像一个决策者，优势函数是评分表。好动作分数高 → 多用，坏动作分数低 → 少用。</p>
<h3 id="5-2-价值损失（Value-Loss）"><a href="#5-2-价值损失（Value-Loss）" class="headerlink" title="5.2 价值损失（Value Loss）"></a>5.2 价值损失（Value Loss）</h3><p>公式：$L_{value} &#x3D; (R - V(s))^2$<br>作用：让 Critic 学会准确预测状态价值 V(s)，学会打分，减小估计误差。    </p>
<ul>
<li>Critic 给每个状态打分，R 是 n-step 回报的真实估计</li>
<li>V(s) 是 Critic 的预测        </li>
<li>损失函数是 MSE（均方误差），优化 V(s) 逼近真实回报</li>
</ul>
<p> Critic 是裁判，价值损失是校准评分表，让评分更准确，只有评分准确了，Actor 才能根据优势函数判断动作优劣。</p>
<h3 id="5-3-熵损失（Entropy-Loss）"><a href="#5-3-熵损失（Entropy-Loss）" class="headerlink" title="5.3 熵损失（Entropy Loss）"></a>5.3 熵损失（Entropy Loss）</h3><p>公式：$L_{entropy} &#x3D; -\sum_a \pi(a|s) \log \pi(a|s)$<br>作用：鼓励策略保持一定随机性，避免过早收敛到单一动作。</p>
<ul>
<li>如果策略过于确定（概率几乎集中在一个动作），探索能力下降</li>
<li>加入熵正则项，让策略保持多样性，提高探索能力</li>
</ul>
<p>熵损失就像给 Actor 一个“小小的冒险精神”，提醒它偶尔尝试新动作，不要只走老路。</p>
<h3 id="5-4-总体损失公式"><a href="#5-4-总体损失公式" class="headerlink" title="5.4 总体损失公式"></a>5.4 总体损失公式</h3><p>综合三项损失：$L &#x3D; L_{policy} + \alpha L_{value} + \beta L_{entropy}$</p>
<ul>
<li><strong>α</strong>：控制价值损失的重要性</li>
<li><strong>β</strong>：控制熵正则的重要性</li>
</ul>
<p>总损失就是三者的平衡，既保证策略学习正确，又让策略稳定且有探索性。</p>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>本文主要讲了 Actor-Critic (AC) 框架及其高效实现——Actor + Critic (A3C) 算法。核心内容可概括为以下几点：</p>
<h3 id="6-1-​策略梯度与基线（Baseline）的引入​"><a href="#6-1-​策略梯度与基线（Baseline）的引入​" class="headerlink" title="6.1 ​策略梯度与基线（Baseline）的引入​"></a>6.1 ​策略梯度与基线（Baseline）的引入​</h3><p>策略梯度的核心思想是<strong>通过梯度上升，调整策略参数，增加高回报动作的概率，减少低回报动作的概率</strong>，以最大化期望累积奖励。<br>直接使用动作价值 $Q^\pi(s,a)$ 进行更新会导致<strong>高方差</strong>，训练不稳定。引入状态价值函数 $V^\pi(s)$ 作为基线（Baseline），将更新基准从“绝对奖励”变为“相对优势”（即 $A^\pi(s,a) &#x3D; Q^\pi(s,a) - V^\pi(s)$），显著降低了方差，使学习过程更平稳、高效。</p>
<h3 id="6-2-​Actor-Critic-架构的分工​"><a href="#6-2-​Actor-Critic-架构的分工​" class="headerlink" title="6.2 ​Actor-Critic 架构的分工​"></a>6.2 ​Actor-Critic 架构的分工​</h3><p>​<strong>Actor（行动者）​</strong>​：负责执行策略 $\pi_\theta(a|s)$，并根据优势函数的信号更新策略，决定“如何行动”。<br>​<strong>Critic（评论者）​</strong>​：负责评估状态价值 $V^\pi(s)$，提供基线，并计算优势函数，扮演“评价者”的角色。<br>两者协作，形成了“行动-评价-更新”的闭环，这是AC系列算法的基石。</p>
<h3 id="6-3-​优势函数（Advantage-Function）的核心作用​"><a href="#6-3-​优势函数（Advantage-Function）的核心作用​" class="headerlink" title="6.3 ​优势函数（Advantage Function）的核心作用​"></a>6.3 ​优势函数（Advantage Function）的核心作用​</h3><p>优势函数 $A^\pi(s,a)$ 量化了<strong>特定动作相对于该状态下平均水平的优劣程度</strong>。<br>再通过时序差分（TD）思想，其计算被近似为 $A^\pi(s,a) \approx r(s,a) + \gamma V^\pi(s’) - V^\pi(s)$。这意味着只需训练一个估计 $V(s)$ 的Critic网络，即可同时得到$Q$值和优势函数，大大简化了架构和训练难度。</p>
<h3 id="6-4-A3C-算法的异步并行架构与创新​"><a href="#6-4-A3C-算法的异步并行架构与创新​" class="headerlink" title="6.4 A3C 算法的异步并行架构与创新​"></a>6.4 A3C 算法的异步并行架构与创新​</h3><p>A3C 在AC基础上引入了<strong>多线程异步并行</strong>的框架。每个线程拥有一个<strong>本地网络</strong>与环境交互、采集数据、计算梯度。 一个<strong>全局网络</strong>作为中央大脑，异步接收并聚合所有线程的梯度进行更新，随后将更新后的参数同步给各线程。</p>
<p>这种架构带来了两大核心优势：</p>
<ol>
<li><strong>数据来源多样化</strong>，降低了样本相关性，使训练更稳定</li>
<li><strong>效率极大提升</strong>，通过并行探索加快了学习速度</li>
</ol>
<h3 id="6-5-A3C-的损失函数与稳定化技术​"><a href="#6-5-A3C-的损失函数与稳定化技术​" class="headerlink" title="6.5 A3C 的损失函数与稳定化技术​"></a>6.5 A3C 的损失函数与稳定化技术​</h3><p>A3C的优化目标是一个综合损失函数，包含三项：</p>
<ul>
<li>​<strong>策略损失 ($L_{policy}$)​</strong>​：引导Actor根据优势函数优化策略</li>
<li>​<strong>价值损失 ($L_{value}$)​</strong>​：训练Critic更准确地估计状态价值</li>
<li>​<strong>熵正则项 ($L_{entropy}$)​</strong>​：鼓励探索，防止策略过早收敛到局部最优，是保障算法稳定性和性能的关键技术</li>
</ul>
<p>总而言之，从策略梯度到AC，再到A3C，其演进脉络清晰：​<strong>为了更稳定、更高效地求解强化学习问题</strong>。A3C通过<strong>优势函数</strong>解决了AC的方差问题，通过<strong>异步并行</strong>框架解决了效率和探索问题，通过<strong>熵正则化</strong>等技巧确保了稳定性，成为深度强化学习发展史上一个里程碑式的高效算法。</p>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>策略梯度</tag>
      </tags>
  </entry>
</search>
