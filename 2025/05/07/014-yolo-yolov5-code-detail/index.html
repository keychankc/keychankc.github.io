<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo-512x512.png" color="#222">
  <meta name="google-site-verification" content="jZ7dJJlouQrswxytAryX3LanLNrTthfFdMUkDJzRqIU">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.keychan.xyz","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="1.基本使用1.YOLOv5整体概述YOLOv5本质上是一个经过大量优化的工程项目，不像前几代那样有对应的学术论文。它主要是在YOLOv4的基础上做了更实用的工程改进，让使用者能更轻松地应用到实际场景中。主要有以下特点：  ​工程优化为主​ 没有官方论文，核心改进在于代码实现，比如训练效率、代码可读性 相比YOLOv4，工程结构更简洁，配置更直观，适合直接拿来训练自己的数据   ​使用体验升级​">
<meta property="og:type" content="article">
<meta property="og:title" content="[YOLO系列④] YOLOv5模型训练与流程解析">
<meta property="og:url" content="https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/index.html">
<meta property="og:site_name" content="KeyChan&#39;s blog">
<meta property="og:description" content="1.基本使用1.YOLOv5整体概述YOLOv5本质上是一个经过大量优化的工程项目，不像前几代那样有对应的学术论文。它主要是在YOLOv4的基础上做了更实用的工程改进，让使用者能更轻松地应用到实际场景中。主要有以下特点：  ​工程优化为主​ 没有官方论文，核心改进在于代码实现，比如训练效率、代码可读性 相比YOLOv4，工程结构更简洁，配置更直观，适合直接拿来训练自己的数据   ​使用体验升级​">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250503142232.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/yolov5s.onnx.png">
<meta property="article:published_time" content="2025-05-07T09:50:12.000Z">
<meta property="article:modified_time" content="2025-09-21T12:04:48.538Z">
<meta property="article:author" content="KeyChan">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="YOLO">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250503142232.png">


<link rel="canonical" href="https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/","path":"2025/05/07/014-yolo-yolov5-code-detail/","title":"[YOLO系列④] YOLOv5模型训练与流程解析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>[YOLO系列④] YOLOv5模型训练与流程解析 | KeyChan's blog</title>
  







<link rel="dns-prefetch" href="https://comment.mengyajia.com">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="KeyChan's blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KeyChan's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-随想"><a href="/think/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="nav-text">1.基本使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-YOLOv5%E6%95%B4%E4%BD%93%E6%A6%82%E8%BF%B0"><span class="nav-text">1.YOLOv5整体概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E8%AE%AD%E7%BB%83%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">2.训练自定义数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E4%B8%8B%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0"><span class="nav-text">2.下载预训练模型与配置参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-text">2.数据处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="nav-text">1.数据加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-text">2.数据增强</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-getitem"><span class="nav-text">1.__getitem__</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Mosaic-%E5%A2%9E%E5%BC%BA"><span class="nav-text">2.Mosaic 增强</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">3.网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">1.网络结构可视化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-ONNX%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="nav-text">1.ONNX模型导出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-ONNX%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">2.ONNX模型可视化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E9%85%8D%E7%BD%AE%E8%A7%A3%E8%AF%BB"><span class="nav-text">2.网络结构配置解读</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97"><span class="nav-text">1.核心模块</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-Conv%E6%A8%A1%E5%9D%97%EF%BC%88%E6%A0%87%E5%87%86%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%EF%BC%89"><span class="nav-text">1.Conv模块（标准卷积模块）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-C3%E6%A8%A1%E5%9D%97%EF%BC%88%E6%AE%8B%E5%B7%AE%E6%A8%A1%E5%9D%97%EF%BC%89"><span class="nav-text">2.C3模块（残差模块）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-SPPF%E6%A8%A1%E5%9D%97%EF%BC%88Spatial-Pyramid-Pooling-Fast%EF%BC%89"><span class="nav-text">3.SPPF模块（Spatial Pyramid Pooling - Fast）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-Concat%EF%BC%88%E7%89%B9%E5%BE%81%E6%8B%BC%E6%8E%A5%EF%BC%89"><span class="nav-text">4.Concat（特征拼接）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-%E4%B8%8A%E9%87%87%E6%A0%B7%E6%A8%A1%E5%9D%97%EF%BC%88nn-Upsample%EF%BC%89"><span class="nav-text">5.上采样模块（nn.Upsample）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-Detect"><span class="nav-text">5.Detect</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">2.网络结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90"><span class="nav-text">3.模型解析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="nav-text">1.模型构建</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E9%98%B6%E6%AE%B5"><span class="nav-text">2.前向传播阶段</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-forward-once"><span class="nav-text">3.forward_once</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-Detect-Segment-%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90"><span class="nav-text">4.Detect&#x2F;Segment 模块解析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-%E5%A2%9E%E5%BC%BA%E6%8E%A8%E7%90%86%EF%BC%88-forward-augment%EF%BC%89"><span class="nav-text">5.增强推理（_forward_augment）</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%AD%96%E7%95%A5"><span class="nav-text">4.训练流程与策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-text">1.训练流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E4%B8%8E%E6%96%87%E4%BB%B6%E4%BF%9D%E5%AD%98%E2%80%8B"><span class="nav-text">1.日志记录与文件保存​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96%E2%80%8B"><span class="nav-text">2. 模型加载与初始化​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%8E%E5%8A%A0%E8%BD%BD%E6%9D%83%E9%87%8D"><span class="nav-text">3.模型构建与加载权重</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%86%BB%E7%BB%93%E5%B1%82%E8%AE%BE%E7%BD%AE"><span class="nav-text">4.迁移学习与冻结层设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%A2%AF%E5%BA%A6%E7%B4%AF%E7%A7%AF%E6%9C%BA%E5%88%B6%EF%BC%9Anbs-%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-text">5.梯度累积机制：nbs 参数的作用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%8E%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6"><span class="nav-text">6.优化器与学习率调度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5"><span class="nav-text">2.训练策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%96%AD%E7%82%B9%E7%BB%AD%E8%AE%AD%E9%80%BB%E8%BE%91"><span class="nav-text">1.断点续训逻辑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%9B%BE%E5%83%8F%E5%B0%BA%E5%AF%B8%E6%A0%A1%E9%AA%8C%E9%80%BB%E8%BE%91%EF%BC%88gs-%E6%A3%80%E6%9F%A5%EF%BC%89"><span class="nav-text">2.图像尺寸校验逻辑（gs 检查）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-EMA%EF%BC%88%E6%BB%91%E5%8A%A8%E5%B9%B3%E5%9D%87%EF%BC%89%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-text">3.EMA（滑动平均）机制的作用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E6%80%BB%E7%BB%93"><span class="nav-text">5.总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KeyChan"
      src="/images/key_avatar.png">
  <p class="site-author-name" itemprop="name">KeyChan</p>
  <div class="site-description" itemprop="description">全干工程师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">49</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/keychankc" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kckeychan@gmail.com" title="E-Mail → mailto:kckeychan@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/keychankc" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/key_avatar.png">
      <meta itemprop="name" content="KeyChan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeyChan's blog">
      <meta itemprop="description" content="全干工程师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="[YOLO系列④] YOLOv5模型训练与流程解析 | KeyChan's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [YOLO系列④] YOLOv5模型训练与流程解析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-07 17:50:12" itemprop="dateCreated datePublished" datetime="2025-05-07T17:50:12+08:00">2025-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-21 20:04:48" itemprop="dateModified" datetime="2025-09-21T20:04:48+08:00">2025-09-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/05/07/014-yolo-yolov5-code-detail/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/05/07/014-yolo-yolov5-code-detail/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>27 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="1-基本使用"><a href="#1-基本使用" class="headerlink" title="1.基本使用"></a>1.基本使用</h2><h3 id="1-YOLOv5整体概述"><a href="#1-YOLOv5整体概述" class="headerlink" title="1.YOLOv5整体概述"></a>1.YOLOv5整体概述</h3><p>YOLOv5本质上是一个经过大量优化的<strong>工程项目</strong>，不像前几代那样有对应的学术论文。它主要是在YOLOv4的基础上做了更实用的工程改进，让使用者能更轻松地应用到实际场景中。主要有以下特点：</p>
<ol>
<li>​<strong>工程优化为主</strong>​<ul>
<li>没有官方论文，核心改进在于代码实现，比如训练效率、代码可读性</li>
<li>相比YOLOv4，工程结构更简洁，配置更直观，适合直接拿来训练自己的数据</li>
</ul>
</li>
<li>​<strong>使用体验升级</strong>​<ul>
<li>作者把数据增强、模型结构（如CSP、SPP模块）等复杂逻辑封装得很好，使用者几乎不用改代码</li>
<li>支持混合精度训练，训练速度更快，对硬件要求更友好</li>
</ul>
</li>
</ol>
<span id="more"></span>
<ol start="3">
<li>​<strong>简化训练自定义数据</strong>​<ul>
<li>不需要用庞大的COCO数据集，准备好自己的标注数据（格式和目录按规范整理）就能直接开跑</li>
<li>数据增强、模型配置都通过配置文件（YAML）管理，改几个参数就能适配不同任务</li>
</ul>
</li>
<li>​<strong>代码简洁</strong>​<ul>
<li>相比YOLOv3&#x2F;v4的“堆料式”代码，V5的代码结构清晰，模块化程度高，容易二次开发</li>
<li>项目文档详细，从安装到训练、测试都有现成指令，能快速上手</li>
</ul>
</li>
</ol>
<p>YOLOv5 的代码量虽然多一点，但设计非常细致、实用，并且持续更新维护，不同于很多“一发论文就停止维护”的学术项目。</p>
<h3 id="2-训练自定义数据集"><a href="#2-训练自定义数据集" class="headerlink" title="2.训练自定义数据集"></a>2.训练自定义数据集</h3><p>如何训练自定义数据集，可分为三步：</p>
<ol>
<li>下载（准备）标注好的数据集</li>
<li>按指定文件夹结构存放</li>
<li>改配置文件里的路径和类别数</li>
</ol>
<p>训练数据也可以从<a target="_blank" rel="noopener" href="https://public.roboflow.com/">Roboflow</a>上下载，<strong>Roboflow</strong>​ 是一个面向开发者和企业的端到端计算机视觉（CV）开发平台，可以帮助用户高效构建、训练、部署和管理AI视觉模型，上面也有多个轻量级的目标检测数据集（如手写数字、象棋、扑克牌、口罩等），比较适合单机或低配置训练。</p>
<p>我们选择<a target="_blank" rel="noopener" href="https://public.roboflow.com/object-detection/mask-wearing/4">口罩数据集</a>，下载的时候选择格式为 <strong>YOLOv5 PyTorch</strong>（.txt 标签格式），下载后将数据集解压到与 YOLOv5 源码（如 yolov5-master）同级目录下，例如：mask_wearing_data。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mask<span class="emphasis">_wearing_</span>data/</span><br><span class="line">├── train/</span><br><span class="line">│   ├── images/  # 训练图片</span><br><span class="line">│   └── labels/  # 对应txt标注文件</span><br><span class="line">├── valid/       # 验证集（结构同train）</span><br><span class="line">├── test/        # 测试集（结构同train）</span><br><span class="line">└── data.yaml    # 配置文件（改路径和类别数就用它）</span><br></pre></td></tr></table></figure>
<p>配置文件（data.yaml）需要指定图像路径、标签路径、类别数（如口罩数据集为2类：戴口罩 &#x2F; 未戴口罩）。    </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">data.yaml/</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">../mask_wearing_data/train/images</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">../mask_wearing_data/valid/images</span></span><br><span class="line"><span class="attr">test:</span> <span class="string">../mask_wearing_data/test/images</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;mask&#x27;</span>, <span class="string">&#x27;no-mask&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>标签为 .txt 格式，第一列是类别编号，后四列是归一化后的边框坐标（YOLO格式）。标签文件需与图片文件名对应，如果想定义自己的数据集可以参考这个数据格式。</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">126202-untitled-design-13_jpg.rf.baa3d2e55d469ae5d5d4cd81c4603e1d.txt</span><br><span class="line"></span><br><span class="line">0 0.855119825708061 0.18280632411067194 0.15250544662309368 0.3458498023715415</span><br><span class="line">0 0.6726579520697168 0.48023715415019763 0.21895424836601307 0.5612648221343873</span><br><span class="line">0 0.48257080610021785 0.35276679841897235 0.1895424836601307 0.44861660079051385</span><br><span class="line">0 0.2587145969498911 0.5632411067193676 0.17973856209150327 0.41106719367588934</span><br><span class="line">0 0.09477124183006536 0.41699604743083 0.18082788671023964 0.5217391304347826</span><br></pre></td></tr></table></figure>
<p>YOLOv5 会在训练时自动生成缓存文件（如 .cache），提高后续训练速度。</p>
<h3 id="2-下载预训练模型与配置参数"><a href="#2-下载预训练模型与配置参数" class="headerlink" title="2.下载预训练模型与配置参数"></a>2.下载预训练模型与配置参数</h3><p>YOLOv5给我们提供了很多预训练模型，这些模型在参数量、计算量和性能上都有所区别，主要面向不同的应用场景和硬件需求。模型名称后缀越大，参数量越多，精度越高，但训练速度会越慢：</p>
<ul>
<li>​<strong>YOLOv5n</strong>​（Nano）<ul>
<li>参数量：约 1.9M</li>
<li>计算量：约 4.5 GFLOPs</li>
<li>适用场景：​<strong>移动端&#x2F;嵌入式设备</strong>​（如 Jetson Nano、树莓派）或对实时性要求极高的场景。</li>
</ul>
</li>
<li>​<strong>YOLOv5s</strong>​（Small）<ul>
<li>参数量：约 7.2M</li>
<li>计算量：约 16.5 GFLOPs</li>
<li>适用场景：​<strong>轻量级通用检测</strong>，平衡速度与精度，适合边缘计算设备（如 Jetson TX2）。</li>
</ul>
</li>
<li>​<strong>YOLOv5m</strong>​（Medium）<ul>
<li>参数量：约 21.2M</li>
<li>计算量：约 49.0 GFLOPs</li>
<li>适用场景：​<strong>通用场景下的实时检测</strong>​（如视频监控、无人机航拍）。</li>
</ul>
</li>
<li>​<strong>YOLOv5l</strong>​（Large）<ul>
<li>参数量：约 46.5M</li>
<li>计算量：约 109.1 GFLOPs</li>
<li>适用场景：​<strong>服务器端或高性能 GPU</strong>，对精度要求较高的任务。</li>
</ul>
</li>
<li>​<strong>YOLOv5x</strong>​（X-Large）<ul>
<li>参数量：约 86.7M</li>
<li>计算量：约 205.7 GFLOPs</li>
<li>适用场景：​<strong>研究或高精度需求场景</strong>​（如医学图像分析、卫星图像检测）。</li>
</ul>
</li>
</ul>
<p>一般我们在学习和测试的时候建议先用 yolov5s，好处是小模型、十几 MB，训练速度快一些。</p>
<p>使用<code>train.py</code>训练当前自定义数据集<code>mask_wearing_data</code>命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --data ../mask_wearing_data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --batch-size 16 --freeze 10 --epochs 10    </span><br></pre></td></tr></table></figure>

<p>如果命令在运行的时候判断如果指定模型结构还没有下载预训练模型就会自动下载到项目根目录。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>--data</code></td>
<td>指定数据配置文件 <code>data.yaml</code>，描述数据集路径、类别数、类别名称等信息</td>
</tr>
<tr>
<td><code>--cfg</code></td>
<td>指定模型结构配置文件 <code>yolov5s.yaml</code>，定义 YOLOv5s 的网络结构</td>
</tr>
<tr>
<td><code>--weight</code></td>
<td>使用yolov5s预训练权重，可加速收敛并提升精度</td>
</tr>
<tr>
<td><code>--batch-size</code></td>
<td>设置每个批次的样本数为 16，影响训练速度和显存占用</td>
</tr>
<tr>
<td><code>--freeze</code></td>
<td>冻结骨干网络的前 10 层，减少计算量</td>
</tr>
<tr>
<td><code>--epochs</code></td>
<td>训练轮数</td>
</tr>
</tbody></table>
<p>最后的一个Epoch+summary日志：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250503142232.png"></p>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h2><p>下面就来分析一下YOLOv5的代码，看看如何实现，如何加载数据集， 数据增强特别是 Mosaic 的实现逻辑，最终返回可用于训练的数据与标签</p>
<h3 id="1-数据加载"><a href="#1-数据加载" class="headerlink" title="1.数据加载"></a>1.数据加载</h3><p> <code>utils/dataloaders.py</code> 文件是 YOLOv5 的数据加载和处理模块，支持多种训练和推理场景，大致包含以下主要功能：</p>
<ol>
<li>​<strong>数据加载器</strong>​：支持图像&#x2F;视频文件、实时视频流、屏幕截图及分类数据集的加载（<code>LoadImages</code>&#x2F;<code>LoadStreams</code>&#x2F;<code>LoadImagesAndLabels</code>等）</li>
<li>​<strong>预处理与增强</strong>​：包含图像缩放、填充、Mosaic&#x2F;MixUp增强、随机透视变换、HSV调整等，支持训练时动态数据增强</li>
<li>​<strong>视频处理</strong>​：多线程处理本地视频、YouTube流和IP摄像头，实现高效帧读取</li>
<li>​<strong>数据集管理</strong>​：提供缓存机制、数据集验证、自动分割（训练&#x2F;验证&#x2F;测试）及统计信息生成（<code>HUBDatasetStats</code>）</li>
<li>​<strong>分布式训练支持</strong>​：通过<code>SmartDistributedSampler</code>实现多GPU数据分配，确保数据加载与并行训练协调</li>
<li>​<strong>格式转换工具</strong>​：自动转换图像路径到标签路径、处理EXIF信息、验证数据合法性（<code>verify_image_label</code>）</li>
<li>​<strong>性能优化</strong>​：采用内存&#x2F;磁盘缓存、多线程加载、批处理优化（如四合一拼接）加速数据流水线</li>
<li>​<strong>错误处理</strong>​：检测损坏图像&#x2F;标签，记录异常并跳过无效数据，保障训练稳定性</li>
<li>​<strong>分类任务扩展</strong>​：专用<code>ClassificationDataset</code>支持图像分类数据加载与增强</li>
<li>​<strong>导出与兼容性</strong>​：支持数据集压缩、格式转换及统计报告生成，便于模型部署和迁移</li>
</ol>
<p>如何取数据，来看看<code>create_dataloader</code>的各个参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">utils/dataloaders.py</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">  </span></span><br><span class="line"><span class="params">    path,  <span class="comment"># 数据集路径</span></span></span><br><span class="line"><span class="params">    imgsz,  <span class="comment"># 输入图像的尺寸（如640表示图像会被调整为 640x640）</span></span></span><br><span class="line"><span class="params">    batch_size,  <span class="comment"># 每个批次的样本数量</span></span></span><br><span class="line"><span class="params">    stride,  <span class="comment"># 模型的下采样步长（用于调整标签尺寸）</span></span></span><br><span class="line"><span class="params">    single_cls=<span class="literal">False</span>,  <span class="comment"># 是否将所有类别视为同一类别（用于单类别任务）</span></span></span><br><span class="line"><span class="params">    hyp=<span class="literal">None</span>,  <span class="comment"># 超参数字典（包含数据增强相关的参数）</span></span></span><br><span class="line"><span class="params">    augment=<span class="literal">False</span>,  <span class="comment"># 是否启用数据增强</span></span></span><br><span class="line"><span class="params">    cache=<span class="literal">False</span>,  <span class="comment"># 是否缓存图像到内存或磁盘（加速后续加载）</span></span></span><br><span class="line"><span class="params">    pad=<span class="number">0.0</span>,  <span class="comment"># 图像填充比例（用于矩形训练）</span></span></span><br><span class="line"><span class="params">    rect=<span class="literal">False</span>,  <span class="comment"># 是否使用矩形批次（非方形图像，减少填充）</span></span></span><br><span class="line"><span class="params">    rank=-<span class="number">1</span>,  <span class="comment"># 分布式训练的进程排名（-1表示非分布式）</span></span></span><br><span class="line"><span class="params">    workers=<span class="number">8</span>,  <span class="comment"># 数据加载的子进程数</span></span></span><br><span class="line"><span class="params">    image_weights=<span class="literal">False</span>,  <span class="comment"># 是否根据类别分布对图像进行加权采样</span></span></span><br><span class="line"><span class="params">    quad=<span class="literal">False</span>,  <span class="comment"># 是否使用四合一拼接的数据加载（用于更大的批次）</span></span></span><br><span class="line"><span class="params">    prefix=<span class="string">&quot;&quot;</span>,  <span class="comment"># 日志信息的前缀（用于调试）</span></span></span><br><span class="line"><span class="params">    shuffle=<span class="literal">False</span>,  <span class="comment"># 是否打乱数据顺序</span></span></span><br><span class="line"><span class="params">    seed=<span class="number">0</span>,  <span class="comment"># 随机种子</span></span></span><br><span class="line"><span class="params"></span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates and returns a configured DataLoader instance for loading and processing image datasets.&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="keyword">if</span> rect <span class="keyword">and</span> shuffle:</span><br><span class="line">        LOGGER.warning(<span class="string">&quot;WARNING ⚠️ --rect is incompatible with DataLoader shuffle, setting shuffle=False&quot;</span>)  </span><br><span class="line">        <span class="comment"># 如果启用矩形训练（rect=True），则强制关闭shuffle（因为矩形批次需要固定顺序）</span></span><br><span class="line">        shuffle = <span class="literal">False</span>  </span><br><span class="line">    <span class="comment">#  确保在分布式训练中，数据集缓存（如.cache文件）只由rank=0的进程生成一次</span></span><br><span class="line">    <span class="keyword">with</span> torch_distributed_zero_first(rank):</span><br><span class="line">	    <span class="comment"># 负责加载图像和标签，支持数据增强、缓存、矩形训练等功能，内部会解析标签文件（如 YOLO 格式的.txt），调整图像尺寸，并应用增强（如旋转、缩放等）</span></span><br><span class="line">        dataset = LoadImagesAndLabels(  </span><br><span class="line">            path,  </span><br><span class="line">            imgsz,  </span><br><span class="line">            batch_size,  </span><br><span class="line">            augment=augment,  <span class="comment"># augmentation  </span></span><br><span class="line">            hyp=hyp,  <span class="comment"># hyperparameters  </span></span><br><span class="line">            rect=rect,  <span class="comment"># rectangular batches  </span></span><br><span class="line">            cache_images=cache,  </span><br><span class="line">            single_cls=single_cls,  </span><br><span class="line">            stride=<span class="built_in">int</span>(stride),  </span><br><span class="line">            pad=pad,  </span><br><span class="line">            image_weights=image_weights,  </span><br><span class="line">            prefix=prefix,  </span><br><span class="line">            rank=rank,  </span><br><span class="line">        )  </span><br><span class="line">  </span><br><span class="line">    batch_size = <span class="built_in">min</span>(batch_size, <span class="built_in">len</span>(dataset))  </span><br><span class="line">    nd = torch.cuda.device_count()  <span class="comment"># number of CUDA devices  </span></span><br><span class="line">    <span class="comment"># 计算实际使用的子进程数nw，考虑 CPU 核心数、GPU 数量和批次大小</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count() // <span class="built_in">max</span>(nd, <span class="number">1</span>), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, workers])</span><br><span class="line">    <span class="comment"># ​配置分布式采样器，分布式训练支持​，如果rank != -1（分布式训练），使用 SmartDistributedSampler 分配数据到各进程；否则不使用采样器</span></span><br><span class="line">    sampler = <span class="literal">None</span> <span class="keyword">if</span> rank == -<span class="number">1</span> <span class="keyword">else</span> SmartDistributedSampler(dataset, shuffle=shuffle)  </span><br><span class="line">    <span class="comment"># 选择DataLoader类型，使用标准DataLoader（支持动态权重更新）；否则使用InfiniteDataLoader（无限循环迭代数据）</span></span><br><span class="line">    loader = DataLoader <span class="keyword">if</span> image_weights <span class="keyword">else</span> InfiniteDataLoader</span><br><span class="line">    <span class="comment"># 通过generator控制数据加载的随机性，确保实验可复现</span></span><br><span class="line">    generator = torch.Generator()  </span><br><span class="line">    generator.manual_seed(<span class="number">6148914691236517205</span> + seed + RANK)  </span><br><span class="line">    <span class="keyword">return</span> loader(  </span><br><span class="line">        dataset,  </span><br><span class="line">        batch_size=batch_size,  </span><br><span class="line">        shuffle=shuffle <span class="keyword">and</span> sampler <span class="keyword">is</span> <span class="literal">None</span>,  </span><br><span class="line">        num_workers=nw,  </span><br><span class="line">        sampler=sampler,  </span><br><span class="line">        <span class="comment"># 是否丢弃不完整的批次（quad时启用）</span></span><br><span class="line">        drop_last=quad,  </span><br><span class="line">        <span class="comment"># 是否将数据固定到内存（加速 GPU 传输）</span></span><br><span class="line">        pin_memory=PIN_MEMORY,  </span><br><span class="line">        <span class="comment"># 处理批次数据的函数（quad时使用四合一拼接的collate_fn4）</span></span><br><span class="line">        collate_fn=LoadImagesAndLabels.collate_fn4 <span class="keyword">if</span> quad <span class="keyword">else</span> LoadImagesAndLabels.collate_fn,</span><br><span class="line">        <span class="comment"># 进程的初始化函数（seed_worker 设置子进程的随机种子）</span></span><br><span class="line">        worker_init_fn=seed_worker,  </span><br><span class="line">        generator=generator,  </span><br><span class="line">    ), dataset</span><br></pre></td></tr></table></figure>

<p>返回值：</p>
<ol>
<li><strong>loader</strong>:  配置好的 DataLoader 实例，用于迭代训练数据</li>
<li>​<strong>dataset</strong>:  数据集对象，可用于获取样本数、类别数等元信息</li>
</ol>
<h3 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2.数据增强"></a>2.数据增强</h3><p>数据和标签已经准备好了接下来要读取每一个样本并进行处理（如数据增强）<br>整体流程如下：</p>
<ol>
<li>调用 <code>__getitem__</code> 加载图像</li>
<li>判断是否启用 Mosaic 增强</li>
<li>随机设定 Mosaic 中心点</li>
<li>拼接 4 张图像（1 当前索引 + 3 随机图）</li>
<li>将图像和标签重新组合，作为一个新的训练样本返回</li>
</ol>
<h4 id="1-getitem"><a href="#1-getitem" class="headerlink" title="1.__getitem__"></a>1.<code>__getitem__</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Fetches the dataset item at the given index, considering linear, shuffled, or weighted sampling.&quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="comment"># 采样策略适配,根据预设的采样策略（线性/随机/加权）转换索引，支持多种数据加载模式</span></span><br><span class="line">    index = <span class="variable language_">self</span>.indices[index]  <span class="comment"># linear, shuffled, or image_weights  </span></span><br><span class="line">  </span><br><span class="line">    hyp = <span class="variable language_">self</span>.hyp  </span><br><span class="line">    <span class="comment"># Mosaic增强，概率性启用Mosaic</span></span><br><span class="line">    <span class="keyword">if</span> mosaic := <span class="variable language_">self</span>.mosaic <span class="keyword">and</span> random.random() &lt; hyp[<span class="string">&quot;mosaic&quot;</span>]:  </span><br><span class="line">        <span class="comment"># 加载4图拼接的大图及标签</span></span><br><span class="line">        img, labels = <span class="variable language_">self</span>.load_mosaic(index)  </span><br><span class="line">        shapes = <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 以hyp[&quot;mixup&quot;]概率叠加另一张Mosaic图，增强目标混合效果</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;mixup&quot;</span>]:  </span><br><span class="line">            img, labels = mixup(img, labels, *<span class="variable language_">self</span>.load_mosaic(random.choice(<span class="variable language_">self</span>.indices)))  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        <span class="comment"># Load image  </span></span><br><span class="line">        img, (h0, w0), (h, w) = <span class="variable language_">self</span>.load_image(index)  </span><br><span class="line">        <span class="comment"># Letterbox 调整 </span></span><br><span class="line">        shape = <span class="variable language_">self</span>.batch_shapes[<span class="variable language_">self</span>.batch[index]] <span class="keyword">if</span> <span class="variable language_">self</span>.rect <span class="keyword">else</span> <span class="variable language_">self</span>.img_size  <span class="comment"># final letterboxed shape  </span></span><br><span class="line">        img, ratio, pad = letterbox(img, shape, auto=<span class="literal">False</span>, scaleup=<span class="variable language_">self</span>.augment)  </span><br><span class="line">        shapes = (h0, w0), ((h / h0, w / w0), pad)  <span class="comment"># for COCO mAP rescaling  </span></span><br><span class="line">  </span><br><span class="line">        labels = <span class="variable language_">self</span>.labels[index].copy()  </span><br><span class="line">        <span class="comment"># 标签坐标转换</span></span><br><span class="line">        <span class="keyword">if</span> labels.size:  <span class="comment"># normalized xywh to pixel xyxy format  </span></span><br><span class="line">            labels[:, <span class="number">1</span>:] = xywhn2xyxy(labels[:, <span class="number">1</span>:], ratio[<span class="number">0</span>] * w, ratio[<span class="number">1</span>] * h, padw=pad[<span class="number">0</span>], padh=pad[<span class="number">1</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.augment:  </span><br><span class="line">            <span class="comment"># 数据增强：随机透视变换（旋转/缩放/平移/剪切/透视）（opencv实现）</span></span><br><span class="line">            img, labels = random_perspective(  </span><br><span class="line">                img,  </span><br><span class="line">                labels,  </span><br><span class="line">                degrees=hyp[<span class="string">&quot;degrees&quot;</span>],  </span><br><span class="line">                translate=hyp[<span class="string">&quot;translate&quot;</span>],  </span><br><span class="line">                scale=hyp[<span class="string">&quot;scale&quot;</span>],  </span><br><span class="line">                shear=hyp[<span class="string">&quot;shear&quot;</span>],  </span><br><span class="line">                perspective=hyp[<span class="string">&quot;perspective&quot;</span>],  </span><br><span class="line">            )  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标签归一化处理</span></span><br><span class="line">    nl = <span class="built_in">len</span>(labels)  <span class="comment"># number of labels  </span></span><br><span class="line">    <span class="keyword">if</span> nl:  </span><br><span class="line">        labels[:, <span class="number">1</span>:<span class="number">5</span>] = xyxy2xywhn(labels[:, <span class="number">1</span>:<span class="number">5</span>], w=img.shape[<span class="number">1</span>], h=img.shape[<span class="number">0</span>], clip=<span class="literal">True</span>, eps=<span class="number">1e-3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.augment:  </span><br><span class="line">        <span class="comment"># 调用第三方库实现多样化增强（如模糊、噪声、仿射变换等）  </span></span><br><span class="line">        img, labels = <span class="variable language_">self</span>.albumentations(img, labels)  </span><br><span class="line">        nl = <span class="built_in">len</span>(labels)  <span class="comment"># update after albumentations  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 随机调整HSV通道，模拟光照、饱和度变化  </span></span><br><span class="line">        augment_hsv(img, hgain=hyp[<span class="string">&quot;hsv_h&quot;</span>], sgain=hyp[<span class="string">&quot;hsv_s&quot;</span>], vgain=hyp[<span class="string">&quot;hsv_v&quot;</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 上下随机翻转</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;flipud&quot;</span>]:  </span><br><span class="line">            img = np.flipud(img)  </span><br><span class="line">            <span class="keyword">if</span> nl:  </span><br><span class="line">                labels[:, <span class="number">2</span>] = <span class="number">1</span> - labels[:, <span class="number">2</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 左右随机翻转</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; hyp[<span class="string">&quot;fliplr&quot;</span>]:  </span><br><span class="line">            img = np.fliplr(img)  </span><br><span class="line">            <span class="keyword">if</span> nl:  </span><br><span class="line">                labels[:, <span class="number">1</span>] = <span class="number">1</span> - labels[:, <span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 随机遮挡区域增强鲁棒性  </span></span><br><span class="line">        <span class="comment"># labels = cutout(img, labels, p=0.5)       </span></span><br><span class="line">	    <span class="comment"># nl = len(labels)  # update after cutout  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据格式标准化​</span></span><br><span class="line">    labels_out = torch.zeros((nl, <span class="number">6</span>))  </span><br><span class="line">    <span class="keyword">if</span> nl:  </span><br><span class="line">        <span class="comment"># 标签张量化</span></span><br><span class="line">        labels_out[:, <span class="number">1</span>:] = torch.from_numpy(labels)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># ​图像通道处理  </span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))[::-<span class="number">1</span>]  <span class="comment"># HWC to CHW, BGR to RGB  </span></span><br><span class="line">    img = np.ascontiguousarray(img)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># (图像张量， 标签张量， 图像路径， 原始与调整后的尺寸信息)</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(img), labels_out, <span class="variable language_">self</span>.im_files[index], shapes</span><br></pre></td></tr></table></figure>

<p><code>__getitem__</code>核心作用：</p>
<ol>
<li>​<strong>动态数据增强</strong>​：通过Mosaic、MixUp、空间&#x2F;颜色变换等提升模型泛化能力</li>
<li>​<strong>多策略采样</strong>​：支持多种索引分配方式，适配不同训练需求</li>
<li>​<strong>坐标系统一</strong>​：确保标签在不同增强步骤后仍保持归一化格式</li>
<li>​<strong>格式标准化</strong>​：输出直接适配模型训练的Tensor格式</li>
</ol>
<h4 id="2-Mosaic-增强"><a href="#2-Mosaic-增强" class="headerlink" title="2.Mosaic 增强"></a>2.Mosaic 增强</h4><p><code>load_mosaic</code>是用于实现Mosaic数据增强的核心函数，其主要作用是将四张图像拼接成一张大图，并调整对应的标注信息，以提升模型训练时的数据多样性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_mosaic</span>(<span class="params">self, index</span>):  <span class="comment"># index（当前样本的索引）</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Loads a 4-image mosaic for YOLOv5, combining 1 selected and 3 random images, with labels and segments.&quot;&quot;&quot;</span>  </span><br><span class="line">    labels4, segments4 = [], []  <span class="comment"># 存储四张图像的标注和分割信息</span></span><br><span class="line">    s = <span class="variable language_">self</span>.img_size  <span class="comment"># 输入图像的尺寸（如640x640）</span></span><br><span class="line">    yc, xc = (<span class="built_in">int</span>(random.uniform(-x, <span class="number">2</span> * s + x)) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.mosaic_border)  <span class="comment"># 随机生成在[-border, 2*s + border]范围内的马赛克中心点坐标</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成4张图的索引：1张当前索引 + 3张随机索引</span></span><br><span class="line">    indices = [index] + random.choices(<span class="variable language_">self</span>.indices, k=<span class="number">3</span>)</span><br><span class="line">    random.shuffle(indices)  <span class="comment"># 打乱顺序，位置随机</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历处理每张图</span></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> <span class="built_in">enumerate</span>(indices):  </span><br><span class="line">        <span class="comment"># 加载图像和尺寸 (h,w) </span></span><br><span class="line">        img, _, (h, w) = <span class="variable language_">self</span>.load_image(index)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># === 计算当前图像在大图中的放置位置 ===</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:  <span class="comment"># 左上角  </span></span><br><span class="line">            <span class="comment"># 创建2s x 2s的基图，初始填充为114（灰色）</span></span><br><span class="line">            img4 = np.full((s * <span class="number">2</span>, s * <span class="number">2</span>, img.shape[<span class="number">2</span>]), <span class="number">114</span>, dtype=np.uint8)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 大图中的坐标范围（可能被裁剪）xmin, ymin, xmax, ymax (large image)  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = <span class="built_in">max</span>(xc - w, <span class="number">0</span>), <span class="built_in">max</span>(yc - h, <span class="number">0</span>), xc, yc</span><br><span class="line">            <span class="comment"># 原图中的对应裁剪区域 xmin, ymin, xmax, ymax (small image)  </span></span><br><span class="line">            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h</span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">1</span>:  <span class="comment"># 右上角  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = xc, <span class="built_in">max</span>(yc - h, <span class="number">0</span>), <span class="built_in">min</span>(xc + w, s * <span class="number">2</span>), yc  </span><br><span class="line">            x1b, y1b, x2b, y2b = <span class="number">0</span>, h - (y2a - y1a), <span class="built_in">min</span>(w, x2a - x1a), h  </span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">2</span>:  <span class="comment"># 左下角</span></span><br><span class="line">            x1a, y1a, x2a, y2a = <span class="built_in">max</span>(xc - w, <span class="number">0</span>), yc, xc, <span class="built_in">min</span>(s * <span class="number">2</span>, yc + h)  </span><br><span class="line">            x1b, y1b, x2b, y2b = w - (x2a - x1a), <span class="number">0</span>, w, <span class="built_in">min</span>(y2a - y1a, h)  </span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">3</span>:  <span class="comment"># 右下角  </span></span><br><span class="line">            x1a, y1a, x2a, y2a = xc, yc, <span class="built_in">min</span>(xc + w, s * <span class="number">2</span>), <span class="built_in">min</span>(s * <span class="number">2</span>, yc + h)  </span><br><span class="line">            x1b, y1b, x2b, y2b = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">min</span>(w, x2a - x1a), <span class="built_in">min</span>(y2a - y1a, h)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将原图区域img[y1b:y2b, x1b:x2b] 粘贴到大图img4[y1a:y2a, x1a:x2a]</span></span><br><span class="line">        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算坐标偏移量（用于调整标注框）</span></span><br><span class="line">        padw = x1a - x1b  <span class="comment"># x方向偏移</span></span><br><span class="line">        padh = y1a - y1b  <span class="comment"># y方向偏移</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># === 处理标注信息 ===  </span></span><br><span class="line">        labels, segments = <span class="variable language_">self</span>.labels[index].copy(), <span class="variable language_">self</span>.segments[index].copy()  </span><br><span class="line">        <span class="keyword">if</span> labels.size:  </span><br><span class="line">            <span class="comment"># 将归一化的xywh转换为大图中的绝对坐标xyxy</span></span><br><span class="line">            labels[:, <span class="number">1</span>:] = xywhn2xyxy(labels[:, <span class="number">1</span>:], w, h, padw, padh)</span><br><span class="line">            <span class="comment"># 调整分割点坐标 </span></span><br><span class="line">            segments = [xyn2xy(x, w, h, padw, padh) <span class="keyword">for</span> x <span class="keyword">in</span> segments]  </span><br><span class="line">            </span><br><span class="line">        labels4.append(labels)  <span class="comment"># 收集标签</span></span><br><span class="line">        segments4.extend(segments)  <span class="comment"># 收集分割点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># === 后处理 ===</span></span><br><span class="line">    <span class="comment"># 合并所有标签 (shape=[N, 5]) </span></span><br><span class="line">    labels4 = np.concatenate(labels4, <span class="number">0</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 裁剪坐标到[0, 2s]范围内，防止越界</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> (labels4[:, <span class="number">1</span>:], *segments4):  </span><br><span class="line">        np.clip(x, <span class="number">0</span>, <span class="number">2</span> * s, out=x)  <span class="comment"># clip when using random_perspective()  </span></span><br><span class="line">    <span class="comment"># img4, labels4 = replicate(img4, labels4)  # replicate  </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数据增强：随机复制粘贴目标（根据概率）   </span></span><br><span class="line">    img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=<span class="variable language_">self</span>.hyp[<span class="string">&quot;copy_paste&quot;</span>])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据增强：随机透视变换（旋转/缩放/平移/剪切/透视）（opencv实现）</span></span><br><span class="line">    img4, labels4 = random_perspective(  </span><br><span class="line">        img4,  </span><br><span class="line">        labels4,  </span><br><span class="line">        segments4,  </span><br><span class="line">        degrees=<span class="variable language_">self</span>.hyp[<span class="string">&quot;degrees&quot;</span>],  </span><br><span class="line">        translate=<span class="variable language_">self</span>.hyp[<span class="string">&quot;translate&quot;</span>],  </span><br><span class="line">        scale=<span class="variable language_">self</span>.hyp[<span class="string">&quot;scale&quot;</span>],  </span><br><span class="line">        shear=<span class="variable language_">self</span>.hyp[<span class="string">&quot;shear&quot;</span>],  </span><br><span class="line">        perspective=<span class="variable language_">self</span>.hyp[<span class="string">&quot;perspective&quot;</span>],  </span><br><span class="line">        border=<span class="variable language_">self</span>.mosaic_border,  </span><br><span class="line">    )  <span class="comment"># border to remove  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接后的图像img4和对应的标注labels4</span></span><br><span class="line">    <span class="keyword">return</span> img4, labels4</span><br></pre></td></tr></table></figure>

<h2 id="3-网络结构"><a href="#3-网络结构" class="headerlink" title="3.网络结构"></a>3.网络结构</h2><p>从输入层到输出层，讲解网络各层及结构的逻辑 会用清晰的“主线逻辑”串联复杂结构</p>
<h3 id="1-网络结构可视化"><a href="#1-网络结构可视化" class="headerlink" title="1.网络结构可视化"></a>1.网络结构可视化</h3><p>如果想要更直观的查看模型结构，可以使用模型可视化工具，比如<a target="_blank" rel="noopener" href="https://github.com/lutzroeder/netron?tab=readme-ov-file">Netron</a>，但如果直接导入<code>yolov5s.pt</code> 模型时，展示的结构会不完整，只显示模块名称，看不出实际的数据流动细节，这时需要将<code>pt</code>格式转化为<code>onnx</code>格式。</p>
<blockquote>
<p><strong>ONNX（Open Neural Network Exchange）​</strong>​ 是一种开放格式，用于表示和交换深度学习模型。它的核心作用是让不同框架（如PyTorch、TensorFlow）训练的模型能够互相转换和运行。</p>
</blockquote>
<h4 id="1-ONNX模型导出"><a href="#1-ONNX模型导出" class="headerlink" title="1.ONNX模型导出"></a>1.ONNX模型导出</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先安装</span></span><br><span class="line">pip install onnx</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">转换成onnx文件</span></span><br><span class="line">python export.py --weights yolov5s.pt --include onnx</span><br></pre></td></tr></table></figure>
<h4 id="2-ONNX模型可视化"><a href="#2-ONNX模型可视化" class="headerlink" title="2.ONNX模型可视化"></a>2.ONNX模型可视化</h4><p>Netron支持多种方式可视化，我们可以通过浏览器地址<a target="_blank" rel="noopener" href="https://netron.app/">Netron</a>加载<code>.onnx</code>模型：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/yolov5s.onnx.png"></p>
<h3 id="2-网络结构配置解读"><a href="#2-网络结构配置解读" class="headerlink" title="2.网络结构配置解读"></a>2.网络结构配置解读</h3><h4 id="1-核心模块"><a href="#1-核心模块" class="headerlink" title="1.核心模块"></a>1.核心模块</h4><h5 id="1-Conv模块（标准卷积模块）"><a href="#1-Conv模块（标准卷积模块）" class="headerlink" title="1.Conv模块（标准卷积模块）"></a>1.Conv模块（标准卷积模块）</h5><p>结构：Conv → BatchNorm → SiLU（激活函数）<br>作用：</p>
<ul>
<li>提取局部特征（边缘、纹理、角点等）</li>
<li>下采样（如果步长 &gt; 1）</li>
<li>控制通道数量，压缩或扩展特征图维度</li>
</ul>
<h5 id="2-C3模块（残差模块）"><a href="#2-C3模块（残差模块）" class="headerlink" title="2.C3模块（残差模块）"></a>2.C3模块（残差模块）</h5><p>结构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">       ┌────────────┐</span><br><span class="line">input──┴─┐        ┌─┴─────┐</span><br><span class="line">         └─&gt; Bottleneck ──┤</span><br><span class="line">               × N次      └──&gt; Concat + Conv → output</span><br></pre></td></tr></table></figure>
<ul>
<li>输入被<strong>一分为二</strong></li>
<li>一部分走多个 Bottleneck 残差单元（默认含卷积 + 残差连接）</li>
<li>一部分不变</li>
<li>最后两者 Concatenate → 再接个卷积融合<br>作用：</li>
<li>提高特征提取能力</li>
<li>控制模型计算量（参数量比 ResNet 少）</li>
<li>保留不同路径的特征信息（浅+深）</li>
</ul>
<h5 id="3-SPPF模块（Spatial-Pyramid-Pooling-Fast）"><a href="#3-SPPF模块（Spatial-Pyramid-Pooling-Fast）" class="headerlink" title="3.SPPF模块（Spatial Pyramid Pooling - Fast）"></a>3.SPPF模块（Spatial Pyramid Pooling - Fast）</h5><p>结构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input ──────────────┐</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                │</span><br><span class="line">MaxPool(k=5)        │</span><br><span class="line">   ↓                ↓</span><br><span class="line">   └─────Concat────→ Conv → output</span><br></pre></td></tr></table></figure>
<ul>
<li>连续做 <strong>3 次相同核大小的最大池化</strong></li>
<li>所得多个特征图拼接</li>
<li>最后再通过卷积融合<br>作用：</li>
<li><strong>扩展感受野</strong>：融合不同尺度空间上下文信息</li>
<li><strong>增强特征表达</strong>：尤其适合大目标或上下文强依赖的情况</li>
</ul>
<h5 id="4-Concat（特征拼接）"><a href="#4-Concat（特征拼接）" class="headerlink" title="4.Concat（特征拼接）"></a>4.Concat（特征拼接）</h5><p>结构：<br>Concat 模块没有卷积，它只是<strong>把来自不同层的特征图在通道维度拼接在一起</strong><br>作用：</p>
<ul>
<li>融合上采样后的特征图和 backbone 中较浅层（如 P3&#x2F;P4）的特征</li>
<li>提高模型对不同尺度目标的检测能力</li>
</ul>
<h5 id="5-上采样模块（nn-Upsample）"><a href="#5-上采样模块（nn-Upsample）" class="headerlink" title="5.上采样模块（nn.Upsample）"></a>5.上采样模块（nn.Upsample）</h5><p>结构：<br>PyTorch 内置上采样模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>作用：<br><strong>将特征图放大（恢复空间分辨率）</strong>，常用于：</p>
<ul>
<li>将深层（小尺寸）特征图上采样，和浅层（大尺寸）特征图进行拼接</li>
<li>类似 U-Net 中的上采样路径</li>
</ul>
<h5 id="5-Detect"><a href="#5-Detect" class="headerlink" title="5.Detect"></a>5.Detect</h5><p>为每个网格（每个 anchor）预测：    </p>
<ul>
<li>边界框坐标（x, y, w, h）</li>
<li>置信度（objectness）</li>
<li>类别概率（cls）</li>
</ul>
<h4 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2.网络结构"></a>2.网络结构</h4><p>YOLOv5s（small 版本）网络结构，包括超参数、骨干网络（backbone）和检测头（head）：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">models/yolov5s.yaml/</span></span><br><span class="line"><span class="comment"># 1. 超参数配置Parameters  </span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">80</span> <span class="comment"># 分类数量（COCO数据集中为80类） </span></span><br><span class="line"><span class="attr">depth_multiple:</span> <span class="number">0.33</span> <span class="comment"># 模块深度缩放因子（用于控制网络深度）</span></span><br><span class="line"><span class="attr">width_multiple:</span> <span class="number">0.50</span> <span class="comment"># 通道宽度缩放因子（用于控制网络宽度）</span></span><br><span class="line"><span class="attr">anchors:</span>  <span class="comment"># 不同特征层的锚框设置</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>] <span class="comment"># P3/8  </span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>] <span class="comment"># P4/16  </span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>] <span class="comment"># P5/32  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># depth_multiple和width_multiple控制模型轻量化，S版用的是最小的系数，表示较浅且窄的网络结构</span></span><br><span class="line"><span class="comment"># anchors是先验框的大小列表，每行表示一个输出尺度（3个）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOLOv5 v6.0 backbone（主干网络）</span></span><br><span class="line"><span class="comment"># 主干网络负责提取特征，基本上是由卷积层（Conv）、C3模块、SPPF模块组成</span></span><br><span class="line"><span class="attr">backbone:</span>  </span><br><span class="line">  <span class="comment"># [from, number, module, args]  </span></span><br><span class="line">  <span class="comment"># from: 当前层的输入来自哪一层（-1 表示上一层）</span></span><br><span class="line">  <span class="comment"># number: 当前模块重复几次（比如 C3 模块可重复多次）</span></span><br><span class="line">  <span class="comment"># module: 模块名称，比如 Conv, C3, SPPF</span></span><br><span class="line">  <span class="comment"># args: 模块的参数，具体由模块类型决定</span></span><br><span class="line">  [  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]], <span class="comment"># 通道64 卷积6*6 步长2 padding2 </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 通道128 卷积3*3 步长2</span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">128</span>]],  <span class="comment"># 通道128</span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 3-P3/8  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">6</span>, <span class="string">C3</span>, [<span class="number">256</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 5-P4/16  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">9</span>, <span class="string">C3</span>, [<span class="number">512</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]], <span class="comment"># 7-P5/32  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">1024</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">SPPF</span>, [<span class="number">1024</span>, <span class="number">5</span>]], <span class="comment"># 通道1024 池化核 5</span></span><br><span class="line">  ]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># YOLOv5 v6.0 head  </span></span><br><span class="line"><span class="comment"># head作用：将主干网络（backbone）提取到的特征图转化为目标检测的最终结果：即边界框、置信度、以及每个类别的概率</span></span><br><span class="line"><span class="attr">head:</span> [  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">nn.Upsample</span>, [<span class="string">None</span>, <span class="number">2</span>, <span class="string">&quot;nearest&quot;</span>]],  <span class="comment"># 使用最近邻插值方法特征图尺寸扩大2倍</span></span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">6</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat backbone P4  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">512</span>, <span class="literal">False</span>]], <span class="comment"># 输出通道数512  不使用残差连接</span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>]],  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">nn.Upsample</span>, [<span class="string">None</span>, <span class="number">2</span>, <span class="string">&quot;nearest&quot;</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">4</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat backbone P3  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">256</span>, <span class="literal">False</span>]], <span class="comment"># 17 (P3/8-small)  </span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">14</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat head P4  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">512</span>, <span class="literal">False</span>]], <span class="comment"># 20 (P4/16-medium)  </span></span><br><span class="line">  </span><br><span class="line">    [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  </span><br><span class="line">    [[<span class="number">-1</span>, <span class="number">10</span>], <span class="number">1</span>, <span class="string">Concat</span>, [<span class="number">1</span>]], <span class="comment"># cat head P5  </span></span><br><span class="line">    [<span class="number">-1</span>, <span class="number">3</span>, <span class="string">C3</span>, [<span class="number">1024</span>, <span class="literal">False</span>]], <span class="comment"># 23 (P5/32-large)  </span></span><br><span class="line">  </span><br><span class="line">    [[<span class="number">17</span>, <span class="number">20</span>, <span class="number">23</span>], <span class="number">1</span>, <span class="string">Detect</span>, [<span class="string">nc</span>, <span class="string">anchors</span>]], <span class="comment"># nc分类数量  anchors锚框</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>
<h4 id="3-模型解析"><a href="#3-模型解析" class="headerlink" title="3.模型解析"></a>3.模型解析</h4><h5 id="1-模型构建"><a href="#1-模型构建" class="headerlink" title="1.模型构建"></a>1.模型构建</h5><p><code>DetectionModel.__init__</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg=<span class="string">&quot;yolov5s.yaml&quot;</span>, ch=<span class="number">3</span>, nc=<span class="literal">None</span>, anchors=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>加载并解析 YAML 配置文件，构建模型字典 self.yaml</li>
<li>如果传入 nc 或 anchors 会覆盖配置文件中的默认值</li>
<li>调用 parse_model(…) 来解析模型结构（构建 backbone、neck、head 等）</li>
<li>设置类别名 self.names，默认是 [0, 1, …, nc-1]</li>
<li>若最后一层是 Detect 或 Segment，还会：<ul>
<li>构建 stride（下采样倍数）</li>
<li>调整 anchors（除以 stride）</li>
<li>初始化偏置项 self._initialize_biases()</li>
</ul>
</li>
<li>初始化网络权重：initialize_weights(self)</li>
<li>打印模型信息：self.info()</li>
</ul>
<h5 id="2-前向传播阶段"><a href="#2-前向传播阶段" class="headerlink" title="2.前向传播阶段"></a>2.前向传播阶段</h5><p>调用 model(x) 会触发：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, augment=<span class="literal">False</span>, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>默认进入 _forward_once(x)</li>
<li>如果 augment&#x3D;True，则走增强推理 _forward_augment(x) 分支（多尺度+翻转）</li>
<li>profile 和 visualize 是可选功能：性能分析、特征可视化</li>
</ul>
<h5 id="3-forward-once"><a href="#3-forward-once" class="headerlink" title="3.forward_once"></a>3.forward_once</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_once</span>(<span class="params">self, x, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>遍历 self.model 中的每一层模块</li>
<li>如果 m.f !&#x3D; -1，说明当前模块依赖前面某一层的输出</li>
<li>执行前向传播：x &#x3D; m(x)</li>
<li>如果 m.i in self.save，就将输出 x 保存到 y 中</li>
<li>如果 visualize&#x3D;True，还会进行特征可视化<br>最终返回最后一层输出 x，对于 Detect&#x2F;Segment 模块，输出格式如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Detect:</span></span><br><span class="line"><span class="keyword">return</span> (batch, num_predictions, <span class="number">85</span>) -&gt; (x, y, w, h, obj_conf, class_probs)</span><br><span class="line"><span class="comment"># Segment:</span></span><br><span class="line"><span class="keyword">return</span> (x, proto) <span class="keyword">or</span> (x0, proto, x1) depending on mode</span><br></pre></td></tr></table></figure>
<p>最终返回最后一层输出 x，对于 Detect&#x2F;Segment 模块，输出格式如下：</p>
<h5 id="4-Detect-Segment-模块解析"><a href="#4-Detect-Segment-模块解析" class="headerlink" title="4.Detect&#x2F;Segment 模块解析"></a>4.Detect&#x2F;Segment 模块解析</h5><p>Detect 是检测 head，会根据 anchor&#x2F;grid 解码预测框：</p>
<ul>
<li>分类数 nc，每个输出通道为 no &#x3D; nc + 5（中心、宽高、置信度、分类概率）</li>
<li>anchor&#x2F;grid 是在首次前向推理中动态计算的</li>
<li>推理时输出 (batch, anchors × grid_x × grid_y, no)</li>
</ul>
<p>Segment 继承自 Detect，额外处理 mask 信息：    </p>
<ul>
<li>输出通道为 no &#x3D; 5 + nc + nm，其中 nm 是 mask 数量</li>
<li>使用 Proto 结构生成原型掩膜</li>
</ul>
<h5 id="5-增强推理（-forward-augment）"><a href="#5-增强推理（-forward-augment）" class="headerlink" title="5.增强推理（_forward_augment）"></a>5.增强推理（_forward_augment）</h5><p>通过缩放和翻转图像进行多尺度推理增强:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_augment</span>(<span class="params">self, x</span>):</span><br></pre></td></tr></table></figure>
<ul>
<li>对每个缩放比例和翻转方向进行推理</li>
<li>对输出结果反向还原：_descale_pred()</li>
<li>拼接所有预测结果：torch.cat(…)</li>
<li>修剪增强推理中的冗余部分：_clip_augmented(…)</li>
</ul>
<h2 id="4-训练流程与策略"><a href="#4-训练流程与策略" class="headerlink" title="4.训练流程与策略"></a>4.训练流程与策略</h2><h3 id="1-训练流程"><a href="#1-训练流程" class="headerlink" title="1.训练流程"></a>1.训练流程</h3><h4 id="1-日志记录与文件保存​"><a href="#1-日志记录与文件保存​" class="headerlink" title="1.日志记录与文件保存​"></a>1.日志记录与文件保存​</h4><p>YOLOv5 在训练过程中，不仅会在控制台输出训练信息，还会将大量有价值的训练信息保存到日志中。每次训练都会在runs&#x2F;train下生成一个exp文件夹:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">runs/train/exp4/</span><br><span class="line">├── F1_curve.png # F1 分数随阈值变化的曲线</span><br><span class="line">├── PR_curve.png # Precision-Recall 曲线，用于衡量模型在不同阈值下的性能</span><br><span class="line">├── P_curve.png # Precision（查准率）随置信度阈值的变化曲线</span><br><span class="line">├── R_curve.png # Recall（查全率）曲线</span><br><span class="line">├── confusion_matrix.png # 混淆矩阵图，用于展示不同类别的预测混淆情况（分类任务中常用）</span><br><span class="line">├── events.out.tfevents.xxx.xx # TensorBoard 记录文件</span><br><span class="line">├── hyp.yaml # 训练超参数（如学习率、IoU 阈值、损失权重等）</span><br><span class="line">├── labels.jpg # 展示训练集中标注框的分布情况</span><br><span class="line">├── labels_correlogram.jpg # 类别之间的相关性热力图（适合多标签任务）</span><br><span class="line">├── opt.yaml # 训练过程中的各种配置参数（命令行参数的备份）</span><br><span class="line">├── results.csv # 每个epoch的指标记录表格</span><br><span class="line">├── results.png # 包含loss、mAP、Precision、Recall等关键训练指标随epoch变化的曲线图</span><br><span class="line">├── train_batch0.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── train_batch1.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── train_batch2.jpg # 训练集中部分图片及其标注框预览图</span><br><span class="line">├── val_batch0_labels.jpg # 验证集图像及其真实标签框</span><br><span class="line">├── val_batch0_pred.jpg # 验证集图像的模型预测结果</span><br><span class="line">└── weights # 用于保存模型权重文件</span><br><span class="line">    ├── best.pt # 验证集上效果最好的模型权重（val_loss 最低的）</span><br><span class="line">    └── last.pt # 训练过程中最后一次保存的模型权重（最后一个 epoch）</span><br></pre></td></tr></table></figure>
<h4 id="2-模型加载与初始化​"><a href="#2-模型加载与初始化​" class="headerlink" title="2. 模型加载与初始化​"></a>2. 模型加载与初始化​</h4><p>训练开始前，YOLOv5 会进行一系列初始化设置：</p>
<ul>
<li><strong>设置随机种子</strong>，保证结果可复现</li>
<li><strong>读取数据配置文件</strong>（如 data.yaml），确定类别数和路径</li>
<li><strong>检查数据集路径和配置是否正确</strong>，防止路径错误导致训练失败</li>
</ul>
<h4 id="3-模型构建与加载权重"><a href="#3-模型构建与加载权重" class="headerlink" title="3.模型构建与加载权重"></a>3.模型构建与加载权重</h4><p>模型的构建依赖配置文件（如 yolov5s.yaml），源码会根据结构定义逐层构建模型。<br>如果本地已经存在预训练模型（如 yolov5s.pt），则会优先加载本地模型；否则，会从 YOLOv5 的官方仓库自动下载。建议提前下载，以避免自动下载速度较慢。</p>
<h4 id="4-迁移学习与冻结层设置"><a href="#4-迁移学习与冻结层设置" class="headerlink" title="4.迁移学习与冻结层设置"></a>4.迁移学习与冻结层设置</h4><p>YOLOv5 支持迁移学习，即在预训练模型基础上进行微调。你可以选择是否“冻结”部分网络层（通常是 backbone 部分）来保留其预训练特征。<br>实践中发现：<strong>即便只用几十张图片，在不冻结层的情况下也能获得不错的检测效果</strong>。因此除非数据量特别小或训练不稳定，通常不需要特意冻结层。</p>
<h4 id="5-梯度累积机制：nbs-参数的作用"><a href="#5-梯度累积机制：nbs-参数的作用" class="headerlink" title="5.梯度累积机制：nbs 参数的作用"></a>5.梯度累积机制：nbs 参数的作用</h4><p>YOLOv5 中引入了 <strong>梯度累积（Gradient Accumulation）</strong> 机制，主要通过 nbs 参数控制。<br>举个例子：</p>
<ul>
<li>如果 batch size 为 16，nbs 为 64，那么模型会累积 4 个 batch 的梯度再进行一次反向传播更新。</li>
<li><strong>优点</strong>：在显存受限的设备上模拟更大的 batch size，提高训练稳定性和效果。<br>这个机制通过代码实现了变相扩大 batch size，有助于更稳定地更新模型权重。</li>
</ul>
<h4 id="6-优化器与学习率调度"><a href="#6-优化器与学习率调度" class="headerlink" title="6.优化器与学习率调度"></a>6.优化器与学习率调度</h4><p>优化器方面，YOLOv5 将模型参数分组处理（如偏置项、权重项分别优化），并支持如下优化策略：</p>
<ul>
<li>初始学习率、动量、权重衰减等参数可配置</li>
<li>支持多种 <strong>学习率衰减策略</strong>（如余弦衰减 CosineLR）</li>
<li>提供完整的学习率调度函数，借鉴了多个经典文献<br>虽然这部分源码涉及的数学细节较多，但理解其核心目的即可——<strong>随着训练迭代，逐步降低学习率，提高模型稳定性与精度</strong>。</li>
</ul>
<h3 id="2-训练策略"><a href="#2-训练策略" class="headerlink" title="2.训练策略"></a>2.训练策略</h3><h4 id="1-断点续训逻辑"><a href="#1-断点续训逻辑" class="headerlink" title="1.断点续训逻辑"></a>1.断点续训逻辑</h4><p>YOLOv5 支持断点续训，便于训练中断后的恢复。其机制如下：</p>
<ol>
<li><strong>加载断点模型</strong><ul>
<li>当我们指定了一个断点模型（如 –weights&#x3D;weights&#x2F;last.pt），YOLOv5 会自动加载上次训练时保存的所有状态（模型参数、优化器状态、学习率调度器状态、EMA等）。</li>
</ul>
</li>
<li><strong>自动判断是否继续训练</strong><ul>
<li>假设我们上次训练了 150 个 epoch，现在使用 –epochs 100 启动新的训练。</li>
<li>YOLOv5 会检查当前模型的已训练轮数。如果已经超过 100（如已训练 150），则不会再训练；如果未达到（如当前为 80），则会 <strong>继续训练剩余的轮数</strong>（此例中为 20）。</li>
</ul>
</li>
<li><strong>额外保存模型（双重保险）</strong><ul>
<li>加载断点模型后，YOLOv5 会额外保存一次模型权重。这一操作的初衷似乎是为了保险——防止覆盖原有模型。</li>
<li>实测表明：加载模型并不会覆盖原始权重文件。这个多保存一次的逻辑目前看起来意义不大，反而增加了存储负担，不过可以理解为一种“冗余备份机制”。</li>
</ul>
</li>
</ol>
<h4 id="2-图像尺寸校验逻辑（gs-检查）"><a href="#2-图像尺寸校验逻辑（gs-检查）" class="headerlink" title="2.图像尺寸校验逻辑（gs 检查）"></a>2.图像尺寸校验逻辑（gs 检查）</h4><p>在训练前，YOLOv5 会校验输入图像的尺寸是否符合网络结构要求。主要逻辑如下：</p>
<ul>
<li>YOLOv5 的 backbone 下采样倍数为 32，因此输入图像尺寸必须能被 32 整除（如 640×640）。</li>
<li>gs（grid size） 就是该下采样因子。如果尺寸不满足要求，会报错或自动调整图像尺寸。<br>这一检查确保了网络中卷积和特征图尺寸的兼容性，是非常基础但关键的一步。</li>
</ul>
<h4 id="3-EMA（滑动平均）机制的作用"><a href="#3-EMA（滑动平均）机制的作用" class="headerlink" title="3.EMA（滑动平均）机制的作用"></a>3.EMA（滑动平均）机制的作用</h4><p>YOLOv5 默认启用了 <strong>EMA（Exponential Moving Average）</strong>：</p>
<ul>
<li>通过对模型参数的历史状态进行滑动平均，生成一个更稳定的权重；</li>
<li>EMA 权重会用于最终评估和保存（best.pt），因为其结果通常更平滑、鲁棒性更强。</li>
</ul>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>YOLOv5是一个高度工程优化的目标检测框架，核心特点包括：</p>
<ol>
<li>​<strong>工程友好</strong>​：模块化代码结构清晰，支持快速训练自定义数据集（只需规范数据格式并修改YAML配置）</li>
<li>​<strong>高效训练</strong>​：集成Mosaic&#x2F;MixUp数据增强、梯度累积（nbs参数）、EMA权重平均等技术，提升模型泛化能力</li>
<li>​<strong>灵活部署</strong>​：提供Nano到XLarge多规格预训练模型，适配从嵌入式设备到服务器的不同场景</li>
<li>​<strong>全流程支持</strong>​：训练中自动记录日志、可视化指标（如PR曲线）、保存最佳模型（best.pt），便于调试和部署</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>KeyChan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/" title="[YOLO系列④] YOLOv5模型训练与流程解析">https://www.keychan.xyz/2025/05/07/014-yolo-yolov5-code-detail/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://x.com/keychankc">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"># 目标检测</a>
              <a href="/tags/YOLO/" rel="tag"># YOLO</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/04/29/013-yolo-yolov3-yolov4/" rel="prev" title="[YOLO系列③] YOLOv3和YOLOv4优化策略">
                  <i class="fa fa-angle-left"></i> [YOLO系列③] YOLOv3和YOLOv4优化策略
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/13/015-transformer-to-detr/" rel="next" title="基于Transformer的detr目标检测算法思路分析">
                  基于Transformer的detr目标检测算法思路分析 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KeyChan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">206k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/keychankc" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="/js/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/ribbon.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://comment.mengyajia.com","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":false,"pageview":false,"placeholder":"欢迎评论~","emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq"],"requiredMeta":["nick","mail"],"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/2025/05/07/014-yolo-yolov5-code-detail/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
