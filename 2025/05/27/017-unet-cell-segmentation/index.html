<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo-512x512.png" color="#222">
  <meta name="google-site-verification" content="jZ7dJJlouQrswxytAryX3LanLNrTthfFdMUkDJzRqIU">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.keychan.xyz","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="下面我们以一个医学图像实例分割任务为例，来介绍在 PyTorch 框架下如何使用 U-Net++ 网络。U-Net++ 是在经典 U-Net 基础上进行改进的语义分割网络，它通过引入密集跳跃连接和深层监督机制，增强了特征融合能力与梯度传播效果，特别适用于医学图像中边界模糊、结构复杂的分割任务。 1.数据预处理1.数据集介绍这个数据集是一些细胞图像，我们的目标是做前景背景分离，对每一个细胞做实例分割">
<meta property="og:type" content="article">
<meta property="og:title" content="基于U-Net++的细胞分割代码实现">
<meta property="og:url" content="https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/index.html">
<meta property="og:site_name" content="KeyChan&#39;s blog">
<meta property="og:description" content="下面我们以一个医学图像实例分割任务为例，来介绍在 PyTorch 框架下如何使用 U-Net++ 网络。U-Net++ 是在经典 U-Net 基础上进行改进的语义分割网络，它通过引入密集跳跃连接和深层监督机制，增强了特征融合能力与梯度传播效果，特别适用于医学图像中边界模糊、结构复杂的分割任务。 1.数据预处理1.数据集介绍这个数据集是一些细胞图像，我们的目标是做前景背景分离，对每一个细胞做实例分割">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173505.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173609.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250516135710.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526155728.png">
<meta property="article:published_time" content="2025-05-27T09:54:12.000Z">
<meta property="article:modified_time" content="2025-09-21T12:04:48.539Z">
<meta property="article:author" content="KeyChan">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="目标分割">
<meta property="article:tag" content="U-Net">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173505.png">


<link rel="canonical" href="https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/","path":"2025/05/27/017-unet-cell-segmentation/","title":"基于U-Net++的细胞分割代码实现"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>基于U-Net++的细胞分割代码实现 | KeyChan's blog</title>
  







<link rel="dns-prefetch" href="https://comment.mengyajia.com">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="KeyChan's blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KeyChan's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-系列"><a href="/series/" rel="section"><i class="fa fa-list-ol fa-fw"></i>系列</a></li><li class="menu-item menu-item-随想"><a href="/think/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">1.数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="nav-text">1.数据集介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88"><span class="nav-text">2.数据整合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%90%88%E5%B9%B6%E6%8E%A9%E7%A0%81"><span class="nav-text">1.合并掩码</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-text">3.数据增强</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">4.加载数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-U-Net-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">2.U-Net++网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-VGGBlock"><span class="nav-text">1.VGGBlock</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-UNet"><span class="nav-text">2.UNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-NestedUNet"><span class="nav-text">3.NestedUNet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99"><span class="nav-text">1.命名规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%B7%B1%E5%BA%A6%E7%9B%91%E7%9D%A3"><span class="nav-text">2.深度监督</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%9B%BE%E7%A4%BA"><span class="nav-text">3.图示</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%9B%BE%E4%B8%AD%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%90%AB%E4%B9%89"><span class="nav-text">1.图中每个节点的含义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E5%9B%BE%E4%B8%AD%E7%AE%AD%E5%A4%B4%E8%A1%A8%E7%A4%BA%E5%90%AB%E4%B9%89"><span class="nav-text">2.图中箭头表示含义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E7%BB%93%E6%9E%84%E6%A0%B8%E5%BF%83%EF%BC%9A%E5%B5%8C%E5%A5%97%E5%AF%86%E9%9B%86%E8%B7%B3%E8%B7%83%E8%BF%9E%E6%8E%A5"><span class="nav-text">3.结构核心：嵌套密集跳跃连接</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-%E6%B7%B1%E7%9B%91%E7%9D%A3%E8%BE%93%E5%87%BA%EF%BC%88deep-supervision%EF%BC%89"><span class="nav-text">4.深监督输出（deep supervision）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-%E4%BB%A3%E7%A0%81%E4%B8%8E%E7%BB%93%E6%9E%84%E5%9B%BE%E8%8A%82%E7%82%B9%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="nav-text">5.代码与结构图节点对应关系</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E8%AE%AD%E7%BB%83"><span class="nav-text">3.训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="nav-text">1.训练参数配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">2.损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-BCEDiceLoss"><span class="nav-text">1.BCEDiceLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-LovaszHingeLoss"><span class="nav-text">2.LovaszHingeLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%AF%B9%E6%AF%94"><span class="nav-text">3.对比</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-text">3.优化器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="nav-text">4.学习率</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-CosineAnnealingLR"><span class="nav-text">1.CosineAnnealingLR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-ReduceLROnPlateau"><span class="nav-text">2.ReduceLROnPlateau</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-MultiStepLR"><span class="nav-text">3.MultiStepLR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-ConstantLR"><span class="nav-text">4.ConstantLR</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-text">5.训练流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E8%AE%AD%E7%BB%83"><span class="nav-text">1.训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E9%AA%8C%E8%AF%81"><span class="nav-text">2.验证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E4%B8%BB%E6%B5%81%E7%A8%8B"><span class="nav-text">3.主流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E9%AA%8C%E8%AF%81"><span class="nav-text">4.验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="nav-text">1.可视化结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%AA%8C%E8%AF%81-1"><span class="nav-text">2.验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E6%80%BB%E7%BB%93"><span class="nav-text">5.总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E5%A4%87%E6%B3%A8"><span class="nav-text">6.备注</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83"><span class="nav-text">环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B5%84%E6%BA%90%E5%92%8C%E4%BB%A3%E7%A0%81"><span class="nav-text">资源和代码</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KeyChan"
      src="/images/key_avatar.png">
  <p class="site-author-name" itemprop="name">KeyChan</p>
  <div class="site-description" itemprop="description">全干工程师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">63</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/keychankc" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kckeychan@gmail.com" title="E-Mail → mailto:kckeychan@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/keychankc" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/key_avatar.png">
      <meta itemprop="name" content="KeyChan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeyChan's blog">
      <meta itemprop="description" content="全干工程师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="基于U-Net++的细胞分割代码实现 | KeyChan's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于U-Net++的细胞分割代码实现
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-27 17:54:12" itemprop="dateCreated datePublished" datetime="2025-05-27T17:54:12+08:00">2025-05-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-21 20:04:48" itemprop="dateModified" datetime="2025-09-21T20:04:48+08:00">2025-09-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/05/27/017-unet-cell-segmentation/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/05/27/017-unet-cell-segmentation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>25 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>下面我们以一个医学图像实例分割任务为例，来介绍在 PyTorch 框架下如何使用 U-Net++ 网络。U-Net++ 是在经典 U-Net 基础上进行改进的语义分割网络，它通过引入密集跳跃连接和深层监督机制，增强了特征融合能力与梯度传播效果，特别适用于医学图像中边界模糊、结构复杂的分割任务。</p>
<h2 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1.数据预处理"></a>1.数据预处理</h2><h3 id="1-数据集介绍"><a href="#1-数据集介绍" class="headerlink" title="1.数据集介绍"></a>1.数据集介绍</h3><p>这个数据集是一些细胞图像，我们的目标是做前景背景分离，对每一个细胞做实例分割。数据集有以下特点：</p>
<span id="more"></span>
<ol>
<li>每个样本有图像（image）和标签（mask），如下图所示</li>
<li>标签（mask），是二值图（0&#x2F;1），表示像素点是否属于细胞</li>
<li>数据集总样本量为 670，样本数量比较少</li>
<li>图像（image）尺寸相对也是偏小的</li>
</ol>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173505.png"></p>
<h3 id="2-数据整合"><a href="#2-数据整合" class="headerlink" title="2.数据整合"></a>2.数据整合</h3><p>如上图所示，原始标签是每个细胞都被划分成一个独立 mask，不适合拿来直接做训练。需要将所有单个 mask 合并成一个统一的 mask 图（前景&#x3D;1，背景&#x3D;0）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 设置输出图像大小为 96×96    </span></span><br><span class="line">    img_size = <span class="number">96</span>  </span><br><span class="line">    <span class="comment"># 读取所有子文件夹，每个子文件夹对应一个图像样本（包含 images 和 masks 子目录）  </span></span><br><span class="line">    paths = glob(<span class="string">&#x27;inputs/stage1_train/*&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 用于存放缩放后的图像（image）</span></span><br><span class="line">    os.makedirs(<span class="string">&#x27;inputs/dsb2018_%d/images&#x27;</span> % img_size, exist_ok=<span class="literal">True</span>)  </span><br><span class="line">    <span class="comment"># 用于存放合并后的掩码图像（mask）</span></span><br><span class="line">    os.makedirs(<span class="string">&#x27;inputs/dsb2018_%d/masks/0&#x27;</span> % img_size, exist_ok=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(paths))): <span class="comment"># 用tqdm可在控制台显示处理进度  </span></span><br><span class="line">        path = paths[i]  </span><br><span class="line">        <span class="comment"># 读取图片  </span></span><br><span class="line">        img = cv2.imread(os.path.join(path, <span class="string">&#x27;images&#x27;</span>, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 合并掩码  </span></span><br><span class="line">        mask = np.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]))  </span><br><span class="line">        <span class="keyword">for</span> mask_path <span class="keyword">in</span> glob(os.path.join(path, <span class="string">&#x27;masks&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)):  </span><br><span class="line">            mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) &gt; <span class="number">127</span>  </span><br><span class="line">            mask[mask_] = <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 图像通道处理  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(img.shape) == <span class="number">2</span>: <span class="comment"># 灰度图（2D），复制为3通道图像  </span></span><br><span class="line">            img = np.tile(img[..., <span class="literal">None</span>], (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))  </span><br><span class="line">        <span class="keyword">if</span> img.shape[<span class="number">2</span>] == <span class="number">4</span>: <span class="comment"># RGBA（4通道），去掉透明度通道，只保留RGB  </span></span><br><span class="line">            img = img[..., :<span class="number">3</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 将图像和掩码都缩放为 96×96        </span></span><br><span class="line">        img = cv2.resize(img, (img_size, img_size))  </span><br><span class="line">        mask = cv2.resize(mask, (img_size, img_size))  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 保存缩放后的图像和掩码  </span></span><br><span class="line">        cv2.imwrite(os.path.join(<span class="string">&#x27;inputs/dsb2018_%d/images&#x27;</span> % img_size, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>), img)  </span><br><span class="line">        cv2.imwrite(os.path.join(<span class="string">&#x27;inputs/dsb2018_%d/masks/0&#x27;</span> % img_size, os.path.basename(path) + <span class="string">&#x27;.png&#x27;</span>), (mask * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="1-合并掩码"><a href="#1-合并掩码" class="headerlink" title="1.合并掩码"></a>1.合并掩码</h4><p>重点讲一下如何合并掩码，如何将某一张图像对应的多个单独掩码文件（每个掩码标注一个目标区域）合并为一个总掩码？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化一个与原始图像 img 大小相同的二维数组 mask，初始值全为 0</span></span><br><span class="line"><span class="comment"># mask 用于存放所有分割区域的合并结果（即所有目标的整体掩码）</span></span><br><span class="line">mask = np.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历路径 path/masks/ 目录下的所有掩码文件（每个文件对应一个实例或目标区域）</span></span><br><span class="line"><span class="comment"># glob 返回所有匹配的文件路径</span></span><br><span class="line"><span class="keyword">for</span> mask_path <span class="keyword">in</span> glob(os.path.join(path, <span class="string">&#x27;masks&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)):</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 读取当前掩码图像 mask_path，以灰度模式读取</span></span><br><span class="line">	<span class="comment"># &gt; 127 将图像二值化，转换为布尔数组，表示掩码中前景（目标）的位置</span></span><br><span class="line">	mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) &gt; <span class="number">127</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将所有当前掩码图中为 True（即目标区域）的位置，在总的 mask 中赋值为 1</span></span><br><span class="line">	<span class="comment"># 最终 mask 中为 1 的地方表示所有目标区域的合集</span></span><br><span class="line">	mask[mask_] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>合并后如下，图像（image）和标签（mask）：</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526173609.png"></p>
<h3 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3.数据增强"></a>3.数据增强</h3><p>数据增强我们使用<a target="_blank" rel="noopener" href="https://github.com/albumentations-team/albumentations">Albumentations</a>，它特别适合用于图像分类、分割、检测等深度学习任务。具有高性能（C++后端加速），高度可配置（支持组合增强），易于与 PyTorch、TensorFlow 等深度学习框架集成等特点。并且支持多种增强操作，包括但不限于：</p>
<ul>
<li><strong>几何变换</strong>：旋转、裁剪、缩放、仿射变换、透视变换等</li>
<li><strong>颜色变换</strong>：亮度、对比度、色调、饱和度、CLAHE、自适应直方图均衡</li>
<li><strong>噪声添加</strong>：高斯噪声、椒盐噪声、模糊、压缩失真</li>
<li><strong>分割&#x2F;检测支持</strong>：自动处理 mask、bboxes 等</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对训练数据进行增强</span></span><br><span class="line">train_transform = Compose([  </span><br><span class="line">    A.RandomRotate90(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率将图像随机旋转90、180或270度</span></span><br><span class="line">    A.HorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率进行水平翻转</span></span><br><span class="line">    A.VerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 以50%的概率进行垂直翻转</span></span><br><span class="line">    OneOf([</span><br><span class="line">        A.HueSaturationValue(p=<span class="number">1</span>),  <span class="comment"># 对图像的色调、饱和度和亮度进行随机扰动</span></span><br><span class="line">        A.RandomBrightnessContrast(brightness_limit=<span class="number">0.2</span>, contrast_limit=<span class="number">0.2</span>, p=<span class="number">1</span>),  <span class="comment"># 随机调整亮度和对比度</span></span><br><span class="line">    ], p=<span class="number">1</span>),  <span class="comment"># 二选一，只选择其中一个图像增强方式（概率为1，必须执行其一）</span></span><br><span class="line">    A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  <span class="comment"># 将图像缩放到模型输入所需的高度和宽度</span></span><br><span class="line">    A.Normalize(),  <span class="comment"># 将图像像素归一化到标准分布</span></span><br><span class="line">])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 对验证数据仅做必要的预处理</span></span><br><span class="line">val_transform = Compose([  </span><br><span class="line">    A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  <span class="comment"># 尺寸调整 96 * 96</span></span><br><span class="line">    A.Normalize(),  <span class="comment"># 归一化</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h3 id="4-加载数据集"><a href="#4-加载数据集" class="headerlink" title="4.加载数据集"></a>4.加载数据集</h3><p>config具体配置参数见3-1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test_size=0.2 20%的图像将作为验证集，剩下 80% 作为训练集</span></span><br><span class="line"><span class="comment"># random_state=41 设置随机种子，确保每次运行划分结果一致（可复现）</span></span><br><span class="line">train_img_ids, val_img_ids = train_test_split(img_ids, test_size=<span class="number">0.2</span>, random_state=<span class="number">41</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载训练数据集  </span></span><br><span class="line">train_dataset = Dataset(  </span><br><span class="line">    img_ids=train_img_ids,  <span class="comment"># 用于定位每张图像</span></span><br><span class="line">    img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  <span class="comment"># 图像所在目录</span></span><br><span class="line">    mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  <span class="comment"># 掩码文件所在目录</span></span><br><span class="line">    img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  <span class="comment"># 图像扩展名</span></span><br><span class="line">    mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  <span class="comment"># 掩码扩展名</span></span><br><span class="line">    num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  <span class="comment"># 类别数量（用于多分类掩码，通常为1表示二分类）</span></span><br><span class="line">    transform=train_transform)  <span class="comment"># 图像与掩码的增强变换</span></span><br><span class="line"><span class="comment"># 加载验证数据集  </span></span><br><span class="line">val_dataset = Dataset(  </span><br><span class="line">    img_ids=val_img_ids,  </span><br><span class="line">    img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  </span><br><span class="line">    mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  </span><br><span class="line">    img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  </span><br><span class="line">    mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  </span><br><span class="line">    num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">    transform=val_transform)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据加载器</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(  </span><br><span class="line">    train_dataset,  </span><br><span class="line">    batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  <span class="comment"># 每次训练所取的样本数量</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,  <span class="comment"># 是否打乱数据顺序</span></span><br><span class="line">    num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  <span class="comment"># 读取数据时的线程数</span></span><br><span class="line">    drop_last=<span class="literal">True</span>)  <span class="comment"># 如果最后一个batch不足batch_size，是否丢弃它</span></span><br><span class="line"><span class="comment"># 验证数据加载器</span></span><br><span class="line">val_loader = torch.utils.data.DataLoader(  </span><br><span class="line">    val_dataset,  </span><br><span class="line">    batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  </span><br><span class="line">    shuffle=<span class="literal">False</span>,  </span><br><span class="line">    num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  </span><br><span class="line">    drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2-U-Net-网络结构"><a href="#2-U-Net-网络结构" class="headerlink" title="2.U-Net++网络结构"></a>2.U-Net++网络结构</h2><h3 id="1-VGGBlock"><a href="#1-VGGBlock" class="headerlink" title="1.VGGBlock"></a>1.VGGBlock</h3><p>VGG-style 卷积模块，也是图像分割网络（如 U-Net++）中常用的基础构建块，包含了两个连续的卷积层 + BN + ReLU激活，用于提取图像的局部特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGGBlock</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># in_channels: 输入特征图的通道数</span></span><br><span class="line">    <span class="comment"># middle_channels: 第一个卷积的输出通道数</span></span><br><span class="line">    <span class="comment"># out_channels: 第二个卷积的输出通道数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, middle_channels, out_channels</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># ReLU 激活函数，inplace=True 节省内存</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)  </span><br><span class="line">        <span class="comment"># Conv2d 3×3 卷积层，padding=1 保证输入输出尺寸一致</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels, middle_channels, <span class="number">3</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># BatchNorm2d 批标准化，加快训练速度、稳定收敛</span></span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(middle_channels)  </span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(middle_channels, out_channels, <span class="number">3</span>, padding=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channels)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        out = <span class="variable language_">self</span>.conv1(x)  <span class="comment"># 第一次卷积</span></span><br><span class="line">        out = <span class="variable language_">self</span>.bn1(out)  <span class="comment"># 批标准化</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)  <span class="comment"># 激活</span></span><br><span class="line">  </span><br><span class="line">        out = <span class="variable language_">self</span>.conv2(out)  <span class="comment"># 第二次卷积</span></span><br><span class="line">        out = <span class="variable language_">self</span>.bn2(out)  <span class="comment"># 批标准化</span></span><br><span class="line">        out = <span class="variable language_">self</span>.relu(out)  <span class="comment"># 激活</span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h3 id="2-UNet"><a href="#2-UNet" class="headerlink" title="2.UNet"></a>2.UNet</h3><p>一个基于 <strong>U-Net++ 架构的语义分割模型（简化版）</strong>，用于将输入图像逐像素分类成 num_classes 个类别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># num_classes: 最终输出类别数（语义分割中每个像素属于哪个类）</span></span><br><span class="line">    <span class="comment"># input_channels: 输入图像的通道数（RGB=3，灰度=1）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, input_channels=<span class="number">3</span>, **kwargs</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        <span class="comment"># 每一层的通道数配置</span></span><br><span class="line">        nb_filter = [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器部分（下采样路径）</span></span><br><span class="line">        <span class="comment"># 图像尺寸逐步减小，通道数逐步增大，用于提取深层语义特征</span></span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)  <span class="comment"># 下采样操作</span></span><br><span class="line">        <span class="variable language_">self</span>.conv0_0 = VGGBlock(input_channels, nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_0 = VGGBlock(nb_filter[<span class="number">0</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_0 = VGGBlock(nb_filter[<span class="number">1</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_0 = VGGBlock(nb_filter[<span class="number">2</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv4_0 = VGGBlock(nb_filter[<span class="number">3</span>], nb_filter[<span class="number">4</span>], nb_filter[<span class="number">4</span>])  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器部分（上采样路径）</span></span><br><span class="line">        <span class="comment"># 包含多个上采样 + 特征融合（concat）+ 卷积</span></span><br><span class="line">        <span class="variable language_">self</span>.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)  <span class="comment"># 上采样</span></span><br><span class="line">        <span class="variable language_">self</span>.conv3_1 = VGGBlock(nb_filter[<span class="number">3</span>]+nb_filter[<span class="number">4</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_2 = VGGBlock(nb_filter[<span class="number">2</span>]+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_3 = VGGBlock(nb_filter[<span class="number">1</span>]+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_4 = VGGBlock(nb_filter[<span class="number">0</span>]+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 最终输出层</span></span><br><span class="line">        <span class="variable language_">self</span>.final = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        <span class="comment"># 编码阶段（下采样）：图像尺寸每次减半，特征逐步变深</span></span><br><span class="line">        x0_0 = <span class="variable language_">self</span>.conv0_0(<span class="built_in">input</span>)  </span><br><span class="line">        x1_0 = <span class="variable language_">self</span>.conv1_0(<span class="variable language_">self</span>.pool(x0_0))  </span><br><span class="line">        x2_0 = <span class="variable language_">self</span>.conv2_0(<span class="variable language_">self</span>.pool(x1_0))  </span><br><span class="line">        x3_0 = <span class="variable language_">self</span>.conv3_0(<span class="variable language_">self</span>.pool(x2_0))  </span><br><span class="line">        x4_0 = <span class="variable language_">self</span>.conv4_0(<span class="variable language_">self</span>.pool(x3_0))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码阶段（U-Net++风格）</span></span><br><span class="line">        <span class="comment"># 每一层的输出不仅使用其下层的上采样结果，还结合了它本身的特征图，形成一个更密集的 skip-connection 网络结构</span></span><br><span class="line">        x3_1 = <span class="variable language_">self</span>.conv3_1(torch.cat([x3_0, <span class="variable language_">self</span>.up(x4_0)], <span class="number">1</span>))  </span><br><span class="line">        x2_2 = <span class="variable language_">self</span>.conv2_2(torch.cat([x2_0, <span class="variable language_">self</span>.up(x3_1)], <span class="number">1</span>))  </span><br><span class="line">        x1_3 = <span class="variable language_">self</span>.conv1_3(torch.cat([x1_0, <span class="variable language_">self</span>.up(x2_2)], <span class="number">1</span>))  </span><br><span class="line">        x0_4 = <span class="variable language_">self</span>.conv0_4(torch.cat([x0_0, <span class="variable language_">self</span>.up(x1_3)], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出预测图</span></span><br><span class="line">        <span class="comment"># output是一个张量，形状为 (B, num_classes, H, W)，表示每个像素的类别预测</span></span><br><span class="line">        output = <span class="variable language_">self</span>.final(x0_4)  </span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="3-NestedUNet"><a href="#3-NestedUNet" class="headerlink" title="3.NestedUNet"></a>3.NestedUNet</h3><p><strong>U-Net++（Nested U-Net）</strong> 网络，通过<strong>更密集的 skip connections（跳跃连接）</strong>，实现更好的特征融合。</p>
<h4 id="1-命名规则"><a href="#1-命名规则" class="headerlink" title="1.命名规则"></a>1.命名规则</h4><p>convX_Y 表示第 X 层、第 Y 次更新，如：</p>
<ul>
<li>conv1_0: 第 1 层的初始特征提取</li>
<li>conv1_1: 第 1 层的第 1 次上采样拼接更新</li>
<li>conv0_3: 第 0 层的第 3 次融合更新<br>这些是 U-Net++ 的嵌套跳跃连接结构，越来越密集。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NestedUNet</span>(nn.Module):  </span><br><span class="line">    <span class="comment"># num_classes: 分割类别数</span></span><br><span class="line">    <span class="comment"># input_channels: 输入图像通道数，默认为 3（RGB 图像）</span></span><br><span class="line">    <span class="comment"># deep_supervision: 是否启用多层输出作为监督信号（训练时更有效，测试时只用最后一层输出）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, input_channels=<span class="number">3</span>, deep_supervision=<span class="literal">False</span>, **kwargs</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">        nb_filter = [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.deep_supervision = deep_supervision  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_0 = VGGBlock(input_channels, nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_0 = VGGBlock(nb_filter[<span class="number">0</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_0 = VGGBlock(nb_filter[<span class="number">1</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_0 = VGGBlock(nb_filter[<span class="number">2</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv4_0 = VGGBlock(nb_filter[<span class="number">3</span>], nb_filter[<span class="number">4</span>], nb_filter[<span class="number">4</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_1 = VGGBlock(nb_filter[<span class="number">0</span>]+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_1 = VGGBlock(nb_filter[<span class="number">1</span>]+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_1 = VGGBlock(nb_filter[<span class="number">2</span>]+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv3_1 = VGGBlock(nb_filter[<span class="number">3</span>]+nb_filter[<span class="number">4</span>], nb_filter[<span class="number">3</span>], nb_filter[<span class="number">3</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_2 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">2</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_2 = VGGBlock(nb_filter[<span class="number">1</span>]*<span class="number">2</span>+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv2_2 = VGGBlock(nb_filter[<span class="number">2</span>]*<span class="number">2</span>+nb_filter[<span class="number">3</span>], nb_filter[<span class="number">2</span>], nb_filter[<span class="number">2</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_3 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">3</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">        <span class="variable language_">self</span>.conv1_3 = VGGBlock(nb_filter[<span class="number">1</span>]*<span class="number">3</span>+nb_filter[<span class="number">2</span>], nb_filter[<span class="number">1</span>], nb_filter[<span class="number">1</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv0_4 = VGGBlock(nb_filter[<span class="number">0</span>]*<span class="number">4</span>+nb_filter[<span class="number">1</span>], nb_filter[<span class="number">0</span>], nb_filter[<span class="number">0</span>])  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.deep_supervision:  </span><br><span class="line">            <span class="variable language_">self</span>.final1 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final2 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final3 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">            <span class="variable language_">self</span>.final4 = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="variable language_">self</span>.final = nn.Conv2d(nb_filter[<span class="number">0</span>], num_classes, kernel_size=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  </span><br><span class="line">        x0_0 = <span class="variable language_">self</span>.conv0_0(<span class="built_in">input</span>)  </span><br><span class="line">        x1_0 = <span class="variable language_">self</span>.conv1_0(<span class="variable language_">self</span>.pool(x0_0))  </span><br><span class="line">        x0_1 = <span class="variable language_">self</span>.conv0_1(torch.cat([x0_0, <span class="variable language_">self</span>.up(x1_0)], <span class="number">1</span>))  </span><br><span class="line">  </span><br><span class="line">        x2_0 = <span class="variable language_">self</span>.conv2_0(<span class="variable language_">self</span>.pool(x1_0))  </span><br><span class="line">        x1_1 = <span class="variable language_">self</span>.conv1_1(torch.cat([x1_0, <span class="variable language_">self</span>.up(x2_0)], <span class="number">1</span>))  </span><br><span class="line">        x0_2 = <span class="variable language_">self</span>.conv0_2(torch.cat([x0_0, x0_1, <span class="variable language_">self</span>.up(x1_1)], <span class="number">1</span>))  </span><br><span class="line">  </span><br><span class="line">        x3_0 = <span class="variable language_">self</span>.conv3_0(<span class="variable language_">self</span>.pool(x2_0))  </span><br><span class="line">        x2_1 = <span class="variable language_">self</span>.conv2_1(torch.cat([x2_0, <span class="variable language_">self</span>.up(x3_0)], <span class="number">1</span>))  </span><br><span class="line">        x1_2 = <span class="variable language_">self</span>.conv1_2(torch.cat([x1_0, x1_1, <span class="variable language_">self</span>.up(x2_1)], <span class="number">1</span>))  </span><br><span class="line">        x0_3 = <span class="variable language_">self</span>.conv0_3(torch.cat([x0_0, x0_1, x0_2, <span class="variable language_">self</span>.up(x1_2)], <span class="number">1</span>))  </span><br><span class="line">        </span><br><span class="line">        x4_0 = <span class="variable language_">self</span>.conv4_0(<span class="variable language_">self</span>.pool(x3_0))  </span><br><span class="line">        x3_1 = <span class="variable language_">self</span>.conv3_1(torch.cat([x3_0, <span class="variable language_">self</span>.up(x4_0)], <span class="number">1</span>))  </span><br><span class="line">        x2_2 = <span class="variable language_">self</span>.conv2_2(torch.cat([x2_0, x2_1, <span class="variable language_">self</span>.up(x3_1)], <span class="number">1</span>))  </span><br><span class="line">        x1_3 = <span class="variable language_">self</span>.conv1_3(torch.cat([x1_0, x1_1, x1_2, <span class="variable language_">self</span>.up(x2_2)], <span class="number">1</span>))  </span><br><span class="line">        x0_4 = <span class="variable language_">self</span>.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, <span class="variable language_">self</span>.up(x1_3)], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出层（支持深监督）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.deep_supervision:  </span><br><span class="line">            output1 = <span class="variable language_">self</span>.final1(x0_1)  </span><br><span class="line">            output2 = <span class="variable language_">self</span>.final2(x0_2)  </span><br><span class="line">            output3 = <span class="variable language_">self</span>.final3(x0_3)  </span><br><span class="line">            output4 = <span class="variable language_">self</span>.final4(x0_4)  </span><br><span class="line">            <span class="comment"># 输出多个不同深度的预测，常用于训练阶段融合损失</span></span><br><span class="line">            <span class="keyword">return</span> [output1, output2, output3, output4]  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            output = <span class="variable language_">self</span>.final(x0_4)  <span class="comment"># 卷积，输出最终预测</span></span><br><span class="line">            <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h4 id="2-深度监督"><a href="#2-深度监督" class="headerlink" title="2.深度监督"></a>2.深度监督</h4><p>深度监督是一种训练策略：在模型的中间层添加辅助输出，并在这些中间输出上也施加监督信号（即计算损失函数），帮助模型更早地获得梯度反馈，从而 <strong>加速收敛</strong>、<strong>提升性能</strong>。<br>其核心思想是，不仅在最终输出处监督模型，还要在中间层也加入监督，防止深层网络训练时梯度消失或收敛缓慢。</p>
<h4 id="3-图示"><a href="#3-图示" class="headerlink" title="3.图示"></a>3.图示</h4><p>下图是 <strong>U-Net++（Nested U-Net）</strong> 网络结构图，展示了它相较于原始 U-Net 所引入的“密集跳跃连接”和“深监督输出”机制。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250516135710.png"></p>
<h5 id="1-图中每个节点的含义"><a href="#1-图中每个节点的含义" class="headerlink" title="1.图中每个节点的含义"></a>1.图中每个节点的含义</h5><p>图中的每个节点用 $X^{i,j}$ 表示，含义如下：</p>
<ul>
<li>$i$：代表网络的深度层（下采样层数）</li>
<li>$j$：代表当前路径上该节点在嵌套结构中的层数（横向扩展层数）<br>例如：</li>
<li>$X^{0,0}$：最浅层（原图分辨率）第一次卷积输出</li>
<li>$X^{3,0}$：经过三次下采样后的卷积输出</li>
<li>$X^{0,3}$：第0层经过3次横向跳跃融合后的特征</li>
</ul>
<h5 id="2-图中箭头表示含义"><a href="#2-图中箭头表示含义" class="headerlink" title="2.图中箭头表示含义"></a>2.图中箭头表示含义</h5><p>右下角图例解释了箭头含义：</p>
<ul>
<li><strong>Down-sampling</strong>（下采样）：粗实线向下箭头<ul>
<li>如：从 $X^{0,0} → X^{1,0}$，通过 MaxPool 实现</li>
</ul>
</li>
<li><strong>Up-sampling</strong>（上采样）：粗实线向上箭头<ul>
<li>如：从 $X^{1,0} → X^{0,1}$，通过插值上采样（如 bilinear）</li>
</ul>
</li>
<li><strong>Skip connection</strong>（跳跃连接）：虚线箭头<ul>
<li>表示来自不同路径的特征拼接（cat）</li>
</ul>
</li>
</ul>
<h5 id="3-结构核心：嵌套密集跳跃连接"><a href="#3-结构核心：嵌套密集跳跃连接" class="headerlink" title="3.结构核心：嵌套密集跳跃连接"></a>3.结构核心：嵌套密集跳跃连接</h5><p>与原始 U-Net 不同，U-Net++ 每一个横向的节点（$X^{i,j}，j&gt;0$）不仅融合来自下一级的上采样特征，还融合同级之前所有横向特征（如 $X^{i,0}, X^{i,1}, …$）。这实现了<strong>更细致的特征聚合</strong>，提升了模型表现力。</p>
<h5 id="4-深监督输出（deep-supervision）"><a href="#4-深监督输出（deep-supervision）" class="headerlink" title="4.深监督输出（deep supervision）"></a>4.深监督输出（deep supervision）</h5><p>如上图中黄色框标注了 4 个输出点：$X^{0,1}、X^{0,2}、X^{0,3}、X^{0,4}$，每个点后面接一个 1×1 卷积层进行通道压缩得到预测，所有输出参与 loss 计算，提升训练稳定性和梯度传播效率。</p>
<h5 id="5-代码与结构图节点对应关系"><a href="#5-代码与结构图节点对应关系" class="headerlink" title="5.代码与结构图节点对应关系"></a>5.代码与结构图节点对应关系</h5><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">图结构节点：             对应代码：</span><br><span class="line">X^0,0  →             self.conv0_0</span><br><span class="line">X^1,0  →             self.conv1_0</span><br><span class="line">X^2,0  →             self.conv2_0</span><br><span class="line">X^3,0  →             self.conv3_0</span><br><span class="line">X^4,0  →             self.conv4_0</span><br><span class="line"></span><br><span class="line">X^0,1  →             self.conv0_1</span><br><span class="line">X^1,1  →             self.conv1_1</span><br><span class="line">X^2,1  →             self.conv2_1</span><br><span class="line">X^3,1  →             self.conv3_1</span><br><span class="line"></span><br><span class="line">X^0,2  →             self.conv0_2</span><br><span class="line">X^1,2  →             self.conv1_2</span><br><span class="line">X^2,2  →             self.conv2_2</span><br><span class="line"></span><br><span class="line">X^0,3  →             self.conv0_3</span><br><span class="line">X^1,3  →             self.conv1_3</span><br><span class="line"></span><br><span class="line">X^0,4  →             self.conv0_4</span><br></pre></td></tr></table></figure>
<p>所有 convX_Y 都是 VGGBlock（即 2 个 3×3 卷积 + BN + ReLU），节点间的数据流动方式严格对应图中的方向和跳跃连接，上采样统一用的是 <code>nn.Upsample(scale_factor=2, mode=&#39;bilinear&#39;)</code>。</p>
<h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3.训练"></a>3.训练</h2><h3 id="1-训练参数配置"><a href="#1-训练参数配置" class="headerlink" title="1.训练参数配置"></a>1.训练参数配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():  </span><br><span class="line">    parser = argparse.ArgumentParser()  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型名称  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="literal">None</span>, <span class="built_in">help</span>=<span class="string">&#x27;model name: (default: arch+timestamp)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 训练轮数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, default=<span class="number">10</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of total epochs to run&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 每个batch的数据量  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-b&#x27;</span>, <span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">8</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;mini-batch size (default: 16)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># model，控制模型结构、是否使用深度监督、输入图像尺寸  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--arch&#x27;</span>, <span class="string">&#x27;-a&#x27;</span>, metavar=<span class="string">&#x27;ARCH&#x27;</span>, default=<span class="string">&#x27;NestedUNet&#x27;</span>,  </span><br><span class="line">                        choices=ARCH_NAMES,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;model architecture: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join(ARCH_NAMES) + <span class="string">&#x27; (default: NestedUNet)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 是否使用深度监督（U-Net++ 特性），false，只用最后一层输出  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--deep_supervision&#x27;</span>, default=<span class="literal">False</span>, <span class="built_in">type</span>=str2bool)  </span><br><span class="line">    <span class="comment"># 输入图像通道数 3表示彩色图像（RGB）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_channels&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input channels&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 类别数量1 表示二分类（前景 vs 背景）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of classes&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 输入图像宽  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_w&#x27;</span>, default=<span class="number">96</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;image width&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 输入图像高  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_h&#x27;</span>, default=<span class="number">96</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;image height&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 损失函数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--loss&#x27;</span>, default=<span class="string">&#x27;BCEDiceLoss&#x27;</span>, choices=LOSS_NAMES,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;loss: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join(LOSS_NAMES) + <span class="string">&#x27; (default: BCEDiceLoss)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数据集  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, default=<span class="string">&#x27;dsb2018_96&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;dataset name&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 图像文件后缀  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--img_ext&#x27;</span>, default=<span class="string">&#x27;.png&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;image file extension&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 掩码的文件后缀  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mask_ext&#x27;</span>, default=<span class="string">&#x27;.png&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;mask file extension&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 优化器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--optimizer&#x27;</span>, default=<span class="string">&#x27;SGD&#x27;</span>,  </span><br><span class="line">                        choices=[<span class="string">&#x27;Adam&#x27;</span>, <span class="string">&#x27;SGD&#x27;</span>],  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;loss: &#x27;</span> + <span class="string">&#x27; | &#x27;</span>.join([<span class="string">&#x27;Adam&#x27;</span>, <span class="string">&#x27;SGD&#x27;</span>]) + <span class="string">&#x27; (default: Adam)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 初始学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="string">&#x27;--learning_rate&#x27;</span>, default=<span class="number">1e-3</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, metavar=<span class="string">&#x27;LR&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;initial learning rate&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 动量项（SGD 特有）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--momentum&#x27;</span>, default=<span class="number">0.9</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;momentum&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 权重衰减（正则化）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weight_decay&#x27;</span>, default=<span class="number">1e-4</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;weight decay&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 是否使用 Nesterov 动量  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nesterov&#x27;</span>, default=<span class="literal">False</span>, <span class="built_in">type</span>=str2bool, <span class="built_in">help</span>=<span class="string">&#x27;nesterov&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 学习率调度器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scheduler&#x27;</span>, default=<span class="string">&#x27;CosineAnnealingLR&#x27;</span>,  </span><br><span class="line">                        choices=[<span class="string">&#x27;CosineAnnealingLR&#x27;</span>, <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>, <span class="string">&#x27;MultiStepLR&#x27;</span>, <span class="string">&#x27;ConstantLR&#x27;</span>])  </span><br><span class="line">    <span class="comment"># 最小学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_lr&#x27;</span>, default=<span class="number">1e-5</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;minimum learning rate&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 每次降低的倍数，用于某些调度器  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--factor&#x27;</span>, default=<span class="number">0.1</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)  </span><br><span class="line">    <span class="comment"># scheduler 的耐心（多少次不提升再调整学习率）  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--patience&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)  </span><br><span class="line">    <span class="comment"># 在哪些 epoch 降低学习率  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--milestones&#x27;</span>, default=<span class="string">&#x27;1,2&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>)  </span><br><span class="line">    <span class="comment"># 学习率衰减系数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gamma&#x27;</span>, default=<span class="number">2</span> / <span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)  </span><br><span class="line">    <span class="comment"># 早停 -1 表示不启用  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--early_stopping&#x27;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;early stopping (default: -1)&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 数据加载线程数  </span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)  </span><br><span class="line">  </span><br><span class="line">    config = parser.parse_args()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure>
<h3 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2.损失函数"></a>2.损失函数</h3><h4 id="1-BCEDiceLoss"><a href="#1-BCEDiceLoss" class="headerlink" title="1.BCEDiceLoss"></a>1.BCEDiceLoss</h4><p>BCEDiceLoss结合了两种损失函数:</p>
<ul>
<li><strong>BCE（Binary Cross Entropy）</strong>：像素级分类准确性</li>
<li><strong>Dice Loss</strong>：评估预测区域与真实区域的重叠程度，适合前景-背景不平衡问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BCEDiceLoss</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, target</span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">        :param input: 模型输出 logits        </span></span><br><span class="line"><span class="string">        :param target: ground truth 掩码（0/1）  </span></span><br><span class="line"><span class="string">        :return:  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>        </span><br><span class="line">        <span class="comment"># 1.BCE Loss  </span></span><br><span class="line">        <span class="comment"># 直接使用带logits的BCE，内部自动做了sigmoid  </span></span><br><span class="line">        bce = F.binary_cross_entropy_with_logits(<span class="built_in">input</span>, target)  </span><br><span class="line">        smooth = <span class="number">1e-5</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 2.Dice Loss  </span></span><br><span class="line">        <span class="built_in">input</span> = torch.sigmoid(<span class="built_in">input</span>) <span class="comment"># 激活sigmoid，转换为概率  </span></span><br><span class="line">        <span class="comment"># reshape 展平  </span></span><br><span class="line">        num = target.size(<span class="number">0</span>)  </span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.view(num, -<span class="number">1</span>)  </span><br><span class="line">        target = target.view(num, -<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 计算Dice系数，Dice系数表示预测和目标之间的重叠程度，越大越好  </span></span><br><span class="line">        intersection = (<span class="built_in">input</span> * target)  </span><br><span class="line">        dice = (<span class="number">2.</span> * intersection.<span class="built_in">sum</span>(<span class="number">1</span>) + smooth) / (<span class="built_in">input</span>.<span class="built_in">sum</span>(<span class="number">1</span>) + target.<span class="built_in">sum</span>(<span class="number">1</span>) + smooth)  </span><br><span class="line">        dice = <span class="number">1</span> - dice.<span class="built_in">sum</span>() / num  </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * bce + dice</span><br></pre></td></tr></table></figure>
<p>前景像素非常少（比如肿瘤检测、医学分割、道路提取），Dice 可增强区域预测能力，BCE 保证细节与边界预测精度。</p>
<h4 id="2-LovaszHingeLoss"><a href="#2-LovaszHingeLoss" class="headerlink" title="2.LovaszHingeLoss"></a>2.LovaszHingeLoss</h4><p>结构感知的分割损失函数，基于 <strong>Lovász Hinge Loss</strong> 的结构性优化目标：</p>
<ul>
<li>与 IoU（交并比）相关，专门为 <strong>非凸、不可微的 mIoU 目标</strong> 设计的近似优化方法</li>
<li>强调 <strong>结构</strong> 的正确性（不是单个像素）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LovaszHingeLoss</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, target</span>):  </span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.squeeze(<span class="number">1</span>)  </span><br><span class="line">        target = target.squeeze(<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 计算每张图的结构性错误  </span></span><br><span class="line">        loss = lovasz_hinge(<span class="built_in">input</span>, target, per_image=<span class="literal">True</span>)  </span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>优势</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>结构感知</td>
<td>优化 IoU 相关指标而非逐像素损失</td>
</tr>
<tr>
<td>非凸优化</td>
<td>用次梯度方法优化非连续目标（如 mIoU）</td>
</tr>
<tr>
<td>表现优秀</td>
<td>在结构敏感型分割（如边缘、孔洞等）表现更佳</td>
</tr>
</tbody></table>
<h4 id="3-对比"><a href="#3-对比" class="headerlink" title="3.对比"></a>3.对比</h4><table>
<thead>
<tr>
<th><strong>损失函数</strong></th>
<th><strong>优点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td>BCEDiceLoss</td>
<td>简单有效，能兼顾像素准确与区域重叠</td>
<td>医学图像、前景稀疏场景</td>
</tr>
<tr>
<td>LovaszHingeLoss</td>
<td>更贴近 IoU 优化目标，更关注结构完整性</td>
<td>对结构敏感的任务，如道路提取、器官边界分割等</td>
</tr>
</tbody></table>
<h3 id="3-优化器"><a href="#3-优化器" class="headerlink" title="3.优化器"></a>3.优化器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.筛选需要优化的参数</span></span><br><span class="line"><span class="comment"># 只把可训练的参数传给优化器（忽略被冻结的参数）</span></span><br><span class="line">params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: p.requires_grad, model.parameters())  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.根据配置创建优化器</span></span><br><span class="line"><span class="comment"># 读取config字典，按配置创建对应的优化器实例</span></span><br><span class="line"><span class="keyword">if</span> config[<span class="string">&#x27;optimizer&#x27;</span>] == <span class="string">&#x27;Adam&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 自适应学习率的 Adam 优化器</span></span><br><span class="line">    optimizer = optim.Adam(  </span><br><span class="line">        params, lr=config[<span class="string">&#x27;lr&#x27;</span>], weight_decay=config[<span class="string">&#x27;weight_decay&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;optimizer&#x27;</span>] == <span class="string">&#x27;SGD&#x27;</span>: </span><br><span class="line">    <span class="comment"># 经典的随机梯度下降优化器</span></span><br><span class="line">    <span class="comment"># momentum：动量参数</span></span><br><span class="line">    <span class="comment"># nesterov：是否使用 Nesterov 动量加速（提前看一步梯度）</span></span><br><span class="line">    <span class="comment"># weight_decay：L2 正则项</span></span><br><span class="line">    optimizer = optim.SGD(params, </span><br><span class="line">		    lr=config[<span class="string">&#x27;lr&#x27;</span>], </span><br><span class="line">		    momentum=config[<span class="string">&#x27;momentum&#x27;</span>],  </span><br><span class="line">            nesterov=config[<span class="string">&#x27;nesterov&#x27;</span>], </span><br><span class="line">            weight_decay=config[<span class="string">&#x27;weight_decay&#x27;</span>])  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p> Adam 优化器适用：训练不稳定或梯度稀疏（如 Transformer、U-Net）。<br> SGD 优化器适用：训练稳定、想控制收敛过程精细（如 ResNet、分类任务）。</p>
<h3 id="4-学习率"><a href="#4-学习率" class="headerlink" title="4.学习率"></a>4.学习率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;CosineAnnealingLR&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 余弦下降：学习率在训练过程中像余弦曲线一样先慢慢下降，接近最后阶段时趋于 min_lr</span></span><br><span class="line">    scheduler = lr_scheduler.CosineAnnealingLR(  </span><br><span class="line">        optimizer, T_max=config[<span class="string">&#x27;epochs&#x27;</span>], eta_min=config[<span class="string">&#x27;min_lr&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 当模型某个评价指标（如验证 loss）在若干轮内不再下降时，就减小学习率</span></span><br><span class="line">    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=config[<span class="string">&#x27;factor&#x27;</span>], patience=config[<span class="string">&#x27;patience&#x27;</span>],  verbose=<span class="literal">True</span>, min_lr=config[<span class="string">&#x27;min_lr&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;MultiStepLR&#x27;</span>:  </span><br><span class="line">    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="built_in">int</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> config[<span class="string">&#x27;milestones&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)], gamma=config[<span class="string">&#x27;gamma&#x27;</span>])  </span><br><span class="line"><span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ConstantLR&#x27;</span>:  </span><br><span class="line">    scheduler = <span class="literal">None</span>  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<h4 id="1-CosineAnnealingLR"><a href="#1-CosineAnnealingLR" class="headerlink" title="1.CosineAnnealingLR"></a>1.CosineAnnealingLR</h4><p>余弦退火，适合训练后期希望缓慢收敛，防止震荡，比如分类、分割、目标检测等任务</p>
<h4 id="2-ReduceLROnPlateau"><a href="#2-ReduceLROnPlateau" class="headerlink" title="2.ReduceLROnPlateau"></a>2.ReduceLROnPlateau</h4><p>性能不提升时降低学习率，适合模型容易早停，需要动态响应性能变化，比如医学图像、少样本任务等</p>
<h4 id="3-MultiStepLR"><a href="#3-MultiStepLR" class="headerlink" title="3.MultiStepLR"></a>3.MultiStepLR</h4><p>多阶段下降，训练有明显阶段性（如 ImageNet 训练常见策略）</p>
<h4 id="4-ConstantLR"><a href="#4-ConstantLR" class="headerlink" title="4.ConstantLR"></a>4.ConstantLR</h4><p>不使用调度器，适合做实验对照，或已知固定学习率效果不错</p>
<h3 id="5-训练流程"><a href="#5-训练流程" class="headerlink" title="5.训练流程"></a>5.训练流程</h3><h4 id="1-训练"><a href="#1-训练" class="headerlink" title="1.训练"></a>1.训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">config, train_loader, model, criterion, optimizer</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化状态</span></span><br><span class="line">    <span class="comment"># 记录每轮的平均 loss 和 IOU    </span></span><br><span class="line">    avg_meters = &#123;<span class="string">&#x27;loss&#x27;</span>: AverageMeter(), <span class="string">&#x27;iou&#x27;</span>: AverageMeter()&#125;  </span><br><span class="line">    model.train()  <span class="comment"># 设置为训练模式</span></span><br><span class="line">    pbar = tqdm(total=<span class="built_in">len</span>(train_loader))  <span class="comment"># 进度条，显示训练过程</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.遍历训练数据</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target, _ <span class="keyword">in</span> train_loader:  <span class="comment"># 每次读取一个批次（image mask）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.处理设备</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">            target = target.cuda()  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">            target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 4. 正向传播 &amp; 计算损失 + IoU</span></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">            outputs = model(<span class="built_in">input</span>) <span class="comment"># 多输出用于深度监督  </span></span><br><span class="line">            loss = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">for</span> output <span class="keyword">in</span> outputs:  </span><br><span class="line">                loss += criterion(output, target)  </span><br><span class="line">            loss /= <span class="built_in">len</span>(outputs)  </span><br><span class="line">            iou = iou_score(outputs[-<span class="number">1</span>], target)  </span><br><span class="line">            <span class="comment"># model(input) 返回多个输出（如 x0_1, x0_2, …, x0_4）</span></span><br><span class="line">            <span class="comment"># 每个输出都参与损失计算，然后平均</span></span><br><span class="line">            <span class="comment"># 只用最后一个输出计算 IoU（最深层最准确）</span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            output = model(<span class="built_in">input</span>)  </span><br><span class="line">            loss = criterion(output, target)  </span><br><span class="line">            iou = iou_score(output, target)  </span><br><span class="line">            <span class="comment"># 正常的单输出模型，直接计算损失和IoU</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 5. 梯度更新</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清空旧梯度</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 执行一次优化器更新</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 6.更新统计 &amp; 展示进度</span></span><br><span class="line">        avg_meters[<span class="string">&#x27;loss&#x27;</span>].update(loss.item(), <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">        avg_meters[<span class="string">&#x27;iou&#x27;</span>].update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">        <span class="comment"># 每个 batch 结束后更新累计 loss 与 iou 的加权平均</span></span><br><span class="line">        postfix = OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg),])  </span><br><span class="line">        pbar.set_postfix(postfix)  </span><br><span class="line">        pbar.update(<span class="number">1</span>)  </span><br><span class="line">    pbar.close()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7. 返回训练结果</span></span><br><span class="line">    <span class="comment"># 平均 loss 和 IoU，用于日志记录、调度器调整、验证等</span></span><br><span class="line">    <span class="keyword">return</span> OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg)])</span><br></pre></td></tr></table></figure>
<h4 id="2-验证"><a href="#2-验证" class="headerlink" title="2.验证"></a>2.验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">validate</span>(<span class="params">config, val_loader, model, criterion</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化两个累加器：分别记录本轮平均损失 与 IoU</span></span><br><span class="line">    avg_meters = &#123;<span class="string">&#x27;loss&#x27;</span>: AverageMeter(),  </span><br><span class="line">                  <span class="string">&#x27;iou&#x27;</span>: AverageMeter()&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2.把模型切到评估模式：BatchNorm使用全局均值/方差 Dropout关闭随机丢弃</span></span><br><span class="line">    model.<span class="built_in">eval</span>()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.不计算梯度，节省显存  </span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">        pbar = tqdm(total=<span class="built_in">len</span>(val_loader))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.每次读取一个批次（image mask）</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">input</span>, target, _ <span class="keyword">in</span> val_loader:  </span><br><span class="line">            <span class="comment"># 5.处理设备</span></span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">                target = target.cuda()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">                target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 6.前向推理与损失 / IoU 计算</span></span><br><span class="line">            <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">                outputs = model(<span class="built_in">input</span>)  </span><br><span class="line">                loss = <span class="number">0</span>  </span><br><span class="line">                <span class="keyword">for</span> output <span class="keyword">in</span> outputs:  </span><br><span class="line">                    <span class="comment"># 对每个输出单独计算损失，再求平均</span></span><br><span class="line">                    loss += criterion(output, target)  </span><br><span class="line">                loss /= <span class="built_in">len</span>(outputs)  </span><br><span class="line">                <span class="comment"># 只用最后一级 outputs[-1] 计算 IoU（最精细）</span></span><br><span class="line">                iou = iou_score(outputs[-<span class="number">1</span>], target)  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)  </span><br><span class="line">                loss = criterion(output, target)  </span><br><span class="line">                iou = iou_score(output, target)  </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 7.指标累积</span></span><br><span class="line">            avg_meters[<span class="string">&#x27;loss&#x27;</span>].update(loss.item(), <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">            avg_meters[<span class="string">&#x27;iou&#x27;</span>].update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">  </span><br><span class="line">            postfix = OrderedDict([  </span><br><span class="line">                (<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg),  </span><br><span class="line">                (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg),  </span><br><span class="line">            ])  </span><br><span class="line">            pbar.set_postfix(postfix)  </span><br><span class="line">            pbar.update(<span class="number">1</span>)  </span><br><span class="line">        pbar.close()  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以OrderedDict形式返回本epoch的 验证损失 与 验证 IoU</span></span><br><span class="line">    <span class="keyword">return</span> OrderedDict([(<span class="string">&#x27;loss&#x27;</span>, avg_meters[<span class="string">&#x27;loss&#x27;</span>].avg), (<span class="string">&#x27;iou&#x27;</span>, avg_meters[<span class="string">&#x27;iou&#x27;</span>].avg)])</span><br></pre></td></tr></table></figure>
<h4 id="3-主流程"><a href="#3-主流程" class="headerlink" title="3.主流程"></a>3.主流程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    <span class="comment"># 获取参数字典  </span></span><br><span class="line">    config = <span class="built_in">vars</span>(parse_args())  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 自动生成模型名  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 保存配置文件  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 初始化损失函数  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建模型  </span></span><br><span class="line">    ... </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 选择优化器  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 配置学习率调度器  </span></span><br><span class="line">    ... </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载图像ID，并划分训练/验证集  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数据增强策略  </span></span><br><span class="line">    ...  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载数据集  </span></span><br><span class="line">    ...</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 日志记录结构  </span></span><br><span class="line">    log = OrderedDict([  </span><br><span class="line">        (<span class="string">&#x27;epoch&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;lr&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;loss&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;iou&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;val_loss&#x27;</span>, []),  </span><br><span class="line">        (<span class="string">&#x27;val_iou&#x27;</span>, []),  </span><br><span class="line">    ])  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.初始化参数</span></span><br><span class="line">    best_iou = <span class="number">0</span>  <span class="comment"># 记录迄今为止验证集上的最佳 IoU，用于模型保存判断</span></span><br><span class="line">    trigger = <span class="number">0</span>  <span class="comment"># - 记录连续验证集没有提升的 epoch 数，用于早停</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2.主训练循环 </span></span><br><span class="line">    <span class="comment"># 循环执行多个 epoch，每轮执行完整的训练-验证流程</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;epochs&#x27;</span>]):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch [%d/%d]&#x27;</span> % (epoch, config[<span class="string">&#x27;epochs&#x27;</span>]))  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 每轮训练 &amp; 验证</span></span><br><span class="line">        train_log = train(config, train_loader, model, criterion, optimizer)  </span><br><span class="line">        val_log = validate(config, val_loader, model, criterion)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.学习率调度器更新  </span></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;CosineAnnealingLR&#x27;</span>: <span class="comment"># 基于 epoch 数变化</span></span><br><span class="line">            scheduler.step()  </span><br><span class="line">        <span class="keyword">elif</span> config[<span class="string">&#x27;scheduler&#x27;</span>] == <span class="string">&#x27;ReduceLROnPlateau&#x27;</span>: <span class="comment"># 根据 val loss 变化调整</span></span><br><span class="line">            scheduler.step(val_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 打印指标</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f&#x27;</span>  </span><br><span class="line">              % (train_log[<span class="string">&#x27;loss&#x27;</span>], train_log[<span class="string">&#x27;iou&#x27;</span>], val_log[<span class="string">&#x27;loss&#x27;</span>], val_log[<span class="string">&#x27;iou&#x27;</span>])) </span><br><span class="line">               </span><br><span class="line">        <span class="comment"># 6.日志记录  </span></span><br><span class="line">        log[<span class="string">&#x27;epoch&#x27;</span>].append(epoch)  </span><br><span class="line">        log[<span class="string">&#x27;lr&#x27;</span>].append(config[<span class="string">&#x27;lr&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;loss&#x27;</span>].append(train_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;iou&#x27;</span>].append(train_log[<span class="string">&#x27;iou&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;val_loss&#x27;</span>].append(val_log[<span class="string">&#x27;loss&#x27;</span>])  </span><br><span class="line">        log[<span class="string">&#x27;val_iou&#x27;</span>].append(val_log[<span class="string">&#x27;iou&#x27;</span>])  </span><br><span class="line">        pd.DataFrame(log).to_csv(<span class="string">&#x27;models/%s/log.csv&#x27;</span> % config[<span class="string">&#x27;name&#x27;</span>], index=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">        trigger += <span class="number">1</span>  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 7.保存最佳模型  </span></span><br><span class="line">        <span class="keyword">if</span> val_log[<span class="string">&#x27;iou&#x27;</span>] &gt; best_iou:  </span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&#x27;models/%s/model.pth&#x27;</span> %  </span><br><span class="line">                       config[<span class="string">&#x27;name&#x27;</span>])  </span><br><span class="line">            best_iou = val_log[<span class="string">&#x27;iou&#x27;</span>]  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;=&gt; saved best model&quot;</span>)  </span><br><span class="line">            trigger = <span class="number">0</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 8.早停判断  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= config[<span class="string">&#x27;early_stopping&#x27;</span>] &lt;= trigger:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;=&gt; early stopping&quot;</span>)  </span><br><span class="line">            <span class="keyword">break</span>  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 9. 清理缓存</span></span><br><span class="line">        torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h2 id="4-验证"><a href="#4-验证" class="headerlink" title="4.验证"></a>4.验证</h2><h3 id="1-可视化结果"><a href="#1-可视化结果" class="headerlink" title="1.可视化结果"></a>1.可视化结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_examples</span>(<span class="params">datax, datay, model, num_examples=<span class="number">6</span></span>):  </span><br><span class="line">    <span class="comment"># 创建画布，准备绘制num_examples行、每行3列的图像（原图、预测、真值）</span></span><br><span class="line">    fig, ax = plt.subplots(nrows=num_examples, ncols=<span class="number">3</span>, figsize=(<span class="number">18</span>, <span class="number">4</span> * num_examples))  </span><br><span class="line">    m = datax.shape[<span class="number">0</span>]  <span class="comment"># 数据集样本总数（datax 是一个 batch 或完整验证集）</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> row_num <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):  </span><br><span class="line">        <span class="comment"># 随机选取一个图像索引</span></span><br><span class="line">        image_indx = np.random.randint(m)  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取模型预测结果：输入的是一个图像 batch（1 张），</span></span><br><span class="line">        <span class="comment"># 输出后 squeeze 成单张，再转为 NumPy</span></span><br><span class="line">        image_arr = model(datax[image_indx:image_indx + <span class="number">1</span>]).squeeze(<span class="number">0</span>).detach().cpu().numpy()  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 原始图像  </span></span><br><span class="line">        ax[row_num][<span class="number">0</span>].imshow(np.transpose(datax[image_indx].cpu().numpy(), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))[:, :, <span class="number">0</span>])  </span><br><span class="line">        ax[row_num][<span class="number">0</span>].set_title(<span class="string">&quot;Orignal Image&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 模型预测图像  </span></span><br><span class="line">        ax[row_num][<span class="number">1</span>].imshow(np.squeeze((image_arr &gt; <span class="number">0.40</span>)[<span class="number">0</span>, :, :].astype(<span class="built_in">int</span>)))  </span><br><span class="line">        ax[row_num][<span class="number">1</span>].set_title(<span class="string">&quot;Segmented Image localization&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># Ground Truth 掩码图像  </span></span><br><span class="line">        ax[row_num][<span class="number">2</span>].imshow(np.transpose(datay[image_indx].cpu().numpy(), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))[:, :, <span class="number">0</span>])  </span><br><span class="line">        ax[row_num][<span class="number">2</span>].set_title(<span class="string">&quot;Target image&quot;</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="2-验证-1"><a href="#2-验证-1" class="headerlink" title="2.验证"></a>2.验证</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():  </span><br><span class="line">    args = parse_args()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 1. 加载配置文件  </span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;models/%s/config.yml&#x27;</span> % args.name, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        config = yaml.load(f, Loader=yaml.FullLoader)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 打印配置信息，便于调试查看</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)  </span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> config.keys():  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (key, <span class="built_in">str</span>(config[key])))  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 2. 初始化环境，启用 cuDNN 自动优化  </span></span><br><span class="line">    cudnn.benchmark = <span class="literal">True</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3. 创建模型  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; creating model %s&quot;</span> % config[<span class="string">&#x27;arch&#x27;</span>])  </span><br><span class="line">    model = archs.__dict__[config[<span class="string">&#x27;arch&#x27;</span>]](config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">                                           config[<span class="string">&#x27;input_channels&#x27;</span>],  </span><br><span class="line">                                           config[<span class="string">&#x27;deep_supervision&#x27;</span>])  </span><br><span class="line">    <span class="comment"># 加载到 CUDA（如可用）  </span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">        model = model.cuda()  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">        model.to(device)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 4.加载数据集，读取所有图像ID（去掉扩展名）  </span></span><br><span class="line">    img_ids = glob(os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>, <span class="string">&#x27;*&#x27;</span> + config[<span class="string">&#x27;img_ext&#x27;</span>]))  </span><br><span class="line">    img_ids = [os.path.splitext(os.path.basename(p))[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> img_ids]  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 拆分验证集，随机划分出 20% 的验证集</span></span><br><span class="line">    _, val_img_ids = train_test_split(img_ids, test_size=<span class="number">0.2</span>, random_state=<span class="number">41</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 5.加载模型参数</span></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;models/%s/model.pth&#x27;</span> % config[<span class="string">&#x27;name&#x27;</span>]))  </span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># 设置为评估模式  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 6. 定义验证集增强，定义验证集图像增强（大小缩放 + 归一化）  </span></span><br><span class="line">    val_transform = Compose([  </span><br><span class="line">        A.Resize(config[<span class="string">&#x27;input_h&#x27;</span>], config[<span class="string">&#x27;input_w&#x27;</span>]),  </span><br><span class="line">        A.Normalize(),  </span><br><span class="line">    ])  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 加载验证集数据集  </span></span><br><span class="line">    val_dataset = Dataset(  </span><br><span class="line">        img_ids=val_img_ids,  </span><br><span class="line">        img_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;images&#x27;</span>),  </span><br><span class="line">        mask_dir=os.path.join(<span class="string">&#x27;inputs&#x27;</span>, config[<span class="string">&#x27;dataset&#x27;</span>], <span class="string">&#x27;masks&#x27;</span>),  </span><br><span class="line">        img_ext=config[<span class="string">&#x27;img_ext&#x27;</span>],  </span><br><span class="line">        mask_ext=config[<span class="string">&#x27;mask_ext&#x27;</span>],  </span><br><span class="line">        num_classes=config[<span class="string">&#x27;num_classes&#x27;</span>],  </span><br><span class="line">        transform=val_transform)  </span><br><span class="line">    <span class="comment"># 构建数据加载器  </span></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(  </span><br><span class="line">        val_dataset,  </span><br><span class="line">        batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>],  </span><br><span class="line">        shuffle=<span class="literal">False</span>,  </span><br><span class="line">        num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>],  </span><br><span class="line">        drop_last=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 7. 评估模型 初始化 IoU 评估器  </span></span><br><span class="line">    avg_meter = AverageMeter()  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 创建输出目录  </span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;num_classes&#x27;</span>]):  </span><br><span class="line">        os.makedirs(os.path.join(<span class="string">&#x27;outputs&#x27;</span>, config[<span class="string">&#x27;name&#x27;</span>], <span class="built_in">str</span>(c)), exist_ok=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 8. 模型推理</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 验证阶段不计算梯度，节省显存 </span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">input</span>, target, meta <span class="keyword">in</span> tqdm(val_loader, total=<span class="built_in">len</span>(val_loader)):  </span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.cuda()  </span><br><span class="line">                target = target.cuda()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                device = torch.device(<span class="string">&quot;cpu&quot;</span>)  </span><br><span class="line">                <span class="built_in">input</span> = <span class="built_in">input</span>.to(device)  </span><br><span class="line">                target = target.to(device)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 模型前向传播  </span></span><br><span class="line">            <span class="keyword">if</span> config[<span class="string">&#x27;deep_supervision&#x27;</span>]:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)[-<span class="number">1</span>] <span class="comment"># 深度监督则使用最后一个输出  </span></span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                output = model(<span class="built_in">input</span>)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 计算 IoU 得分并更新平均器  </span></span><br><span class="line">            iou = iou_score(output, target)  </span><br><span class="line">            avg_meter.update(iou, <span class="built_in">input</span>.size(<span class="number">0</span>))  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 输出后处理（Sigmoid + 转为 numpy）  </span></span><br><span class="line">            output = torch.sigmoid(output).cpu().numpy()  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 将预测结果保存为图像  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output)):  </span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;num_classes&#x27;</span>]):  </span><br><span class="line">                    cv2.imwrite(os.path.join(<span class="string">&#x27;outputs&#x27;</span>, config[<span class="string">&#x27;name&#x27;</span>], <span class="built_in">str</span>(c), meta[<span class="string">&#x27;img_id&#x27;</span>][i] + <span class="string">&#x27;.jpg&#x27;</span>), (output[i, c] * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>))  </span><br><span class="line">    <span class="comment"># 9. 打印验证结果 平均 IoU    </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;IoU: %.4f&#x27;</span> % avg_meter.avg)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 10.可视化样例  </span></span><br><span class="line">    plot_examples(<span class="built_in">input</span>, target, model, num_examples=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 11.释放显存  </span></span><br><span class="line">    torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<p>可视化样例如下图：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250526155728.png"></p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>本文主要介绍了在PyTorch框架下使用U-Net++网络进行医学图像实例分割的代码实现：</p>
<ol>
<li>​<strong>数据预处理</strong>​<ul>
<li>数据集特点：670张细胞图像，二值掩码标签（0背景&#x2F;1细胞），图像尺寸较小</li>
<li>关键操作：合并多个独立细胞掩码为统一mask，使用OpenCV进行图像缩放和通道处理</li>
<li>数据增强：采用Albumentations库实现旋转&#x2F;翻转&#x2F;色彩扰动等增强策略</li>
</ul>
</li>
<li>​<strong>U-Net++网络结构</strong>​<ul>
<li>改进点：相比经典U-Net增加密集跳跃连接和深度监督机制</li>
<li>核心组件：<ul>
<li>VGGBlock：基础卷积模块（3x3卷积+BN+ReLU×2）</li>
<li>嵌套解码结构：convX_Y命名规则表示第X层第Y次特征融合</li>
</ul>
</li>
<li>深度监督：中间层输出辅助损失，缓解梯度消失</li>
</ul>
</li>
<li>​<strong>模型训练</strong>​<ul>
<li>损失函数：BCEDiceLoss（兼顾像素精度和区域重叠）和LovaszHingeLoss（优化IoU指标）</li>
<li>训练策略：余弦退火学习率、早停机制、模型保存最佳检查点</li>
<li>评估指标：IoU（交并比）作为主要评估标准</li>
</ul>
</li>
<li>​<strong>结果验证</strong>​<ul>
<li>可视化对比：并列显示原图、预测结果和真实标注</li>
<li>性能评估：批量计算验证集平均IoU，保存预测结果图像</li>
</ul>
</li>
</ol>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>mac: 15.2</li>
<li>python: 3.12.4</li>
<li>numpy: 1.26.4</li>
<li>opencv-python: 4.11.0.86</li>
<li>albumentations: 2.0.6</li>
</ul>
<h3 id="资源和代码"><a href="#资源和代码" class="headerlink" title="资源和代码"></a>资源和代码</h3><pre><code>https://github.com/keychankc/dl_code_for_blog/tree/main/011_U-net%2B%2B
</code></pre>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>KeyChan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/" title="基于U-Net++的细胞分割代码实现">https://www.keychan.xyz/2025/05/27/017-unet-cell-segmentation/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://x.com/keychankc">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/" rel="tag"># 目标分割</a>
              <a href="/tags/U-Net/" rel="tag"># U-Net</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/05/19/016-image-segmentation-u-net/" rel="prev" title="图像分割与U-Net系列模型解析">
                  <i class="fa fa-angle-left"></i> 图像分割与U-Net系列模型解析
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/04/018-u2net-saliency-detection/" rel="next" title="U²-Net显著性目标检测">
                  U²-Net显著性目标检测 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KeyChan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">237k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/keychankc" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="/js/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/ribbon.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://comment.mengyajia.com","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":false,"pageview":false,"placeholder":"欢迎评论~","emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq"],"requiredMeta":["nick","mail"],"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/2025/05/27/017-unet-cell-segmentation/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
