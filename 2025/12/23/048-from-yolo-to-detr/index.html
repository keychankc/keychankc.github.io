<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo-512x512.png" color="#222">
  <meta name="google-site-verification" content="jZ7dJJlouQrswxytAryX3LanLNrTthfFdMUkDJzRqIU">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.keychan.xyz","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":272,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="1. DETR 出现的原因在目标检测的发展历程中，YOLO 与 DETR 往往被视为两种截然不同的技术路线，其差异不仅体现在网络结构或训练策略上，更反映了对“目标检测这一问题应当如何建模”的根本理解差别。 直观而言，YOLO 系列方法遵循的是一种密集预测思路：模型在图像的各个空间位置上独立判断是否存在目标，并同时回归其类别与边界框位置。这种做法强调局部决策与并行计算，因而具备极高的推理效率，但也不">
<meta property="og:type" content="article">
<meta property="og:title" content="从 YOLO 到 DETR：目标检测范式的演化与分工">
<meta property="og:url" content="https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/index.html">
<meta property="og:site_name" content="KeyChan&#39;s blog">
<meta property="og:description" content="1. DETR 出现的原因在目标检测的发展历程中，YOLO 与 DETR 往往被视为两种截然不同的技术路线，其差异不仅体现在网络结构或训练策略上，更反映了对“目标检测这一问题应当如何建模”的根本理解差别。 直观而言，YOLO 系列方法遵循的是一种密集预测思路：模型在图像的各个空间位置上独立判断是否存在目标，并同时回归其类别与边界框位置。这种做法强调局部决策与并行计算，因而具备极高的推理效率，但也不">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102312.jpg">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250512154553.png">
<meta property="article:published_time" content="2025-12-23T10:05:12.000Z">
<meta property="article:modified_time" content="2025-12-23T10:06:23.739Z">
<meta property="article:author" content="KeyChan">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="YOLO">
<meta property="article:tag" content="detr">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102312.jpg">


<link rel="canonical" href="https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/","path":"2025/12/23/048-from-yolo-to-detr/","title":"从 YOLO 到 DETR：目标检测范式的演化与分工"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>从 YOLO 到 DETR：目标检测范式的演化与分工 | KeyChan's blog</title>
  







<link rel="dns-prefetch" href="https://comment.mengyajia.com">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="KeyChan's blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KeyChan's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-随想"><a href="/think/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-DETR-%E5%87%BA%E7%8E%B0%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-text">1. DETR 出现的原因</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E5%B7%A5%E4%B8%9A%E7%8E%B0%E5%AE%9E%EF%BC%9AYOLO-%E5%B7%B2%E6%88%90%E4%B8%BA%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%BA%8B%E5%AE%9E%E6%A0%87%E5%87%86"><span class="nav-text">1.1 工业现实：YOLO 已成为目标检测的事实标准</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E4%B8%89%E4%B8%AA%E5%B7%A5%E7%A8%8B%E5%A6%A5%E5%8D%8F"><span class="nav-text">1.2 三个工程妥协</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-%E4%B8%80%E4%B8%AA%E8%A2%AB%E9%95%BF%E6%9C%9F%E5%BF%BD%E7%95%A5%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9A%E6%98%AF%E5%90%A6%E5%BF%85%E9%A1%BB%E2%80%9C%E5%85%88%E9%A2%84%E6%B5%8B%E5%BE%88%E5%A4%9A%EF%BC%8C%E5%86%8D%E5%88%A0%E6%8E%89%E5%A4%A7%E5%A4%9A%E6%95%B0%E2%80%9D"><span class="nav-text">1.3 一个被长期忽略的问题：是否必须“先预测很多，再删掉大多数”</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-YOLO-%E7%9A%84%E6%9C%AC%E8%B4%A8%EF%BC%9A%E6%8A%8A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BD%93%E6%88%90%E2%80%9C%E5%AF%86%E9%9B%86%E9%A2%84%E6%B5%8B%E4%B8%8E%E6%8E%92%E5%BA%8F%E2%80%9D%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-text">2. YOLO 的本质：把目标检测当成“密集预测与排序”的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E4%B8%80%E9%98%B6%E6%AE%B5%E6%A3%80%E6%B5%8B%E7%9A%84%E7%BB%9F%E4%B8%80%E5%BB%BA%E6%A8%A1%E5%81%87%E8%AE%BE"><span class="nav-text">2.1 一阶段检测的统一建模假设</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Anchor-%E4%B8%8E-NMS-%E5%B9%B6%E9%9D%9E%E5%8E%86%E5%8F%B2%E5%8C%85%E8%A2%B1%EF%BC%8C%E8%80%8C%E6%98%AF%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%9C"><span class="nav-text">2.2 Anchor 与 NMS 并非历史包袱，而是逻辑结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-YOLO-%E5%8D%81%E5%B9%B4%E6%BC%94%E5%8C%96%E4%B8%AD%E7%9C%9F%E6%AD%A3%E5%8F%98%E5%8C%96%E4%B8%8E%E4%B8%8D%E5%8F%98%E7%9A%84%E9%83%A8%E5%88%86"><span class="nav-text">2.3 YOLO 十年演化中真正变化与不变的部分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-%E6%8E%92%E5%BA%8F%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-text">2.4 排序视角下的目标检测</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-YOLO-%E5%BE%88%E5%BC%BA%EF%BC%8C%E4%BD%86-NMS-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A7%8B%E7%BB%88%E6%97%A0%E6%B3%95%E8%A2%AB%E7%A7%BB%E9%99%A4%EF%BC%9F"><span class="nav-text">3. YOLO 很强，但 NMS 为什么始终无法被移除？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-NMS-%E8%A7%A3%E5%86%B3%E7%9A%84%E4%B8%8D%E6%98%AF%E6%A3%80%E6%B5%8B%EF%BC%8C%E8%80%8C%E6%98%AF%E9%A2%84%E6%B5%8B%E5%86%B2%E7%AA%81"><span class="nav-text">3.1 NMS 解决的不是检测，而是预测冲突</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-IoU-%E9%98%88%E5%80%BC%E9%97%AE%E9%A2%98%E6%8F%AD%E7%A4%BA%E7%9A%84%E7%BB%93%E6%9E%84%E6%80%A7%E4%B8%8D%E7%A8%B3%E5%AE%9A"><span class="nav-text">3.2 IoU 阈值问题揭示的结构性不稳定</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-Anchor-free-%E5%B9%B6%E6%9C%AA%E7%9C%9F%E6%AD%A3%E6%B6%88%E9%99%A4%E5%86%97%E4%BD%99%E9%A2%84%E6%B5%8B"><span class="nav-text">3.3 Anchor-free 并未真正消除冗余预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-%E4%B8%80%E4%B8%AA%E5%85%B3%E9%94%AE%E5%8F%8D%E6%80%9D%EF%BC%9A%E5%BD%93%E6%A8%A1%E5%9E%8B%E9%9C%80%E8%A6%81-NMS%EF%BC%8C%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-text">3.4 一个关键反思：当模型需要 NMS，意味着什么？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-DETR-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%EF%BC%9A%E5%B0%86%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BB%BA%E6%A8%A1%E4%B8%BA%E4%B8%80%E4%B8%AA%E9%9B%86%E5%90%88%E9%A2%84%E6%B5%8B%E9%97%AE%E9%A2%98"><span class="nav-text">4. DETR 的核心思想：将目标检测建模为一个集合预测问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-%E4%BB%8E%E2%80%9C%E8%A6%86%E7%9B%96%E6%89%80%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BD%8D%E7%BD%AE%E2%80%9D%E5%88%B0%E2%80%9C%E5%8F%AA%E9%A2%84%E6%B5%8B%E5%BA%94%E8%AF%A5%E5%AD%98%E5%9C%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E2%80%9D"><span class="nav-text">4.1 从“覆盖所有可能位置”到“只预测应该存在的目标”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-%E5%9B%BA%E5%AE%9A%E6%95%B0%E9%87%8F%E9%A2%84%E6%B5%8B%E4%B8%8E%E4%B8%80%E5%AF%B9%E4%B8%80%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%90%AB%E4%B9%89"><span class="nav-text">4.2 固定数量预测与一对一约束的含义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-%E4%B8%BA%E4%BB%80%E4%B9%88-DETR-%E5%A4%A9%E7%84%B6%E4%B8%8D%E9%9C%80%E8%A6%81-NMS"><span class="nav-text">4.3 为什么 DETR 天然不需要 NMS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-%E9%9B%86%E5%90%88%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E6%A3%80%E6%B5%8B%E4%BB%BB%E5%8A%A1%E9%87%8D%E6%9E%84"><span class="nav-text">4.4 集合视角下的检测任务重构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-text">4.5 范式转变的意义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E5%8C%88%E7%89%99%E5%88%A9%E5%8C%B9%E9%85%8D%EF%BC%9ADETR-%E4%B8%AD%E6%9C%80%E5%AE%B9%E6%98%93%E8%A2%AB%E8%AF%AF%E8%A7%A3%E7%9A%84%E9%83%A8%E5%88%86"><span class="nav-text">5. 匈牙利匹配：DETR 中最容易被误解的部分</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-%E5%8C%88%E7%89%99%E5%88%A9%E5%8C%B9%E9%85%8D%E4%B8%8D%E6%98%AF%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%8C%E8%80%8C%E6%98%AF%E7%9B%91%E7%9D%A3%E5%AF%B9%E9%BD%90%E6%9C%BA%E5%88%B6"><span class="nav-text">5.1 匈牙利匹配不是后处理，而是监督对齐机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%85%E9%A1%BB%E6%98%AF%E4%B8%80%E5%AF%B9%E4%B8%80%E5%8C%B9%E9%85%8D"><span class="nav-text">5.2 为什么必须是一对一匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E7%9C%9F%E6%AD%A3%E5%90%AB%E4%B9%89%EF%BC%9A%E5%AE%9E%E4%BE%8B%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%8C%E8%80%8C%E9%9D%9E%E5%87%A0%E4%BD%95%E8%B7%9D%E7%A6%BB"><span class="nav-text">5.3 代价函数的真正含义：实例相似度，而非几何距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-%E4%BB%8E%E4%BC%98%E5%8C%96%E8%A7%86%E8%A7%92%E7%90%86%E8%A7%A3-Set-Prediction"><span class="nav-text">5.4 从优化视角理解 Set Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-%E5%B8%B8%E8%A7%81%E8%AF%AF%E8%A7%A3%E4%B8%8E%E6%BE%84%E6%B8%85"><span class="nav-text">5.5 常见误解与澄清</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-DETR-V1%EF%BC%9A%E7%90%86%E5%BF%B5%E6%AD%A3%E7%A1%AE%EF%BC%8C%E5%8D%B4%E5%B9%B6%E4%B8%8D%E5%A5%BD%E7%94%A8"><span class="nav-text">6. DETR-V1：理念正确，却并不好用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-Transformer-%E5%9C%A8%E6%A3%80%E6%B5%8B%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%A4%A9%E7%84%B6%E4%B8%8D%E9%80%82%E9%85%8D"><span class="nav-text">6.1 Transformer 在检测任务中的天然不适配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-%E6%94%B6%E6%95%9B%E7%BC%93%E6%85%A2%E6%98%AF%E5%AD%A6%E4%B9%A0%E9%9A%BE%E5%BA%A6%EF%BC%8C%E8%80%8C%E9%9D%9E%E5%B7%A5%E7%A8%8B%E9%97%AE%E9%A2%98"><span class="nav-text">6.2 收敛缓慢是学习难度，而非工程问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%80%A7%E8%83%BD%E5%8F%97%E9%99%90%E7%9A%84%E6%A0%B9%E6%9C%AC%E5%8E%9F%E5%9B%A0"><span class="nav-text">6.3 小目标性能受限的根本原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-%E4%B8%80%E4%B8%AA%E5%85%B3%E9%94%AE%E5%88%A4%E6%96%AD%EF%BC%9ADETR-%E6%98%AF%E2%80%9C%E8%8D%89%E5%9B%BE%E2%80%9D%EF%BC%8C%E8%80%8C%E9%9D%9E%E7%BB%88%E6%80%81"><span class="nav-text">6.4 一个关键判断：DETR 是“草图”，而非终态</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Deformable-DETR%EF%BC%9A%E8%AE%A9-Transformer-%E5%AD%A6%E4%BC%9A%E5%8F%AA%E7%9C%8B%E9%87%8D%E8%A6%81%E5%8C%BA%E5%9F%9F"><span class="nav-text">7. Deformable DETR：让 Transformer 学会只看重要区域</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-%E4%BB%8E%E5%85%A8%E5%B1%80%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%B0%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E5%BF%85%E7%84%B6%E8%BD%AC%E5%8F%98"><span class="nav-text">7.1 从全局注意力到稀疏注意力的必然转变</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-%E2%80%9C%E5%8F%AF%E5%8F%98%E5%BD%A2%E2%80%9D%E5%B9%B6%E9%9D%9E%E5%87%A0%E4%BD%95%E5%BD%A2%E5%8F%98%EF%BC%8C%E8%80%8C%E6%98%AF%E5%8F%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%87%87%E6%A0%B7%E4%BD%8D%E7%BD%AE"><span class="nav-text">7.2 “可变形”并非几何形变，而是可学习的采样位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%EF%BC%9A%E8%A1%A5%E9%BD%90%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%9A%84%E7%BB%93%E6%9E%84%E6%80%A7%E7%9F%AD%E6%9D%BF"><span class="nav-text">7.3 多尺度特征：补齐小目标的结构性短板</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-%E6%94%B6%E6%95%9B%E9%80%9F%E5%BA%A6%E4%B8%8E%E6%80%A7%E8%83%BD%E7%9A%84%E6%95%B0%E9%87%8F%E7%BA%A7%E6%8F%90%E5%8D%87"><span class="nav-text">7.4 收敛速度与性能的数量级提升</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-5-%E6%94%B9%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%8C%E6%B2%A1%E6%94%B9%E4%BB%80%E4%B9%88"><span class="nav-text">7.5 改了什么，没改什么</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-YOLO-%E4%B8%8E-DETR%EF%BC%9A%E4%B8%8D%E6%98%AF%E6%9B%BF%E4%BB%A3%E5%85%B3%E7%B3%BB%EF%BC%8C%E8%80%8C%E6%98%AF%E5%BB%BA%E6%A8%A1%E6%80%9D%E6%83%B3%E7%9A%84%E5%88%86%E5%B7%A5"><span class="nav-text">8. YOLO 与 DETR：不是替代关系，而是建模思想的分工</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-%E4%B8%A4%E7%A7%8D%E8%8C%83%E5%BC%8F%E8%A7%A3%E5%86%B3%E7%9A%84%E6%98%AF%E4%B8%8D%E5%90%8C%E5%B1%82%E7%BA%A7%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-text">8.1 两种范式解决的是不同层级的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-%E5%B7%A5%E4%B8%9A%E7%B3%BB%E7%BB%9F%E4%B8%BA%E4%BD%95%E9%95%BF%E6%9C%9F%E5%81%8F%E5%90%91-YOLO"><span class="nav-text">8.2 工业系统为何长期偏向 YOLO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-%E5%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%86%8D%E6%98%AF%E7%BB%88%E7%82%B9%EF%BC%8CDETR-%E7%9A%84%E4%BC%98%E5%8A%BF%E5%BC%80%E5%A7%8B%E6%98%BE%E7%8E%B0"><span class="nav-text">8.3 当检测不再是终点，DETR 的优势开始显现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-%E4%B8%80%E4%B8%AA%E5%AE%B9%E6%98%93%E8%A2%AB%E5%BF%BD%E7%95%A5%E7%9A%84%E4%BA%8B%E5%AE%9E%EF%BC%9AYOLO-%E4%B9%9F%E5%9C%A8%E5%90%B8%E6%94%B6-DETR-%E7%9A%84%E6%80%9D%E6%83%B3"><span class="nav-text">8.4 一个容易被忽略的事实：YOLO 也在吸收 DETR 的思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-%E5%88%86%E5%B7%A5%E8%80%8C%E9%9D%9E%E8%83%9C%E8%B4%9F%E7%9A%84%E7%8E%B0%E5%AE%9E%E7%BB%93%E8%AE%BA"><span class="nav-text">8.5 分工而非胜负的现实结论</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-%E5%AE%9E%E8%B7%B5%EF%BC%9AYOLO-%E4%B8%8E-DETR-%E8%8C%83%E5%BC%8F%E5%9C%A8%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E4%B8%8A%E7%9A%84%E5%B7%AE%E5%BC%82%E4%BD%93%E7%8E%B0%E5%9C%A8%E5%93%AA%E9%87%8C"><span class="nav-text">9. 实践：YOLO 与 DETR 范式在真实数据上的差异体现在哪里</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-%E5%AE%9E%E9%AA%8C%E7%9B%AE%E6%A0%87%EF%BC%9A%E5%85%B3%E6%B3%A8%E9%94%99%E8%AF%AF%E7%BB%93%E6%9E%84%EF%BC%8C%E8%80%8C%E9%9D%9E%E5%8D%95%E4%B8%80%E6%8C%87%E6%A0%87"><span class="nav-text">9.1 实验目标：关注错误结构，而非单一指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE%E6%A6%82%E8%BF%B0"><span class="nav-text">9.2 实验设置概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-%E5%AE%9A%E9%87%8F%E7%BB%93%E6%9E%9C%EF%BC%9A%E6%80%A7%E8%83%BD%E6%95%B0%E5%AD%97%E8%83%8C%E5%90%8E%E7%9A%84%E5%90%AB%E4%B9%89"><span class="nav-text">9.3 定量结果：性能数字背后的含义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-4-%E5%AE%9A%E6%80%A7%E5%88%86%E6%9E%90%EF%BC%9A%E5%85%B8%E5%9E%8B%E9%94%99%E8%AF%AF%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="nav-text">9.4 定性分析：典型错误模式的对比</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-5-%E8%B0%83%E5%8F%82%E8%83%BD%E8%A7%A3%E5%86%B3%E7%9A%84%EF%BC%8C%E4%B8%8E%E8%B0%83%E5%8F%82%E8%A7%A3%E5%86%B3%E4%B8%8D%E4%BA%86%E7%9A%84"><span class="nav-text">9.5 调参能解决的，与调参解决不了的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-6-%E4%BB%A3%E7%A0%81%E4%B8%8E%E5%AE%9E%E7%8E%B0"><span class="nav-text">9.6 代码与实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-1-%E6%95%B0%E6%8D%AE%E5%B1%82%EF%BC%9ACOCO-%E6%A0%87%E6%B3%A8%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%8F%97%E6%8E%A7%E6%8A%BD%E6%A0%B7"><span class="nav-text">9.6.1 数据层：COCO 标注解析与受控抽样</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-2-%E6%A8%A1%E5%9E%8B%E5%B1%82%EF%BC%9A%E4%BB%A5-Wrapper-%E7%BB%9F%E4%B8%80%E4%B8%8D%E5%90%8C%E8%8C%83%E5%BC%8F%E7%9A%84%E6%8E%A8%E7%90%86%E6%8E%A5%E5%8F%A3"><span class="nav-text">9.6.2 模型层：以 Wrapper 统一不同范式的推理接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-3-%E8%AF%84%E6%B5%8B%E5%B1%82%EF%BC%9A%E5%9F%BA%E4%BA%8E-IoU-%E7%9A%84%E7%BB%93%E6%9E%84%E6%80%A7%E9%94%99%E8%AF%AF%E7%BB%9F%E8%AE%A1%EF%BC%88TP-FP-FN-dup%EF%BC%89"><span class="nav-text">9.7.3 评测层：基于 IoU 的结构性错误统计（TP&#x2F;FP&#x2F;FN&#x2F;dup）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-4-%E6%B1%87%E6%80%BB%E5%B1%82%EF%BC%9A%E9%80%90%E6%A0%B7%E6%9C%AC%E8%AE%B0%E5%BD%95%E4%B8%8E%E6%95%B4%E4%BD%93%E7%BB%9F%E8%AE%A1%E8%BE%93%E5%87%BA"><span class="nav-text">9.6.4 汇总层：逐样本记录与整体统计输出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-5-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="nav-text">9.6.5 实验结果分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-7-%E5%AE%9E%E8%B7%B5%E5%B1%82%E9%9D%A2%E7%9A%84%E7%BB%BC%E5%90%88%E8%A7%82%E5%AF%9F"><span class="nav-text">9.7 实践层面的综合观察</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-%E6%80%BB%E7%BB%93%EF%BC%9A%E4%BB%8E%E4%BB%BB%E5%8A%A1%E6%A8%A1%E5%9E%8B%E5%88%B0%E8%A7%86%E8%A7%89%E7%B3%BB%E7%BB%9F%E8%83%BD%E5%8A%9B"><span class="nav-text">10. 总结：从任务模型到视觉系统能力</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-%E4%BB%8E%E5%B0%81%E9%97%AD%E7%B1%BB%E5%88%AB%E5%88%B0%E5%BC%80%E6%94%BE%E8%AF%AD%E4%B9%89%E7%A9%BA%E9%97%B4"><span class="nav-text">10.1 从封闭类别到开放语义空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E6%AD%A3%E5%9C%A8%E8%9E%8D%E5%85%A5%E5%9F%BA%E7%A1%80%E8%A7%86%E8%A7%89%E8%A1%A8%E7%A4%BA"><span class="nav-text">10.2 检测模型正在融入基础视觉表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-%E9%9B%86%E5%90%88%E9%A2%84%E6%B5%8B%E5%9C%A8%E7%B3%BB%E7%BB%9F%E7%BA%A7%E5%BB%BA%E6%A8%A1%E4%B8%AD%E7%9A%84%E9%95%BF%E6%9C%9F%E4%BB%B7%E5%80%BC"><span class="nav-text">10.3 集合预测在系统级建模中的长期价值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-%E5%AE%9E%E6%97%B6%E6%80%A7%E7%BA%A6%E6%9D%9F%E4%B8%8B%E7%9A%84%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-text">10.4 实时性约束下的再平衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-5-%E7%BB%93%E8%AF%AD%EF%BC%9A%E6%A3%80%E6%B5%8B%E4%BD%9C%E4%B8%BA%E8%83%BD%E5%8A%9B%EF%BC%8C%E8%80%8C%E9%9D%9E%E7%BB%88%E7%82%B9"><span class="nav-text">10.5 结语：检测作为能力，而非终点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-%E5%A4%87%E6%B3%A8"><span class="nav-text">11. 备注</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KeyChan"
      src="/images/key_avatar.png">
  <p class="site-author-name" itemprop="name">KeyChan</p>
  <div class="site-description" itemprop="description">全干工程师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">59</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">145</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:kckeychan@gmail.com" title="E-Mail → mailto:kckeychan@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/keychankc" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/key_avatar.png">
      <meta itemprop="name" content="KeyChan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeyChan's blog">
      <meta itemprop="description" content="全干工程师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="从 YOLO 到 DETR：目标检测范式的演化与分工 | KeyChan's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          从 YOLO 到 DETR：目标检测范式的演化与分工
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-12-23 18:05:12 / 修改时间：18:06:23" itemprop="dateCreated datePublished" datetime="2025-12-23T18:05:12+08:00">2025-12-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/12/23/048-from-yolo-to-detr/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/12/23/048-from-yolo-to-detr/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>19k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:09</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="1-DETR-出现的原因"><a href="#1-DETR-出现的原因" class="headerlink" title="1. DETR 出现的原因"></a>1. DETR 出现的原因</h2><p>在目标检测的发展历程中，YOLO 与 DETR 往往被视为两种截然不同的技术路线，其差异不仅体现在网络结构或训练策略上，更反映了对“目标检测这一问题应当如何建模”的根本理解差别。</p>
<p>直观而言，YOLO 系列方法遵循的是一种密集预测思路：模型在图像的各个空间位置上独立判断是否存在目标，并同时回归其类别与边界框位置。这种做法强调局部决策与并行计算，因而具备极高的推理效率，但也不可避免地会对同一目标产生多次冗余预测，必须借助非极大值抑制等后处理机制进行去重。具体可参考： <a href="https://www.keychan.xyz/2025/04/17/011-yolo-eval-metrics-yolov1/">物体检测评估指标和YOLO-v1实现思路</a></p>
<span id="more"></span>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/202504102312.jpg" width="80%" />
<center>YOLO 目标检测流程示意图</center>

<p>与此不同，DETR 则从整体视角重新审视检测任务，将其建模为一个集合预测问题：模型首先对整幅图像进行全局建模，再通过一组固定数量的查询向量为潜在目标分配预测“名额”，并利用集合匹配机制确保每个真实目标只被预测一次。具体可参考：<a href="https://www.keychan.xyz/2025/05/13/015-transformer-to-detr/">基于Transformer的detr目标检测算法思路分析</a></p>
<img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/Pasted%20image%2020250512154553.png" width="80%" />
<center>DETR（Detection Transformer）端到端目标检测流程示意图</center>

<p>在过去十年中，目标检测领域以 YOLO 系列为代表的一阶段检测模型在工业界取得了很全面的成功，其在速度、稳定性与工程可控性方面已成为事实标准；另一方面，学术界却并未在这一范式上停下脚步，提出了 DETR 这样一种在结构与思想上都显著不同的新模型。表面上看，这似乎是一种“在问题已被解决之后重新发明轮子”的行为，但如果深入分析其动机与背景，会发现 DETR 的出现并非偶然。</p>
<p>本章将从工业现实与研究动机两个维度出发，回答一个核心问题：当 YOLO 已经足够高效且成熟时，目标检测领域究竟还存在哪些未被真正解决的问题，从而促使 DETR 这样的模型得以诞生。</p>
<h3 id="1-1-工业现实：YOLO-已成为目标检测的事实标准"><a href="#1-1-工业现实：YOLO-已成为目标检测的事实标准" class="headerlink" title="1.1 工业现实：YOLO 已成为目标检测的事实标准"></a>1.1 工业现实：YOLO 已成为目标检测的事实标准</h3><p>从工程应用的角度看，YOLO 系列模型已经在相当程度上“赢得了竞争”。其推理链路高度统一：输入图像经过骨干网络提取特征，再由检测头在多尺度特征上进行密集预测，最终通过阈值筛选与 NMS 得到结果。该流程天然适配 GPU 并行计算与现代推理框架，因而在云端、边缘、嵌入式等多种场景中都能维持可预期的延迟与吞吐。</p>
<p>更重要的是，YOLO 的工程生态成熟且可迁移。围绕其形成了完善的部署工具链（如 ONNX、TensorRT 等），并积累了大量量化、剪枝、蒸馏等工程经验，使其在真实生产环境中具备较低的维护成本。对于工业系统而言，很多时候“可解释、可调参的不足”反而是一种优势：当出现漏检或误检时，问题往往能够被定位到阈值选择、特定尺度的特征表达或数据分布偏差，从而具备清晰的调试路径与控制手段。</p>
<p>在这样的背景下，单纯从结果导向的角度出发，很难得出“必须引入全新检测范式”的结论。DETR 的出现因此更像是来自研究层面对“范式边界”的反思，而非对 YOLO 现实表现不足的回应。</p>
<h3 id="1-2-三个工程妥协"><a href="#1-2-三个工程妥协" class="headerlink" title="1.2 三个工程妥协"></a>1.2 三个工程妥协</h3><p>尽管 YOLO 在实践中表现卓越，但从建模角度看，它的成功始终伴随着若干难以回避的工程妥协。这些妥协并不一定会导致性能灾难，却在理论一致性与模型优雅性上留下了长期争议。</p>
<ol>
<li><strong>NMS：不可微、阈值敏感、训练与推理割裂。</strong><br> 非极大值抑制是密集预测范式下冲突消解的关键步骤，但其本质是一种启发式规则：依赖置信度排序与 IoU 阈值设定，并且不可微。这意味着模型在训练过程中无法感知 NMS 的存在，优化目标与推理阶段的实际行为之间始终存在间隙。</li>
<li><strong>Anchor&#x2F;先验：迁移成本高，仍依赖经验设计。</strong><br> 无论是显式 Anchor 还是后续 Anchor-free 变体，其核心思想仍是在特征空间中预设大量潜在目标假设，并通过回归或中心点机制对这些假设进行修正。即便自动 Anchor 搜索、解耦预测头等设计在一定程度上缓解了人工经验依赖，但“先验假设强、数据集变化时需要再次适配”的问题并未彻底消除。</li>
<li><strong>密集预测：计算冗余不可避免。</strong><br> YOLO 的核心假设是：图像的任意空间位置都可能存在目标。为了不漏检，模型必须在大量位置生成候选预测，而真实目标数量通常远小于候选数量。换言之，推理中相当一部分计算被用于生成最终必然被丢弃的结果。这种冗余在算力充足时并非不可接受，但从建模思想上看，它暗含着“先过度假设、再事后修正”的思路。</li>
</ol>
<p>这三点妥协共同指向同一个事实：YOLO 的成功依赖于一套成熟而有效的工程机制，但这套机制并不必然是目标检测问题的唯一表述方式。</p>
<h3 id="1-3-一个被长期忽略的问题：是否必须“先预测很多，再删掉大多数”"><a href="#1-3-一个被长期忽略的问题：是否必须“先预测很多，再删掉大多数”" class="headerlink" title="1.3 一个被长期忽略的问题：是否必须“先预测很多，再删掉大多数”"></a>1.3 一个被长期忽略的问题：是否必须“先预测很多，再删掉大多数”</h3><p>将上述现象综合起来，可以发现传统一阶段检测方法隐含着一个几乎未被质疑的前提：检测过程必须经历两步——先生成大量候选预测，再通过规则或排序机制将其中绝大多数剔除。该前提在工程上行之有效，却并非逻辑上的必然。真实场景中，一幅图像里实际存在的目标数量通常是有限且相对稳定的；从问题定义的角度看，检测更接近于“找出图像中有哪些目标实例”，而不是“在所有位置上判断是否存在目标”。</p>
<p>正是在这一层面上，DETR 提出了截然不同的建模视角：它不再试图覆盖所有潜在位置，而是假设目标输出本质上是一个无序集合，并用固定数量的 object queries 直接预测这一集合中的元素。由此，冗余预测与冲突消解被前移至模型内部，通过结构约束与一对一匹配实现，而不再依赖 NMS 等外部后处理。</p>
<p>因此，DETR 的出现并不是对 YOLO 性能不足的回应，而是对其建模思想的一次根本性反思。理解这一点，是理解后续范式演化（包括 Deformable DETR、开放词汇检测等）的关键前提。</p>
<pre class="mermaid">flowchart LR
	%% DETR pipeline
    subgraph DETR["DETR：集合预测 + 匹配"]
        direction LR
        B1[输入图像]
        B2[CNN Backbone]
        B3[Transformer Encoder]
        B4[Transformer Decoder<br/>+ Object Queries（固定数量）]
        B5[固定数量输出<br/>目标 / 空集]
        B1 --> B2 --> B3 --> B4 --> B5
    end

    %% YOLO pipeline
    subgraph YOLO["YOLO：密集预测 + NMS"]
        direction LR
        A1[输入图像]
        A2[CNN Backbone]
        A3[密集预测头<br/>多尺度特征]
        A4[大量候选框]
        A5[NMS 去重]
        A6[最终检测结果]
        A1 --> A2 --> A3 --> A4 --> A5 --> A6
    end</pre>
<center>图1-1 YOLO 与 DETR 检测流程对比示意图</center>

<p>如上图对比了两种主流目标检测范式的整体流程：YOLO 通过密集预测与后处理去重来维持输出稳定；DETR 通过固定数量 queries 的集合预测与一对一结构约束，在模型内部完成冲突消解与去重，不再依赖 NMS。该对比直观体现了“先预测大量候选再筛选”与“直接预测目标集合”两种范式在建模思路上的根本差异。</p>
<h2 id="2-YOLO-的本质：把目标检测当成“密集预测与排序”的问题"><a href="#2-YOLO-的本质：把目标检测当成“密集预测与排序”的问题" class="headerlink" title="2. YOLO 的本质：把目标检测当成“密集预测与排序”的问题"></a>2. YOLO 的本质：把目标检测当成“密集预测与排序”的问题</h2><p>在明确了 DETR 出现的背景之后，有必要重新回到 YOLO 本身，理解其长期成功所依赖的核心建模假设。本章不沿着 YOLO 版本更迭的时间线展开，而是从统一的建模视角出发，分析 YOLO 系列模型在十余年演化过程中始终保持不变的思想内核。</p>
<h3 id="2-1-一阶段检测的统一建模假设"><a href="#2-1-一阶段检测的统一建模假设" class="headerlink" title="2.1 一阶段检测的统一建模假设"></a>2.1 一阶段检测的统一建模假设</h3><p>YOLO 并非一个具体模型，而是一类方法的代表。这类方法的共同点在于，将目标检测视为一个<strong>密集预测问题</strong>。模型首先将连续的图像空间离散化为规则的特征网格（或特征图），随后在每一个空间位置上，同时预测类别概率与边界框参数。</p>
<p>这一建模方式隐含着一个关键假设：<strong>图像中的任意空间位置，都可能存在一个目标实例</strong>。为了避免漏检，模型必须对整个空间进行覆盖式预测。这一假设在形式上极为直接，却带来了两个结构性后果：</p>
<ol>
<li><strong>预测数量远大于真实目标数量</strong><br> 在大多数真实场景中，图像中实际存在的目标数量是有限的，且远少于特征图上的预测位置数。然而，YOLO 仍需在所有位置生成预测结果，其中绝大多数最终都会被判定为背景。</li>
<li><strong>检测问题自然转化为排序问题</strong><br> 同一目标往往会在多个相邻位置被重复预测，模型必须依据某种置信度标准，对这些预测进行排序与筛选，才能得到最终输出。</li>
</ol>
<p>这一逻辑并非 YOLO 独有，而是几乎所有一阶段检测方法的共同基础。不同版本之间的差异，更多体现在如何提高这一过程的效率与稳定性，而非对其进行根本性重构。</p>
<h3 id="2-2-Anchor-与-NMS-并非历史包袱，而是逻辑结果"><a href="#2-2-Anchor-与-NMS-并非历史包袱，而是逻辑结果" class="headerlink" title="2.2 Anchor 与 NMS 并非历史包袱，而是逻辑结果"></a>2.2 Anchor 与 NMS 并非历史包袱，而是逻辑结果</h3><p>在密集预测假设成立的前提下，Anchor 与 NMS 的出现并非偶然选择，而是直接的逻辑推论。</p>
<p>Anchor 机制的核心作用，在于将连续的边界框回归问题转化为相对于一组离散参考框的偏移预测。通过在每个位置预设多种尺度与长宽比，模型可以更容易覆盖不同形态的目标实例，并在训练早期获得更稳定的梯度信号。这一设计在早期检测模型中显著提升了收敛速度与定位精度。</p>
<p>然而，Anchor 的引入也进一步放大了预测冗余：每增加一种 Anchor 配置，都会成倍增加潜在预测数量。即便在 Anchor-free 方法中，显式的 Anchor 被移除，模型依然在每个位置生成多组候选，只是将先验从“框形状”转化为“回归参数”。</p>
<p>在这一背景下，<strong>NMS 成为不可或缺的冲突消解机制</strong>。只要模型允许同一目标在多个位置被预测，就必须在推理阶段通过某种规则，将这些重复预测压缩为单一输出。从这个意义上看，NMS 并非某个实现细节的权宜之计，而是密集预测范式下维持实例一致性的必要机制。</p>
<h3 id="2-3-YOLO-十年演化中真正变化与不变的部分"><a href="#2-3-YOLO-十年演化中真正变化与不变的部分" class="headerlink" title="2.3 YOLO 十年演化中真正变化与不变的部分"></a>2.3 YOLO 十年演化中真正变化与不变的部分</h3><p>回顾 YOLO 从最初版本到近期模型的发展轨迹，可以发现其演化并非围绕“是否密集预测”展开，而是集中于如何<strong>降低密集预测所带来的副作用</strong>。在变化的层面，模型结构与训练策略经历了多次重要调整：</p>
<p>多尺度特征被引入以改善小目标检测能力；解耦预测头缓解了分类与回归之间的相互干扰；更合理的损失函数与样本分配策略提升了定位精度与训练稳定性。这些改进显著提高了 YOLO 的性能上限，使其在速度与精度之间取得了更优平衡。</p>
<p>与此同时，大量工程层面的优化被不断引入，包括数据增强、推理加速、模型压缩等。这些优化并不改变模型的核心建模方式，却极大增强了其工程可用性。</p>
<p>然而，在不变的层面，YOLO 始终坚持同一套核心逻辑：<strong>对整个空间进行密集预测，并在预测之后通过排序与抑制机制得到最终结果</strong>。无论是 Anchor-based 还是 Anchor-free，无论网络结构如何变化，这一逻辑始终未被打破。</p>
<p>这一事实具有重要意义：YOLO 的成功，并非源于对检测问题本质的重新定义，而是对既有工程范式的持续打磨与极致优化。</p>
<h3 id="2-4-排序视角下的目标检测"><a href="#2-4-排序视角下的目标检测" class="headerlink" title="2.4 排序视角下的目标检测"></a>2.4 排序视角下的目标检测</h3><p>从更抽象的角度看，YOLO 将目标检测问题隐式地表述为一个<strong>排序问题</strong>。模型输出的是一组带有置信度评分的候选框集合，推理阶段的核心任务，是在这些候选中选出排名靠前且相互不冲突的部分。</p>
<p>这一视角在实践中非常自然，却也引入了若干难以避免的副作用。排序机制对评分分布高度敏感，微小的分数变化可能导致输出结果发生显著差异。此外，不同类别之间的排序与抑制规则往往需要额外设计，增加了系统复杂度。</p>
<p>更关键的是，排序并非目标检测问题的唯一表述方式。目标实例之间本质上是<strong>无序的集合关系</strong>，而非有序序列。当检测被强行映射为排序问题时，模型需要在后处理阶段额外承担这一结构错配所带来的代价。正是这一点，为后续基于集合预测的检测方法提供了切入空间。</p>
<pre class="mermaid">flowchart LR
    A[特征图<br/>Dense Feature Map]
        --> B[密集预测<br/>大量重叠候选框]
    B --> C[按置信度排序<br/>Score Ranking]
    C --> D[NMS 筛选<br/>Suppress Overlap]
    D --> E[最终检测结果<br/>少量高置信度框]

    B -. 冗余预测 .-> C
    C -. 排序依赖 .-> D</pre>
<center>图2-1 密集预测与排序机制示意图</center>

<p>如上图展示了以 YOLO 为代表的一阶段检测方法中的典型处理流程：模型在特征图上生成大量彼此重叠的候选框，通过排序与非极大值抑制逐步消除冗余预测，最终输出少量检测结果。该流程直观体现了密集预测方法中“预测冗余”与“排序筛选”之间的紧密耦合关系，也揭示了其对后处理机制的高度依赖。</p>
<h2 id="3-YOLO-很强，但-NMS-为什么始终无法被移除？"><a href="#3-YOLO-很强，但-NMS-为什么始终无法被移除？" class="headerlink" title="3. YOLO 很强，但 NMS 为什么始终无法被移除？"></a>3. YOLO 很强，但 NMS 为什么始终无法被移除？</h2><p>在过去数年中，YOLO 系列模型在网络结构、训练策略和工程实现层面不断演化，其检测精度与稳定性已远超早期版本。然而，一个看似矛盾的事实始终存在：尽管模型本身不断变强，<strong>非极大值抑制（NMS）这一后处理步骤却从未被真正移除</strong>。即便在 Anchor-free、解耦预测头等新设计出现之后，NMS 仍然作为推理流程中的关键组成部分存在。</p>
<p>这一现象并非偶然。本章将从建模逻辑的角度出发，分析 NMS 在一阶段检测范式中的必然性，并进一步指出这一必然性所揭示的深层问题。</p>
<h3 id="3-1-NMS-解决的不是检测，而是预测冲突"><a href="#3-1-NMS-解决的不是检测，而是预测冲突" class="headerlink" title="3.1 NMS 解决的不是检测，而是预测冲突"></a>3.1 NMS 解决的不是检测，而是预测冲突</h3><p>从功能上看，NMS 并不参与“是否存在目标”的判断，而是专门用于解决<strong>预测之间的冲突</strong>。所谓冲突，指的是同一真实目标被模型在多个空间位置、多个尺度下重复预测，从而在输出中形成大量高度重叠的候选框。</p>
<p>在密集预测框架下，这种冲突几乎不可避免。模型在特征图上进行覆盖式预测，相邻位置会对同一目标给出相似但不完全一致的回归结果。这些预测在几何上高度重叠，在语义上却彼此独立，模型本身并不具备“这些预测属于同一实例”的显式表示能力。</p>
<p>NMS 的引入，正是为了在推理阶段弥补这一能力缺失。通过设定置信度排序规则和 IoU 阈值，NMS 将多个相似预测压缩为单一输出，从而恢复实例级别的一致性。需要强调的是，这一过程<strong>完全发生在模型之外</strong>，模型在训练时并不知道哪些预测最终会被保留。</p>
<h3 id="3-2-IoU-阈值问题揭示的结构性不稳定"><a href="#3-2-IoU-阈值问题揭示的结构性不稳定" class="headerlink" title="3.2 IoU 阈值问题揭示的结构性不稳定"></a>3.2 IoU 阈值问题揭示的结构性不稳定</h3><p>在实际应用中，NMS 的阈值选择往往成为影响性能的关键因素之一。过高的 IoU 阈值可能导致重复检测，过低的阈值则容易误删相邻目标，尤其是在密集场景中。</p>
<p>这一现象并非简单的参数调优问题，而是<strong>结构性不稳定</strong>的体现。IoU 阈值试图用一个全局规则，解决所有目标实例之间的局部几何关系。然而，不同类别、不同尺度、不同密度分布的目标，其合理的抑制策略并不相同。单一阈值难以在所有场景下取得理想平衡。</p>
<p>更重要的是，NMS 的排序机制使得检测结果对置信度分布高度敏感。微小的分数变化，可能改变候选框的保留顺序，从而导致输出结果发生非连续变化。这种不稳定性在视频流或在线系统中尤为明显。</p>
<h3 id="3-3-Anchor-free-并未真正消除冗余预测"><a href="#3-3-Anchor-free-并未真正消除冗余预测" class="headerlink" title="3.3 Anchor-free 并未真正消除冗余预测"></a>3.3 Anchor-free 并未真正消除冗余预测</h3><p>近年来，Anchor-free 方法常被视为简化检测流程的重要方向。通过直接预测中心点或边界距离，这类方法在形式上摆脱了对预设 Anchor 的依赖，并在一定程度上降低了设计复杂度。</p>
<p>然而，从预测密度的角度看，Anchor-free 并未改变一阶段检测的基本假设。模型依然在每一个空间位置生成预测，只是将显式的 Anchor 先验转化为隐式的回归参数。对于同一目标，多个相邻位置仍可能同时给出有效预测，从而产生与 Anchor-based 方法相同的冲突结构。</p>
<p>因此，即便在 Anchor-free 架构中，NMS 依然不可或缺。它解决的并不是 Anchor 带来的问题，而是<strong>密集预测本身带来的实例歧义</strong>。这一事实进一步表明，Anchor 只是冗余预测的放大器，而非其根本原因。</p>
<h3 id="3-4-一个关键反思：当模型需要-NMS，意味着什么？"><a href="#3-4-一个关键反思：当模型需要-NMS，意味着什么？" class="headerlink" title="3.4 一个关键反思：当模型需要 NMS，意味着什么？"></a>3.4 一个关键反思：当模型需要 NMS，意味着什么？</h3><p>综合以上分析，可以提出一个更具根本性的问题：<strong>当一个检测模型在推理阶段必须依赖 NMS 才能输出合理结果时，这意味着什么？</strong></p>
<p>从实例层面看，真实场景中的目标数量通常是有限的，且每个目标在图像中只对应一个实例。然而，密集预测范式却假设每一个位置都可能对应一个独立实例，并在事后通过规则将这些假设合并。这种“先过度假设，再事后修正”的策略在工程上可行，却在建模上显得迂回。</p>
<p>正是在这一反思中，另一种建模思路逐渐浮现：如果模型在结构上就明确规定“每个目标只能被预测一次”，并在训练阶段强制执行这一约束，那么预测冲突是否可以被从源头上消除？如果检测输出不再是排序后的候选集合，而是一个无序的目标实例集合，那么后处理规则是否还有存在的必要？</p>
<p>这些问题并非对 YOLO 的否定，而是对其建模假设边界的清晰认知。也正是在这一认知基础上，DETR 所代表的集合预测范式得以提出，并为目标检测问题提供了另一种可能的答案。</p>
<pre class="mermaid">flowchart LR
    A[同一目标<br/>在相邻位置被多次预测]
        --> B[生成多个高度重叠的预测框]
    B --> C[按置信度排序<br/>Score Ranking]
    C --> D{IoU > 阈值?}
    D -->|是| E[抑制低置信度框]
    D -->|否| F[保留该预测框]
    E --> D
    F --> G[最终检测结果<br/>单一目标框]</pre>
<center>图3-1 NMS 冲突消解过程示意图</center>

<p>这一章的结论可以一句话概括：<strong>NMS 不是一个可以随意移除的工程细节，而是密集预测范式的逻辑产物</strong>。要真正摆脱 NMS，必须在建模阶段改变“同一目标允许被多次预测”的前提条件。下一章将以此为起点，系统讨论 DETR 如何通过集合预测与一对一约束，从源头上消解这一问题。</p>
<h2 id="4-DETR-的核心思想：将目标检测建模为一个集合预测问题"><a href="#4-DETR-的核心思想：将目标检测建模为一个集合预测问题" class="headerlink" title="4. DETR 的核心思想：将目标检测建模为一个集合预测问题"></a>4. DETR 的核心思想：将目标检测建模为一个集合预测问题</h2><p>在前一章中，我们已经看到：在密集预测范式下，只要允许同一目标被多次预测，冲突消解机制（如 NMS）就不可避免。DETR 的出发点，正是对这一前提的根本性否定。它并不试图改进 NMS，也不试图减少预测冗余，而是直接重新定义了目标检测的输出形式。</p>
<h3 id="4-1-从“覆盖所有可能位置”到“只预测应该存在的目标”"><a href="#4-1-从“覆盖所有可能位置”到“只预测应该存在的目标”" class="headerlink" title="4.1 从“覆盖所有可能位置”到“只预测应该存在的目标”"></a>4.1 从“覆盖所有可能位置”到“只预测应该存在的目标”</h3><p>传统一阶段检测方法的核心策略，是对空间位置进行穷尽式覆盖：在特征图的每一个位置上判断是否存在目标。DETR 则采取了相反的思路。它不再假设每个空间位置都对应一个潜在实例，而是假设<strong>一幅图像中存在若干个目标实例，这些实例构成一个无序集合</strong>。</p>
<p>基于这一假设，检测任务被重新表述为：直接预测这个集合中的元素，而非对空间位置逐一作出判断。DETR 通过引入固定数量的 <strong>object queries</strong> 实现这一目标。每一个 query 可以被理解为一个“目标槽位”，其输出要么对应一个真实目标实例，要么明确表示为空（no-object）。</p>
<p>这一设计在结构上引入了一个强约束：<strong>目标实例的数量是受控的，且每个实例最多只能被预测一次</strong>。冗余预测不再是一个需要在推理阶段解决的问题，而是在建模阶段被直接禁止。</p>
<h3 id="4-2-固定数量预测与一对一约束的含义"><a href="#4-2-固定数量预测与一对一约束的含义" class="headerlink" title="4.2 固定数量预测与一对一约束的含义"></a>4.2 固定数量预测与一对一约束的含义</h3><p>DETR 的输出并不是空间分布，而是一个固定长度的预测列表。每个列表元素包含类别预测和边界框回归结果，所有元素在语义上是对等的、无序的。模型不关心“第几个预测对应图像的哪个位置”，而是关心“这些预测作为一个集合，是否完整描述了图像中的目标实例”。</p>
<p>关键在于<strong>一对一约束</strong>。在 DETR 中，每个真实目标在训练阶段最多只会被分配给一个 query，其余 query 必须学习输出 no-object。这一约束使模型在结构上具备“一个目标只预测一次”的能力，从而从源头上避免了重复预测与实例冲突。</p>
<p>需要注意的是，这种约束并非通过推理规则实现，而是通过训练目标强制学习得到。预测数量在一开始就是受控的，模型不再需要在输出之后再进行筛选或压缩。</p>
<h3 id="4-3-为什么-DETR-天然不需要-NMS"><a href="#4-3-为什么-DETR-天然不需要-NMS" class="headerlink" title="4.3 为什么 DETR 天然不需要 NMS"></a>4.3 为什么 DETR 天然不需要 NMS</h3><p>在理解了一对一预测的结构之后，DETR 不再使用 NMS 便显得顺理成章。由于模型在设计上已经保证了预测之间不存在实例级冲突，推理阶段不再需要任何基于排序或阈值的冲突消解规则。</p>
<p>更重要的是，NMS 的移除并不仅仅减少了一个后处理步骤，而是消除了检测流程中一个<strong>不可微、不可学习的环节</strong>。DETR 的训练目标与推理行为保持高度一致，模型可以直接针对最终输出进行端到端优化。这种一致性正是 DETR 被视为范式转变的重要原因之一。</p>
<p>从这一角度看，DETR 的优势并不在于“更强的网络结构”，而在于“更一致的问题表述”。</p>
<h3 id="4-4-集合视角下的检测任务重构"><a href="#4-4-集合视角下的检测任务重构" class="headerlink" title="4.4 集合视角下的检测任务重构"></a>4.4 集合视角下的检测任务重构</h3><p>将目标检测视为集合预测问题，还带来了更深层次的建模变化。在集合视角下，目标实例之间不再通过空间位置隐式关联，而是通过模型内部的表示进行显式区分。每个 query 在高维特征空间中承担着区分不同实例的角色。</p>
<p>这种建模方式使检测任务更容易与其他实例级任务结合。例如，当检测结果需要进一步参与关系建模、实例交互或多任务联合预测时，集合形式的输出比排序后的候选列表更自然、更稳定。</p>
<p>需要强调的是，这种优势并不会立刻转化为单一指标上的性能提升。DETR 的价值并不在于短期 mAP 表现，而在于为目标检测提供了一种新的结构化表达方式。</p>
<h3 id="4-5-范式转变的意义"><a href="#4-5-范式转变的意义" class="headerlink" title="4.5 范式转变的意义"></a>4.5 范式转变的意义</h3><p>从更宏观的角度看，DETR 的核心贡献并不在于某个具体模块，而在于其对目标检测问题本质的重新定义。它将检测从“空间覆盖与后处理驱动”的问题，转化为“实例集合预测”的问题，从而在逻辑上摆脱了对排序与抑制机制的依赖。</p>
<p>这一转变并不意味着传统方法的失效，而是拓展了问题的解空间。YOLO 所代表的密集预测范式在工程效率与实时性方面仍具有不可替代的优势；而 DETR 所代表的集合预测范式，则为更高层次的视觉理解任务提供了更自然的建模基础。</p>
<pre class="mermaid">flowchart LR
    subgraph Dense["密集预测范式（YOLO 等）"]
        direction LR
        A1[特征图]
        A2[大量候选框预测]
        A3[排序]
        A4[NMS 去重]
        A5[最终检测结果]
        A1 --> A2 --> A3 --> A4 --> A5
    end

    subgraph SetPred["集合预测范式（DETR）"]
        direction LR
        B1[全局特征表示]
        B2[固定数量<br/>Object Queries]
        B3[一对一预测<br/>Set Prediction]
        B4[直接输出目标集合]
        B1 --> B2 --> B3 --> B4
    end</pre>
<center>图4-1 集合预测与密集预测对比示意图</center>

<p>到这里，<strong>DETR 的核心建模思想已经完整闭环</strong>：</p>
<ul>
<li>第 3 章指出了 NMS 的结构必然性；</li>
<li>第 4 章给出了“如何从根源上避免它”的答案。</li>
</ul>
<h2 id="5-匈牙利匹配：DETR-中最容易被误解的部分"><a href="#5-匈牙利匹配：DETR-中最容易被误解的部分" class="headerlink" title="5. 匈牙利匹配：DETR 中最容易被误解的部分"></a>5. 匈牙利匹配：DETR 中最容易被误解的部分</h2><p>在 DETR 的整体设计中，匈牙利匹配常常被视为一个“复杂但必要的算法组件”，甚至被误解为 Transformer 不擅长检测而不得不引入的补丁。然而，从建模角度看，这种理解是本末倒置的。<strong>匈牙利匹配并不是 DETR 的附加技巧，而是集合预测范式在监督学习条件下的逻辑必然结果</strong>。</p>
<p>如果忽略这一点，DETR 所强调的一对一预测机制将无法成立。</p>
<h3 id="5-1-匈牙利匹配不是后处理，而是监督对齐机制"><a href="#5-1-匈牙利匹配不是后处理，而是监督对齐机制" class="headerlink" title="5.1 匈牙利匹配不是后处理，而是监督对齐机制"></a>5.1 匈牙利匹配不是后处理，而是监督对齐机制</h3><p>在 DETR 中，模型在一次前向传播中会输出固定数量的预测查询。这些查询在初始阶段是对等且无序的，并不预先绑定某个具体目标。与此同时，一张图像中真实存在的目标数量是变化的，且真实目标本身同样构成一个无序集合。</p>
<p>训练阶段必须解决一个核心问题：<strong>预测集合中的元素，如何与真实目标集合中的元素建立对应关系？</strong></p>
<p>如果缺乏统一的分配机制，多个预测可能会同时对同一个真实目标产生响应，从而破坏“一对一预测”的基本假设。匈牙利匹配正是为了解决这一问题而引入的。它在训练阶段对预测集合与真实集合进行全局匹配，在所有可能的一对一分配方案中，选择整体代价最小的那一个。</p>
<p>因此，匈牙利匹配的本质作用并不是“提升匹配精度”，而是<strong>为训练过程提供一个稳定、明确的一对一监督对齐关系</strong>。</p>
<h3 id="5-2-为什么必须是一对一匹配"><a href="#5-2-为什么必须是一对一匹配" class="headerlink" title="5.2 为什么必须是一对一匹配"></a>5.2 为什么必须是一对一匹配</h3><p>一对一匹配是 DETR 成立的前提条件，而非一个可选设计。如果允许多对一或一对多的匹配关系，那么同一个真实目标就可能同时监督多个预测查询，模型便会自然回到冗余预测的状态。</p>
<p>在这种情况下，即便结构上使用了固定数量的查询，模型仍然会倾向于“多个查询预测同一目标”，从而在推理阶段重新引入实例冲突。这与 DETR 试图从源头消除冗余预测的目标是根本冲突的。</p>
<p>通过强制一对一匹配，DETR 在训练阶段就明确规定：<strong>每个真实目标只能由一个查询负责，其余查询必须学习输出 no-object</strong>。这种约束迫使模型在查询层面形成稳定分工，为推理阶段的无冲突输出奠定基础。</p>
<h3 id="5-3-代价函数的真正含义：实例相似度，而非几何距离"><a href="#5-3-代价函数的真正含义：实例相似度，而非几何距离" class="headerlink" title="5.3 代价函数的真正含义：实例相似度，而非几何距离"></a>5.3 代价函数的真正含义：实例相似度，而非几何距离</h3><p>在匈牙利匹配中，匹配关系的确定依赖于一个代价函数。该函数通常由分类代价与回归代价共同构成，用于衡量预测结果与真实目标之间的相似程度。</p>
<p>需要强调的是，这一代价函数并非简单的框距离度量。它并不是在寻找“最近的预测框”，而是在寻找<strong>最可能对应同一实例的预测</strong>。换言之，代价函数度量的是实例级相似度，而非纯几何邻近关系。</p>
<p>这种定义使得匹配过程具有语义一致性：一个预测只有在类别和位置上同时合理时，才会被分配给某个真实目标。这一机制确保了监督信号的稳定性，也避免了训练过程中的随机分配问题。</p>
<h3 id="5-4-从优化视角理解-Set-Prediction"><a href="#5-4-从优化视角理解-Set-Prediction" class="headerlink" title="5.4 从优化视角理解 Set Prediction"></a>5.4 从优化视角理解 Set Prediction</h3><p>从更抽象的角度看，DETR 所解决的是一个典型的集合预测问题。在集合预测中，输出元素之间是无序的，损失函数必须对排列不敏感。匈牙利匹配正是实现这一“排列不变性”的关键工具。</p>
<p>通过在训练阶段寻找最优的一对一匹配，损失计算只依赖于集合内容本身，而不依赖于预测的排列顺序。这使得模型能够在连续参数空间中进行梯度优化，同时在离散匹配空间中保持监督结构的一致性。</p>
<p>从这一视角看，匈牙利匹配并不是 DETR 的额外复杂性，而是集合预测问题在监督学习框架下的自然结果。</p>
<h3 id="5-5-常见误解与澄清"><a href="#5-5-常见误解与澄清" class="headerlink" title="5.5 常见误解与澄清"></a>5.5 常见误解与澄清</h3><p>围绕匈牙利匹配，存在两类常见误解。其一是认为其计算复杂度过高，不适用于实际系统。事实上，由于 DETR 中查询数量通常是固定且相对较小的，匹配过程在整体训练时间中的占比有限，并不会成为主要瓶颈。</p>
<p>其二是认为匈牙利匹配在推理阶段同样存在。需要明确的是，<strong>匹配仅用于训练阶段的监督对齐</strong>，推理阶段并不涉及任何匹配、排序或抑制操作。</p>
<p>澄清这些误解，有助于避免将 DETR 简化为“复杂但低效的检测模型”，而忽略其在建模层面的真正创新。</p>
<pre class="mermaid">flowchart LR
    subgraph Pred["预测集合（Object Queries）"]
        direction TB
        P1[预测 #1]
        P2[预测 #2]
        P3[预测 #3]
        P4[预测 #4]
    end

    subgraph GT["真实目标集合（Ground Truth）"]
        direction TB
        G1[目标 A]
        G2[目标 B]
    end

    P1 -- 最优匹配 --> G1
    P3 -- 最优匹配 --> G2

    P2 -. 未匹配 .-> N[No Object]
    P4 -. 未匹配 .-> N</pre>
<center>图5-1 预测集合与真实集合的一对一匹配示意图</center>

<p>这一章的核心结论是：<strong>匈牙利匹配不是 DETR 的“复杂之处”，而是其建模逻辑得以成立的必要条件</strong>。它为无序集合预测提供了可学习的一对一监督机制，使“一个目标只预测一次”从设计理念转化为可优化的训练目标。</p>
<h2 id="6-DETR-V1：理念正确，却并不好用"><a href="#6-DETR-V1：理念正确，却并不好用" class="headerlink" title="6. DETR-V1：理念正确，却并不好用"></a>6. DETR-V1：理念正确，却并不好用</h2><p>在前述章节中，DETR 作为一种集合预测范式，展示了高度一致且优雅的建模逻辑。然而，在其最初提出时，DETR 并未在主流评测基准上全面超越成熟的一阶段检测模型。相反，其训练缓慢、推理成本高、对小目标不友好等问题，成为限制其实际应用的主要因素。</p>
<p>理解这些问题的来源，对于正确评价 DETR 的意义至关重要。它们并非实现细节不足，而是集合预测范式在<strong>缺乏结构先验</strong>条件下的直接结果。</p>
<h3 id="6-1-Transformer-在检测任务中的天然不适配"><a href="#6-1-Transformer-在检测任务中的天然不适配" class="headerlink" title="6.1 Transformer 在检测任务中的天然不适配"></a>6.1 Transformer 在检测任务中的天然不适配</h3><p>初代 DETR 直接采用标准 Transformer 结构作为核心建模模块。这一选择在语义建模能力上具有明显优势，但在目标检测任务中也暴露出结构性不适配。</p>
<p>标准自注意力机制在空间维度上是全局的。对于高分辨率特征图而言，每一个查询都需要与所有空间位置建立关联。这种全局建模虽然在理论上信息充分，但在检测任务中往往显得代价过高：大量计算被用于建模与当前目标无关的背景区域。</p>
<p>此外，目标检测高度依赖局部几何信息，尤其是在小目标场景中。全局注意力缺乏对局部结构的显式偏置，使模型在训练初期难以聚焦于目标区域。相比之下，卷积网络通过局部感受野和权值共享，天然具备对局部模式的敏感性。</p>
<p>因此，将标准 Transformer 直接用于检测，并非“用错模型”，而是<strong>用了一种缺乏检测先验的通用结构</strong>。</p>
<h3 id="6-2-收敛缓慢是学习难度，而非工程问题"><a href="#6-2-收敛缓慢是学习难度，而非工程问题" class="headerlink" title="6.2 收敛缓慢是学习难度，而非工程问题"></a>6.2 收敛缓慢是学习难度，而非工程问题</h3><p>初代 DETR 的另一个典型问题是训练收敛缓慢。相较于 YOLO 等模型，DETR 往往需要显著更长的训练周期才能达到可接受性能。</p>
<p>这一现象并非源于优化器选择或超参数设置，而是由其建模假设所决定。在 DETR 中，对象查询在初始化时是完全对称的，不具备任何空间或语义先验。模型不仅需要学习目标的类别与位置，还需要同时学习查询之间的分工关系。</p>
<p>这种“从零开始分配实例责任”的学习过程本身难度较高。相比之下，密集预测方法在训练一开始就通过空间位置、Anchor 或特征金字塔为预测提供了强先验，从而显著降低了学习难度。</p>
<p>从这一角度看，DETR 的收敛缓慢并非缺陷，而是其<strong>去除工程先验所必须付出的代价</strong>。</p>
<h3 id="6-3-小目标性能受限的根本原因"><a href="#6-3-小目标性能受限的根本原因" class="headerlink" title="6.3 小目标性能受限的根本原因"></a>6.3 小目标性能受限的根本原因</h3><p>在早期实验中，DETR 在小目标检测上的表现明显弱于基于多尺度特征的检测模型。这一问题同样可以追溯到其结构设计。</p>
<p>一方面，初代 DETR 通常仅使用单一尺度的高层特征进行预测。对于尺寸较小的目标，其细节信息往往在高层特征中被显著压缩，难以保留足够的判别信号。</p>
<p>另一方面，全局注意力机制在面对大量背景区域时，容易分散注意力权重，使小目标的信号被淹没在背景信息之中。这种现象在目标稀疏但背景复杂的场景中尤为明显。</p>
<p>这些问题并非通过简单调参即可解决，而是提示需要在保持集合预测思想的同时，引入更符合检测任务特性的结构设计。</p>
<h3 id="6-4-一个关键判断：DETR-是“草图”，而非终态"><a href="#6-4-一个关键判断：DETR-是“草图”，而非终态" class="headerlink" title="6.4 一个关键判断：DETR 是“草图”，而非终态"></a>6.4 一个关键判断：DETR 是“草图”，而非终态</h3><p>综合来看，初代 DETR 所暴露的问题并不意味着集合预测范式本身存在缺陷。相反，它清晰地指出了范式落地所需要补齐的关键环节：更高效的注意力机制、更合理的特征层级设计，以及对训练过程的适当引导。</p>
<p>从技术演化的角度看，DETR 更像是一份“概念验证”或“第一版草图”，而非可直接替代现有方法的工程方案。它的价值在于明确了方向，而非提供了最终答案。</p>
<p>正是在这一基础上，后续工作开始围绕“如何在不破坏集合预测核心思想的前提下，引入必要的结构先验”展开。下一章将讨论的 <strong>Deformable DETR</strong>，正是这一探索路径上的关键节点。</p>
<pre class="mermaid">flowchart LR
    subgraph Global["标准 Transformer 注意力"]
        direction LR
        A1[特征图所有位置]
        A2[全局两两计算<br/>Self-Attention]
        A3[注意力分散<br/>背景占比高]
        A4[计算量大<br/>小目标信号被稀释]
        A1 --> A2 --> A3 --> A4
    end

    subgraph DetectNeed["检测任务的关注需求"]
        direction LR
        B1[特征图]
        B2[少量关键区域<br/>（目标位置）]
        B3[局部聚焦计算]
        B4[高效且对小目标友好]
        B1 --> B2 --> B3 --> B4
    end</pre>
<center>图6-1 标准 Transformer 注意力与检测任务需求对比示意图</center>

<p>这一章的结论可以总结为：<strong>DETR 的问题不在于“集合预测是否合理”，而在于“如何让这一范式高效落地”</strong>。</p>
<h2 id="7-Deformable-DETR：让-Transformer-学会只看重要区域"><a href="#7-Deformable-DETR：让-Transformer-学会只看重要区域" class="headerlink" title="7. Deformable DETR：让 Transformer 学会只看重要区域"></a>7. Deformable DETR：让 Transformer 学会只看重要区域</h2><p>在上一章中，我们已经明确：初代 DETR 的问题不在于集合预测这一思想本身，而在于其实现方式缺乏对检测任务的结构性适配。Deformable DETR 的出现，正是为了回答一个关键问题：<strong>在不破坏集合预测与一对一匹配这一核心思想的前提下，如何显著提升效率与可用性？</strong></p>
<p>Deformable DETR 给出的答案并不是推翻 DETR，而是对其注意力机制与特征使用方式进行有针对性的重构。  </p>
<h3 id="7-1-从全局注意力到稀疏注意力的必然转变"><a href="#7-1-从全局注意力到稀疏注意力的必然转变" class="headerlink" title="7.1 从全局注意力到稀疏注意力的必然转变"></a>7.1 从全局注意力到稀疏注意力的必然转变</h3><p>初代 DETR 使用标准 Transformer 自注意力机制，其特点是对特征图中所有位置进行两两交互。这种设计在语义建模任务中具有优势，但在目标检测中代价高昂且效率低下。</p>
<p>Deformable DETR 的核心改变在于：<strong>放弃全局遍历，转而采用稀疏注意力机制</strong>。对于每一个 object query，模型不再关注整幅特征图，而是仅在少量关键位置上进行特征聚合。这些位置并非人工指定，而是由模型在训练过程中自动学习。</p>
<p>这一转变直接带来了两个结果：</p>
<ol>
<li>计算复杂度显著降低，使 Transformer 能够处理更高分辨率的特征；</li>
<li>注意力更加聚焦于潜在目标区域，而非被背景信息稀释。</li>
</ol>
<h3 id="7-2-“可变形”并非几何形变，而是可学习的采样位置"><a href="#7-2-“可变形”并非几何形变，而是可学习的采样位置" class="headerlink" title="7.2 “可变形”并非几何形变，而是可学习的采样位置"></a>7.2 “可变形”并非几何形变，而是可学习的采样位置</h3><p>“Deformable”一词常被直观理解为几何形变，但在 Deformable DETR 中，其核心含义是<strong>采样位置的可学习性</strong>。</p>
<p>对于每一个 query，模型会预测若干个参考点及其偏移量，从而在特征图上选取少量最相关的位置进行信息聚合。这种机制相当于为每个查询配备了一组自适应的“观察点”，它们会在训练过程中逐渐对齐到目标实例的关键区域，例如中心或边界附近。</p>
<p>从直觉上看，这一机制为 Transformer 引入了类似卷积网络中“局部感受野”的结构偏置，但这种偏置是动态的、可学习的，而非固定的。这使模型在保持表达灵活性的同时，获得了对检测任务至关重要的局部聚焦能力。</p>
<h3 id="7-3-多尺度特征：补齐小目标的结构性短板"><a href="#7-3-多尺度特征：补齐小目标的结构性短板" class="headerlink" title="7.3 多尺度特征：补齐小目标的结构性短板"></a>7.3 多尺度特征：补齐小目标的结构性短板</h3><p>除了稀疏注意力机制，Deformable DETR 还系统性地引入了多尺度特征表示。不同尺度的特征图可以捕获不同尺寸目标的判别信息，使模型在面对小目标与大目标时具备更均衡的感知能力。</p>
<p>在这一设计下，每个 query 可以同时从多个尺度的特征图中采样信息，而不再受限于单一高层特征。这一改进显著缓解了初代 DETR 在小目标场景中的性能不足。</p>
<p>需要强调的是，多尺度设计并未改变 DETR 的输出形式或训练方式。一对一匹配、集合预测以及端到端优化框架均保持不变，改进仅发生在<strong>特征提取与注意力计算层面</strong>。</p>
<h3 id="7-4-收敛速度与性能的数量级提升"><a href="#7-4-收敛速度与性能的数量级提升" class="headerlink" title="7.4 收敛速度与性能的数量级提升"></a>7.4 收敛速度与性能的数量级提升</h3><p>得益于稀疏注意力和多尺度特征的引入，Deformable DETR 在训练效率上取得了数量级的提升。相较于初代 DETR，其收敛所需的训练轮数显著减少，使集合预测范式第一次在实践中具备可行性。</p>
<p>在性能层面，Deformable DETR 在多个评测基准上显著缩小了与成熟一阶段检测模型之间的差距，并在高 IoU 阈值下展现出较为稳定的定位能力。这表明，集合预测并非天然劣于密集预测，其性能瓶颈更多来自实现方式而非理论上限。</p>
<h3 id="7-5-改了什么，没改什么"><a href="#7-5-改了什么，没改什么" class="headerlink" title="7.5 改了什么，没改什么"></a>7.5 改了什么，没改什么</h3><p>从方法演进的角度看，Deformable DETR 的重要性在于其“克制的改动”。<br><strong>它改的部分</strong>：</p>
<ul>
<li>注意力从全局变为稀疏</li>
<li>引入可学习的采样位置</li>
<li>系统性使用多尺度特征</li>
</ul>
<p><strong>它没改的部分</strong>：</p>
<ul>
<li>集合预测的输出形式</li>
<li>一对一匹配与匈牙利监督</li>
<li>不依赖 NMS 的端到端检测流程</li>
</ul>
<p>这种“只改实现、不改范式”的策略，使 Deformable DETR 成为 DETR 家族中的关键转折点，也为后续一系列基于 Transformer 的检测方法奠定了基础。</p>
<pre class="mermaid">flowchart LR
    subgraph Global["全局注意力（Standard Self-Attention）"]
        direction LR
        A1[特征图所有位置 H×W]
        A2[全局两两计算]
        A3[注意力分散]
        A4[计算开销大]
        A1 --> A2 --> A3 --> A4
    end

    subgraph Deform["可变形注意力（Deformable Attention）"]
        direction LR
        B1[特征图]
        B2[为每个 Query 预测 K 个采样点]
        B3[仅在采样点聚合特征]
        B4[聚焦目标区域<br/>高效且稳定]
        B1 --> B2 --> B3 --> B4
    end</pre>
<center>图7-1 全局注意力与可变形注意力对比示意图</center>

<p>这一章的核心结论是：<strong>Deformable DETR 并没有改变 DETR 的“是什么”，而是第一次回答了 DETR 的“如何才能好用”</strong>。</p>
<h2 id="8-YOLO-与-DETR：不是替代关系，而是建模思想的分工"><a href="#8-YOLO-与-DETR：不是替代关系，而是建模思想的分工" class="headerlink" title="8. YOLO 与 DETR：不是替代关系，而是建模思想的分工"></a>8. YOLO 与 DETR：不是替代关系，而是建模思想的分工</h2><p>在前述章节中，YOLO 与 DETR 被作为两种截然不同的目标检测范式加以分析。从密集预测到集合预测，从后处理驱动到端到端建模，这种差异在结构与训练方式上表现得尤为明显。然而，如果仅以性能指标或发布时间顺序来比较二者，往往会得出片面的结论。</p>
<p>更合理的视角是：<strong>YOLO 与 DETR 关注的并不是同一个层级的问题</strong>。它们并非站在同一条技术路径上竞争，而是在不同约束条件下，对“目标检测应如何被建模”给出的两种合理答案。</p>
<h3 id="8-1-两种范式解决的是不同层级的问题"><a href="#8-1-两种范式解决的是不同层级的问题" class="headerlink" title="8.1 两种范式解决的是不同层级的问题"></a>8.1 两种范式解决的是不同层级的问题</h3><p>YOLO 所代表的一阶段检测方法，本质上解决的是<strong>高效感知</strong>问题。其核心目标是在严格的延迟、算力与部署约束下，稳定地回答“哪里有什么目标”。在这一层级上，速度、可预测性与工程可控性往往比理论一致性更为重要。</p>
<p>与之相对，DETR 所关注的问题层级更高。通过将检测建模为集合预测任务，DETR 更强调实例级一致性与全局建模能力。这种设计天然适合与关系建模、多任务学习等更复杂的视觉理解任务结合，而不仅仅停留在目标定位本身。</p>
<p>因此，YOLO 与 DETR 并非在同一个目标函数上竞争，而是在不同问题抽象层级上各自优化。</p>
<h3 id="8-2-工业系统为何长期偏向-YOLO"><a href="#8-2-工业系统为何长期偏向-YOLO" class="headerlink" title="8.2 工业系统为何长期偏向 YOLO"></a>8.2 工业系统为何长期偏向 YOLO</h3><p>在现实工程系统中，YOLO 被广泛采用并非因为其在所有指标上最优，而是因为其整体行为高度可控。</p>
<p>首先，YOLO 的推理延迟和吞吐率具有良好的可预测性，这对于实时系统至关重要。其次，其失败模式通常与阈值设置、特定尺度特征或数据分布偏差相关，具有明确的调试路径。</p>
<p>此外，YOLO 的结构相对简单，易于裁剪、量化和跨平台部署。这些特性使其在长期维护和工程落地中具备明显优势。</p>
<p>相比之下，DETR 及其变体在结构复杂度和推理成本上仍然偏高，其行为也更依赖整体表示能力。这些特性并不一定适合对延迟和资源高度敏感的场景。</p>
<h3 id="8-3-当检测不再是终点，DETR-的优势开始显现"><a href="#8-3-当检测不再是终点，DETR-的优势开始显现" class="headerlink" title="8.3 当检测不再是终点，DETR 的优势开始显现"></a>8.3 当检测不再是终点，DETR 的优势开始显现</h3><p>尽管在纯检测任务中 YOLO 仍具优势，但当检测不再是系统的最终输出，而是更大视觉系统中的中间表示时，DETR 的建模优势开始显现。</p>
<p>在多任务场景中，检测结果往往需要与分割、跟踪、关系推理等任务共享表示。集合预测形式的输出更容易与这些任务进行统一建模，而无需额外引入排序或去重规则。</p>
<p>此外，DETR 的端到端特性使其更容易融入大规模预训练框架。在这一背景下，检测不再是孤立任务，而是整体视觉理解能力的一部分。这也是近年来 DETR 风格方法在研究领域持续活跃的重要原因。</p>
<h3 id="8-4-一个容易被忽略的事实：YOLO-也在吸收-DETR-的思想"><a href="#8-4-一个容易被忽略的事实：YOLO-也在吸收-DETR-的思想" class="headerlink" title="8.4 一个容易被忽略的事实：YOLO 也在吸收 DETR 的思想"></a>8.4 一个容易被忽略的事实：YOLO 也在吸收 DETR 的思想</h3><p>需要指出的是，范式之间并非泾渭分明。近年来，YOLO 系列模型也在不断吸收 DETR 所代表的一些思想，例如更简洁的预测头设计、对冗余预测的进一步抑制，以及在一定程度上弱化后处理规则的影响。</p>
<p>这种相互借鉴说明，目标检测的发展并非沿着单一方向演进，而是在不同范式之间不断调整平衡。YOLO 与 DETR 更像是两种极端假设下的代表性方案，其实际应用形态往往位于两者之间。</p>
<h3 id="8-5-分工而非胜负的现实结论"><a href="#8-5-分工而非胜负的现实结论" class="headerlink" title="8.5 分工而非胜负的现实结论"></a>8.5 分工而非胜负的现实结论</h3><p>综合来看，将 YOLO 与 DETR 视为胜负关系，往往会遮蔽二者在不同问题层级上的合理定位。YOLO 并未因 DETR 的出现而失去价值，DETR 也并非为了取代 YOLO 而设计。</p>
<p>更合理的理解方式是，将二者视为目标检测问题在不同约束条件下的两种解法：</p>
<ul>
<li><strong>YOLO</strong> 强调效率、稳定性与工程可控性；</li>
<li><strong>DETR</strong> 强调一致性、结构表达与可扩展性。</li>
</ul>
<p>正是在这种分工关系下，目标检测领域得以同时满足工业实践与理论探索的双重需求。</p>
<pre class="mermaid">flowchart TB
    subgraph DETR["DETR：结构建模层"]
        direction TB
        B1[实例集合建模]
        B2[一对一预测]
        B3[端到端一致性]
        B1 --> B2 --> B3
    end

    subgraph YOLO["YOLO：高效感知层"]
        direction TB
        A1[实时性优先]
        A2[密集预测 + 规则去重]
        A3[工程可控、稳定输出]
        A1 --> A2 --> A3
    end</pre>
<center>图8-1 YOLO 与 DETR 在系统层级上的分工示意图</center>

<p>这一章的结论可以概括为：<strong>YOLO 与 DETR 并非在“谁更好”的问题上竞争，而是在“在什么约束下该如何建模”这一问题上各司其职</strong>。</p>
<h2 id="9-实践：YOLO-与-DETR-范式在真实数据上的差异体现在哪里"><a href="#9-实践：YOLO-与-DETR-范式在真实数据上的差异体现在哪里" class="headerlink" title="9. 实践：YOLO 与 DETR 范式在真实数据上的差异体现在哪里"></a>9. 实践：YOLO 与 DETR 范式在真实数据上的差异体现在哪里</h2><p>在前述章节中，YOLO 与 DETR 的差异主要从建模思想与结构设计层面加以分析。然而，不同检测范式的设计取舍是否具有现实意义，最终仍需回到真实数据与具体结果上进行检验。本章通过一组对照实验，考察 <strong>一阶段检测范式（YOLO）</strong> 与 <strong>集合预测范式（DETR 系）</strong> 在真实检测任务中的<strong>行为差异</strong>。</p>
<p>需要强调的是，本章的关注重点并非比较模型的极限性能，而在于揭示不同范式在复杂场景中所呈现出的<strong>典型错误模式与可控性差异</strong>。</p>
<h3 id="9-1-实验目标：关注错误结构，而非单一指标"><a href="#9-1-实验目标：关注错误结构，而非单一指标" class="headerlink" title="9.1 实验目标：关注错误结构，而非单一指标"></a>9.1 实验目标：关注错误结构，而非单一指标</h3><p>在目标检测评测中，mAP 等综合指标通常被用作主要比较依据。然而，这类指标在一定程度上会<strong>掩盖模型在不同场景下的结构性行为差异</strong>。例如，两种模型可能取得相近的 mAP，但其漏检位置、误检分布以及错误可调性却截然不同。<br>因此，本章实验并非回答“哪个模型更强”，而是试图回答以下问题：</p>
<ul>
<li>在相同数据分布与算力约束下，不同检测范式更容易在什么情况下失败？</li>
<li>这些失败是推理阶段的规则性问题，还是源于建模假设本身？</li>
<li>不同范式的错误在实践中是否具有可调性与可控性？</li>
</ul>
<p>基于上述目标，实验重点从以下三个维度展开分析：</p>
<ol>
<li><strong>小目标场景</strong></li>
<li><strong>密集目标场景</strong></li>
<li><strong>推理延迟与稳定性</strong></li>
</ol>
<h3 id="9-2-实验设置概述"><a href="#9-2-实验设置概述" class="headerlink" title="9.2 实验设置概述"></a>9.2 实验设置概述</h3><p>实验选用一个规模适中、目标分布较为复杂的coco数据集，以避免单一场景对结论产生过强影响。数据集中同时包含孤立目标与密集排列目标，并覆盖多个尺度区间，从而对模型的泛化行为提出更具挑战性的要求。</p>
<p>模型选择方面，本章采用如下配置：</p>
<ul>
<li>使用轻量化配置的 <strong>YOLO 模型</strong> 作为一阶段检测范式的代表；</li>
<li>使用 <strong>Deformable DETR</strong> 作为集合预测范式的代表实现。</li>
</ul>
<p>之所以采用 Deformable DETR 而非原始 DETR，是基于以下考虑：原始 DETR 在小目标建模与收敛效率方面存在已知局限，而 Deformable DETR 在保持端到端集合预测与一对一匹配特性的同时，通过可变形注意力机制显著增强了对多尺度与稀疏特征的建模能力，更能代表当前 DETR 范式在实践中的合理形态。</p>
<p>所有模型均在<strong>相近训练预算</strong>下完成收敛，推理阶段统一采用官方推荐的默认配置，避免针对单一模型进行极端调优，从而保证对比的公平性。评测阶段使用统一的框格式、IoU 计算方式与错误统计逻辑，以确保不同模型的输出行为在同一语义空间中进行比较。</p>
<h3 id="9-3-定量结果：性能数字背后的含义"><a href="#9-3-定量结果：性能数字背后的含义" class="headerlink" title="9.3 定量结果：性能数字背后的含义"></a>9.3 定量结果：性能数字背后的含义</h3><p>从整体指标上看，YOLO 在推理速度与吞吐率方面保持明显优势，尤其在资源受限或对实时性要求较高的环境中表现稳定。其性能随模型规模变化呈现出较好的可预测性，工程部署成本相对较低。</p>
<p>相比之下，Deformable DETR 在较高 IoU 阈值下展现出更稳定的定位表现，预测框在位置一致性方面具有一定优势，尤其在目标分布复杂的场景中表现出更强的召回能力。但这一优势以更高的推理延迟与显存占用为代价，其部署复杂度仍明显高于同级别的 YOLO 模型。</p>
<p>需要指出的是，这些数值差异本身并不构成优劣判断，而是反映了两种检测范式在<strong>优化目标与资源分配策略上的不同取舍</strong>。</p>
<h3 id="9-4-定性分析：典型错误模式的对比"><a href="#9-4-定性分析：典型错误模式的对比" class="headerlink" title="9.4 定性分析：典型错误模式的对比"></a>9.4 定性分析：典型错误模式的对比</h3><p>相比定量指标，错误模式的分析更能揭示模型的内在特性。</p>
<p>在<strong>密集目标场景</strong>中，YOLO 更容易出现因非极大值抑制（NMS）导致的漏检现象。当多个目标在空间位置上高度接近且尺度相似时，模型往往能够生成多个合理候选，但在后处理阶段被规则性合并为较少的预测结果。这类错误具有一定的可解释性，并可通过阈值调节在不同场景下进行折中，但难以彻底消除。</p>
<p>在<strong>小目标场景</strong>中，集合预测范式的优势与局限同时显现。Deformable DETR 相比原始 DETR 在小目标召回方面已有明显改善，但仍可观察到部分小目标未被任何查询有效覆盖的情况。这类错误并非源于后处理，而是发生在模型内部的查询分配与特征建模阶段，属于结构性遗漏。</p>
<p>值得注意的是，两类错误在性质上存在显著差异：</p>
<ul>
<li>YOLO 的错误主要发生在<strong>推理阶段</strong>，依赖规则与阈值，具有一定可调性；</li>
<li>Deformable DETR 的错误更多发生在<strong>建模阶段</strong>，一旦形成，往往难以通过简单规则进行修正。</li>
</ul>
<h3 id="9-5-调参能解决的，与调参解决不了的"><a href="#9-5-调参能解决的，与调参解决不了的" class="headerlink" title="9.5 调参能解决的，与调参解决不了的"></a>9.5 调参能解决的，与调参解决不了的</h3><p>实践中常见的一种误区，是将不同模型之间的性能差异简单归因于参数设置不当。实验结果表明，这种看法并不完全成立。</p>
<p>对于 YOLO，置信度阈值、NMS 阈值等参数对检测结果具有显著影响。通过合理调节，这些参数可以在误检与漏检之间取得不同权衡。这种<strong>可调性</strong>正是其工程友好性的体现。</p>
<p>而对于 Deformable DETR，尽管查询数量、匹配代价权重等参数会对训练过程产生影响，但其对最终错误分布的影响相对有限。一旦模型在特征层级或查询表达能力上存在不足，简单调参难以从根本上改变结果。这反映出集合预测范式对<strong>结构设计的高度敏感性</strong>。</p>
<h3 id="9-6-代码与实现"><a href="#9-6-代码与实现" class="headerlink" title="9.6 代码与实现"></a>9.6 代码与实现</h3><p>本节将对照实验整理为最小可运行工程 <strong>YOLO_DeformableDETR_behavior_study</strong>。该工程的核心思想是：用统一的数据接口与评测逻辑，将不同检测范式（YOLO 一阶段密集预测、Deformable DETR 集合预测）约束在同一语义空间内比较，从而把差异聚焦到“模型行为”而非“评测适配”。工程实现流程可概括为四个层次：数据层、模型层、评测层与汇总层。</p>
<h4 id="9-6-1-数据层：COCO-标注解析与受控抽样"><a href="#9-6-1-数据层：COCO-标注解析与受控抽样" class="headerlink" title="9.6.1 数据层：COCO 标注解析与受控抽样"></a>9.6.1 数据层：COCO 标注解析与受控抽样</h4><p>数据入口位于 datasets&#x2F;coco.py。使用 pycocotools.COCO 读取 COCO 格式标注（instances_val2017.json），并从验证集图片 ID 中随机抽取 sample_n 张构成评测子集。每次迭代返回两类信息：</p>
<ul>
<li>一是以 numpy.ndarray 形式加载的 RGB 图像；</li>
<li>二是由 COCO bbox（xywh）转换得到的 GT 框（xyxy）。</li>
</ul>
<p>这一设计保证了两种模型接收的输入完全一致，并使实验规模可控、复现实验成本可接受。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CocoDataset</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    COCO 数据集最小封装，用于推理/评测阶段（非训练）。</span></span><br><span class="line"><span class="string">    功能：</span></span><br><span class="line"><span class="string">    - 从 COCO 标注文件中随机抽取 sample_n 张图片</span></span><br><span class="line"><span class="string">    - 按顺序返回：</span></span><br><span class="line"><span class="string">        - RGB 图像（numpy.ndarray, H×W×3）</span></span><br><span class="line"><span class="string">        - 对应的 GT 边界框列表（xyxy 格式）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_dir, ann_path, sample_n=<span class="number">300</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数说明：</span></span><br><span class="line"><span class="string">        - img_dir : COCO 图像目录（如 val2017/）</span></span><br><span class="line"><span class="string">        - ann_path: COCO 标注文件路径（instances_val2017.json）</span></span><br><span class="line"><span class="string">        - sample_n: 随机抽取的图像数量，用于构建受控评测子集</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 加载 COCO 标注</span></span><br><span class="line">        <span class="variable language_">self</span>.coco = COCO(ann_path)</span><br><span class="line">        <span class="comment"># 图像根目录</span></span><br><span class="line">        <span class="variable language_">self</span>.img_dir = img_dir</span><br><span class="line">        <span class="comment"># 从所有图像 ID 中随机抽取 sample_n 个</span></span><br><span class="line">        <span class="comment"># 目的是控制实验规模，同时保持真实数据分布</span></span><br><span class="line">        <span class="variable language_">self</span>.img_ids = random.sample(<span class="variable language_">self</span>.coco.getImgIds(), sample_n)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回数据集中图像数量&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.img_ids)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        迭代器接口：每次返回一张图像及其对应的 GT 边界框</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> iid <span class="keyword">in</span> <span class="variable language_">self</span>.img_ids:</span><br><span class="line">            <span class="comment"># 读取图像元信息（文件名、尺寸等）</span></span><br><span class="line">            info = <span class="variable language_">self</span>.coco.loadImgs(iid)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 读取图像文件（OpenCV 默认 BGR，需要转为 RGB）</span></span><br><span class="line">            img_path = os.path.join(<span class="variable language_">self</span>.img_dir, info[<span class="string">&#x27;file_name&#x27;</span>])</span><br><span class="line">            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)</span><br><span class="line">            <span class="comment"># 加载该图像对应的所有标注（annotations）</span></span><br><span class="line">            ann_ids = <span class="variable language_">self</span>.coco.getAnnIds(imgIds=iid)</span><br><span class="line">            anns = <span class="variable language_">self</span>.coco.loadAnns(ann_ids)</span><br><span class="line">            <span class="comment"># 将 COCO 的 bbox（xywh）转换为 xyxy 格式</span></span><br><span class="line">            boxes = []</span><br><span class="line">            <span class="keyword">for</span> a <span class="keyword">in</span> anns:</span><br><span class="line">                x, y, w, h = a[<span class="string">&#x27;bbox&#x27;</span>]</span><br><span class="line">                boxes.append([x, y, x + w, y + h])</span><br><span class="line">            <span class="comment"># - img  : RGB 图像（numpy.ndarray）</span></span><br><span class="line">            <span class="comment"># - boxes: GT 边界框列表（List[List[float]]）</span></span><br><span class="line">            <span class="keyword">yield</span> img, boxes</span><br></pre></td></tr></table></figure>
<h4 id="9-6-2-模型层：以-Wrapper-统一不同范式的推理接口"><a href="#9-6-2-模型层：以-Wrapper-统一不同范式的推理接口" class="headerlink" title="9.6.2 模型层：以 Wrapper 统一不同范式的推理接口"></a>9.6.2 模型层：以 Wrapper 统一不同范式的推理接口</h4><p>模型接入位于 wrappers&#x2F; 目录，YOLO 与 Deformable DETR 各自实现 predict(img) -&gt; (boxes, scores)。</p>
<ul>
<li>wrappers&#x2F;yolo_wrapper.py 负责封装 YOLO 的推理流程，并将其输出规范化为 boxes_xyxy 与 scores。YOLO 内部可能包含解码、阈值过滤与 NMS，但这些差异被封装在 wrapper 内部，不向外泄漏。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOWrapper</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    YOLO 推理封装类。</span></span><br><span class="line"><span class="string">    该封装用于将一阶段检测模型（YOLO）的推理过程</span></span><br><span class="line"><span class="string">    统一为实验所需的预测接口：</span></span><br><span class="line"><span class="string">        predict(img) -&gt; (boxes_xyxy, scores)</span></span><br><span class="line"><span class="string">    通过 wrapper 屏蔽 YOLO 内部的 dense prediction、anchor 解码、NMS 等工程细节，使其输出可与 Deformable DETR 直接对照。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=<span class="string">&quot;cpu&quot;</span>, score_thr=<span class="number">0.25</span>, model_name=<span class="string">&quot;yolov8n.pt&quot;</span>, imgsz=<span class="number">640</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数说明：</span></span><br><span class="line"><span class="string">        - device     : 推理设备（&quot;cpu&quot; / &quot;cuda&quot; / &quot;cuda:0&quot;）</span></span><br><span class="line"><span class="string">        - score_thr  : 置信度阈值，用于过滤低置信预测框</span></span><br><span class="line"><span class="string">        - model_name : YOLO 权重文件名或路径（Ultralytics 格式）</span></span><br><span class="line"><span class="string">        - imgsz      : 推理时使用的输入分辨率</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.device = device</span><br><span class="line">        <span class="variable language_">self</span>.score_thr = <span class="built_in">float</span>(score_thr)</span><br><span class="line">        <span class="variable language_">self</span>.imgsz = <span class="built_in">int</span>(imgsz)</span><br><span class="line">        <span class="comment"># 加载 YOLO 模型（如本地不存在，Ultralytics 会自动下载权重）</span></span><br><span class="line">        <span class="variable language_">self</span>.model = YOLO(model_name)</span><br><span class="line">        <span class="comment"># 尝试将模型移动到指定设备</span></span><br><span class="line">        <span class="comment"># 不同版本的 Ultralytics 对 .to(device) 的支持略有差异，因此使用 try / except 保证代码的兼容性</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="variable language_">self</span>.model.to(device)</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, img_rgb: np.ndarray</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对单张图像执行 YOLO 推理。</span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - img_rgb : numpy.ndarray，RGB 图像，形状为 (H, W, 3)</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">        - boxes_xyxy : numpy.ndarray，形状 (N, 4)，边界框坐标 (x1, y1, x2, y2)</span></span><br><span class="line"><span class="string">        - scores     : numpy.ndarray，形状 (N,)，对应的置信度分数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Ultralytics YOLO 支持直接以 numpy RGB 图像作为输入，内部自动完成 resize、归一化与前向推理</span></span><br><span class="line">        results = <span class="variable language_">self</span>.model.predict(</span><br><span class="line">            source=img_rgb,</span><br><span class="line">            imgsz=<span class="variable language_">self</span>.imgsz,</span><br><span class="line">            conf=<span class="variable language_">self</span>.score_thr,</span><br><span class="line">            device=<span class="variable language_">self</span>.device,</span><br><span class="line">            verbose=<span class="literal">False</span></span><br><span class="line">        )[<span class="number">0</span>]  <span class="comment"># 只取当前图像对应的预测结果</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 若该图像没有任何检测结果，返回空数组，以保证后续评测（IoU / error_profile）逻辑稳定</span></span><br><span class="line">        <span class="keyword">if</span> results.boxes <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">len</span>(results.boxes) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> (</span><br><span class="line">                np.zeros((<span class="number">0</span>, <span class="number">4</span>), dtype=np.float32),</span><br><span class="line">                np.zeros((<span class="number">0</span>,), dtype=np.float32)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取预测框坐标（xyxy）与置信度分数</span></span><br><span class="line">        boxes = (</span><br><span class="line">            results.boxes.xyxy</span><br><span class="line">            .detach()</span><br><span class="line">            .cpu()</span><br><span class="line">            .numpy()</span><br><span class="line">            .astype(np.float32)</span><br><span class="line">        )</span><br><span class="line">        scores = (</span><br><span class="line">            results.boxes.conf</span><br><span class="line">            .detach()</span><br><span class="line">            .cpu()</span><br><span class="line">            .numpy()</span><br><span class="line">            .astype(np.float32)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 再次应用置信度阈值过滤，作为不同 YOLO 版本行为差异的保险措施</span></span><br><span class="line">        keep = scores &gt;= <span class="variable language_">self</span>.score_thr</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> boxes[keep], scores[keep]</span><br></pre></td></tr></table></figure>
<ul>
<li>wrappers&#x2F;detr_wrapper.py 使用 HuggingFace Transformers 的 DeformableDetrForObjectDetection 与对应 processor：完成输入预处理、模型前向与 post_process_object_detection，并输出与 YOLO 相同格式的 boxes_xyxy 与 scores。Deformable DETR 的集合预测特性（有限查询、无 NMS、一对一匹配）因此被完整保留，同时在接口层面与 YOLO 对齐。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoImageProcessor, DeformableDetrForObjectDetection</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DetrWrapper</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Deformable DETR 推理封装类。</span></span><br><span class="line"><span class="string">    该封装用于将集合预测范式（Deformable DETR）的推理流程</span></span><br><span class="line"><span class="string">    统一为实验所需的预测接口：</span></span><br><span class="line"><span class="string">        predict(img) -&gt; (boxes_xyxy, scores)</span></span><br><span class="line"><span class="string">    与 YOLOWrapper 保持相同的输出语义，</span></span><br><span class="line"><span class="string">    以支持不同检测范式在同一评测逻辑下的对照分析。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=<span class="string">&#x27;cpu&#x27;</span>, score_thr=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数说明：</span></span><br><span class="line"><span class="string">        - device    : 推理设备（&#x27;cpu&#x27; / &#x27;cuda&#x27; / &#x27;cuda:0&#x27;）</span></span><br><span class="line"><span class="string">        - score_thr : 置信度阈值，用于过滤低置信预测结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 指定推理设备</span></span><br><span class="line">        <span class="variable language_">self</span>.device = torch.device(device)</span><br><span class="line">        <span class="variable language_">self</span>.score_thr = score_thr</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加载 Deformable DETR 的图像预处理器，负责 resize、归一化以及输入张量构建</span></span><br><span class="line">        <span class="variable language_">self</span>.processor = AutoImageProcessor.from_pretrained(</span><br><span class="line">            <span class="string">&#x27;SenseTime/deformable-detr&#x27;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加载预训练的 Deformable DETR 模型并进入评估模式</span></span><br><span class="line">        <span class="variable language_">self</span>.model = (</span><br><span class="line">            DeformableDetrForObjectDetection</span><br><span class="line">            .from_pretrained(<span class="string">&#x27;SenseTime/deformable-detr&#x27;</span>)</span><br><span class="line">            .to(<span class="variable language_">self</span>.device)</span><br><span class="line">            .<span class="built_in">eval</span>()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, img</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对单张图像执行 Deformable DETR 推理。</span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">        - img : 输入图像，可为 numpy.ndarray（RGB）或 PIL.Image</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">        - boxes_xyxy : numpy.ndarray，形状 (N, 4)，预测框坐标 (x1, y1, x2, y2)</span></span><br><span class="line"><span class="string">        - scores     : numpy.ndarray，形状 (N,)，对应的置信度分数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 若输入为 numpy 数组，则转换为 PIL.Image，以满足 HuggingFace processor 的输入要求</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(img, np.ndarray):</span><br><span class="line">            img = Image.fromarray(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图像预处理：构建模型所需的输入张量</span></span><br><span class="line">        inputs = <span class="variable language_">self</span>.processor(</span><br><span class="line">            images=img,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span></span><br><span class="line">        ).to(<span class="variable language_">self</span>.device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向推理</span></span><br><span class="line">        outputs = <span class="variable language_">self</span>.model(**inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取原始图像尺寸（注意 PIL.Image.size 返回顺序为 (W, H)）</span></span><br><span class="line">        h, w = img.size[<span class="number">1</span>], img.size[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 后处理：将模型输出的相对坐标，转换为与原图尺寸一致的绝对坐标（xyxy），同时根据 score_thr 过滤低置信预测</span></span><br><span class="line">        res = <span class="variable language_">self</span>.processor.post_process_object_detection(</span><br><span class="line">            outputs,</span><br><span class="line">            target_sizes=torch.tensor([[h, w]], device=<span class="variable language_">self</span>.device),</span><br><span class="line">            threshold=<span class="variable language_">self</span>.score_thr</span><br><span class="line">        )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回 numpy 格式的预测框与置信度</span></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            res[<span class="string">&#x27;boxes&#x27;</span>].cpu().numpy().astype(np.float32),</span><br><span class="line">            res[<span class="string">&#x27;scores&#x27;</span>].cpu().numpy().astype(np.float32)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>通过 wrapper 机制，实验主循环无需关心模型内部差异，从而避免“为适配模型而改变评测”的隐性偏差。</p>
<h4 id="9-7-3-评测层：基于-IoU-的结构性错误统计（TP-FP-FN-dup）"><a href="#9-7-3-评测层：基于-IoU-的结构性错误统计（TP-FP-FN-dup）" class="headerlink" title="9.7.3 评测层：基于 IoU 的结构性错误统计（TP&#x2F;FP&#x2F;FN&#x2F;dup）"></a>9.7.3 评测层：基于 IoU 的结构性错误统计（TP&#x2F;FP&#x2F;FN&#x2F;dup）</h4><p>评测逻辑位于 utils&#x2F;boxes.py。工程不直接依赖 mAP，而是计算 GT 框与预测框之间的 IoU 矩阵，并在图像级别统计四类结构性错误：</p>
<ul>
<li><strong>TP</strong>：被至少一个预测框命中的 GT 数量（GT 视角）；</li>
<li><strong>FN</strong>：未被任何预测框命中的 GT 数量（GT 视角）；</li>
<li><strong>FP</strong>：未命中任何 GT 的预测框数量（Pred 视角）；</li>
<li><strong>dup</strong>：多个预测框命中同一 GT 的重复量（用于观察冗余与后处理需求）。</li>
</ul>
<p>实现上，为避免 NumPy&#x2F;Torch 混用带来的语义差异与广播陷阱，评测层统一使用 torch.Tensor 完成 IoU 与统计计算，并在输出阶段再转换为 Python 标量。这使得不同模型输出的比较建立在同一套数值语义与阈值标准之上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">box_iou_xyxy</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算两组边界框之间的 IoU（Intersection over Union）。</span></span><br><span class="line"><span class="string">    输入：</span></span><br><span class="line"><span class="string">    - a : (Na, 4)，边界框，xyxy 格式</span></span><br><span class="line"><span class="string">    - b : (Nb, 4)，边界框，xyxy 格式</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">    - iou : (Na, Nb)，IoU 矩阵</span></span><br><span class="line"><span class="string">      iou[i, j] 表示第 i 个 GT 框与第 j 个预测框之间的 IoU</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># --------- 统一数据类型为 torch.Tensor ---------</span></span><br><span class="line">    <span class="comment"># 允许输入为 numpy.ndarray 或 torch.Tensor</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, np.ndarray):</span><br><span class="line">        a = torch.from_numpy(a)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(b, np.ndarray):</span><br><span class="line">        b = torch.from_numpy(b)</span><br><span class="line"></span><br><span class="line">    a = a.<span class="built_in">float</span>()</span><br><span class="line">    b = b.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 计算每个框的面积 ---------</span></span><br><span class="line">    area_a = (</span><br><span class="line">        (a[:, <span class="number">2</span>] - a[:, <span class="number">0</span>]).clamp(<span class="built_in">min</span>=<span class="number">0</span>) *</span><br><span class="line">        (a[:, <span class="number">3</span>] - a[:, <span class="number">1</span>]).clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    )</span><br><span class="line">    area_b = (</span><br><span class="line">        (b[:, <span class="number">2</span>] - b[:, <span class="number">0</span>]).clamp(<span class="built_in">min</span>=<span class="number">0</span>) *</span><br><span class="line">        (b[:, <span class="number">3</span>] - b[:, <span class="number">1</span>]).clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 计算两两框的交集区域 ---------</span></span><br><span class="line">    <span class="comment"># 左上角取最大值，右下角取最小值</span></span><br><span class="line">    lt = torch.<span class="built_in">max</span>(a[:, <span class="literal">None</span>, :<span class="number">2</span>], b[<span class="literal">None</span>, :, :<span class="number">2</span>])</span><br><span class="line">    rb = torch.<span class="built_in">min</span>(a[:, <span class="literal">None</span>, <span class="number">2</span>:], b[<span class="literal">None</span>, :, <span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 交集宽高（负值截断为 0）</span></span><br><span class="line">    wh = (rb - lt).clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    inter = wh[..., <span class="number">0</span>] * wh[..., <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 计算并集面积 ---------</span></span><br><span class="line">    union = area_a[:, <span class="literal">None</span>] + area_b[<span class="literal">None</span>, :] - inter + <span class="number">1e-9</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 返回 IoU 矩阵 ---------</span></span><br><span class="line">    <span class="keyword">return</span> (inter / union).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">error_profile</span>(<span class="params">gt_boxes, pred_boxes, iou_thr=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算结构性错误统计（TP / FP / FN / dup）。</span></span><br><span class="line"><span class="string">    与传统 mAP 不同，该函数关注的是：</span></span><br><span class="line"><span class="string">    - 模型“如何出错”，而不是“错了多少”。</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">    - gt_boxes   : GT 边界框（List / np.ndarray / torch.Tensor）</span></span><br><span class="line"><span class="string">    - pred_boxes : 预测边界框（List / np.ndarray / torch.Tensor）</span></span><br><span class="line"><span class="string">    - iou_thr    : IoU 阈值，用于判断是否命中（默认 0.5）</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">    - dict，包含：</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &#x27;tp&#x27;  : 命中目标数量（GT 视角）</span></span><br><span class="line"><span class="string">            &#x27;fp&#x27;  : 误检数量（Pred 视角）</span></span><br><span class="line"><span class="string">            &#x27;fn&#x27;  : 漏检数量（GT 视角）</span></span><br><span class="line"><span class="string">            &#x27;dup&#x27; : 重复预测数量（多个预测命中同一 GT）</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># --------- 边界情况处理 ---------</span></span><br><span class="line">    <span class="comment"># 没有 GT：所有预测都算 FP</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(gt_boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;tp&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;fp&#x27;</span>: <span class="built_in">len</span>(pred_boxes), <span class="string">&#x27;fn&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;dup&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 没有预测：所有 GT 都算 FN</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pred_boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;tp&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;fp&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;fn&#x27;</span>: <span class="built_in">len</span>(gt_boxes), <span class="string">&#x27;dup&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 统一输入类型 ---------</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(gt_boxes, <span class="built_in">list</span>):</span><br><span class="line">        gt_boxes = torch.tensor(gt_boxes)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pred_boxes, <span class="built_in">list</span>):</span><br><span class="line">        pred_boxes = torch.tensor(pred_boxes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 计算 IoU 矩阵 ---------</span></span><br><span class="line">    <span class="comment"># iou.shape = (num_gt, num_pred)</span></span><br><span class="line">    iou = box_iou_xyxy(gt_boxes, pred_boxes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================= GT 视角 =================</span></span><br><span class="line">    <span class="comment"># 每个 GT 只关心与其 IoU 最大的预测框</span></span><br><span class="line">    gt_best = iou.<span class="built_in">max</span>(dim=<span class="number">1</span>).values</span><br><span class="line">    gt_hit = gt_best &gt;= iou_thr</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 命中的 GT 数量</span></span><br><span class="line">    tp = <span class="built_in">int</span>(gt_hit.<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 未命中的 GT 数量</span></span><br><span class="line">    fn = <span class="built_in">int</span>((~gt_hit).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================= Pred 视角 =================</span></span><br><span class="line">    <span class="comment"># 每个预测框只关心与其 IoU 最大的 GT</span></span><br><span class="line">    pred_best_iou, pred_best_gt = iou.<span class="built_in">max</span>(dim=<span class="number">0</span>)</span><br><span class="line">    pred_hit = pred_best_iou &gt;= iou_thr</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 未命中任何 GT 的预测框视为 FP</span></span><br><span class="line">    fp = <span class="built_in">int</span>((~pred_hit).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ================= 重复预测（dup） =================</span></span><br><span class="line">    <span class="comment"># 若多个预测命中同一个 GT，则计为重复预测</span></span><br><span class="line">    dup = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> pred_hit.<span class="built_in">any</span>():</span><br><span class="line">        cnt = Counter(pred_best_gt[pred_hit].tolist())</span><br><span class="line">        dup = <span class="built_in">sum</span>(v - <span class="number">1</span> <span class="keyword">for</span> v <span class="keyword">in</span> cnt.values() <span class="keyword">if</span> v &gt; <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;tp&#x27;</span>: tp, <span class="string">&#x27;fp&#x27;</span>: fp, <span class="string">&#x27;fn&#x27;</span>: fn, <span class="string">&#x27;dup&#x27;</span>: dup&#125;</span><br></pre></td></tr></table></figure>
<h4 id="9-6-4-汇总层：逐样本记录与整体统计输出"><a href="#9-6-4-汇总层：逐样本记录与整体统计输出" class="headerlink" title="9.6.4 汇总层：逐样本记录与整体统计输出"></a>9.6.4 汇总层：逐样本记录与整体统计输出</h4><p>主入口 run_experiment.py 负责组织实验执行。其核心循环对每一张图像依次执行：读取 (img, gt_boxes)、调用两种模型的 predict 得到预测框、分别调用 error_profile 得到错误结构字典，并将结果追加到 summary 中。最终通过汇总函数对 300 张样本的错误结构累加，输出全局 TP&#x2F;FP&#x2F;FN&#x2F;dup。若启用延迟测试（可在工程中扩展），则调用 utils&#x2F;profiler.py 的 benchmark_latency 对同一输入重复推理若干次，统计 mean&#x2F;std&#x2F;p95，用于对比范式在工程可用性上的代价差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集封装：负责从 COCO 中按需抽样并返回 (img, gt_boxes)</span></span><br><span class="line"><span class="keyword">from</span> datasets.coco <span class="keyword">import</span> CocoDataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型封装：统一不同检测范式的推理接口</span></span><br><span class="line"><span class="keyword">from</span> wrappers.yolo_wrapper <span class="keyword">import</span> YOLOWrapper</span><br><span class="line"><span class="keyword">from</span> wrappers.detr_wrapper <span class="keyword">import</span> DetrWrapper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评测工具：计算 TP / FP / FN / dup 等结构性错误</span></span><br><span class="line"><span class="keyword">from</span> utils.boxes <span class="keyword">import</span> error_profile</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">summarize</span>(<span class="params">err_list</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将逐样本的错误统计结果进行累加汇总。</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">    - err_list : List[dict]，每个元素对应一张图像的错误统计</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">    - dict，包含整体 TP / FP / FN / dup</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    out = &#123;<span class="string">&quot;tp&quot;</span>: <span class="number">0</span>, <span class="string">&quot;fp&quot;</span>: <span class="number">0</span>, <span class="string">&quot;fn&quot;</span>: <span class="number">0</span>, <span class="string">&quot;dup&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> err_list:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> out:</span><br><span class="line">            out[k] += e[k]</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    实验主入口。</span></span><br><span class="line"><span class="string">    负责：</span></span><br><span class="line"><span class="string">    1. 解析命令行参数</span></span><br><span class="line"><span class="string">    2. 构建数据集与模型</span></span><br><span class="line"><span class="string">    3. 执行逐样本推理与错误统计</span></span><br><span class="line"><span class="string">    4. 汇总并输出实验结果</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># --------- 命令行参数 ---------</span></span><br><span class="line">    ap = argparse.ArgumentParser()</span><br><span class="line">    ap.add_argument(<span class="string">&#x27;--img_dir&#x27;</span>, required=<span class="literal">True</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;COCO 图像目录，如 val2017/&#x27;</span>)</span><br><span class="line">    ap.add_argument(<span class="string">&#x27;--ann_path&#x27;</span>, required=<span class="literal">True</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;COCO 标注文件，如 instances_val2017.json&#x27;</span>)</span><br><span class="line">    ap.add_argument(<span class="string">&#x27;--sample_n&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">300</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;随机抽取的评测样本数量&#x27;</span>)</span><br><span class="line">    ap.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cpu&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;推理设备：cpu / cuda / cuda:0&#x27;</span>)</span><br><span class="line">    args = ap.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 构建数据集 ---------</span></span><br><span class="line">    <span class="comment"># 从 COCO 标注中随机抽取 sample_n 张图像</span></span><br><span class="line">    ds = CocoDataset(</span><br><span class="line">        args.img_dir,</span><br><span class="line">        args.ann_path,</span><br><span class="line">        sample_n=args.sample_n</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 构建模型封装 ---------</span></span><br><span class="line">    <span class="comment"># 两种检测范式通过 wrapper 接入，统一 predict 接口</span></span><br><span class="line">    yolo = YOLOWrapper(device=args.device)</span><br><span class="line">    detr = DetrWrapper(device=args.device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 实验主循环 ---------</span></span><br><span class="line">    <span class="comment"># 用于记录逐样本的错误统计结果</span></span><br><span class="line">    summary = &#123;<span class="string">&#x27;yolo&#x27;</span>: [], <span class="string">&#x27;detr&#x27;</span>: []&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img, gt_boxes <span class="keyword">in</span> tqdm(ds):</span><br><span class="line">        <span class="comment"># YOLO 推理（一阶段密集预测）</span></span><br><span class="line">        yb, _ = yolo.predict(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Deformable DETR 推理（集合预测）</span></span><br><span class="line">        db, _ = detr.predict(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对同一张图像，分别统计两种模型的结构性错误</span></span><br><span class="line">        summary[<span class="string">&#x27;yolo&#x27;</span>].append(</span><br><span class="line">            error_profile(gt_boxes, yb)</span><br><span class="line">        )</span><br><span class="line">        summary[<span class="string">&#x27;detr&#x27;</span>].append(</span><br><span class="line">            error_profile(gt_boxes, db)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --------- 汇总并输出结果 ---------</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=== Error Summary ===&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;all samples:&quot;</span>, <span class="built_in">len</span>(summary[<span class="string">&quot;yolo&quot;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; YOLO:&quot;</span>, summarize(summary[<span class="string">&quot;yolo&quot;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; DETR:&quot;</span>, summarize(summary[<span class="string">&quot;detr&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>总体而言，<strong>YOLO_DeformableDETR_behavior_study</strong> 将“范式对照”落实为一条清晰的代码链路：COCO 统一输入 → wrapper 统一输出 → IoU 统一评测 → 汇总得到结构性错误分布与延迟统计。</p>
<h4 id="9-6-5-实验结果分析"><a href="#9-6-5-实验结果分析" class="headerlink" title="9.6.5 实验结果分析"></a>9.6.5 实验结果分析</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">=== Error Summary ===</span><br><span class="line">all samples: 300</span><br><span class="line"> YOLO: &#123;&#x27;tp&#x27;: 1177, &#x27;fp&#x27;: 320, &#x27;fn&#x27;: 1210, &#x27;dup&#x27;: 110&#125;</span><br><span class="line"> DETR: &#123;&#x27;tp&#x27;: 1151, &#x27;fp&#x27;: 110, &#x27;fn&#x27;: 1236, &#x27;dup&#x27;: 5&#125;</span><br></pre></td></tr></table></figure>
<p>在 300 张 COCO 验证样本的统一评测下，YOLO 与 Deformable DETR 在整体召回能力上表现接近，二者的 TP 与 FN 数量处于同一量级。然而，两种范式在错误分布结构上呈现出显著差异。YOLO 产生了更多误检（FP）与重复预测（dup），反映出密集预测与后处理机制在复杂场景中的固有冗余；相比之下，Deformable DETR 的误检数量显著更低，且几乎不存在重复预测，体现了集合预测与一对一匹配约束在抑制冗余方面的结构性优势。这表明，两种模型的差异并非体现在“能否检测到目标”，而在于“如何组织与约束预测结果”。</p>
<h3 id="9-7-实践层面的综合观察"><a href="#9-7-实践层面的综合观察" class="headerlink" title="9.7 实践层面的综合观察"></a>9.7 实践层面的综合观察</h3><p>综合上述实验结果可以得出一个清晰结论：YOLO 与 DETR 范式的差异不仅体现在性能指标上，更体现在<strong>错误分布形态与可控性</strong>上。</p>
<ul>
<li>YOLO 通过规则与阈值在推理阶段维持结果稳定，其不完美是“可调的”，更符合工程场景对可控性的需求；</li>
<li>Deformable DETR 则将更多决策前移至模型内部，以换取端到端一致性与更强的全局建模能力，其不完美往往是“结构性的”。</li>
</ul>
<p>这种差异并不存在绝对优劣，而是对应不同应用需求与设计目标。本章实验结果为前述理论分析提供了现实层面的佐证，也为后续关于检测范式演进趋势的讨论奠定了经验基础。</p>
<h2 id="10-总结：从任务模型到视觉系统能力"><a href="#10-总结：从任务模型到视觉系统能力" class="headerlink" title="10. 总结：从任务模型到视觉系统能力"></a>10. 总结：从任务模型到视觉系统能力</h2><p>在比较 YOLO 与 DETR 两种经典检测范式之后，一个更值得关注的问题逐渐浮现：<strong>目标检测这一任务本身，是否仍将以“检测模型”的形式长期存在？</strong> 近年来出现的一系列工作，尤其是以 YOLO-World 为代表的方法，正在从根本上重塑检测任务在视觉系统中的定位。</p>
<p>本章不再聚焦具体模型细节，而是从方法演进的角度，概括目标检测正在发生的几项结构性变化，并据此给出一个更长远的判断。</p>
<h3 id="10-1-从封闭类别到开放语义空间"><a href="#10-1-从封闭类别到开放语义空间" class="headerlink" title="10.1 从封闭类别到开放语义空间"></a>10.1 从封闭类别到开放语义空间</h3><p>传统目标检测几乎无一例外地建立在<strong>封闭类别假设</strong>之上：模型只能在训练时预定义的类别集合中进行预测。这一假设在工程实践中长期有效，却也天然限制了模型的泛化能力。</p>
<p>近年来，检测模型开始与大规模语言或跨模态表示对齐，使“类别预测”逐步转变为“语义匹配”。在这一框架下，检测不再局限于输出离散类别编号，而是与自然语言语义空间建立联系，从而具备一定的开放词汇能力。</p>
<p>这一变化并非简单的类别扩展，而是<strong>检测任务语义层级的整体提升</strong>：模型开始回答“图像中存在哪些语义实体”，而不仅仅是“是否属于某个已知类别”。</p>
<h3 id="10-2-检测模型正在融入基础视觉表示"><a href="#10-2-检测模型正在融入基础视觉表示" class="headerlink" title="10.2 检测模型正在融入基础视觉表示"></a>10.2 检测模型正在融入基础视觉表示</h3><p>随着大规模视觉预训练模型的发展，目标检测不再被视为孤立的下游任务，而是逐渐成为<strong>基础视觉表示之上的一种能力头</strong>。</p>
<p>在这一趋势下，检测模型的关注点从“如何高效地产生边界框”，转向“如何在共享表示空间中稳定地定位实例”。检测开始与分类、分割、检索等任务共享特征表示，从而降低整体系统复杂度。</p>
<p>这一变化使得检测模型的角色发生转变：它不再是一个独立终点，而是视觉系统中用于实例级理解的基础模块。  </p>
<h3 id="10-3-集合预测在系统级建模中的长期价值"><a href="#10-3-集合预测在系统级建模中的长期价值" class="headerlink" title="10.3 集合预测在系统级建模中的长期价值"></a>10.3 集合预测在系统级建模中的长期价值</h3><p>在这一背景下，DETR 所代表的集合预测范式开始展现出其长期价值。集合形式的输出天然适合作为其他模块的输入，无需依赖排序、阈值或启发式规则进行整理。</p>
<p>当检测结果需要进一步参与关系建模、时序推理或多任务联合优化时，端到端、结构一致的输出形式显得尤为重要。这也是 DETR 风格方法在多任务与大模型背景下持续受到关注的根本原因。</p>
<p>需要指出的是，这并不意味着密集预测范式将被淘汰，而是表明<strong>集合预测在系统层级上具有更强的可组合性</strong>。</p>
<h3 id="10-4-实时性约束下的再平衡"><a href="#10-4-实时性约束下的再平衡" class="headerlink" title="10.4 实时性约束下的再平衡"></a>10.4 实时性约束下的再平衡</h3><p>尽管检测任务正在向更高层次演化，实时性仍然是不可忽视的硬约束。YOLO-World 等工作尝试在引入开放语义能力的同时，尽量保持 YOLO 系列一贯的效率优势。</p>
<p>这一现象表明，未来的发展方向并非在 YOLO 与 DETR 之间做出非此即彼的选择，而是在<strong>统一建模能力与工程可行性之间不断寻找新的平衡点</strong>。部分 DETR 的思想正在被引入高效模型中，而部分 YOLO 的工程经验也在影响更复杂系统的设计。</p>
<h3 id="10-5-结语：检测作为能力，而非终点"><a href="#10-5-结语：检测作为能力，而非终点" class="headerlink" title="10.5 结语：检测作为能力，而非终点"></a>10.5 结语：检测作为能力，而非终点</h3><p>综合来看，目标检测正在逐步失去其作为独立终点任务的地位，而演化为视觉系统中的一种基础能力。未来的检测模型，可能不再以传统意义上的“边界框列表”为主要输出形式，而是以更抽象、更结构化的方式参与整体视觉理解过程。</p>
<p>在这一演化过程中，被淘汰的并非某一种模型，而是一种将大量工程规则视为理所当然、并在事后用启发式方法弥补建模缺陷的思维方式。YOLO 与 DETR 所代表的两种范式，将在相当长一段时间内共存，并在不同系统层级上发挥各自优势。</p>
<p>目标检测的未来，或许不再“长得像检测”，但其核心使命将更加清晰：<strong>为视觉系统提供稳定、可扩展且语义一致的实例级表示</strong>。</p>
<h2 id="11-备注"><a href="#11-备注" class="headerlink" title="11. 备注"></a>11. 备注</h2><ul>
<li>coco数据集Images <a target="_blank" rel="noopener" href="http://images.cocodataset.org/zips/val2017.zip">http://images.cocodataset.org/zips/val2017.zip</a></li>
<li>coco数据集Annotations: <a target="_blank" rel="noopener" href="http://images.cocodataset.org/annotations/annotations_trainval2017.zip">http://images.cocodataset.org/annotations/annotations_trainval2017.zip</a></li>
<li>YOLO_DeformableDETR_behavior_study完整代码： <a target="_blank" rel="noopener" href="https://github.com/keychankc/dl_code_for_blog/tree/main/048-YOLO_DeformableDETR_behavior_study">https://github.com/keychankc/dl_code_for_blog/tree/main/048-YOLO_DeformableDETR_behavior_study</a></li>
</ul>
<script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';	mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); </script>
    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>KeyChan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/" title="从 YOLO 到 DETR：目标检测范式的演化与分工">https://www.keychan.xyz/2025/12/23/048-from-yolo-to-detr/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://x.com/keychankc">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"># 目标检测</a>
              <a href="/tags/YOLO/" rel="tag"># YOLO</a>
              <a href="/tags/detr/" rel="tag"># detr</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/12/16/047-flight-control-software-architecture-communication-system/" rel="prev" title="「无人机⑤」从数据到决策：飞控软件架构与通信体系">
                  <i class="fa fa-angle-left"></i> 「无人机⑤」从数据到决策：飞控软件架构与通信体系
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/12/30/049-ground-station-architecture-and-visualization/" rel="next" title="「无人机⑥」地面站体系结构与可视化">
                  「无人机⑥」地面站体系结构与可视化 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KeyChan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">533k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/keychankc" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="/js/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/ribbon.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://comment.mengyajia.com","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":false,"pageview":false,"placeholder":"欢迎评论~","emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq"],"requiredMeta":["nick","mail"],"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/2025/12/23/048-from-yolo-to-detr/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
