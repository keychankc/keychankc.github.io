<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo-512x512.png" color="#222">
  <meta name="google-site-verification" content="jZ7dJJlouQrswxytAryX3LanLNrTthfFdMUkDJzRqIU">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"keychankc.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="1.U²-Net介绍与应用在 图像分割与U-Net系列模型解析 和 基于U-Net++的细胞分割代码实现 中提到了U-Net系列网络模型，而 U²-Net 虽然是一个U-Net的变体版本，原本用于显著性检测任务，但由于其优异的前景提取能力，逐渐被广泛用于抠图、图像编辑、人像分割等任务中。 1.U²-Net 概述U²-Net 属于“显著性检测”任务中的网络结构，其核心目标是从图像中识别出前景区域，即">
<meta property="og:type" content="article">
<meta property="og:title" content="U²-Net显著性目标检测">
<meta property="og:url" content="https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/index.html">
<meta property="og:site_name" content="KeyChan&#39;s blog">
<meta property="og:description" content="1.U²-Net介绍与应用在 图像分割与U-Net系列模型解析 和 基于U-Net++的细胞分割代码实现 中提到了U-Net系列网络模型，而 U²-Net 虽然是一个U-Net的变体版本，原本用于显著性检测任务，但由于其优异的前景提取能力，逐渐被广泛用于抠图、图像编辑、人像分割等任务中。 1.U²-Net 概述U²-Net 属于“显著性检测”任务中的网络结构，其核心目标是从图像中识别出前景区域，即">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103139.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103241.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250530150316.png">
<meta property="article:published_time" content="2025-06-04T09:01:12.000Z">
<meta property="article:modified_time" content="2025-09-21T12:04:48.539Z">
<meta property="article:author" content="KeyChan">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="目标分割">
<meta property="article:tag" content="U2Net">
<meta property="article:tag" content="显著性检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103139.png">


<link rel="canonical" href="https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/","path":"2025/06/04/018-u2net-saliency-detection/","title":"U²-Net显著性目标检测"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>U²-Net显著性目标检测 | KeyChan's blog</title>
  







<link rel="dns-prefetch" href="https://comment.mengyajia.com">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="KeyChan's blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KeyChan's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-随想"><a href="/think/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-U%C2%B2-Net%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8"><span class="nav-text">1.U²-Net介绍与应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-U%C2%B2-Net-%E6%A6%82%E8%BF%B0"><span class="nav-text">1.U²-Net 概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%BA%94%E7%94%A8"><span class="nav-text">2.应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-U%C2%B2-Net%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="nav-text">2. U²-Net网络架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-RSU-%E6%A8%A1%E5%9D%97"><span class="nav-text">1.RSU 模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6%EF%BC%9AREBNCONV"><span class="nav-text">1.基础组件：REBNCONV</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-RSU-%E6%A8%A1%E5%9D%97%E7%BB%93%E6%9E%84"><span class="nav-text">2.RSU 模块结构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E7%BC%96%E7%A0%81%E5%99%A8%E8%B7%AF%E5%BE%84%EF%BC%88Encoder-Path%EF%BC%89"><span class="nav-text">1.编码器路径（Encoder Path）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E8%A7%A3%E7%A0%81%E5%99%A8%E8%B7%AF%E5%BE%84%EF%BC%88Decoder-Path%EF%BC%89"><span class="nav-text">2 解码器路径（Decoder Path）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5"><span class="nav-text">3.残差连接</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%BB%A5-RSU7-%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="nav-text">4.具体实现（以 RSU7 为例）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-RSU-%E6%A8%A1%E5%9D%97%E7%9A%84%E5%8F%98%E4%BD%93"><span class="nav-text">5. RSU 模块的变体</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-%E4%BD%9C%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8A%BF"><span class="nav-text">6. 作用与优势</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%B7%B1%E5%BA%A6%E7%9B%91%E7%9D%A3"><span class="nav-text">2.深度监督</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%A4%9A%E8%BE%93%E5%87%BA%E8%AE%BE%E8%AE%A1"><span class="nav-text">1. 多输出设计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="nav-text">2. 损失函数定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%BA%A6%E7%9B%91%E7%9D%A3"><span class="nav-text">3. 训练流程中的深度监督</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E4%BD%9C%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8A%BF"><span class="nav-text">4. 作用与优势</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88"><span class="nav-text">3.多尺度融合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">1. 多尺度特征提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E8%A7%A3%E7%A0%81%E5%99%A8%E8%B7%AF%E5%BE%84%E4%B8%8E%E8%B7%B3%E8%B7%83%E8%BF%9E%E6%8E%A5"><span class="nav-text">2. 解码器路径与跳跃连接</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%A4%9A%E8%BE%93%E5%87%BA%E4%B8%8E%E6%9C%80%E7%BB%88%E8%9E%8D%E5%90%88"><span class="nav-text">3. 多输出与最终融合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E4%BD%9C%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8A%BF-1"><span class="nav-text">4. 作用与优势</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E7%BC%96%E7%A0%81%E5%99%A8"><span class="nav-text">3.编码器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%BC%96%E7%A0%81%E5%99%A8%E7%BB%93%E6%9E%84"><span class="nav-text">1. 编码器结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="nav-text">2. 具体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96%E7%BC%96%E7%A0%81%E5%99%A8%E6%A8%A1%E5%9D%97"><span class="nav-text">1.初始化编码器模块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B"><span class="nav-text">2.前向传播过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E4%BD%9C%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8A%BF"><span class="nav-text">3.作用与优势</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="nav-text">4.解码器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%A7%A3%E7%A0%81%E5%99%A8%E7%BB%93%E6%9E%84"><span class="nav-text">1. 解码器结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0-1"><span class="nav-text">2. 具体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96%E8%A7%A3%E7%A0%81%E5%99%A8%E6%A8%A1%E5%9D%97"><span class="nav-text">1.初始化解码器模块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B-1"><span class="nav-text">2.前向传播过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%A4%9A%E8%BE%93%E5%87%BA%E4%B8%8E%E6%9C%80%E7%BB%88%E8%9E%8D%E5%90%88-1"><span class="nav-text">3.多输出与最终融合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E4%BD%9C%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8A%BF-2"><span class="nav-text">4.作用与优势</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E6%80%BB%E7%BB%93"><span class="nav-text">5.总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9%E2%80%8B"><span class="nav-text">1.核心特点​</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%8B2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E2%80%8B"><span class="nav-text">​2.网络架构​</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%8B3-%E5%85%B3%E9%94%AE%E5%BA%94%E7%94%A8%E2%80%8B"><span class="nav-text">​3.关键应用​</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%8B4-%E4%BC%98%E5%8A%BF%E2%80%8B"><span class="nav-text">​4.优势​</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E5%A4%87%E6%B3%A8"><span class="nav-text">6.备注</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KeyChan"
      src="/images/key_avatar.png">
  <p class="site-author-name" itemprop="name">KeyChan</p>
  <div class="site-description" itemprop="description">全干工程师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/keychankc" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kckeychan@gmail.com" title="E-Mail → mailto:kckeychan@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/keychankc" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/key_avatar.png">
      <meta itemprop="name" content="KeyChan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeyChan's blog">
      <meta itemprop="description" content="全干工程师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="U²-Net显著性目标检测 | KeyChan's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          U²-Net显著性目标检测
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-06-04 17:01:12" itemprop="dateCreated datePublished" datetime="2025-06-04T17:01:12+08:00">2025-06-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-21 20:04:48" itemprop="dateModified" datetime="2025-09-21T20:04:48+08:00">2025-09-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/06/04/018-u2net-saliency-detection/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/06/04/018-u2net-saliency-detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="1-U²-Net介绍与应用"><a href="#1-U²-Net介绍与应用" class="headerlink" title="1.U²-Net介绍与应用"></a>1.U²-Net介绍与应用</h2><p>在 <a href="https://keychankc.github.io/2025/05/19/016-image-segmentation-u-net/">图像分割与U-Net系列模型解析</a> 和 <a href="https://keychankc.github.io/2025/05/27/017-unet-cell-segmentation/">基于U-Net++的细胞分割代码实现</a> 中提到了U-Net系列网络模型，而 <a target="_blank" rel="noopener" href="https://github.com/xuebinqin/U-2-Net">U²-Net</a> 虽然是一个U-Net的变体版本，原本用于显著性检测任务，但由于其优异的前景提取能力，逐渐被广泛用于抠图、图像编辑、人像分割等任务中。</p>
<h3 id="1-U²-Net-概述"><a href="#1-U²-Net-概述" class="headerlink" title="1.U²-Net 概述"></a>1.U²-Net 概述</h3><p>U²-Net 属于“显著性检测”任务中的网络结构，其核心目标是从图像中识别出前景区域，即显著目标（Salient Object Detection, SOD）。从任务定义来看，它本质上和语义分割非常接近，将图像划分为前景和背景，只是语义标签通常只有两类。</p>
<span id="more"></span>
<blockquote>
<p>显著性检测（Salient Object Detection）指的是从一幅图像中识别出“最引人注意的”区域，通常即为前景区域。模型的输入是一张图像，输出是一张二值或灰度图，其中白色表示前景（显著区域），黑色表示背景。<br>例如：一只狗在草地上跑动，狗即为显著对象；一群人站在海滩上，人是前景，海滩是背景。</p>
</blockquote>
<h3 id="2-应用"><a href="#2-应用" class="headerlink" title="2.应用"></a>2.应用</h3><p>如下图，在肖像素描任务生成中，输入是一张彩色人像图像，输出则像是一幅素描画，纹理和细节都能够得到很好的保留，效果相比很多图像生成或风格转换方法更为自然一些，甚至比一些 GAN 模型生成的还要好，特别是人脸细节部分，U²-Net 在轮廓、皱纹、发丝等区域的提取的也非常准确。</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103139.png"></p>
<p>除此之外，U²-Net 在抠图（前景分离）任务中也有不错的效果，无论背景复杂与否，它都能较好地将人物主体从图像中分离出来，这在直播、虚拟背景替换、美颜等应用场景中有着非常广泛的应用价值。例如在某些直播中，主播本来需要一张绿幕才能实现实时背景替换，而利用U²-Net这一类模型就可以做到“无绿幕”抠图，显著提升了便捷性和效果稳定性。</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250604103241.png"></p>
<p>U²-Net 的模型结构不仅能够提取精确的前景，还能为后续处理任务提供干净的语义掩码（mask），这为实时视频处理、特效添加、风格迁移等任务打下了基础，要具备这些能力并非仅仅依赖于“更深的U结构”，而是得益于其独特的设计思想。</p>
<h2 id="2-U²-Net网络架构"><a href="#2-U²-Net网络架构" class="headerlink" title="2. U²-Net网络架构"></a>2. U²-Net网络架构</h2><p>U²-Net 的整体结构采用了 <strong>Encoder-Decoder（编码器-解码器）</strong> 框架，但不同于传统 U-Net，它在每个阶段都使用了一个更复杂的模块——<strong>RSU（Residual U-block）</strong>，也就是<strong>双层嵌套U型结构（U-in-U）</strong>。<br>整个网络由：</p>
<ul>
<li><strong>6 个编码模块（En_1 到 En_6）</strong></li>
<li><strong>5 个解码模块（De_1 到 De_5）</strong></li>
<li><strong>多个深监督输出（Sup1 ~ Sup6）</strong></li>
<li><strong>一个最终融合输出（S_fuse）</strong></li>
</ul>
<p>最终组成一个对称且层层嵌套的 U² 结构。如下图所示</p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250530150316.png"></p>
<h3 id="1-RSU-模块"><a href="#1-RSU-模块" class="headerlink" title="1.RSU 模块"></a>1.RSU 模块</h3><p>RSU 模块是 U²-Net 的核心模块，全称为 <em>Residual U-shaped block</em>，如上图每个 En_x 和 De_x 模块其实并不是单纯的卷积块，而是一个 RSU 模块，其内部包含一个编码-解码结构（小型 U-Net），然后使用多个空洞卷积扩展感受野，同时保持输出尺寸不变，最终将输入与输出进行残差连接，强化特征传递与复用。</p>
<p>这样做的好处是能有效平衡模型深度与参数量，在保证性能的同时提高了效率，从而增强局部特征提取与上下文信息聚合的能力。</p>
<h4 id="1-基础组件：REBNCONV"><a href="#1-基础组件：REBNCONV" class="headerlink" title="1.基础组件：REBNCONV"></a>1.基础组件：REBNCONV</h4><p>RSU 模块的基础单元是 REBNCONV，它由以下部分组成：</p>
<ol>
<li>卷积层：3×3 卷积，支持空洞卷积（dilation）</li>
<li>批归一化：<code>BatchNorm2d</code>，用于稳定训练</li>
<li>ReLU激活：<code>ReLU(inplace=True)</code>，用于非线性变换</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">REBNCONV</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_ch=<span class="number">3</span>,out_ch=<span class="number">3</span>,dirate=<span class="number">1</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(REBNCONV,<span class="variable language_">self</span>).__init__()  </span><br><span class="line">  </span><br><span class="line">        <span class="variable language_">self</span>.conv_s1 = nn.Conv2d(in_ch,out_ch,<span class="number">3</span>,padding=<span class="number">1</span>*dirate,dilation=<span class="number">1</span>*dirate)  </span><br><span class="line">        <span class="variable language_">self</span>.bn_s1 = nn.BatchNorm2d(out_ch)  </span><br><span class="line">        <span class="variable language_">self</span>.relu_s1 = nn.ReLU(inplace=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):  </span><br><span class="line">        hx = x  </span><br><span class="line">        xout = <span class="variable language_">self</span>.relu_s1(<span class="variable language_">self</span>.bn_s1(<span class="variable language_">self</span>.conv_s1(hx)))  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> xout</span><br></pre></td></tr></table></figure>
<h4 id="2-RSU-模块结构"><a href="#2-RSU-模块结构" class="headerlink" title="2.RSU 模块结构"></a>2.RSU 模块结构</h4><p>以 RSU7 为例，RSU 模块包含以下部分：</p>
<h5 id="1-编码器路径（Encoder-Path）"><a href="#1-编码器路径（Encoder-Path）" class="headerlink" title="1.编码器路径（Encoder Path）"></a>1.编码器路径（Encoder Path）</h5><p>输入首先通过一个 REBNCONV 层（rebnconvin），然后依次通过多个 REBNCONV 层和最大池化层（MaxPool2d），逐步降低特征图的空间分辨率，同时增加通道数，最后通过一个空洞卷积（dirate&#x3D;2）进一步提取特征。</p>
<h5 id="2-解码器路径（Decoder-Path）"><a href="#2-解码器路径（Decoder-Path）" class="headerlink" title="2 解码器路径（Decoder Path）"></a>2 解码器路径（Decoder Path）</h5><p>从最深层开始，通过上采样 <code>_upsample_like</code> 和 REBNCONV 层逐步恢复空间分辨率，每一步都会将当前特征与编码器对应层的特征拼接（torch.cat），形成跳跃连接（skip connection）。</p>
<h5 id="3-残差连接"><a href="#3-残差连接" class="headerlink" title="3.残差连接"></a>3.残差连接</h5><p>最终输出是解码器路径的最后一层与输入特征（hxin）的残差和（hx1d + hxin），这有助于梯度流动和特征保留。</p>
<h5 id="4-具体实现（以-RSU7-为例）"><a href="#4-具体实现（以-RSU7-为例）" class="headerlink" title="4.具体实现（以 RSU7 为例）"></a>4.具体实现（以 RSU7 为例）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RSU7</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_ch=<span class="number">3</span>, mid_ch=<span class="number">12</span>, out_ch=<span class="number">3</span></span>):  </span><br><span class="line">        <span class="built_in">super</span>(RSU7,<span class="variable language_">self</span>).__init__()  </span><br><span class="line">        <span class="comment"># 输入层</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconvin = REBNCONV(in_ch,out_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="comment"># 编码器路径</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool1 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool2 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool3 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool4 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.pool5 = nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=<span class="number">2</span>)  </span><br><span class="line">        <span class="comment"># 解码器路径</span></span><br><span class="line">        <span class="variable language_">self</span>.rebnconv6d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv5d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv4d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv3d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv2d = REBNCONV(mid_ch*<span class="number">2</span>,mid_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">        <span class="variable language_">self</span>.rebnconv1d = REBNCONV(mid_ch*<span class="number">2</span>,out_ch,dirate=<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):  </span><br><span class="line">        hx = x  </span><br><span class="line">        hxin = <span class="variable language_">self</span>.rebnconvin(hx) </span><br><span class="line">        <span class="comment"># 编码器路径 </span></span><br><span class="line">        hx1 = <span class="variable language_">self</span>.rebnconv1(hxin)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool1(hx1)  </span><br><span class="line">        hx2 = <span class="variable language_">self</span>.rebnconv2(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool2(hx2)  </span><br><span class="line">        hx3 = <span class="variable language_">self</span>.rebnconv3(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool3(hx3)  </span><br><span class="line">        hx4 = <span class="variable language_">self</span>.rebnconv4(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool4(hx4)  </span><br><span class="line">        hx5 = <span class="variable language_">self</span>.rebnconv5(hx)  </span><br><span class="line">        hx = <span class="variable language_">self</span>.pool5(hx5)  </span><br><span class="line">        hx6 = <span class="variable language_">self</span>.rebnconv6(hx)  </span><br><span class="line">        hx7 = <span class="variable language_">self</span>.rebnconv7(hx6)  </span><br><span class="line">        <span class="comment"># 解码器路径</span></span><br><span class="line">        hx6d =  <span class="variable language_">self</span>.rebnconv6d(torch.cat((hx7,hx6),<span class="number">1</span>))  </span><br><span class="line">        hx6dup = _upsample_like(hx6d,hx5)  </span><br><span class="line">        hx5d =  <span class="variable language_">self</span>.rebnconv5d(torch.cat((hx6dup,hx5),<span class="number">1</span>))  </span><br><span class="line">        hx5dup = _upsample_like(hx5d,hx4)  </span><br><span class="line">        hx4d = <span class="variable language_">self</span>.rebnconv4d(torch.cat((hx5dup,hx4),<span class="number">1</span>))  </span><br><span class="line">        hx4dup = _upsample_like(hx4d,hx3)  </span><br><span class="line">        hx3d = <span class="variable language_">self</span>.rebnconv3d(torch.cat((hx4dup,hx3),<span class="number">1</span>))  </span><br><span class="line">        hx3dup = _upsample_like(hx3d,hx2)  </span><br><span class="line">        hx2d = <span class="variable language_">self</span>.rebnconv2d(torch.cat((hx3dup,hx2),<span class="number">1</span>))  </span><br><span class="line">        hx2dup = _upsample_like(hx2d,hx1)  </span><br><span class="line">        hx1d = <span class="variable language_">self</span>.rebnconv1d(torch.cat((hx2dup,hx1),<span class="number">1</span>))  </span><br><span class="line">        <span class="comment"># 残差连接</span></span><br><span class="line">        <span class="keyword">return</span> hx1d + hxin</span><br></pre></td></tr></table></figure>
<h5 id="5-RSU-模块的变体"><a href="#5-RSU-模块的变体" class="headerlink" title="5. RSU 模块的变体"></a>5. RSU 模块的变体</h5><p>U²-Net 中定义了多种 RSU 模块变体（如 RSU7、RSU6、RSU5、RSU4、RSU4F），它们的区别主要在于：</p>
<ul>
<li>深度：编码器路径的层数（如 RSU7 有7层，RSU6 有6层）</li>
<li>通道数：中间层（mid_ch）和输出层（out_ch）的通道数</li>
<li>空洞卷积：最深层是否使用空洞卷积（dirate&#x3D;2）</li>
</ul>
<h5 id="6-作用与优势"><a href="#6-作用与优势" class="headerlink" title="6. 作用与优势"></a>6. 作用与优势</h5><ul>
<li>多尺度特征提取：通过编码器-解码器结构和跳跃连接，RSU 模块能够同时捕获局部和全局特征</li>
<li>残差学习：残差连接有助于梯度流动，避免梯度消失问题</li>
<li>灵活性：不同深度的 RSU 模块可以适应不同复杂度的任务</li>
</ul>
<h3 id="2-深度监督"><a href="#2-深度监督" class="headerlink" title="2.深度监督"></a>2.深度监督</h3><p>深度监督（Deep Supervision）指的是在网络训练时，<strong>不仅对最终输出计算损失</strong>，而是<strong>在中间多个层也加入监督信号</strong>，引导模型在多个尺度和层级上学习有意义的特征。</p>
<p>U²-Net 的深度监督（Deep Supervision）机制通过以下步骤实现：</p>
<h4 id="1-多输出设计"><a href="#1-多输出设计" class="headerlink" title="1. 多输出设计"></a>1. 多输出设计</h4><p>U²-Net 在解码器的每个阶段（stage）都输出一个显著性预测图（side output），这些输出分别对应不同尺度的特征图。模型的前向传播返回了7个输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># d0 是最终输出（主输出）</span></span><br><span class="line"><span class="comment"># d1 到 d6 是中间层的输出（side outputs）</span></span><br><span class="line">d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)</span><br></pre></td></tr></table></figure>
<h4 id="2-损失函数定义"><a href="#2-损失函数定义" class="headerlink" title="2. 损失函数定义"></a>2. 损失函数定义</h4><p>用于计算每个输出的二值交叉熵损失（BCE Loss）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">muti_bce_loss_fusion</span>(<span class="params">d0, d1, d2, d3, d4, d5, d6, labels_v</span>):  </span><br><span class="line">    loss0 = bce_loss(d0,labels_v)  </span><br><span class="line">    loss1 = bce_loss(d1,labels_v)  </span><br><span class="line">    loss2 = bce_loss(d2,labels_v)  </span><br><span class="line">    loss3 = bce_loss(d3,labels_v)  </span><br><span class="line">    loss4 = bce_loss(d4,labels_v)  </span><br><span class="line">    loss5 = bce_loss(d5,labels_v)  </span><br><span class="line">    loss6 = bce_loss(d6,labels_v)  </span><br><span class="line">  </span><br><span class="line">    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6   </span><br><span class="line">    <span class="keyword">return</span> loss0, loss</span><br></pre></td></tr></table></figure>

<p>每个输出（d0 到 d6）都与 ground truth（labels_v）计算 BCE 损失，最终的总损失是所有损失的简单相加（权重相等）。</p>
<h4 id="3-训练流程中的深度监督"><a href="#3-训练流程中的深度监督" class="headerlink" title="3. 训练流程中的深度监督"></a>3. 训练流程中的深度监督</h4><p>在训练循环中，模型的前向传播返回多个输出，然后通过 <code>muti_bce_loss_fusion</code> 计算损失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)</span><br><span class="line"><span class="comment"># loss2 是主输出（d0）的损失，用于监控训练效果</span></span><br><span class="line"><span class="comment"># loss 是所有输出的总损失，用于反向传播和参数更新</span></span><br><span class="line">loss2, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<h4 id="4-作用与优势"><a href="#4-作用与优势" class="headerlink" title="4. 作用与优势"></a>4. 作用与优势</h4><ul>
<li>梯度流动：中间层的输出直接参与损失计算，有助于梯度更好地传递到网络深层，缓解梯度消失问题</li>
<li>多尺度监督：不同尺度的输出能够捕获不同层次的特征，提升模型的泛化能力</li>
<li>加速收敛：多输出的监督信号能够加速模型收敛</li>
</ul>
<h3 id="3-多尺度融合"><a href="#3-多尺度融合" class="headerlink" title="3.多尺度融合"></a>3.多尺度融合</h3><p>显著性目标可能大小不一、形态复杂。单一尺度难以同时兼顾，所以需要关注边缘、纹理、细节的<strong>低层特征</strong>和 关注语义、上下文、全局结构的<strong>高层特征</strong>。</p>
<p>U²-Net 的多尺度融合（Multi-scale Fusion）主要通过以下步骤实现：</p>
<h4 id="1-多尺度特征提取"><a href="#1-多尺度特征提取" class="headerlink" title="1. 多尺度特征提取"></a>1. 多尺度特征提取</h4><p>U²-Net 的编码器路径（Encoder Path）通过多个 RSU 模块（如 RSU7、RSU6、RSU5 等）逐步提取不同尺度的特征。每个 RSU 模块的输出特征图尺寸逐渐减小，但通道数逐渐增加，从而捕获不同层次的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage1 = RSU7(in_ch, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 输入 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage2 = RSU6(<span class="number">64</span>, <span class="number">32</span>, <span class="number">128</span>) <span class="comment"># 64通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage3 = RSU5(<span class="number">128</span>, <span class="number">64</span>, <span class="number">256</span>) <span class="comment"># 128通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage4 = RSU4(<span class="number">256</span>, <span class="number">128</span>, <span class="number">512</span>) <span class="comment"># 256通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage5 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage6 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br></pre></td></tr></table></figure>
<h4 id="2-解码器路径与跳跃连接"><a href="#2-解码器路径与跳跃连接" class="headerlink" title="2. 解码器路径与跳跃连接"></a>2. 解码器路径与跳跃连接</h4><p>解码器路径（Decoder Path）通过上采样<code>_upsample_like</code>和跳跃连接（skip connection）逐步恢复空间分辨率，同时融合不同尺度的特征：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解码器路径</span></span><br><span class="line">hx5d = <span class="variable language_">self</span>.stage5d(torch.cat((hx6up, hx5), <span class="number">1</span>)) <span class="comment"># 融合 hx6up 和 hx5</span></span><br><span class="line">hx5dup = _upsample_like(hx5d, hx4)</span><br><span class="line">hx4d = <span class="variable language_">self</span>.stage4d(torch.cat((hx5dup, hx4), <span class="number">1</span>)) <span class="comment"># 融合 hx5dup 和 hx4</span></span><br><span class="line">hx4dup = _upsample_like(hx4d, hx3)</span><br><span class="line">hx3d = <span class="variable language_">self</span>.stage3d(torch.cat((hx4dup, hx3), <span class="number">1</span>)) <span class="comment"># 融合 hx4dup 和 hx3</span></span><br><span class="line">hx3dup = _upsample_like(hx3d, hx2)</span><br><span class="line">hx2d = <span class="variable language_">self</span>.stage2d(torch.cat((hx3dup, hx2), <span class="number">1</span>)) <span class="comment"># 融合 hx3dup 和 hx2</span></span><br><span class="line">hx2dup = _upsample_like(hx2d, hx1)</span><br><span class="line">hx1d = <span class="variable language_">self</span>.stage1d(torch.cat((hx2dup, hx1), <span class="number">1</span>)) <span class="comment"># 融合 hx2dup 和 hx1</span></span><br></pre></td></tr></table></figure>
<p><code>torch.cat((hx6up, hx5), 1)</code> 将上采样后的特征与编码器对应层的特征拼接，形成跳跃连接<br>每个解码器阶段（stage5d、stage4d 等）进一步处理融合后的特征。</p>
<h4 id="3-多输出与最终融合"><a href="#3-多输出与最终融合" class="headerlink" title="3. 多输出与最终融合"></a>3. 多输出与最终融合</h4><p>U²-Net 在解码器的每个阶段都输出一个显著性预测图（side output），这些输出通过上采样调整到相同分辨率，然后拼接并融合为最终输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多输出</span></span><br><span class="line">d1 = <span class="variable language_">self</span>.side1(hx1d)</span><br><span class="line">d2 = <span class="variable language_">self</span>.side2(hx2d)</span><br><span class="line">d2 = _upsample_like(d2, d1)</span><br><span class="line">d3 = <span class="variable language_">self</span>.side3(hx3d)</span><br><span class="line">d3 = _upsample_like(d3, d1)</span><br><span class="line">d4 = <span class="variable language_">self</span>.side4(hx4d)</span><br><span class="line">d4 = _upsample_like(d4, d1)</span><br><span class="line">d5 = <span class="variable language_">self</span>.side5(hx5d)</span><br><span class="line">d5 = _upsample_like(d5, d1)</span><br><span class="line">d6 = <span class="variable language_">self</span>.side6(hx6)</span><br><span class="line">d6 = _upsample_like(d6, d1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终融合</span></span><br><span class="line">d0 = <span class="variable language_">self</span>.outconv(torch.cat((d1, d2, d3, d4, d5, d6), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>self.side1 到 self.side6 是 1×1 卷积层，用于将每个阶段的特征转换为显著性预测图。<br>self.outconv 是一个 1×1 卷积层，用于将拼接后的多尺度预测图融合为最终输。</p>
<h4 id="4-作用与优势-1"><a href="#4-作用与优势-1" class="headerlink" title="4. 作用与优势"></a>4. 作用与优势</h4><ul>
<li>多尺度特征捕获：通过不同深度的 RSU 模块，模型能够同时捕获局部细节和全局上下文信息</li>
<li>特征复用：跳跃连接允许低层特征（如边缘、纹理）与高层特征（如语义信息）直接融合，提升分割精度</li>
<li>灵活性：多输出设计不仅用于深度监督，还能在推理时提供多尺度的预测结果</li>
</ul>
<h2 id="3-编码器"><a href="#3-编码器" class="headerlink" title="3.编码器"></a>3.编码器</h2><p><strong>Encoder 编码器（En_1 到 En_6）</strong>：逐步提取特征，降低分辨率，增加语义信息。</p>
<h3 id="1-编码器结构"><a href="#1-编码器结构" class="headerlink" title="1. 编码器结构"></a>1. 编码器结构</h3><p>U²-Net 的编码器由多个 RSU（Residual U-block）模块组成，每个模块负责提取不同尺度的特征。编码器的设计遵循以下原则：</p>
<ul>
<li>逐步降采样：通过最大池化（MaxPool2d）逐步降低特征图的空间分辨率</li>
<li>逐步增加通道数：每个 RSU 模块的输出通道数逐渐增加，以捕获更丰富的特征</li>
</ul>
<h3 id="2-具体实现"><a href="#2-具体实现" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h3><h4 id="1-初始化编码器模块"><a href="#1-初始化编码器模块" class="headerlink" title="1.初始化编码器模块"></a>1.初始化编码器模块</h4><p>在 U2NET 类的 <strong>init</strong> 方法中，定义了编码器的各个阶段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage1 = RSU7(in_ch, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 输入 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool12 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage2 = RSU6(<span class="number">64</span>, <span class="number">32</span>, <span class="number">128</span>) <span class="comment"># 64通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool23 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage3 = RSU5(<span class="number">128</span>, <span class="number">64</span>, <span class="number">256</span>) <span class="comment"># 128通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool34 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage4 = RSU4(<span class="number">256</span>, <span class="number">128</span>, <span class="number">512</span>) <span class="comment"># 256通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool45 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage5 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.pool56 = nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.stage6 = RSU4F(<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 512通道 -&gt; 512通道</span></span><br></pre></td></tr></table></figure>
<p>RSU7、RSU6、RSU5、RSU4、RSU4F 是不同深度的 RSU 模块，MaxPool2d 用于降采样，stride&#x3D;2 表示每次将特征图尺寸减半。</p>
<h4 id="2-前向传播过程"><a href="#2-前向传播过程" class="headerlink" title="2.前向传播过程"></a>2.前向传播过程</h4><p>在 forward 方法中，编码器的前向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hx = x</span><br><span class="line"></span><br><span class="line"><span class="comment"># stage 1</span></span><br><span class="line">hx1 = <span class="variable language_">self</span>.stage1(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool12(hx1)</span><br><span class="line"><span class="comment"># stage 2</span></span><br><span class="line">hx2 = <span class="variable language_">self</span>.stage2(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool23(hx2)</span><br><span class="line"><span class="comment"># stage 3</span></span><br><span class="line">hx3 = <span class="variable language_">self</span>.stage3(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool34(hx3)</span><br><span class="line"><span class="comment"># stage 4</span></span><br><span class="line">hx4 = <span class="variable language_">self</span>.stage4(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool45(hx4)</span><br><span class="line"><span class="comment"># stage 5</span></span><br><span class="line">hx5 = <span class="variable language_">self</span>.stage5(hx)</span><br><span class="line">hx = <span class="variable language_">self</span>.pool56(hx5)</span><br><span class="line"><span class="comment"># stage 6</span></span><br><span class="line">hx6 = <span class="variable language_">self</span>.stage6(hx)</span><br></pre></td></tr></table></figure>
<p>输入 x 依次通过 stage1 到 stage6 的 RSU 模块，每个阶段后通过 MaxPool2d 降采样，逐步降低特征图的空间分辨率。</p>
<h4 id="3-作用与优势"><a href="#3-作用与优势" class="headerlink" title="3.作用与优势"></a>3.作用与优势</h4><ul>
<li>多尺度特征提取：编码器通过不同深度的 RSU 模块捕获不同尺度的特征</li>
<li>逐步降采样：通过池化层逐步降低空间分辨率，增加感受野</li>
<li>通道数增加：逐步增加通道数，捕获更丰富的特征信息</li>
</ul>
<h2 id="4-解码器"><a href="#4-解码器" class="headerlink" title="4.解码器"></a>4.解码器</h2><p><strong>Decoder 解码器（De_1 到 De_5）</strong>：逐步恢复分辨率，并融合低层细节与高层语义。</p>
<h3 id="1-解码器结构"><a href="#1-解码器结构" class="headerlink" title="1. 解码器结构"></a>1. 解码器结构</h3><p>解码器的设计遵循以下原则：</p>
<ul>
<li>逐步上采样：通过上采样<code>_upsample_like</code>逐步恢复特征图的空间分辨率</li>
<li>跳跃连接：将编码器对应层的特征与上采样后的特征拼接（torch.cat），形成跳跃连接</li>
<li>多输出：每个解码器阶段都输出一个显著性预测图（side output），用于深度监督</li>
</ul>
<h3 id="2-具体实现-1"><a href="#2-具体实现-1" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h3><h4 id="1-初始化解码器模块"><a href="#1-初始化解码器模块" class="headerlink" title="1.初始化解码器模块"></a>1.初始化解码器模块</h4><p>在 U2NET 类的 <strong>init</strong> 方法中，定义了解码器的各个阶段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.stage5d = RSU4F(<span class="number">1024</span>, <span class="number">256</span>, <span class="number">512</span>) <span class="comment"># 1024通道 -&gt; 512通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage4d = RSU4(<span class="number">1024</span>, <span class="number">128</span>, <span class="number">256</span>) <span class="comment"># 1024通道 -&gt; 256通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage3d = RSU5(<span class="number">512</span>, <span class="number">64</span>, <span class="number">128</span>) <span class="comment"># 512通道 -&gt; 128通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage2d = RSU6(<span class="number">256</span>, <span class="number">32</span>, <span class="number">64</span>) <span class="comment"># 256通道 -&gt; 64通道</span></span><br><span class="line"><span class="variable language_">self</span>.stage1d = RSU7(<span class="number">128</span>, <span class="number">16</span>, <span class="number">64</span>) <span class="comment"># 128通道 -&gt; 64通道</span></span><br></pre></td></tr></table></figure>
<p>RSU4F、RSU4、RSU5、RSU6、RSU7 是不同深度的 RSU 模块，输入通道数是编码器对应层通道数的两倍（因为跳跃连接会拼接特征）。</p>
<h4 id="2-前向传播过程-1"><a href="#2-前向传播过程-1" class="headerlink" title="2.前向传播过程"></a>2.前向传播过程</h4><p>在 forward 方法中，解码器的前向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从最深层开始上采样</span></span><br><span class="line">hx6up = _upsample_like(hx6, hx5)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码器路径</span></span><br><span class="line">hx5d = <span class="variable language_">self</span>.stage5d(torch.cat((hx6up, hx5), <span class="number">1</span>)) <span class="comment"># 融合 hx6up 和 hx5</span></span><br><span class="line">hx5dup = _upsample_like(hx5d, hx4)</span><br><span class="line">hx4d = <span class="variable language_">self</span>.stage4d(torch.cat((hx5dup, hx4), <span class="number">1</span>)) <span class="comment"># 融合 hx5dup 和 hx4</span></span><br><span class="line">hx4dup = _upsample_like(hx4d, hx3)</span><br><span class="line">hx3d = <span class="variable language_">self</span>.stage3d(torch.cat((hx4dup, hx3), <span class="number">1</span>)) <span class="comment"># 融合 hx4dup 和 hx3</span></span><br><span class="line">hx3dup = _upsample_like(hx3d, hx2)</span><br><span class="line">hx2d = <span class="variable language_">self</span>.stage2d(torch.cat((hx3dup, hx2), <span class="number">1</span>)) <span class="comment"># 融合 hx3dup 和 hx2</span></span><br><span class="line">hx2dup = _upsample_like(hx2d, hx1)</span><br><span class="line">hx1d = <span class="variable language_">self</span>.stage1d(torch.cat((hx2dup, hx1), <span class="number">1</span>)) <span class="comment"># 融合 hx2dup 和 hx1</span></span><br></pre></td></tr></table></figure>
<p><code>_upsample_like</code>函数用于将特征图上采样到目标尺寸，torch.cat 将上采样后的特征与编码器对应层的特征拼接，形成跳跃连接。</p>
<h4 id="3-多输出与最终融合-1"><a href="#3-多输出与最终融合-1" class="headerlink" title="3.多输出与最终融合"></a>3.多输出与最终融合</h4><p>解码器的每个阶段都输出一个显著性预测图（side output），这些输出通过上采样调整到相同分辨率，然后拼接并融合为最终输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多输出</span></span><br><span class="line">d1 = <span class="variable language_">self</span>.side1(hx1d)</span><br><span class="line">d2 = <span class="variable language_">self</span>.side2(hx2d)</span><br><span class="line">d2 = _upsample_like(d2, d1)</span><br><span class="line">d3 = <span class="variable language_">self</span>.side3(hx3d)</span><br><span class="line">d3 = _upsample_like(d3, d1)</span><br><span class="line">d4 = <span class="variable language_">self</span>.side4(hx4d)</span><br><span class="line">d4 = _upsample_like(d4, d1)</span><br><span class="line">d5 = <span class="variable language_">self</span>.side5(hx5d)</span><br><span class="line">d5 = _upsample_like(d5, d1)</span><br><span class="line">d6 = <span class="variable language_">self</span>.side6(hx6)</span><br><span class="line">d6 = _upsample_like(d6, d1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终融合</span></span><br><span class="line">d0 = <span class="variable language_">self</span>.outconv(torch.cat((d1, d2, d3, d4, d5, d6), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><code>self.side1</code>到<code>self.side6</code>是 1×1 卷积层，用于将每个阶段的特征转换为显著性预测图。<code>self.outconv</code> 是一个 1×1 卷积层，用于将拼接后的多尺度预测图融合为最终输出。</p>
<h4 id="4-作用与优势-2"><a href="#4-作用与优势-2" class="headerlink" title="4.作用与优势"></a>4.作用与优势</h4><ul>
<li>逐步恢复空间分辨率：通过上采样逐步恢复特征图的空间分辨率</li>
<li>特征复用：跳跃连接允许低层特征（如边缘、纹理）与高层特征（如语义信息）直接融合，提升分割精度</li>
<li>多输出设计：每个解码器阶段都输出一个显著性预测图，用于深度监督</li>
</ul>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>U²-Net 是一种基于 U-Net 改进的显著性检测模型，通过独特的 ​<strong>双层嵌套U型结构（RSU模块）​</strong>​ 和 ​<strong>深度监督机制</strong>，在图像分割、抠图、人像素描生成等任务中表现出色。以下是核心内容总结：</p>
<h3 id="1-核心特点​"><a href="#1-核心特点​" class="headerlink" title="1.核心特点​"></a>1.核心特点​</h3><ul>
<li>​<strong>RSU模块</strong>​：每个模块内部嵌套小型U-Net，结合残差连接，实现多尺度特征提取与高效参数利用</li>
<li>​<strong>深度监督</strong>​：训练时对6个中间层输出和最终融合结果同时计算损失，增强梯度流动与多尺度学习能力</li>
<li>​<strong>多尺度融合</strong>​：通过跳跃连接和上采样整合不同层级的特征，兼顾局部细节与全局语义</li>
</ul>
<h3 id="​2-网络架构​"><a href="#​2-网络架构​" class="headerlink" title="​2.网络架构​"></a>​2.网络架构​</h3><ul>
<li>​<strong>编码器（En_1~En_6）​</strong>​：逐级降采样，使用不同深度的RSU模块（如RSU7、RSU4F）提取特征</li>
<li>​<strong>解码器（De_1~De_5）​</strong>​：逐级上采样并融合编码器特征，通过跳跃连接保留细节</li>
<li>​<strong>输出层</strong>​：生成6个中间预测图和1个融合结果，用于深度监督与最终预测</li>
</ul>
<h3 id="​3-关键应用​"><a href="#​3-关键应用​" class="headerlink" title="​3.关键应用​"></a>​3.关键应用​</h3><ul>
<li>​<strong>人像素描生成</strong>​：精准保留面部轮廓、发丝等细节，效果优于部分GAN模型</li>
<li>​<strong>无绿幕抠图</strong>​：复杂背景下分离前景，适用于直播、虚拟背景替换</li>
<li>​<strong>显著性检测</strong>​：识别图像中的突出物体（如人、动物），输出二值掩码</li>
</ul>
<h3 id="​4-优势​"><a href="#​4-优势​" class="headerlink" title="​4.优势​"></a>​4.优势​</h3><ul>
<li>​<strong>高精度</strong>​：RSU模块嵌套设计增强特征复用，显著提升边缘和细节处理能力</li>
<li>​<strong>轻量化</strong>​：通过残差连接和模块化设计平衡性能与参数量</li>
<li>​<strong>灵活性</strong>​：支持多任务扩展（如医学图像分割、视频处理）</li>
</ul>
<h2 id="6-备注"><a href="#6-备注" class="headerlink" title="6.备注"></a>6.备注</h2><p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.09007">https://arxiv.org/pdf/2005.09007</a><br>开源代码地址：<a target="_blank" rel="noopener" href="https://github.com/xuebinqin/U-2-Net">https://github.com/xuebinqin/U-2-Net</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>KeyChan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/" title="U²-Net显著性目标检测">https://keychankc.github.io/2025/06/04/018-u2net-saliency-detection/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://x.com/keychankc">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/" rel="tag"># 目标分割</a>
              <a href="/tags/U2Net/" rel="tag"># U2Net</a>
              <a href="/tags/%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E6%B5%8B/" rel="tag"># 显著性检测</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/05/27/017-unet-cell-segmentation/" rel="prev" title="基于U-Net++的细胞分割代码实现">
                  <i class="fa fa-angle-left"></i> 基于U-Net++的细胞分割代码实现
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/05/000-deep-learning-concepts/" rel="next" title="深度学习的概念们">
                  深度学习的概念们 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KeyChan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">180k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/keychankc" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="/js/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/ribbon.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://comment.mengyajia.com","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":false,"pageview":false,"placeholder":"欢迎评论~","emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq"],"requiredMeta":["nick","mail"],"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/2025/06/04/018-u2net-saliency-detection/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
