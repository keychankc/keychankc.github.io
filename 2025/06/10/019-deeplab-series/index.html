<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo-512x512.png" color="#222">
  <meta name="google-site-verification" content="jZ7dJJlouQrswxytAryX3LanLNrTthfFdMUkDJzRqIU">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.keychan.xyz","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="1.DeepLab概述DeepLab是由谷歌提出的专用于语义分割任务的系列模型，核心目标是为图像中的每个像素分配一个语义类别标签​。它在图像分割领域有很不错效果，曾在PASCAL VOC-2012数据集上达到当时最高水平（mIOU 79.7%） ，并在Cityscapes、PASCAL-Context等数据集上广泛使用。DeepLab的优势在于能够在保持高精度的同时还能结合上下文信息，对物体边界进">
<meta property="og:type" content="article">
<meta property="og:title" content="图像分割DeepLab系列算法思路分析">
<meta property="og:url" content="https://www.keychan.xyz/2025/06/10/019-deeplab-series/index.html">
<meta property="og:site_name" content="KeyChan&#39;s blog">
<meta property="og:description" content="1.DeepLab概述DeepLab是由谷歌提出的专用于语义分割任务的系列模型，核心目标是为图像中的每个像素分配一个语义类别标签​。它在图像分割领域有很不错效果，曾在PASCAL VOC-2012数据集上达到当时最高水平（mIOU 79.7%） ，并在Cityscapes、PASCAL-Context等数据集上广泛使用。DeepLab的优势在于能够在保持高精度的同时还能结合上下文信息，对物体边界进">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609140911.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150154.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150405.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150455.png">
<meta property="og:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150956.png">
<meta property="article:published_time" content="2025-06-10T08:01:12.000Z">
<meta property="article:modified_time" content="2025-09-21T12:04:48.539Z">
<meta property="article:author" content="KeyChan">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="目标分割">
<meta property="article:tag" content="DeepLab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609140911.png">


<link rel="canonical" href="https://www.keychan.xyz/2025/06/10/019-deeplab-series/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.keychan.xyz/2025/06/10/019-deeplab-series/","path":"2025/06/10/019-deeplab-series/","title":"图像分割DeepLab系列算法思路分析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>图像分割DeepLab系列算法思路分析 | KeyChan's blog</title>
  







<link rel="dns-prefetch" href="https://comment.mengyajia.com">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="KeyChan's blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KeyChan's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-随想"><a href="/think/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-DeepLab%E6%A6%82%E8%BF%B0"><span class="nav-text">1.DeepLab概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-U-Net-%E4%B8%8E-DeepLab"><span class="nav-text">1.U-Net 与 DeepLab</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%84%9F%E5%8F%97%E9%87%8E%EF%BC%88Receptive-Field%EF%BC%89"><span class="nav-text">2.感受野（Receptive Field）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%B7%B1%E5%B1%82%E7%BD%91%E7%BB%9C%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-text">3.深层网络的局限性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%EF%BC%88Dilated-Convolution%EF%BC%89"><span class="nav-text">2.空洞卷积（Dilated Convolution）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%A0%87%E5%87%86%E5%8D%B7%E7%A7%AF%EF%BC%88Standard-Convolution%EF%BC%89%E2%80%8B%E2%80%8B"><span class="nav-text">1.标准卷积（Standard Convolution）​​</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%8B1-%E7%89%B9%E7%82%B9%E4%B8%8E%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%E2%80%8B"><span class="nav-text">​1.特点与适用场景​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%B0%8F%E5%8D%B7%E7%A7%AF%E6%A0%B8VS%E5%A4%A7%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="nav-text">2.小卷积核VS大卷积核</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%8B2-%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%EF%BC%88Dilated-Convolution%EF%BC%89%E2%80%8B%E2%80%8B"><span class="nav-text">​2.空洞卷积（Dilated Convolution）​​</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%8B1-%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6%E2%80%8B"><span class="nav-text">​1.核心机制​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%8B2-%E4%BC%98%E5%8A%BF%E2%80%8B"><span class="nav-text">​2.优势​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%80%8B3-%E5%B1%80%E9%99%90%E6%80%A7%E2%80%8B"><span class="nav-text">​3.局限性​</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-SPP%E5%B1%82%EF%BC%9A%E7%A9%BA%E9%97%B4%E9%87%91%E5%AD%97%E5%A1%94%E6%B1%A0%E5%8C%96"><span class="nav-text">3.SPP层：空间金字塔池化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94"><span class="nav-text">1.图像金字塔</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E2%80%8B"><span class="nav-text">1.核心原理​</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%BC%98%E5%8A%BF"><span class="nav-text">2.优势</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E9%97%AE%E9%A2%98%E7%82%B9"><span class="nav-text">3.问题点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-SPP-%E5%B1%82%EF%BC%88Spatial-Pyramid-Pooling%EF%BC%89"><span class="nav-text">2.SPP 层（Spatial Pyramid Pooling）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E8%BE%93%E5%85%A5%E5%9B%BE%E5%83%8F-%E2%86%92-%E5%8D%B7%E7%A7%AF%E5%B1%82%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"><span class="nav-text">1. 输入图像 → 卷积层提取特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-SPP-%E5%B1%82%EF%BC%9A%E7%A9%BA%E9%97%B4%E9%87%91%E5%AD%97%E5%A1%94%E5%88%92%E5%88%86-%E6%B1%A0%E5%8C%96"><span class="nav-text">2. SPP 层：空间金字塔划分 + 池化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E7%89%B9%E5%BE%81%E6%8B%BC%E6%8E%A5%E6%88%90%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E8%A1%A8%E7%A4%BA"><span class="nav-text">3. 特征拼接成固定长度表示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-text">4. 多尺度特征融合的优势</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-ASPP%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%AD%96%E7%95%A5"><span class="nav-text">4.ASPP特征融合策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E7%AD%96%E7%95%A5"><span class="nav-text">1. 传统的多尺度特征提取策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94%EF%BC%88Image-Pyramid-%EF%BC%89"><span class="nav-text">图像金字塔（Image Pyramid ）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8%E2%80%93%E8%A7%A3%E7%A0%81%E5%99%A8%E7%BB%93%E6%9E%84%EF%BC%88Encoder%E2%80%93Decoder-%EF%BC%89"><span class="nav-text">编码器–解码器结构（Encoder–Decoder ）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E5%8A%A0%E6%B7%B1%E7%BD%91%E7%BB%9C%EF%BC%88Atrous-Convolution-%EF%BC%89"><span class="nav-text">空洞卷积加深网络（Atrous Convolution ）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A9%BA%E9%97%B4%E9%87%91%E5%AD%97%E5%A1%94%E6%B1%A0%E5%8C%96%EF%BC%88Spatial-Pyramid-Pooling-%EF%BC%89"><span class="nav-text">空间金字塔池化（Spatial Pyramid Pooling ）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-ASPP%EF%BC%9A%E8%9E%8D%E5%90%88%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E4%B8%8E-SPP-%E7%9A%84%E6%94%B9%E8%BF%9B%E7%BB%93%E6%9E%84"><span class="nav-text">2.ASPP：融合空洞卷积与 SPP 的改进结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E8%BE%93%E5%85%A5%E5%9B%BE%E5%83%8F%EF%BC%88%E5%B7%A6%E4%BE%A7%E7%8C%AB%E5%92%AA%E5%9B%BE%EF%BC%89"><span class="nav-text">1.输入图像（左侧猫咪图）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9C"><span class="nav-text">2. 主干网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-ASPP-%E6%A8%A1%E5%9D%97%EF%BC%88%E5%8F%B3%E4%BE%A7%E9%BB%84%E8%89%B2%E6%A1%86%EF%BC%89"><span class="nav-text">3. ASPP 模块（右侧黄色框）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E8%9E%8D%E5%90%88%E8%BE%93%E5%87%BA%EF%BC%9A"><span class="nav-text">4.融合输出：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-DeepLab-v3-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="nav-text">5.DeepLab v3+网络架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Encoder%E6%A8%A1%E5%9D%97"><span class="nav-text">1.Encoder模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Decoder%E6%A8%A1%E5%9D%97"><span class="nav-text">2.Decoder模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93%E4%B8%8E%E6%89%A9%E5%B1%95%E6%80%A7"><span class="nav-text">3.网络设计总结与扩展性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-DeepLab%E7%AE%97%E6%B3%95%E6%BC%94%E8%BF%9B%E6%80%BB%E7%BB%93"><span class="nav-text">6.DeepLab算法演进总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E2%80%8B%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E2%80%8B"><span class="nav-text">1. ​核心问题定位​</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E2%80%8B%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%EF%BC%9A%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E2%80%8B"><span class="nav-text">2. ​关键技术：空洞卷积​</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E2%80%8B%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E6%9C%BA%E5%88%B6"><span class="nav-text">3. ​多尺度特征融合机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E2%80%8BDeepLab-v3-%E6%9E%B6%E6%9E%84%E5%88%9B%E6%96%B0"><span class="nav-text">4. ​DeepLab v3+架构创新</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E5%A4%87%E6%B3%A8"><span class="nav-text">7.备注</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KeyChan"
      src="/images/key_avatar.png">
  <p class="site-author-name" itemprop="name">KeyChan</p>
  <div class="site-description" itemprop="description">全干工程师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/keychankc" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kckeychan@gmail.com" title="E-Mail → mailto:kckeychan@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/keychankc" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;keychankc" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.keychan.xyz/2025/06/10/019-deeplab-series/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/key_avatar.png">
      <meta itemprop="name" content="KeyChan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeyChan's blog">
      <meta itemprop="description" content="全干工程师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="图像分割DeepLab系列算法思路分析 | KeyChan's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          图像分割DeepLab系列算法思路分析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-06-10 16:01:12" itemprop="dateCreated datePublished" datetime="2025-06-10T16:01:12+08:00">2025-06-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-21 20:04:48" itemprop="dateModified" datetime="2025-09-21T20:04:48+08:00">2025-09-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/06/10/019-deeplab-series/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/06/10/019-deeplab-series/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="1-DeepLab概述"><a href="#1-DeepLab概述" class="headerlink" title="1.DeepLab概述"></a>1.DeepLab概述</h2><p>DeepLab是由谷歌提出的专用于<strong>语义分割</strong>任务的系列模型，核心目标是为图像中的<strong>每个像素分配一个语义类别标签</strong>​。它在图像分割领域有很不错效果，曾在PASCAL VOC-2012数据集上达到当时最高水平（mIOU 79.7%） ，并在Cityscapes、PASCAL-Context等数据集上广泛使用。DeepLab的优势在于能够在保持高精度的同时还能结合上下文信息，对物体边界进行精确定位。</p>
<h3 id="1-U-Net-与-DeepLab"><a href="#1-U-Net-与-DeepLab" class="headerlink" title="1.U-Net 与 DeepLab"></a>1.U-Net 与 DeepLab</h3><p>同样是做分割任务<strong>U-Net</strong>和<strong>DeepLab</strong>有啥区别呢？<br><strong>U-Net</strong>更适合在生物医学图像分割（细胞、器官、病变区域等）、小目标分割、需要精确边界轮廓的应用，其优势边界分割极其精细、在<strong>小样本数据集</strong>​（尤其是医学影像）上表现卓越、架构相对也简单清晰、易于实现和改进。</p>
<span id="more"></span>
<p><strong>DeepLab (V3+)​</strong>适合对自动驾驶场景理解（Cityscapes 等）、可以用在通用场景分割（PASCAL VOC, ADE20K）、街景分割、实时分割等，它对<strong>多尺度物体识别鲁棒性强</strong>、擅长处理<strong>复杂场景和背景</strong>、在利用强大的骨干网络预训练时优势明显、并且在<strong>大规模自然场景数据集</strong>上能有不错的精度（尤其对大型物体）、推理速度（尤其使用轻量骨干时）也有优势。</p>
<p><strong>U-Net</strong>适用的任务有个显著特点是目标较小，我们可以将这些小目标看作是在整张图像中的局部区域，在此类任务中，仅依赖图像的局部特征往往就足以完成分割任务。而<strong>DeepLab</strong> 所面向的多为真实世界中的语义分割任务，在这些任务中，目标往往尺寸较大（如整个人体、一辆汽车），同时，这些目标还可能存在复杂的背景干扰、遮挡关系等，因此，仅凭局部特征已难以获得准确的分割结果，而这其中的实现原理不得不提一个概念<strong>感受野（Receptive Field）</strong>。</p>
<h3 id="2-感受野（Receptive-Field）"><a href="#2-感受野（Receptive-Field）" class="headerlink" title="2.感受野（Receptive Field）"></a>2.感受野（Receptive Field）</h3><p><strong>感受野（Receptive Field，RF）</strong> 描述的是网络中某一层某个特征图上的一个点所“看到”或“感受”到的输入图像上的区域大小。简单来说就是特征图上的一个点，是由输入图像上多大范围的像素计算出来的？这个输入图像上的范围就是感受野。</p>
<p>为什么感受野重要？<br>因为感受野决定了神经元能够捕获信息的<strong>空间范围</strong>，小的感受野关注局部细节（如边缘、纹理），大的感受野能理解更广阔的区域甚至全局结构（如物体、场景）。通过堆叠卷积层（或池化层），网络可以在较深的层获得更大的感受野，从而整合更大范围内的信息，但深度越深计算开销也会越大。</p>
<h3 id="3-深层网络的局限性"><a href="#3-深层网络的局限性" class="headerlink" title="3.深层网络的局限性"></a>3.深层网络的局限性</h3><p>增大感受野，常见的做法是加深网络结构，堆叠更多的卷积层，同时再辅以池化（Pooling）操作。然而这种方式虽然扩大了感受野，却还会带来其它副作用：<strong>特征图的空间分辨率逐渐降低</strong>，导致部分精细信息的丢失，这在语义分割等任务中是一个非常需要关注的问题，因为准确的像素级定位对于分割质量至关重要。</p>
<p>以 U-Net 为例，其采用<strong>下采样—上采样</strong>结构，试图在恢复高分辨率的同时保留上下文语义信息，但这种方法在处理大目标、复杂结构时仍有不足，尤其是在更深层次的特征图中，细节信息容易丢失。为了解决这个问题，DeepLab 系列算法引入了一个关键技术：空洞卷积（Dilated Convolution）。</p>
<h2 id="2-空洞卷积（Dilated-Convolution）"><a href="#2-空洞卷积（Dilated-Convolution）" class="headerlink" title="2.空洞卷积（Dilated Convolution）"></a>2.空洞卷积（Dilated Convolution）</h2><p>空洞卷积（Dilated Convolution），也称为<strong>膨胀卷积</strong>或<strong>扩张卷积</strong>，是卷积神经网络中一种在不增加参数量或计算量的前提下，显著扩大感受野（Receptive Field）的关键技术，它通过在标准卷积核的权重之间插入“空洞”（零值）来实现的。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609140911.png"></p>
<h3 id="1-标准卷积（Standard-Convolution）​​"><a href="#1-标准卷积（Standard-Convolution）​​" class="headerlink" title="1.标准卷积（Standard Convolution）​​"></a>1.标准卷积（Standard Convolution）​​</h3><p>标准卷积是最基础的卷积操作，其核心特点是卷积核在输入特征图上<strong>连续滑动</strong>进行计算。具体而言，每个输出像素是通过卷积核与输入特征图中对应的<strong>连续局部区域</strong>​（例如3×3的相邻像素块）进行逐元素相乘并求和得到的。</p>
<h4 id="​1-特点与适用场景​"><a href="#​1-特点与适用场景​" class="headerlink" title="​1.特点与适用场景​"></a>​1.特点与适用场景​</h4><ul>
<li>​<strong>连续采样</strong>​：卷积核的权重作用于相邻像素，能够有效捕捉局部细节特征</li>
<li>​<strong>有限感受野</strong>​：每个特征点仅能感知输入图像中的小范围区域（如3×3的局部窗口）</li>
<li>​<strong>适用场景</strong>​：在需要精细局部特征的任务中有不错的表现，例如<strong>小目标检测</strong>​（如医学图像中的细胞、显微结构）或<strong>局部特征提取</strong></li>
<li>​<strong>局限性</strong>​：由于感受野较小，在处理<strong>大尺度目标</strong>或<strong>复杂场景</strong>时，难以捕获足够的上下文信息，这会限制模型的全局建模能力</li>
</ul>
<h4 id="2-小卷积核VS大卷积核"><a href="#2-小卷积核VS大卷积核" class="headerlink" title="2.小卷积核VS大卷积核"></a>2.小卷积核VS大卷积核</h4><p>既然3×3的感受野偏小，为什么我们倾向于堆叠多个小卷积核而非使用大卷积核？</p>
<p>主要原因有：<br>​1.<strong>参数效率更高​</strong>：三层3×3卷积(27C²参数)相比单个7×7卷积(49C²参数)，在实现同样7×7感受野的情况下，参数量减少45%，可以显著降低模型复杂度，有效控制过拟合风险。</p>
<p>​2.<strong>表达能力更强</strong>：每个小卷积层后都包含BN和ReLU等非线性操作，三层3×3卷积提供三次非线性变换，而单个7×7卷积仅有一次，这样可以使模型具备更强的特征抽象能力。<br>	​<br>3.<strong>训练更稳定</strong>：​小卷积核更容易初始化，梯度传播更稳定，收敛过程更平滑，当然这种设计也更灵活，便于集成到残差连接、注意力机制等各种模块中。</p>
<p>​4.<strong>计算更高效</strong>​：虽然总计算量相近，但小卷积核更利于并行计算，更适合现代GPU架构，在实际部署中往往具有更优的推理速度。</p>
<p>这种设计理念已在VGGNet、ResNet等经典网络中得到验证，体现了”分解大问题为多个小问题”的核心思想。虽然在早期网络层或特殊任务中，大卷积核仍有一定优势，但小卷积核堆叠已成为大多数场景的更优选择。</p>
<h3 id="​2-空洞卷积（Dilated-Convolution）​​"><a href="#​2-空洞卷积（Dilated-Convolution）​​" class="headerlink" title="​2.空洞卷积（Dilated Convolution）​​"></a>​2.空洞卷积（Dilated Convolution）​​</h3><p>空洞卷积是对标准卷积的改进，通过引入<strong>膨胀率（dilation rate）​</strong>参数，在卷积核元素之间插入固定间隔的空洞，使得采样位置变为<strong>非连续</strong>。这一设计能够在<strong>不增加参数量</strong>的前提下，显著扩大感受野。</p>
<h4 id="​1-核心机制​"><a href="#​1-核心机制​" class="headerlink" title="​1.核心机制​"></a>​1.核心机制​</h4><ul>
<li>​<strong>感受野扩展</strong>​：例如，一个3×3的卷积核在设置<code>dilation rate=2</code>时，其等效感受野可扩大至5×5（相当于在核元素之间插入1个空洞）。若进一步增大<code>dilation rate=4</code>，感受野可扩展至9×9</li>
<li>​<strong>参数效率</strong>​：空洞卷积仍使用原始卷积核的权重（如3×3的9个参数），计算复杂度与标准卷积相同，仅通过调整采样间隔来扩大感受野</li>
<li>​<strong>稀疏采样</strong>​：随着<code>dilation rate</code>增大，实际参与计算的特征点数量减少，但覆盖的物理范围可以更广</li>
</ul>
<h4 id="​2-优势​"><a href="#​2-优势​" class="headerlink" title="​2.优势​"></a>​2.优势​</h4><ol>
<li>​<strong>大感受野与低计算开销</strong>​：无需通过堆叠更多卷积层或下采样操作（如池化）来扩大感受野，从而避免了信息损失和分辨率下降的问题。这一特性使其特别适合以下场景：<ul>
<li>​<strong>大尺度目标识别</strong>​（如建筑物、自然场景中的大型物体）</li>
<li>​<strong>复杂结构分割</strong>​（如场景解析、医学图像中的器官分割）</li>
<li>​<strong>存在遮挡时的特征判别</strong>​</li>
</ul>
</li>
<li>​<strong>分辨率保持</strong>​：空洞卷积能够在不降低特征图分辨率的情况下捕获全局上下文信息，这对密集预测任务（如语义分割）至关重要</li>
<li>​<strong>实现简单</strong>​：仅需在标准卷积中设置<code>dilation_rate</code>参数即可（例如PyTorch的<code>nn.Conv2d(dilation=2)</code>），因此被广泛应用于图像分类、目标检测、人体姿态估计等任务。</li>
</ol>
<h4 id="​3-局限性​"><a href="#​3-局限性​" class="headerlink" title="​3.局限性​"></a>​3.局限性​</h4><ul>
<li>​<strong>特征稀疏性</strong>​：过大的<code>dilation rate</code>会导致卷积核采样点过于稀疏，可能无法充分捕捉局部细节信息</li>
<li>​<strong>语义连续性假设</strong>​：空洞卷积依赖于输入特征的局部相关性，若目标区域的细节密集（如高频纹理），稀疏采样可能导致关键信息丢失</li>
</ul>
<h2 id="3-SPP层：空间金字塔池化"><a href="#3-SPP层：空间金字塔池化" class="headerlink" title="3.SPP层：空间金字塔池化"></a>3.SPP层：空间金字塔池化</h2><p>在 DeepLab 的 Home 版本中，模型引入了一个关键结构——<strong>SPP（Spatial Pyramid Pooling）层</strong>，用来增强模型对不同输入尺寸和多尺度信息的处理能力。要理解它的设计初衷，我们先从一个经典概念说起：<strong>图像金字塔（Image Pyramid）</strong>。</p>
<h3 id="1-图像金字塔"><a href="#1-图像金字塔" class="headerlink" title="1.图像金字塔"></a>1.图像金字塔</h3><p>图像金字塔是一种模拟人类多尺度视觉观察的方法。举个例子，当你看一幅画时，凑近能看到画笔细节，站远些能看到整体构图。图像金字塔正是通过生成同一图像的多个不同分辨率版本（从清晰的原图到逐渐模糊的小图），构建一个类似金字塔的多层结构，从而帮助算法同时理解细节与全局。</p>
<h4 id="1-核心原理​"><a href="#1-核心原理​" class="headerlink" title="1.核心原理​"></a>1.核心原理​</h4><p>从原始图像开始，每进行一步，都做<strong>高斯模糊</strong>，轻微模糊图像（抑制噪声和细节），再<strong>降采样</strong>​：缩小图像尺寸（如长宽各减半），重复这一过程，得到一系列越来越小的图像（原始图：1000×1000 → 第1层：500×500 → 第2层：250×250 → 第3层：125×125…）。在这个过程中还需要记录相邻层之间的差异信息（高分辨率图像减去低分辨率图像上采样后的结果），用于后续重建图像细节。</p>
<h4 id="2-优势"><a href="#2-优势" class="headerlink" title="2.优势"></a>2.优势</h4><p>可以解决目标尺度变化问题，对于​<strong>小目标</strong>​（如蚂蚁）在高分辨率层（底层）清晰可见，对于​<strong>大目标</strong>​（如建筑）在低分辨率层（高层）更易识别整体结构。</p>
<h4 id="3-问题点"><a href="#3-问题点" class="headerlink" title="3.问题点"></a>3.问题点</h4><p>然而，在实际中，我们往往受限于网络结构，尤其是<strong>全连接层</strong>。这类层通常要求输入尺寸固定，否则会导致参数无法匹配。而卷积层虽然本身支持任意输入大小，但在需要将特征图汇聚成固定维度表示（如用于分类）时，仍然会受到限制。</p>
<h3 id="2-SPP-层（Spatial-Pyramid-Pooling）"><a href="#2-SPP-层（Spatial-Pyramid-Pooling）" class="headerlink" title="2.SPP 层（Spatial Pyramid Pooling）"></a>2.SPP 层（Spatial Pyramid Pooling）</h3><p>SPP 层的设计目标有两个：让模型支持<strong>任意尺寸的输入图像</strong>和强化<strong>多尺度特征的表达能力</strong>。<br>其核心思想是：<strong>将特征图划分为多个尺度的网格区域，分别进行池化（如最大池化），然后将所有池化结果拼接起来，形成一个固定维度的向量。</strong></p>
<p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150154.png"></p>
<p>如上图是SPP 层嵌入在 CNN 模型中的位置和处理流程，核心包含以下几个步骤：</p>
<h4 id="1-输入图像-→-卷积层提取特征"><a href="#1-输入图像-→-卷积层提取特征" class="headerlink" title="1. 输入图像 → 卷积层提取特征"></a>1. 输入图像 → 卷积层提取特征</h4><p>图的底部是输入图像，经过一系列卷积层（如图中的 conv₅）之后，得到一组大小为任意尺寸的特征图，这组特征图的尺寸可能因输入图像的大小不同而不同。而<strong>SPP 层的设计正是为了适应这种“尺寸不固定”的特征图输入</strong>。</p>
<h4 id="2-SPP-层：空间金字塔划分-池化"><a href="#2-SPP-层：空间金字塔划分-池化" class="headerlink" title="2. SPP 层：空间金字塔划分 + 池化"></a>2. SPP 层：空间金字塔划分 + 池化</h4><p>在“spatial pyramid pooling layer”部分，特征图被按照不同粒度划分为多个子区域，分别进行池化（通常是最大池化 Max Pooling），每层划分如下：</p>
<ul>
<li><strong>第一层（蓝色）</strong>：将特征图划分为 <strong>4×4 网格</strong> → 16 个子区域，每个区域进行池化，得到 <code>16 × 256-d</code> 的特征向量</li>
<li><strong>第二层（绿色）</strong>：划分为 <strong>2×2 网格</strong> → 4 个区域，输出 <code>4 × 256-d</code></li>
<li><strong>第三层（灰色）</strong>：全局池化（即 1×1） → 输出 <code>1 × 256-d</code><br>注意：每个子区域输出的都是 256-d（即 256 维）特征向量，因为池化操作只作用在空间维度，不改变通道数。</li>
</ul>
<h4 id="3-特征拼接成固定长度表示"><a href="#3-特征拼接成固定长度表示" class="headerlink" title="3. 特征拼接成固定长度表示"></a>3. 特征拼接成固定长度表示</h4><p>将三层输出的所有特征拼接在一起，得到一个长度为：<br>$(16 + 4 + 1) \times 256 &#x3D; 21 \times 256$<br>这个向量作为<strong>固定长度的特征表示（fixed-length representation）</strong>，传递给后续的全连接层（如 fc₆, fc₇）进行分类等任务。这样就可以不依赖于输入图像的原始尺寸，因此具备良好的通用性</p>
<h4 id="4-多尺度特征融合的优势"><a href="#4-多尺度特征融合的优势" class="headerlink" title="4. 多尺度特征融合的优势"></a>4. 多尺度特征融合的优势</h4><p>通过以上操作，SPP 层不仅实现了输入尺寸无关的特征表达，还融合了不同尺度的上下文信息：</p>
<ul>
<li>局部细节（4×4 子区域）</li>
<li>中等尺度结构（2×2）</li>
<li>全局语义（1×1 全局池化）<br>这种方式不仅显著提升了模型在复杂场景下的表现能力，而且还被后续许多模型广泛借鉴和作为改进的基础结构。</li>
</ul>
<h2 id="4-ASPP特征融合策略"><a href="#4-ASPP特征融合策略" class="headerlink" title="4.ASPP特征融合策略"></a>4.ASPP特征融合策略</h2><p>在 DeepLab 系列的发展过程中，第二代模型（DeepLab v2）又引入了一项重要改进：<strong>ASPP（Atrous Spatial Pyramid Pooling）结构</strong>。</p>
<h3 id="1-传统的多尺度特征提取策略"><a href="#1-传统的多尺度特征提取策略" class="headerlink" title="1. 传统的多尺度特征提取策略"></a>1. 传统的多尺度特征提取策略</h3><p>为了更好地理解 ASPP 的动机和结构，我们先回顾论文中所展示的一张对比图，该图总结了几种不同的多尺度特征提取方法：<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150405.png"></p>
<h4 id="图像金字塔（Image-Pyramid-）"><a href="#图像金字塔（Image-Pyramid-）" class="headerlink" title="图像金字塔（Image Pyramid ）"></a>图像金字塔（Image Pyramid ）</h4><p>如上面讲的，图像金字塔是将原始图像缩放成多个尺度（比如原图、小一半、再小一半），然后分别送入同一个模型进行特征提取。其核心思想是用多种分辨率的输入图像，让模型在多个尺度上提取特征，最后再将这些特征合并。</p>
<ul>
<li><strong>优点</strong>：显式地建模不同物体尺度</li>
<li><strong>缺点</strong>：计算成本高，因为每个尺度都要跑一遍模型</li>
</ul>
<h4 id="编码器–解码器结构（Encoder–Decoder-）"><a href="#编码器–解码器结构（Encoder–Decoder-）" class="headerlink" title="编码器–解码器结构（Encoder–Decoder ）"></a>编码器–解码器结构（Encoder–Decoder ）</h4><p>编码器–解码器结构是先下采样图像提取深层特征，再通过上采样逐步恢复空间信息。其核心思想是在编码阶段提取抽象语义信息，再在解码阶段恢复空间细节。</p>
<ul>
<li><strong>优点</strong>：结构灵活，适用于需要空间分辨率输出的任务，如语义分割</li>
<li><strong>缺点</strong>：可能导致细节丢失，需注意特征融合方式</li>
</ul>
<h4 id="空洞卷积加深网络（Atrous-Convolution-）"><a href="#空洞卷积加深网络（Atrous-Convolution-）" class="headerlink" title="空洞卷积加深网络（Atrous Convolution ）"></a>空洞卷积加深网络（Atrous Convolution ）</h4><p> 空洞卷积是在不增加参数和计算量的前提下，通过引入“空洞”（即膨胀）卷积扩大感受野。其核心思想是通过设置不同的膨胀率，让卷积核在多个尺度上捕捉上下文信息。</p>
<ul>
<li><strong>优点</strong>：提升感受野、保持特征图大小，这是 DeepLab 系列的核心技术之一</li>
<li><strong>缺点</strong>：空洞卷积在小目标上效果可能不如标准卷积</li>
</ul>
<h4 id="空间金字塔池化（Spatial-Pyramid-Pooling-）"><a href="#空间金字塔池化（Spatial-Pyramid-Pooling-）" class="headerlink" title="空间金字塔池化（Spatial Pyramid Pooling ）"></a>空间金字塔池化（Spatial Pyramid Pooling ）</h4><p>空间金字塔池化是对同一张特征图，采用不同尺度的池化窗口提取信息（如 1×1、2×2、4×4），然后拼接结果。其核心思想是通过多尺度的池化操作融合局部和全局特征，获得多尺度上下文。</p>
<ul>
<li><strong>优点</strong>：输入尺寸灵活，能够高效建模多尺度语义信息</li>
<li><strong>缺点</strong>：不像空洞卷积那样直接在卷积层扩展感受野</li>
</ul>
<h3 id="2-ASPP：融合空洞卷积与-SPP-的改进结构"><a href="#2-ASPP：融合空洞卷积与-SPP-的改进结构" class="headerlink" title="2.ASPP：融合空洞卷积与 SPP 的改进结构"></a>2.ASPP：融合空洞卷积与 SPP 的改进结构</h3><p>基于上述方法，DeepLab v2 提出了一种更高效的方案——<strong>ASPP（Atrous Spatial Pyramid Pooling）</strong>。该结构结合了空洞卷积和 SPP 的思想，其核心目标是：<strong>在保持计算效率的同时，进一步提升模型的多尺度感知能力</strong>。<br><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150455.png"></p>
<h4 id="1-输入图像（左侧猫咪图）"><a href="#1-输入图像（左侧猫咪图）" class="headerlink" title="1.输入图像（左侧猫咪图）"></a>1.输入图像（左侧猫咪图）</h4><p>首先进入一系列卷积和池化操作，逐步提取特征并降低分辨率。图中标注了输出特征图的空间步幅（output stride），先后为 4、8、16，表示图像被缩小的倍数。</p>
<h4 id="2-主干网络"><a href="#2-主干网络" class="headerlink" title="2. 主干网络"></a>2. 主干网络</h4><p>由多个 block 组成（如 Block1、Block2 等），每个 block 提取越来越抽象的语义特征。在 Block3 之后，使用了一个 <strong>空洞率为 2 的卷积</strong>，扩大感受野，同时保持分辨率不变。</p>
<h4 id="3-ASPP-模块（右侧黄色框）"><a href="#3-ASPP-模块（右侧黄色框）" class="headerlink" title="3. ASPP 模块（右侧黄色框）"></a>3. ASPP 模块（右侧黄色框）</h4><p>这是图中的重点部分，也就是所谓的<strong>空洞空间金字塔池化结构</strong>，它包含多个分支，每个分支采用不同的卷积感受野。<br>ASPP 用多个不同扩张率（dilation rate）的卷积并行处理同一张特征图，从而获取不同尺度的上下文信息：<br>a. Atrous Convolution 分支：</p>
<ul>
<li><strong>1x1 卷积</strong>：相当于不考虑邻域，仅用于压缩通道或增加非线性</li>
<li><strong>3x3 空洞卷积 rate&#x3D;6</strong>：感受野较小，适合提取中等区域信息</li>
<li><strong>3x3 空洞卷积 rate&#x3D;12</strong>：感受野更大，可以看到更远的上下文</li>
<li><strong>3x3 空洞卷积 rate&#x3D;18</strong>：感受野最大，有利于理解全局语义<br>b. Image Pooling 分支：</li>
<li>对整张特征图做<strong>全局平均池化</strong>，提取全局语义，再通过上采样还原回特征图大小，这样主要是为了引入<strong>图像整体场景的信息</strong></li>
</ul>
<h4 id="4-融合输出："><a href="#4-融合输出：" class="headerlink" title="4.融合输出："></a>4.融合输出：</h4><p>将上述五个分支的输出进行<strong>拼接</strong>（Concat），然后接一个 <strong>1x1 卷积</strong> 用于融合特征。得到的是融合了多个尺度信息的统一特征图，其空间尺寸不变（仍是 output stride 16 对应的大小）。</p>
<p>这种结构的优势在于：</p>
<ul>
<li>可同时具备局部精细信息与全局上下文信息</li>
<li>利用空洞卷积实现更大感受野，避免了图像金字塔带来的重复计算</li>
<li>与 SPP 相比，ASPP 通过引入可调膨胀率的卷积操作，进一步增强了特征的多样性与表达力</li>
</ul>
<p>虽然 DeepLab 系列在不断演进，但每一代之间的改进幅度并不总是显著。例如，在 DeepLab v3 之后，作者并未直接发布 “v4”，而是采用了“DeepLab v3+”这样的命名。这种命名方式反映了在一定程度上，后续改进更侧重于细节优化，而非架构。<br>因此，对于DeepLab 系列模型，理解 <strong>空洞卷积</strong> 与 <strong>ASPP&#x2F;SPP 结构</strong> 的本质与用法是关键。这些组件在语义分割及其他下游任务中具有广泛的适用性和借鉴价值。</p>
<h2 id="5-DeepLab-v3-网络架构"><a href="#5-DeepLab-v3-网络架构" class="headerlink" title="5.DeepLab v3+网络架构"></a>5.DeepLab v3+网络架构</h2><p><img src="https://mark-down-dc.oss-cn-hangzhou.aliyuncs.com/key_blog/image_20250609150956.png"><br>通过如上网络结构图即可很好地理解其设计核心，DeepLab v3+ 的整体结构可以概括为两个主要部分， ​编码器（蓝色虚线框）​，负责特征提取和压缩，解码器（红色虚线框）​​，负责重建细节并输出结果。</p>
<h3 id="1-Encoder模块"><a href="#1-Encoder模块" class="headerlink" title="1.Encoder模块"></a>1.Encoder模块</h3><p>在输入图像进入主干网络（Backbone）进行初步特征提取之后，DeepLab v3+ 在编码器部分引入了 ASPP（Atrous Spatial Pyramid Pooling）模块，用于捕捉不同尺度的上下文信息。<br>ASPP 的设计核心包括以下几条并行路径：</p>
<ol>
<li><strong>1×1 卷积分支</strong>：获取局部精细特征</li>
<li><strong>三个不同空洞率（rate）的空洞卷积分支</strong>：空洞卷积可以在不增加参数量的前提下扩大感受野，捕捉更丰富的上下文信息，不同的空洞率表示不同的采样间距，从而实现多尺度感知</li>
<li><strong>全局平均池化分支</strong>：对整张特征图做平均池化，再通过 1×1 卷积和上采样恢复到原尺寸，作为全局语义信息的补充。<br>这五个分支的输出特征图在尺寸一致的前提下拼接在一起，随后通过 1×1 卷积进一步融合，形成更具语义表达力的特征表示。</li>
</ol>
<blockquote>
<p>注：不同空洞率下的空洞卷积通过适当的 padding 来保证输出特征图尺寸一致。</p>
</blockquote>
<h3 id="2-Decoder模块"><a href="#2-Decoder模块" class="headerlink" title="2.Decoder模块"></a>2.Decoder模块</h3><p>为了提升分割结果的边缘细节与空间定位精度，DeepLab v3+ 引入了 Decoder 结构，将编码器提取的高级语义特征与浅层的低级特征进行融合。</p>
<p>具体流程如下：</p>
<ol>
<li><strong>浅层特征提取</strong>：从主干网络中提取一个较浅层次（如第一个 Block）的输出，作为低级特征（Low-Level Features），用于补充边缘与细节信息</li>
<li><strong>上采样高层特征</strong>：将 ASPP 输出的高层语义特征上采样，使其尺寸与低层特征一致</li>
<li><strong>通道对齐与拼接</strong>：对低层特征先通过 1×1 卷积降维，减少通道数，以匹配高层特征。将两者在通道维度上拼接</li>
<li><strong>融合与预测</strong>：拼接后的特征再经过若干个 3×3 卷积进行融合，最后上采样至输入图像的大小，输出逐像素的语义预测结果</li>
</ol>
<h3 id="3-网络设计总结与扩展性"><a href="#3-网络设计总结与扩展性" class="headerlink" title="3.网络设计总结与扩展性"></a>3.网络设计总结与扩展性</h3><p>DeepLab v3+ 的设计虽然不复杂，但融合了多种关键思想：</p>
<ul>
<li><strong>编码器-解码器结构（Encoder-Decoder）</strong>：提取高语义与低空间分辨率的特征后，通过解码器恢复空间信息</li>
<li><strong>ASPP 模块</strong>：利用空洞卷积实现多尺度感受野的构建</li>
<li><strong>特征融合机制</strong>：结合浅层的局部细节与深层的全局语义，提高分割精度</li>
</ul>
<h2 id="6-DeepLab算法演进总结"><a href="#6-DeepLab算法演进总结" class="headerlink" title="6.DeepLab算法演进总结"></a>6.DeepLab算法演进总结</h2><h3 id="1-​核心问题定位​"><a href="#1-​核心问题定位​" class="headerlink" title="1. ​核心问题定位​"></a>1. ​核心问题定位​</h3><p>针对语义分割任务中<strong>大尺度目标识别</strong>与<strong>复杂场景理解</strong>的挑战，传统方案（如U-Net）依赖局部特征和逐步下采样，易丢失全局信息。DeepLab提出<strong>空洞卷积（Dilated Convolution）​</strong>​。</p>
<h3 id="2-​关键技术：空洞卷积​"><a href="#2-​关键技术：空洞卷积​" class="headerlink" title="2. ​关键技术：空洞卷积​"></a>2. ​关键技术：空洞卷积​</h3><p> ​在标准卷积核中插入”空洞”（零值间距），通过调整<strong>膨胀率（dilation rate）​</strong>​ 控制采样间隔。<br>​<strong>优势</strong>​：  </p>
<ul>
<li>同等参数量下<strong>显著扩大感受野</strong>​（如3×3卷积在dilation&#x3D;6时等效13×13感受野）  </li>
<li><strong>保持特征图分辨率</strong>，避免池化导致的信息损失  </li>
<li>支持<strong>多尺度语义捕获</strong>​（不同膨胀率对应不同感受野）</li>
</ul>
<h3 id="3-​多尺度特征融合机制"><a href="#3-​多尺度特征融合机制" class="headerlink" title="3. ​多尺度特征融合机制"></a>3. ​多尺度特征融合机制</h3><p>ASPP结构（Atrous Spatial Pyramid Pooling）​：并行多分支结构，1×1卷积 + 多个不同膨胀率的3×3空洞卷积（如rate&#x3D;6,12,18） + 全局平均池化。拼接各分支输出，通过1×1卷积融合多尺度特征<br><strong>效果</strong>​：  </p>
<ul>
<li>同时捕获局部细节（小膨胀率）与全局上下文（大膨胀率）  </li>
<li>提升模型对尺度变化和遮挡的鲁棒性</li>
</ul>
<h3 id="4-​DeepLab-v3-架构创新"><a href="#4-​DeepLab-v3-架构创新" class="headerlink" title="4. ​DeepLab v3+架构创新"></a>4. ​DeepLab v3+架构创新</h3><p><strong>编码器-解码器设计</strong>​：</p>
<ul>
<li>​<strong>编码器</strong>​：骨干网络（如ResNet）+ ASPP模块 → 提取<strong>高语义特征</strong>​</li>
<li>​<strong>解码器</strong>​：<ol>
<li>对深层特征上采样</li>
<li>与浅层高分辨率特征拼接（经1×1卷积对齐通道）</li>
<li>3×3卷积融合 → 恢复<strong>细节边界</strong>​<br>​<strong>技术融合</strong>​：<br>  空洞卷积（扩大感受野） + ASPP（多尺度融合） + 跳连（补充细节）</li>
</ol>
</li>
</ul>
<h2 id="7-备注"><a href="#7-备注" class="headerlink" title="7.备注"></a>7.备注</h2><ol>
<li>DeepLab v1 论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.7062v4.pdf">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</a>》</li>
<li>DeepLab v2 论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.00915">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a>》</li>
<li>DeepLab v3 论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.05587v3.pdf">Rethinking Atrous Convolution for Semantic Image Segmentation</a></li>
<li>DeepLab v3+ 论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.02611v3.pdf">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a>》</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>KeyChan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://www.keychan.xyz/2025/06/10/019-deeplab-series/" title="图像分割DeepLab系列算法思路分析">https://www.keychan.xyz/2025/06/10/019-deeplab-series/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://x.com/keychankc">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E5%88%86%E5%89%B2/" rel="tag"># 目标分割</a>
              <a href="/tags/DeepLab/" rel="tag"># DeepLab</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/06/05/000-deep-learning-concepts/" rel="prev" title="深度学习的概念们">
                  <i class="fa fa-angle-left"></i> 深度学习的概念们
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/18/020-deepdab3-with-pascal-voc2012/" rel="next" title="​DeepLabv3+语义分割代码解析">
                  ​DeepLabv3+语义分割代码解析 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">KeyChan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">217k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/keychankc" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="/js/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/ribbon.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://comment.mengyajia.com","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":false,"pageview":false,"placeholder":"欢迎评论~","emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq"],"requiredMeta":["nick","mail"],"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/2025/06/10/019-deeplab-series/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
